{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5ce193-5599-40ac-a5f9-fd127322d1a5",
   "metadata": {},
   "source": [
    "# NLP - HW5\n",
    "### Miguel Bonilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b0e07f-2cae-4baf-934e-199e6207b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk, re,pprint\n",
    "from pattern.en import parsetree\n",
    "import pattern.en\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4bc99-e21d-47d7-8133-9aba61f9fed9",
   "metadata": {},
   "source": [
    "- [1. Compile a List of Reviews](#1.-Compile-a-List-of-Reviews)\n",
    "- [2. Extract Noun Phrase Chunks](#2.-Extract-Noun-Phrase-Chunks)\n",
    "    - [a. Grab the review text from each link](#a.-Grab-the-review-text-from-each-link)\n",
    "    - [b. NP Chunking](#b.-NP-Chunking)\n",
    "    - [c. Add to Lexicon and Repeat NP Chunking](#c.-Add-to-Lexicon-and-Repeat-NP-Chunking)\n",
    "- [3. Output All the Chunks](#3.-Output-All-the-Chunks)\n",
    "    - [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcae084-387a-4494-ae37-8b973bb494f5",
   "metadata": {},
   "source": [
    "1. Compile a list of static links (permalinks) to individual user movie reviews from one particular  website. This will be your working dataset for this assignment, as well as for assignments 7 and 8.   \n",
    "a. It does not matter if you use a crawler or if you manually collect the links, but you will \n",
    "need at least 100 movie review links. Note that, as of this writing, the robots.txt file of \n",
    "IMDB.com allows the crawling of user reviews.  \n",
    "b. Each link should be to a web page that has only one user review of only one movie, e.g., \n",
    "the user review permalinks on the IMDB site.  \n",
    "c. Choose reviews of movies that are all in the same genre, e.g., sci-fi, mystery, romance, \n",
    "superhero, etc.    \n",
    "d. Make sure your collection includes reviews of several movies in your chosen genre and \n",
    "that it includes a mix of negative and positive reviews.  \n",
    "2. Extract noun phrase (NP) chunks from your reviews using the following procedure:  \n",
    "a. In Python, use BeautifulSoup to grab the main review text from each link.  \n",
    "b. Next run each review text through a tokenizer, and then try to NP-chunk it with a \n",
    "shallow parser.  \n",
    "c. You probably will have too many unknown words, owing to proper names of characters, \n",
    "actors, and so on that are not in your working dictionary. Make sure the main names \n",
    "that are relevant to the movies in your collection of reviews are added to the working \n",
    "lexicon, and then run the NP chunker again.  \n",
    "3. Output all the chunks in a single list for each review, and submit that output for this assignment.   \n",
    "Also submit a brief written summary of what you did (describe your selection of genre, your \n",
    "source of reviews, how many you collected, and by what means)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7641bf79-6838-4745-b831-bfe063b0a62c",
   "metadata": {},
   "source": [
    "### 1. Compile a List of Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527e5cd-88a1-466b-bd2f-9ed25d45db47",
   "metadata": {},
   "source": [
    "Using BeautifulSoup to crawl through the featured 25 reviews for each of the films, for a total of 100 reviews. The four movies are: \"The Thing (1982)\", \"A Quiet Place\", \"Alien Covenant\", and \"The Shining\". Each of these has a mix of positive and negative reviews, though the distribution of these depends on the 'quality' of the film. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f273cf07-89ee-4319-bfa5-1820eda61b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### assign headers since IMDB rejects the requests without it\n",
    "headers = {'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.50'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86e5c8a-0039-49fe-83d4-7d979c52e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Thing (1982)\n",
    "url1 = 'https://www.imdb.com/title/tt0084787/reviews/?ref_=tt_ov_rt'\n",
    "## A Quiet Place\n",
    "url2 = 'https://www.imdb.com/title/tt6644200/reviews/?ref_=adv_li_tt'\n",
    "## Alien Covenant\n",
    "url3 = 'https://www.imdb.com/title/tt2316204/reviews/?ref_=adv_li_tt'\n",
    "## The Shining\n",
    "url4 = 'https://www.imdb.com/title/tt0081505/reviews/?ref_=fn_al_tt_1'\n",
    "\n",
    "#movie list\n",
    "movies = ['The_Thing','A_Quiet_Place','Alien_Covenant','The_Shining']\n",
    "#url list\n",
    "urls = [url1, url2, url3, url4]\n",
    "### movies are all of the horror genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6745c94b-5790-4d68-a04e-d5fc3ce28450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(movielist,urllist):\n",
    "    refs = []\n",
    "    title = []\n",
    "    index = []\n",
    "    for i in range(len(movielist)):\n",
    "        movie = get(urllist[i],headers=headers)\n",
    "        movie_soup = BeautifulSoup(movie.content,'html.parser')\n",
    "        container = movie_soup.find_all(class_='title')\n",
    "        for j in range(len(container)):\n",
    "            refs.append('https://www.imdb.com'+ container[j]['href'])\n",
    "            title.append(movielist[i])\n",
    "            index.append('{}_{}'.format(movielist[i],j))\n",
    "    return(pd.DataFrame({'movie':title,\n",
    "                         'url':refs,\n",
    "                         'review':index\n",
    "                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525b8625-d059-47f7-a117-5c01b6e7e707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>url</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>https://www.imdb.com/review/rw0197822/?ref_=tt...</td>\n",
       "      <td>The_Thing_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>https://www.imdb.com/review/rw3346521/?ref_=tt...</td>\n",
       "      <td>The_Thing_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>https://www.imdb.com/review/rw1833451/?ref_=tt...</td>\n",
       "      <td>The_Thing_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>https://www.imdb.com/review/rw6379386/?ref_=tt...</td>\n",
       "      <td>The_Thing_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>https://www.imdb.com/review/rw0197779/?ref_=tt...</td>\n",
       "      <td>The_Thing_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>https://www.imdb.com/review/rw0179869/?ref_=tt...</td>\n",
       "      <td>The_Shining_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>https://www.imdb.com/review/rw7669173/?ref_=tt...</td>\n",
       "      <td>The_Shining_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>https://www.imdb.com/review/rw8801397/?ref_=tt...</td>\n",
       "      <td>The_Shining_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>https://www.imdb.com/review/rw0180168/?ref_=tt...</td>\n",
       "      <td>The_Shining_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>https://www.imdb.com/review/rw2504629/?ref_=tt...</td>\n",
       "      <td>The_Shining_24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie                                                url  \\\n",
       "0     The_Thing  https://www.imdb.com/review/rw0197822/?ref_=tt...   \n",
       "1     The_Thing  https://www.imdb.com/review/rw3346521/?ref_=tt...   \n",
       "2     The_Thing  https://www.imdb.com/review/rw1833451/?ref_=tt...   \n",
       "3     The_Thing  https://www.imdb.com/review/rw6379386/?ref_=tt...   \n",
       "4     The_Thing  https://www.imdb.com/review/rw0197779/?ref_=tt...   \n",
       "..          ...                                                ...   \n",
       "95  The_Shining  https://www.imdb.com/review/rw0179869/?ref_=tt...   \n",
       "96  The_Shining  https://www.imdb.com/review/rw7669173/?ref_=tt...   \n",
       "97  The_Shining  https://www.imdb.com/review/rw8801397/?ref_=tt...   \n",
       "98  The_Shining  https://www.imdb.com/review/rw0180168/?ref_=tt...   \n",
       "99  The_Shining  https://www.imdb.com/review/rw2504629/?ref_=tt...   \n",
       "\n",
       "            review  \n",
       "0      The_Thing_0  \n",
       "1      The_Thing_1  \n",
       "2      The_Thing_2  \n",
       "3      The_Thing_3  \n",
       "4      The_Thing_4  \n",
       "..             ...  \n",
       "95  The_Shining_20  \n",
       "96  The_Shining_21  \n",
       "97  The_Shining_22  \n",
       "98  The_Shining_23  \n",
       "99  The_Shining_24  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_links = get_links(movies,urls)\n",
    "review_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e1e8e9a-00d3-4be9-9b24-6516e1cf9f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.imdb.com/review/rw8801397/?ref_=tt_urv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### sample url returned from parsing the reviews page\n",
    "review_links.url[97]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db073a5a-8195-47e8-8430-215b0f35c243",
   "metadata": {},
   "source": [
    "### 2. Extract Noun Phrase Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3e815-dc50-4573-968b-258de01278d3",
   "metadata": {},
   "source": [
    "#### a. Grab the review text from each link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c650d443-3e42-4677-a742-6aab31c173b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function goes through the table with the URLs to get each direct URL\n",
    "# Parses through the content of each URL to grab the main review\n",
    "# tokenizes the sentences of each review\n",
    "# returns a dataframe with the movie title, review id, and the setence tokens\n",
    "def grab_review(links_table):\n",
    "    tokens = []\n",
    "    for i in range(len(links_table)):\n",
    "        review = get(links_table.url[i],headers)\n",
    "        review_soup = BeautifulSoup(review.content, 'html.parser')\n",
    "        sent = []\n",
    "        for string in review_soup.find(class_='text show-more__control').stripped_strings:\n",
    "            sent.append(sent_tokenize(string))\n",
    "        tokens.append([item for sublist in sent for item in sublist])\n",
    "    return(pd.DataFrame({'movie':links_table.movie,\n",
    "                         'review':links_table.review,\n",
    "                         'tokens':tokens                         \n",
    "                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd670b79-5c1f-4f83-b999-d651f984f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = grab_review(review_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35106de2-f20d-4b8b-b398-acb2e73c99d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>The_Thing_0</td>\n",
       "      <td>[\"I know I'm human., And if you were all these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>The_Thing_1</td>\n",
       "      <td>[A classic film., John Carpenter's \"The Thing\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>The_Thing_2</td>\n",
       "      <td>[John Carpenter shows how much he loves the 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>The_Thing_3</td>\n",
       "      <td>[\"The ultimate in alien terror,\" it says., It'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The_Thing</td>\n",
       "      <td>The_Thing_4</td>\n",
       "      <td>[Remake of the classic 1951 \"The Thing From An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>The_Shining_20</td>\n",
       "      <td>[Chilling, majestic piece of cinematic fright,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>The_Shining_21</td>\n",
       "      <td>[The Shining is directed by Stanley Kubrick an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>The_Shining_22</td>\n",
       "      <td>[The Shining (1980) is a movie in my DVD colle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>The_Shining_23</td>\n",
       "      <td>[*!, !- SPOILERS - !, !, *, Before I begin thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The_Shining</td>\n",
       "      <td>The_Shining_24</td>\n",
       "      <td>[This film is currently the 48th highest rated...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie          review  \\\n",
       "0     The_Thing     The_Thing_0   \n",
       "1     The_Thing     The_Thing_1   \n",
       "2     The_Thing     The_Thing_2   \n",
       "3     The_Thing     The_Thing_3   \n",
       "4     The_Thing     The_Thing_4   \n",
       "..          ...             ...   \n",
       "95  The_Shining  The_Shining_20   \n",
       "96  The_Shining  The_Shining_21   \n",
       "97  The_Shining  The_Shining_22   \n",
       "98  The_Shining  The_Shining_23   \n",
       "99  The_Shining  The_Shining_24   \n",
       "\n",
       "                                               tokens  \n",
       "0   [\"I know I'm human., And if you were all these...  \n",
       "1   [A classic film., John Carpenter's \"The Thing\"...  \n",
       "2   [John Carpenter shows how much he loves the 19...  \n",
       "3   [\"The ultimate in alien terror,\" it says., It'...  \n",
       "4   [Remake of the classic 1951 \"The Thing From An...  \n",
       "..                                                ...  \n",
       "95  [Chilling, majestic piece of cinematic fright,...  \n",
       "96  [The Shining is directed by Stanley Kubrick an...  \n",
       "97  [The Shining (1980) is a movie in my DVD colle...  \n",
       "98  [*!, !- SPOILERS - !, !, *, Before I begin thi...  \n",
       "99  [This film is currently the 48th highest rated...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd104781-2aea-4a91-b777-9ae28c5a1a6d",
   "metadata": {},
   "source": [
    "#### b. NP Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba534345-eb1f-404d-aab5-a7645ab4877c",
   "metadata": {},
   "source": [
    "Define function for tokenizing and pos tagging each word in each of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0781f12-29aa-4fc5-bf69-a561118552ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "unrecognized = ['\\x96','(',')','..','%','-','/','#'] #unrecognized character which shows in multiple reviews, removing it so as to not have it tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7c10b41-6133-4f2c-83a7-c4fcfd6d4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function goes through the table with the tokens and grabs the sentence tokens\n",
    "# word tokenizes each sentence of each review while removing repeating unrecognized characters and then pos tags each token\n",
    "# returns a single column dataframe with the tagged token pairs\n",
    "def tagger(review_tokens):\n",
    "    tags = []\n",
    "    for i in range(len(review_tokens.tokens)):\n",
    "        words_review = []\n",
    "        for j in review_tokens.tokens[i]:\n",
    "            words_review.append(nltk.pos_tag([w for w in word_tokenize(j) if w not in unrecognized]))\n",
    "        tags.append([item for sublist in words_review for item in sublist])\n",
    "    return(pd.DataFrame({'tags':tags}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e466cd-0997-48aa-bc6b-5f197a1f454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['tags'] = tagger(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d19049f-27e8-478f-be24-21fb57a7b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grammar from nltk.org/book, defines NP-chunks as a Determinant or Possessive Pronoun followed by either an adjective (or multiple adjectives) and a noun, or one or more proper nouns\n",
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<DT>*<NNP>+}              # chunk sequences of proper nouns\n",
    "\"\"\"\n",
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed2d7ff-35b9-40fd-b797-bdc2e5e5ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define function for NP chunking the previously pos_tagged tokens for each of the reviews on our table\n",
    "### since only NP is defined in the grammar, all the other forms are not identified (VP, PRP, etc.)\n",
    "def chunker(review_tokens):\n",
    "    chunks = []\n",
    "    review_id = []\n",
    "    for i in range(len(review_tokens)):\n",
    "        tree = cp.parse(review_tokens.tags[i])\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'NP':\n",
    "                chunks.append(subtree.leaves())\n",
    "                review_id.append(review_tokens.review[i])\n",
    "    return(pd.DataFrame({'NP-chunks':chunks},index=review_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de7fcad-0d14-428a-9116-dd8f72b9507d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NP-chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(This, DT), (thing, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(an, DT), (imitation, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(nobody, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(John, NNP), (Carpenter, NNP)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(The, DT), (Thing, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(an, DT), (evil, JJ), (hotel, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(room, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(death, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(mayhem, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(the, DT), (film, NN)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7178 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          NP-chunks\n",
       "The_Thing_0               [(This, DT), (thing, NN)]\n",
       "The_Thing_0             [(an, DT), (imitation, NN)]\n",
       "The_Thing_0                          [(nobody, NN)]\n",
       "The_Thing_0         [(John, NNP), (Carpenter, NNP)]\n",
       "The_Thing_0                [(The, DT), (Thing, NN)]\n",
       "...                                             ...\n",
       "The_Shining_24  [(an, DT), (evil, JJ), (hotel, NN)]\n",
       "The_Shining_24                         [(room, NN)]\n",
       "The_Shining_24                        [(death, NN)]\n",
       "The_Shining_24                       [(mayhem, NN)]\n",
       "The_Shining_24              [(the, DT), (film, NN)]\n",
       "\n",
       "[7178 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = chunker(tokens)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f5041-a79e-4188-87f7-07dd314c90e4",
   "metadata": {},
   "source": [
    "We see we are left with 7178 total NP chunks. This process used the suggested nltk.post_tag function for assigning tags to the word tokens. This method seems to incorporate a default tagger of NNP, meaning words which are not recognized are assigned an NNP tag. These tags seemed to have produced great results with the regex parser for NP chunking, as we can see proper names were properly identified returning Noun Phrases that are satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b7c8c-e51c-4152-a569-350d9dc558e2",
   "metadata": {},
   "source": [
    "#### c. Add to Lexicon and Repeat NP Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15305fc8-3df6-46c9-858e-35086628f59e",
   "metadata": {},
   "source": [
    "While the previous produced great results, for illustration purposes, this step will train a tagger that includes tagged tokens for the movie titles, directors, main actors and characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37b7e1c4-253d-4942-862c-bc07153428a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##actors, characters, titles, etc. to be added to the train set\n",
    "to_add = [[('the','DT'),('thing','NNP')],[('The','DT'),('Thing','NNP')],[('Kurt','NNP'),('Russel','NNP')],[('Keith','NNP'),('David','NNP')],[('John','NNP'),('Carpenter','NNP')],\n",
    "          [('MacReady','NNP')],[('Childs','NNP')],[('A','DT'),('Quiet','JJ'),('Place','NNP')],[('Emily','NNP'),('Blunt','NNP')],[('John','NNP'),('Krasinski','NNP')],\n",
    "          [('Millicent','NNP'),('Simmons','NNP')],[('Noah','NNP'),('Jupe','NNP')],[('Alien','NNP'),('Covenant','NNP')],[('Ridley','NNP'),('Scott','NNP')],[('Michael','NNP'),('Fassbender','NNP')],\n",
    "          [('Katherine','NNP'),('Waterston','NNP')],[('Billy','NNP'),('Crudup','NNP')],[('David','NNP')],[('Daniels','NNP')],[('Oram','NNP')],[('The','NNP'),('Shining','NNP')],\n",
    "          [('the','NNP'),('shining','NNP')],[('Jack','NNP'),('Nicholson','NNP')],[('Jack','NNP'),('Torrance','NNP')],[('Shelley','NNP'),('Duvall','NNP')],[('Danny','NNP'),('Lloyd','NNP')],\n",
    "          [('Stanley','NNP'),('Kubrick','NNP')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5205c20e-8bac-4163-87dd-11d70064dc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tagged sentences in treebank 3914\n",
      "Number of tagged sentences in custom trainset 3941\n"
     ]
    }
   ],
   "source": [
    "tagged_sent = treebank.tagged_sents() #all tagged sentences from the treebank corpus\n",
    "train_sent = tagged_sent + to_add # adding the names, titles to the treebank tagged sentences\n",
    "print('Number of tagged sentences in treebank',len(tagged_sent))\n",
    "print('Number of tagged sentences in custom trainset',len(train_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f254c0e-e096-452e-881f-19d37fa188c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tagger = nltk.tag.PerceptronTagger(load=False) #loading perceptron tagger function without the default training set\n",
    "custom_tagger.train(train_sent) # train custom tagger on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e5f8d91-af4b-427c-ae0a-f8af82f95a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_tagger(review_tokens):\n",
    "    tags = []\n",
    "    for i in range(len(review_tokens.tokens)):\n",
    "        words_review = []\n",
    "        for j in review_tokens.tokens[i]:\n",
    "            words_review.append(custom_tagger.tag([w for w in word_tokenize(j) if w not in unrecognized]))\n",
    "        tags.append([item for sublist in words_review for item in sublist])\n",
    "    return(pd.DataFrame({'tags':tags}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2867462-4e8c-4620-8d0e-0b160c861541",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['tags'] = new_tagger(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c17b1d4-78d1-4a3f-8ff9-994a7bc57009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NP-chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(This, DT), (thing, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(inside, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(an, DT), (imitation, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(nobody, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Thing_0</th>\n",
       "      <td>[(John, NNP), (Carpenter, NNP)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(screw, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(cause, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(death, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(mayhem, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Shining_24</th>\n",
       "      <td>[(the, DT), (film, NN)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7696 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      NP-chunks\n",
       "The_Thing_0           [(This, DT), (thing, NN)]\n",
       "The_Thing_0                      [(inside, NN)]\n",
       "The_Thing_0         [(an, DT), (imitation, NN)]\n",
       "The_Thing_0                      [(nobody, NN)]\n",
       "The_Thing_0     [(John, NNP), (Carpenter, NNP)]\n",
       "...                                         ...\n",
       "The_Shining_24                    [(screw, NN)]\n",
       "The_Shining_24                    [(cause, NN)]\n",
       "The_Shining_24                    [(death, NN)]\n",
       "The_Shining_24                   [(mayhem, NN)]\n",
       "The_Shining_24          [(the, DT), (film, NN)]\n",
       "\n",
       "[7696 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = chunker(tokens)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0366d6b-166d-48e1-9975-56f79ca4651c",
   "metadata": {},
   "source": [
    "This new method returns additional NP Chunks when compared to the original method which utilized the default tagger. A total of 7696 NP chunks were included in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff75405-21a1-4c6c-b91e-f08ca23cabce",
   "metadata": {},
   "source": [
    "### 3. Output All the Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "933ac353-4f33-4bf2-8daf-b8704b8d6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create output list for the assignment\n",
    "df2.to_csv('mb_hw5_npchunks.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed9074-1aea-47be-9fed-26eadb737b0d",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f09c9-e56c-4623-83a6-d7eba7e6d54d",
   "metadata": {},
   "source": [
    "First, four horror movies ('The Thing (1982)', 'A Quiet Place', 'Alien Covenant', and 'The Shining) were chosen, and the URLs for their corresponding user review sections from IMDB saved unto a list. Then, utilizing a custom function which integrated the BeautifulSoup html parser, the direct url links to 25 reviews for each movie were saved into a Pandas dataframe which included the movie name, the direct URL, and a review identifier.  \n",
    "\n",
    "After saving the direct URLs, a custom function, 'grab_review', which integrated the BeautifulSoup html parser was used to parse through each individual review and extract the text of the main review for each of the 100 review URLs (25 for each of the 4 movies), which were then saved on a Pandas dataframe. The grab review function included a sentence tokenizer, so that the text for each review was saved in a tokenized sentence form.  \n",
    "\n",
    "Prior to chunking, another custom function was used, which took the previous output as input, and both word tokenized each sentence in each of the 100 reviews and part-of-speech tagged each word token. The outputted tagged tokens were then shallow parsed using a custom 'chunker' function which utilized nltk.RegexParser, iterating through each review on the list. This resulted in 7178 NP Chunks.  \n",
    "\n",
    "Finally, to ensure that words related to the films (such as titles, actors, directors) were included in the training step, a custom pos tagged list was added to the treebank corpus and utilized to train a custom tagger. This custom pos tagged list included the movie title, main actors, main actresses, directors, and characters' names for each of the four movies. After tagging the word tokens with the custom tagger, the results were then used to find NP chunks using the previously defined 'chunker' function, resulting in 7696 NP chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847290c-1e5e-431f-9858-31f39c4970aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
