{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9991eaaa-b2c9-4281-ba14-1f0fb68390c8",
   "metadata": {},
   "source": [
    "# NLP - HW7\n",
    "### Miguel Bonilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f75157ca-fb0f-47c7-a895-8fd2af807a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import re\n",
    "import contractions\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a2d2c-b0fc-4e51-9c15-1cbeee09893d",
   "metadata": {},
   "source": [
    "Cluster the reviews that you collected in homework 5, by doing the following:  \n",
    "1. In Python, select any one of the clustering methods covered in this course. Run it over the\n",
    "collection of reviews, and show at least two different ways of clustering the reviews, e.g.,\n",
    "changing k in k-Means clustering or changing where you “cut” in Agnes or Diana.  \n",
    "2. Try to write a short phrase to characterize (give a natural interpretation of) what each\n",
    "cluster is generally centered on semantically. Is this hard to do in some cases? If so, make\n",
    "note of that fact.  \n",
    "3. Explain which of the two clustering results from question 1 is preferable (if one of them is),\n",
    "and why.  \n",
    "Submit all of your inputs and outputs and your code for this assignment, along with a brief written\n",
    "explanation of your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a2b5e-3eda-4d34-9d04-b8df9d44b2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7942e703-4dc3-47b6-85c1-b06c07838a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### assign headers since IMDB rejects the requests without it\n",
    "headers = {'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.50'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9537e1d5-8197-4f90-b91c-96608e3b3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load static URL list (from HW5)\n",
    "\n",
    "url_list = pd.read_csv(\"../DS7337/mb_hw5_urls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366ca4f6-df14-4f3e-bce5-6f1e6b70fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function goes through the table with the URLs to get each direct URL\n",
    "# Parses through the content of each URL to grab the main review\n",
    "# tokenizes the sentences of each review\n",
    "# returns a dataframe with the movie title, review id, and the setence tokens\n",
    "def grab_review(links_table):\n",
    "    text = []\n",
    "    for i in range(len(links_table)):\n",
    "        review = get(links_table.url[i],headers)\n",
    "        review_soup = BeautifulSoup(review.content, 'html.parser')\n",
    "        text.append(review_soup.find(class_='text show-more__control').text)\n",
    "    return(pd.DataFrame({'movie':links_table.movie,\n",
    "                         'review':links_table.review,\n",
    "                         'text':text                         \n",
    "                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845d6146-e895-427c-9427-f4644bc26bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = grab_review(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "734af08f-a933-442b-a0a6-1bc199fe2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "special = ['\\x96',':',',','-','(',')','[',']','–','/','#','``',';','.','&','\"',\"''\",'?','!','....','--','...','*','..',\"'\"]\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "special = stop_words + [\"'s\",\"'t\",\"'d\",\"'ll\",\"'m\",\"'re\",\"'ve\",\"n't\"] +special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eec7a1cb-8780-4fac-b39c-466c799e724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_list(review_list):\n",
    "    term = [word_tokenize(term.lower()) for term in review_list]\n",
    "    blank_list = []\n",
    "    for i in range(len(review_list)):\n",
    "        blank_list.append(' '.join([w for w in term[i] if w not in special]))\n",
    "    return(np.array(blank_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "15aa1884-927c-4dba-8fdd-14f8b7e20893",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_corpus = normalize_list(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9756cb0-52e4-42c1-b447-79e5a7ce59bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "92d2d2a3-2a8f-44be-be8d-7d1eead9b772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 299)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), min_df=10, max_df=0.8, stop_words=special)\n",
    "cv_matrix = cv.fit_transform(norm_corpus)\n",
    "cv_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "59660801-e661-41e2-bbdd-021592f8addf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=1000, n_clusters=5, n_init=500, random_state=326)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "NUM_Clusters = 5\n",
    "km = KMeans(n_clusters=NUM_Clusters, max_iter=1000,n_init=500,random_state=326).fit(cv_matrix)\n",
    "km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "62d25163-e29f-4941-9bda-e14e15328278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 7, 2: 57, 0: 28, 4: 4, 3: 4})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5802222-89bf-4662-a1bd-0b613bc3bad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
