{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boneeyah/DS7337/blob/main/Case%20Study%207/CaseStudy7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import DMatrix\n",
        "\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import datetime\n",
        "import pydot\n",
        "import graphviz\n"
      ],
      "metadata": {
        "id": "HrVUsV_b8Ezp",
        "outputId": "c86bbebe-1d70-4af2-c0de-0c0fb49b38fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-06 17:13:09.656604: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-06 17:13:10.309290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('drive')\n",
        "\n",
        "#df = pd.read_csv(\"drive/My Drive/final_project(5).csv\")\n",
        "df = pd.read_csv(\"/home/migue/Downloads/final_project(5).csv\")"
      ],
      "metadata": {
        "id": "hngzaeNL-EXs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "#there are NAs will need handling"
      ],
      "metadata": {
        "id": "kjzOue9y_SuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee8c674-be59-4974-d73d-4ff232f170cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 51 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      159974 non-null  float64\n",
            " 1   x1      159975 non-null  float64\n",
            " 2   x2      159962 non-null  float64\n",
            " 3   x3      159963 non-null  float64\n",
            " 4   x4      159974 non-null  float64\n",
            " 5   x5      159963 non-null  float64\n",
            " 6   x6      159974 non-null  float64\n",
            " 7   x7      159973 non-null  float64\n",
            " 8   x8      159979 non-null  float64\n",
            " 9   x9      159970 non-null  float64\n",
            " 10  x10     159957 non-null  float64\n",
            " 11  x11     159970 non-null  float64\n",
            " 12  x12     159964 non-null  float64\n",
            " 13  x13     159969 non-null  float64\n",
            " 14  x14     159966 non-null  float64\n",
            " 15  x15     159965 non-null  float64\n",
            " 16  x16     159974 non-null  float64\n",
            " 17  x17     159973 non-null  float64\n",
            " 18  x18     159960 non-null  float64\n",
            " 19  x19     159965 non-null  float64\n",
            " 20  x20     159962 non-null  float64\n",
            " 21  x21     159971 non-null  float64\n",
            " 22  x22     159973 non-null  float64\n",
            " 23  x23     159953 non-null  float64\n",
            " 24  x24     159972 non-null  object \n",
            " 25  x25     159978 non-null  float64\n",
            " 26  x26     159964 non-null  float64\n",
            " 27  x27     159970 non-null  float64\n",
            " 28  x28     159965 non-null  float64\n",
            " 29  x29     159970 non-null  object \n",
            " 30  x30     159970 non-null  object \n",
            " 31  x31     159961 non-null  float64\n",
            " 32  x32     159969 non-null  object \n",
            " 33  x33     159959 non-null  float64\n",
            " 34  x34     159959 non-null  float64\n",
            " 35  x35     159970 non-null  float64\n",
            " 36  x36     159973 non-null  float64\n",
            " 37  x37     159977 non-null  object \n",
            " 38  x38     159969 non-null  float64\n",
            " 39  x39     159977 non-null  float64\n",
            " 40  x40     159964 non-null  float64\n",
            " 41  x41     159960 non-null  float64\n",
            " 42  x42     159974 non-null  float64\n",
            " 43  x43     159963 non-null  float64\n",
            " 44  x44     159960 non-null  float64\n",
            " 45  x45     159971 non-null  float64\n",
            " 46  x46     159969 non-null  float64\n",
            " 47  x47     159963 non-null  float64\n",
            " 48  x48     159968 non-null  float64\n",
            " 49  x49     159968 non-null  float64\n",
            " 50  y       160000 non-null  int64  \n",
            "dtypes: float64(45), int64(1), object(5)\n",
            "memory usage: 62.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns:\n",
        "    if df[i].isna().sum() > 0:\n",
        "        print('{} has {}% NAs'.format(i,(df[i].isna().sum() / len(df))*100))"
      ],
      "metadata": {
        "id": "CC3yFJ6BzzOw",
        "outputId": "96ab93c5-aeb2-4f64-f9a9-e7de04ea3fc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 has 0.01625% NAs\n",
            "x1 has 0.015625% NAs\n",
            "x2 has 0.02375% NAs\n",
            "x3 has 0.023125% NAs\n",
            "x4 has 0.01625% NAs\n",
            "x5 has 0.023125% NAs\n",
            "x6 has 0.01625% NAs\n",
            "x7 has 0.016875% NAs\n",
            "x8 has 0.013125% NAs\n",
            "x9 has 0.01875% NAs\n",
            "x10 has 0.026875% NAs\n",
            "x11 has 0.01875% NAs\n",
            "x12 has 0.0225% NAs\n",
            "x13 has 0.019375% NAs\n",
            "x14 has 0.021249999999999998% NAs\n",
            "x15 has 0.021875000000000002% NAs\n",
            "x16 has 0.01625% NAs\n",
            "x17 has 0.016875% NAs\n",
            "x18 has 0.025% NAs\n",
            "x19 has 0.021875000000000002% NAs\n",
            "x20 has 0.02375% NAs\n",
            "x21 has 0.018125% NAs\n",
            "x22 has 0.016875% NAs\n",
            "x23 has 0.029375000000000002% NAs\n",
            "x24 has 0.017499999999999998% NAs\n",
            "x25 has 0.01375% NAs\n",
            "x26 has 0.0225% NAs\n",
            "x27 has 0.01875% NAs\n",
            "x28 has 0.021875000000000002% NAs\n",
            "x29 has 0.01875% NAs\n",
            "x30 has 0.01875% NAs\n",
            "x31 has 0.024374999999999997% NAs\n",
            "x32 has 0.019375% NAs\n",
            "x33 has 0.025625000000000002% NAs\n",
            "x34 has 0.025625000000000002% NAs\n",
            "x35 has 0.01875% NAs\n",
            "x36 has 0.016875% NAs\n",
            "x37 has 0.014374999999999999% NAs\n",
            "x38 has 0.019375% NAs\n",
            "x39 has 0.014374999999999999% NAs\n",
            "x40 has 0.0225% NAs\n",
            "x41 has 0.025% NAs\n",
            "x42 has 0.01625% NAs\n",
            "x43 has 0.023125% NAs\n",
            "x44 has 0.025% NAs\n",
            "x45 has 0.018125% NAs\n",
            "x46 has 0.019375% NAs\n",
            "x47 has 0.023125% NAs\n",
            "x48 has 0.02% NAs\n",
            "x49 has 0.02% NAs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x24'].value_counts()"
      ],
      "metadata": {
        "id": "TybuIbMLz6Ng",
        "outputId": "ef981d0b-aeeb-4666-ef72-7706f5f081f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "asia       138965\n",
              "euorpe      16538\n",
              "america      4469\n",
              "Name: x24, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x=df['x24'].value_counts().index,height=df['x24'].value_counts().values)"
      ],
      "metadata": {
        "id": "ME56MKaIz7sN",
        "outputId": "e67edfcb-0cdf-48af-ae16-76baeab04d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x29'].value_counts()"
      ],
      "metadata": {
        "id": "P7rMlCalz9WH",
        "outputId": "e55694bc-7538-495f-e8e9-cf47d9e69a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "July       45569\n",
              "Jun        41329\n",
              "Aug        29406\n",
              "May        21939\n",
              "sept.      10819\n",
              "Apr         6761\n",
              "Oct         2407\n",
              "Mar         1231\n",
              "Nov          337\n",
              "Feb          140\n",
              "Dev           23\n",
              "January        9\n",
              "Name: x29, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up month formatting to standard 3 letters\n",
        "df['x29'].replace(to_replace=['July','sept.','Dev','January'],value=['Jul','Sep','Dec','Jan'],inplace=True)"
      ],
      "metadata": {
        "id": "gB-gkjC2z_fK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df['x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "eZTNOL9P0CM3",
        "outputId": "3e0c052a-0d38-4f08-e4ac-6705de11cad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1,3, figsize = (25, 5))\n",
        "plt.subplots_adjust(wspace=.18,hspace=1)\n",
        "fig.subplots_adjust(top = .96)\n",
        "sns.set(rc={'figure.figsize':(5.5,6)})\n",
        "sns.countplot(x = 'x29', data = df, hue = 'y', ax = axes[0]);\n",
        "sns.countplot(x = 'x30', data = df, hue = 'y', ax = axes[1]);\n",
        "sns.countplot(x = 'x24', data = df, hue = 'y', ax = axes[2]);\n",
        "\n",
        "fig.suptitle('Count plots for categorical features')"
      ],
      "metadata": {
        "id": "lCaK4Zy0zbuh",
        "outputId": "21221281-7b1f-4db7-c3d3-cb79c5646349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Count plots for categorical features')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x500 with 3 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x30'].value_counts()"
      ],
      "metadata": {
        "id": "_1LSKgy80ENF",
        "outputId": "855a7f94-c907-4475-bdbb-706fa84a59c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wednesday    101535\n",
              "thurday       29429\n",
              "tuesday       27954\n",
              "friday          564\n",
              "monday          488\n",
              "Name: x30, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thursday is incorrect\n",
        "df['x30'].replace(to_replace = 'thurday',value='thursday',inplace=True)\n",
        "days = ['monday','tuesday','wednesday','thursday','friday']\n",
        "d_heights = []\n",
        "for i in days:\n",
        "    x = df['x30'].to_list().count(i)\n",
        "    d_heights.append(x)\n",
        "plt.bar(x=days,height = d_heights)"
      ],
      "metadata": {
        "id": "3hFwgArL0GAB",
        "outputId": "c7d62c5a-1628-4bb4-e2b9-94e85bcb0792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x32'].value_counts()"
      ],
      "metadata": {
        "id": "WErTHaJ70Ia2",
        "outputId": "95284cb3-ca38-434e-9a25-a298d3ee19f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01%     40767\n",
              "-0.01%    34094\n",
              "0.0%      33923\n",
              "-0.0%     30492\n",
              "-0.02%     9924\n",
              "0.02%      7987\n",
              "-0.03%     1727\n",
              "0.03%       855\n",
              "-0.04%      138\n",
              "0.04%        55\n",
              "-0.05%        6\n",
              "0.05%         1\n",
              "Name: x32, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x37'].value_counts()\n"
      ],
      "metadata": {
        "id": "r98Zehw50LS1",
        "outputId": "54546946-15b9-473a-dea0-14b7676a60a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "$-311.26     6\n",
              "$-336.77     6\n",
              "$237.4       6\n",
              "$72.42       6\n",
              "$341.26      6\n",
              "            ..\n",
              "$-505.21     1\n",
              "$770.07      1\n",
              "$74.62       1\n",
              "$-1082.96    1\n",
              "$-1229.34    1\n",
              "Name: x37, Length: 129198, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### x32 and x37 are actually numeric with string format (even though x32 has few \"levels\" or possible values)\n",
        "### x32 is in percentage, but don't think it needs to be transformed to proportion since data will be scaled later (will double check, but should make no difference)\n",
        "\n",
        "df['x32'] = df['x32'].transform(lambda x: float(str(x).replace('%','')))\n",
        "df['x37'] = df['x37'].transform(lambda x: float(str(x).replace('$','')))"
      ],
      "metadata": {
        "id": "-8HSIli70VDX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all significanlty less than 5%, should be no issue imputing,\n",
        "#imputing categorical features with modes\n",
        "# imputing continent with mode, then dates by mode grouped by continent\n",
        "\n",
        "print('imputing continent with mode: {}'.format(df['x24'].aggregate(pd.Series.mode)))\n",
        "df['x24'] = df['x24'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "\n",
        "print('imputing month with mode by cont: {}'.format(df[['x24','x29']].groupby(by='x24').aggregate(pd.Series.mode)))\n",
        "idx_29 = df.loc[df['x29'].isna(),:].index #saving NAs indices to quick check what they've been imputed with\n",
        "df['x29'] = df[['x24','x29']].groupby(by='x24').transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))\n",
        "\n",
        "# will fix index showing on print later\n"
      ],
      "metadata": {
        "id": "qyAc5R1u209T",
        "outputId": "c3d0a370-c9d5-46f9-9fc1-4caed4ebcaaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imputing continent with mode: 0    asia\n",
            "Name: x24, dtype: object\n",
            "imputing month with mode by cont:          x29\n",
            "x24         \n",
            "america  Jul\n",
            "asia     Jul\n",
            "euorpe   Jul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x24','x29','x30']].groupby(by=['x24','x29']).aggregate(pd.Series.mode)\n",
        "# could just impute with wednesday since Wed is mode per month, but adding continent gives more context and different days for some months"
      ],
      "metadata": {
        "id": "2iV02zDI3Emu",
        "outputId": "82a9a065-ea3b-4158-cff1-6317ac898976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   x30\n",
              "x24     x29           \n",
              "america Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "asia    Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb  wednesday\n",
              "        Jan  wednesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "euorpe  Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>x30</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x24</th>\n",
              "      <th>x29</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">america</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"12\" valign=\"top\">asia</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">euorpe</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# impute day\n",
        "df['x30'] = df[['x24','x29','x30']].groupby(by=['x24','x29']).transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))"
      ],
      "metadata": {
        "id": "HVQavir8IV9m"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#created categorical variable for high/low volume based on month/continent\n",
        "conditions = [\n",
        "    (df['x24'] == 'america'),\n",
        "    (df['x24'] =='asia') & (df['x29'] == 'Jan'),\n",
        "    (df['x24'] =='asia') & (df['x29'] != 'Jan'),\n",
        "    (df['x24'] =='euorpe')\n",
        "    ]\n",
        "\n",
        "values = ['low', 'low', 'high', 'high']\n",
        "df['Volume'] = np.select(conditions, values)\n",
        "df[['Volume', 'y']].groupby(['Volume']).count()"
      ],
      "metadata": {
        "id": "Ul1CRi4b4kGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c61a246f-07a7-4104-a380-1dd6fa5b1b36"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             y\n",
              "Volume        \n",
              "high    155522\n",
              "low       4478"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Volume</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>high</th>\n",
              "      <td>155522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>low</th>\n",
              "      <td>4478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:,df.columns != 'y']\n",
        "y = df['y'].values.flatten()\n",
        "\n",
        "df_num = X.select_dtypes(exclude='object')\n",
        "num_cols = df_num.columns\n",
        "\n",
        "# impute numeric with median\n",
        "for i in num_cols:\n",
        "    df_num[i] = df_num[i].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "df_num.info()\n",
        "\n",
        "df_cat = X.select_dtypes(include='object')\n",
        "cat_cols = df_cat.columns\n",
        "\n",
        "# scale numerical data\n",
        "scaler = StandardScaler()\n",
        "df_num = scaler.fit_transform(df_num)\n",
        "\n",
        "#one hot encode cat data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "df_cat = encoder.fit_transform(df_cat)"
      ],
      "metadata": {
        "id": "w8Uy9xG3Iern",
        "outputId": "4be68382-4658-4219-84ba-dbcb26a2026b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 47 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      160000 non-null  float64\n",
            " 1   x1      160000 non-null  float64\n",
            " 2   x2      160000 non-null  float64\n",
            " 3   x3      160000 non-null  float64\n",
            " 4   x4      160000 non-null  float64\n",
            " 5   x5      160000 non-null  float64\n",
            " 6   x6      160000 non-null  float64\n",
            " 7   x7      160000 non-null  float64\n",
            " 8   x8      160000 non-null  float64\n",
            " 9   x9      160000 non-null  float64\n",
            " 10  x10     160000 non-null  float64\n",
            " 11  x11     160000 non-null  float64\n",
            " 12  x12     160000 non-null  float64\n",
            " 13  x13     160000 non-null  float64\n",
            " 14  x14     160000 non-null  float64\n",
            " 15  x15     160000 non-null  float64\n",
            " 16  x16     160000 non-null  float64\n",
            " 17  x17     160000 non-null  float64\n",
            " 18  x18     160000 non-null  float64\n",
            " 19  x19     160000 non-null  float64\n",
            " 20  x20     160000 non-null  float64\n",
            " 21  x21     160000 non-null  float64\n",
            " 22  x22     160000 non-null  float64\n",
            " 23  x23     160000 non-null  float64\n",
            " 24  x25     160000 non-null  float64\n",
            " 25  x26     160000 non-null  float64\n",
            " 26  x27     160000 non-null  float64\n",
            " 27  x28     160000 non-null  float64\n",
            " 28  x31     160000 non-null  float64\n",
            " 29  x32     160000 non-null  float64\n",
            " 30  x33     160000 non-null  float64\n",
            " 31  x34     160000 non-null  float64\n",
            " 32  x35     160000 non-null  float64\n",
            " 33  x36     160000 non-null  float64\n",
            " 34  x37     160000 non-null  float64\n",
            " 35  x38     160000 non-null  float64\n",
            " 36  x39     160000 non-null  float64\n",
            " 37  x40     160000 non-null  float64\n",
            " 38  x41     160000 non-null  float64\n",
            " 39  x42     160000 non-null  float64\n",
            " 40  x43     160000 non-null  float64\n",
            " 41  x44     160000 non-null  float64\n",
            " 42  x45     160000 non-null  float64\n",
            " 43  x46     160000 non-null  float64\n",
            " 44  x47     160000 non-null  float64\n",
            " 45  x48     160000 non-null  float64\n",
            " 46  x49     160000 non-null  float64\n",
            "dtypes: float64(47)\n",
            "memory usage: 57.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack([df_num,df_cat])"
      ],
      "metadata": {
        "id": "R4oaw8CgIkXV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1zPG-Q7z7U3",
        "outputId": "e04e758a-3e99-442f-f100-a577bd1bc56a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 69)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'].value_counts() # not balanced"
      ],
      "metadata": {
        "id": "xbzdACUdImVy",
        "outputId": "96762078-7860-479b-c2b8-9d7915455dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    95803\n",
              "1    64197\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## define cost function\n",
        "def cost_func(y_pred,y_true):\n",
        "    diff = y_pred - y_true\n",
        "    x = 0\n",
        "    for i in diff:\n",
        "        #false pos (y_pred -y_true == 1)\n",
        "        if i == 1:\n",
        "            x += 100\n",
        "        #false neg (y_pred -y_true ==-1)\n",
        "        elif i == -1:\n",
        "            x += 150\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "HRJz__nu_bxm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stratifiedkfold by high/lower volume created category\n",
        "#in order to get an equal distribution of the 0s during high volume time and 1s during low, replace with binary imediately after\n",
        "\n",
        "y=df[['Volume', 'y']].astype(str).apply(\"-\".join, axis=1)\n",
        "skf = StratifiedKFold(n_splits=10,random_state=807,shuffle=True)\n",
        "skf.get_n_splits(X,y)\n",
        "y = df['y'].values.flatten()"
      ],
      "metadata": {
        "id": "qIgBnSnHIqjU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "gpPJ9Gb95HXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logR = LogisticRegression(random_state=807,penalty='l2',class_weight='balanced',solver='lbfgs',max_iter=1000)\n",
        "params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10]}\n",
        "\n",
        "lr_clf = GridSearchCV(estimator=logR,param_grid=params,n_jobs=-1,cv=skf)\n",
        "lr_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "AcpquSzJO6SF",
        "outputId": "cebadab4-2fff-4a88-c4ae-fe90937520d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight='balanced',\n",
              "                                          max_iter=1000, random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10]})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                          max_iter=1000, random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;C&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                          max_iter=1000, random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;C&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=807)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=807)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params = lr_clf.best_params_\n",
        "#lr_params ={'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}\n",
        "lr_params"
      ],
      "metadata": {
        "id": "Eb5e2xOvO8pr",
        "outputId": "a2dfc0ad-ec09-44a1-b27f-26d70edcb627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.001}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(random_state=807,penalty='l2',class_weight='balanced',solver='lbfgs')\n",
        "model1.set_params(**lr_params)\n",
        "model1.fit(X,y)\n",
        "\n",
        "preds_m1 = cross_val_predict(model1,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "RHUkzlw2PATu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m1 = classification_report(y,preds_m1,output_dict=True)\n",
        "cr_m1"
      ],
      "metadata": {
        "id": "3katCHeBPQB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f483645-0179-4c07-f8d7-a42bd4737d20"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.7716230424436943,\n",
              "  'recall': 0.7277433900817302,\n",
              "  'f1-score': 0.7490411370985935,\n",
              "  'support': 95803.0},\n",
              " '1': {'precision': 0.6254863952904013,\n",
              "  'recall': 0.6785675343084567,\n",
              "  'f1-score': 0.6509466385738408,\n",
              "  'support': 64197.0},\n",
              " 'accuracy': 0.7080125,\n",
              " 'macro avg': {'precision': 0.6985547188670478,\n",
              "  'recall': 0.7031554621950935,\n",
              "  'f1-score': 0.6999938878362172,\n",
              "  'support': 160000.0},\n",
              " 'weighted avg': {'precision': 0.7129884528355696,\n",
              "  'recall': 0.7080125,\n",
              "  'f1-score': 0.7096825588373838,\n",
              "  'support': 160000.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m1)"
      ],
      "metadata": {
        "id": "ent8XHdUPayB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "d2d3c840-0480-4470-f616-9d8f5e87a322"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f1aaa4a29d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 2 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m1 = cost_func(preds_m1,y)\n",
        "cost_m1"
      ],
      "metadata": {
        "id": "zawbBlwk_fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12faffb3-e7d2-446c-9e2b-3544656d7de7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5703550"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "gWPF0EgN5Mw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "params = {'n_estimators':[100, 200],'max_features':['sqrt','log2',20]}\n",
        "rf_clf = GridSearchCV(rf,param_grid=params,cv=skf,n_jobs = -1)"
      ],
      "metadata": {
        "id": "4HWotr_VPhhH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "soQp5nQ8PkUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "71b7bd79-8f07-4f0b-e739-9bbe38401eeb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/migue/anaconda3/envs/CS7/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight='balanced',\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_features': ['sqrt', 'log2', 20],\n",
              "                         'n_estimators': [100, 200]})"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3jhHtsE6rFk",
        "outputId": "0e773cb5-3155-4caf-a3ba-5dd564fdff86"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = {'max_features': 20, 'n_estimators': 200}\n",
        "rf_params"
      ],
      "metadata": {
        "id": "Hz6owkMTPlOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced2beca-0528-4c3d-b630-6db83b3aae93"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "model2.set_params(**rf_params)\n",
        "preds_m2 = cross_val_predict(model2,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "hvIbks5bPnfm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m2 = pd.read_csv(\"/content/rf_results.csv\")"
      ],
      "metadata": {
        "id": "PFByIS7pi7fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJeX4IS7jP_W",
        "outputId": "2422bdd1-06c3-4a09-d8f1-b6db86814e05"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m2 = preds_m2['0']"
      ],
      "metadata": {
        "id": "dczRs5VZjHoV",
        "outputId": "c2c5a5a3-91f2-4af3-c509-c87e63ac8823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds_m2 \u001b[38;5;241m=\u001b[39m \u001b[43mpreds_m2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m2 = classification_report(y,preds_m2,output_dict=True)\n",
        "cr_m2"
      ],
      "metadata": {
        "id": "Aaw8aFI7PpCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd39bd6f-6e2e-4013-98bd-7bdf1d02a411"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.9573556175358869,\n",
              "  'recall': 0.9279563270461259,\n",
              "  'f1-score': 0.9424267480812449,\n",
              "  'support': 95803.0},\n",
              " '1': {'precision': 0.8971983496924292,\n",
              "  'recall': 0.938314874526847,\n",
              "  'f1-score': 0.9172960955107511,\n",
              "  'support': 64197.0},\n",
              " 'accuracy': 0.9321125,\n",
              " 'macro avg': {'precision': 0.9272769836141581,\n",
              "  'recall': 0.9331356007864864,\n",
              "  'f1-score': 0.929861421795998,\n",
              "  'support': 160000.0},\n",
              " 'weighted avg': {'precision': 0.9332186417624715,\n",
              "  'recall': 0.9321125,\n",
              "  'f1-score': 0.93234354493707,\n",
              "  'support': 160000.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m2 ,cmap='Blues', colorbar=False)"
      ],
      "metadata": {
        "id": "BK6zSOo4Pq_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "5c0da27d-af02-43a1-fdcd-b2d870fa46a9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f1b1e33f1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m2 = cost_func(preds_m2,y)\n",
        "cost_m2"
      ],
      "metadata": {
        "id": "XqmhfmAx9Ge2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79392f99-f21b-404d-e773-d4106509283d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1284200"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "kf48YNxF5eEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up a hyperparameter dataframe\n",
        "\n",
        "learning_rates = [0.1, 0.25, 0.35]\n",
        "max_depths = [3, 5, 10, 20]\n",
        "gamma = [0,1,3]\n",
        "lambda_ls = [1,2,3]\n",
        "alpha = [0,0.1,1]\n",
        "\n",
        "xgb_param = pd.DataFrame(list(product(learning_rates, max_depths, gamma, lambda_ls, alpha)), columns=['learning_rate', 'max_depth', 'gamma', 'lambda', 'alpha'])\n",
        "\n",
        "#randomizing the dataframe order\n",
        "xgb_param = shuffle(xgb_param)\n",
        "xgb_param = xgb_param.reset_index()\n",
        "xgb_param=xgb_param.drop(['index'], axis=1)\n",
        "xgb_param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "crFxa8d68wBQ",
        "outputId": "07866282-b41f-403a-d5fc-c5ad77bf1022"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     learning_rate  max_depth  gamma  lambda  alpha\n",
              "0             0.25         10      3       1    1.0\n",
              "1             0.10          5      3       1    1.0\n",
              "2             0.35          5      0       2    1.0\n",
              "3             0.35         20      0       3    0.1\n",
              "4             0.35         20      1       1    0.1\n",
              "..             ...        ...    ...     ...    ...\n",
              "319           0.10         20      1       3    0.1\n",
              "320           0.10          5      3       2    1.0\n",
              "321           0.35          3      3       1    0.1\n",
              "322           0.25          3      0       1    0.0\n",
              "323           0.10          3      3       2    0.0\n",
              "\n",
              "[324 rows x 5 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.10</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.35</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.35</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>0.10</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>0.10</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.35</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>324 rows × 5 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trials = 30\n",
        "best_params = {}\n",
        "for j, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "  dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "\n",
        "\n",
        "  i=0\n",
        "\n",
        "  for i in range(trials):\n",
        "    #random sampling from paramdf\n",
        "    hyperparams = {'objective': 'binary:logistic',\n",
        "                  'eta': xgb_param['learning_rate'][i],\n",
        "                  'max_depth': xgb_param['max_depth'][i],\n",
        "                  'gamma': xgb_param['gamma'][i],\n",
        "                  'lambda': xgb_param['lambda'][i],\n",
        "                  'alpha': xgb_param['alpha'][i],\n",
        "                  'eval_metric': 'aucpr'\n",
        "                  }\n",
        "\n",
        "    print(hyperparams)\n",
        "    out=xgb.cv(params=hyperparams,\n",
        "              num_boost_round=20,\n",
        "              dtrain=dtrain,\n",
        "              nfold=5,\n",
        "              stratified=True,\n",
        "              early_stopping_rounds=3,\n",
        "              verbose_eval=1\n",
        "              )\n",
        "\n",
        "    index=out.shape[0]-1\n",
        "    result=out.iloc[index,2]\n",
        "    if i< 1.1:\n",
        "      best_result = result\n",
        "      best_params = hyperparams\n",
        "\n",
        "    if result> best_result:\n",
        "        best_result = result\n",
        "        best_params = hyperparams\n",
        "        print('result: ' ,result)\n",
        "        print('best result: ' ,best_result)\n",
        "        print('hyperparameters: ' ,hyperparams)\n",
        "        print('best hyperparameters: ' ,best_params)\n",
        "        i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejnx8bTi5lsU",
        "outputId": "34ffef96-564c-4fa6-ec92-7090cdbe9d9f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[4]\ttrain-aucpr:0.75408+0.00421\ttest-aucpr:0.74960+0.00529\n",
            "[5]\ttrain-aucpr:0.76847+0.00477\ttest-aucpr:0.76378+0.00599\n",
            "[6]\ttrain-aucpr:0.77926+0.00525\ttest-aucpr:0.77517+0.00589\n",
            "[7]\ttrain-aucpr:0.79105+0.00461\ttest-aucpr:0.78679+0.00609\n",
            "[8]\ttrain-aucpr:0.80141+0.00674\ttest-aucpr:0.79656+0.00824\n",
            "[9]\ttrain-aucpr:0.81007+0.00540\ttest-aucpr:0.80512+0.00579\n",
            "[10]\ttrain-aucpr:0.81743+0.00238\ttest-aucpr:0.81241+0.00438\n",
            "[11]\ttrain-aucpr:0.82371+0.00256\ttest-aucpr:0.81899+0.00459\n",
            "[12]\ttrain-aucpr:0.83044+0.00287\ttest-aucpr:0.82559+0.00475\n",
            "[13]\ttrain-aucpr:0.83554+0.00328\ttest-aucpr:0.83043+0.00443\n",
            "[14]\ttrain-aucpr:0.84040+0.00256\ttest-aucpr:0.83512+0.00419\n",
            "[15]\ttrain-aucpr:0.84579+0.00272\ttest-aucpr:0.84073+0.00473\n",
            "[16]\ttrain-aucpr:0.84822+0.00317\ttest-aucpr:0.84285+0.00489\n",
            "[17]\ttrain-aucpr:0.85105+0.00386\ttest-aucpr:0.84550+0.00554\n",
            "[18]\ttrain-aucpr:0.85553+0.00226\ttest-aucpr:0.84979+0.00431\n",
            "[19]\ttrain-aucpr:0.85873+0.00230\ttest-aucpr:0.85293+0.00439\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76523+0.00257\ttest-aucpr:0.75960+0.00510\n",
            "[1]\ttrain-aucpr:0.81317+0.00433\ttest-aucpr:0.80641+0.00767\n",
            "[2]\ttrain-aucpr:0.83493+0.00458\ttest-aucpr:0.82806+0.00890\n",
            "[3]\ttrain-aucpr:0.84869+0.00400\ttest-aucpr:0.84143+0.00509\n",
            "[4]\ttrain-aucpr:0.85959+0.00324\ttest-aucpr:0.85251+0.00484\n",
            "[5]\ttrain-aucpr:0.86812+0.00278\ttest-aucpr:0.86073+0.00460\n",
            "[6]\ttrain-aucpr:0.87501+0.00185\ttest-aucpr:0.86745+0.00419\n",
            "[7]\ttrain-aucpr:0.88107+0.00109\ttest-aucpr:0.87327+0.00299\n",
            "[8]\ttrain-aucpr:0.88793+0.00229\ttest-aucpr:0.87997+0.00405\n",
            "[9]\ttrain-aucpr:0.89288+0.00128\ttest-aucpr:0.88506+0.00273\n",
            "[10]\ttrain-aucpr:0.89756+0.00170\ttest-aucpr:0.88975+0.00265\n",
            "[11]\ttrain-aucpr:0.90112+0.00158\ttest-aucpr:0.89307+0.00245\n",
            "[12]\ttrain-aucpr:0.90575+0.00149\ttest-aucpr:0.89781+0.00247\n",
            "[13]\ttrain-aucpr:0.90972+0.00255\ttest-aucpr:0.90192+0.00296\n",
            "[14]\ttrain-aucpr:0.91214+0.00228\ttest-aucpr:0.90429+0.00214\n",
            "[15]\ttrain-aucpr:0.91574+0.00200\ttest-aucpr:0.90788+0.00255\n",
            "[16]\ttrain-aucpr:0.91903+0.00137\ttest-aucpr:0.91088+0.00271\n",
            "[17]\ttrain-aucpr:0.92103+0.00195\ttest-aucpr:0.91279+0.00301\n",
            "[18]\ttrain-aucpr:0.92278+0.00175\ttest-aucpr:0.91456+0.00278\n",
            "[19]\ttrain-aucpr:0.92500+0.00143\ttest-aucpr:0.91674+0.00246\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90544+0.00177\ttest-aucpr:0.87684+0.00343\n",
            "[1]\ttrain-aucpr:0.93903+0.00090\ttest-aucpr:0.91416+0.00303\n",
            "[2]\ttrain-aucpr:0.95246+0.00155\ttest-aucpr:0.92809+0.00228\n",
            "[3]\ttrain-aucpr:0.96069+0.00172\ttest-aucpr:0.93673+0.00246\n",
            "[4]\ttrain-aucpr:0.96729+0.00102\ttest-aucpr:0.94384+0.00143\n",
            "[5]\ttrain-aucpr:0.97162+0.00075\ttest-aucpr:0.94861+0.00090\n",
            "[6]\ttrain-aucpr:0.97573+0.00079\ttest-aucpr:0.95303+0.00131\n",
            "[7]\ttrain-aucpr:0.97781+0.00034\ttest-aucpr:0.95545+0.00119\n",
            "[8]\ttrain-aucpr:0.97984+0.00112\ttest-aucpr:0.95768+0.00190\n",
            "[9]\ttrain-aucpr:0.98150+0.00073\ttest-aucpr:0.95963+0.00150\n",
            "[10]\ttrain-aucpr:0.98244+0.00063\ttest-aucpr:0.96080+0.00136\n",
            "[11]\ttrain-aucpr:0.98363+0.00063\ttest-aucpr:0.96218+0.00142\n",
            "[12]\ttrain-aucpr:0.98471+0.00073\ttest-aucpr:0.96330+0.00100\n",
            "[13]\ttrain-aucpr:0.98555+0.00066\ttest-aucpr:0.96411+0.00103\n",
            "[14]\ttrain-aucpr:0.98653+0.00090\ttest-aucpr:0.96497+0.00065\n",
            "[15]\ttrain-aucpr:0.98740+0.00081\ttest-aucpr:0.96593+0.00088\n",
            "[16]\ttrain-aucpr:0.98816+0.00039\ttest-aucpr:0.96663+0.00138\n",
            "[17]\ttrain-aucpr:0.98862+0.00037\ttest-aucpr:0.96695+0.00146\n",
            "[18]\ttrain-aucpr:0.98938+0.00029\ttest-aucpr:0.96725+0.00118\n",
            "[19]\ttrain-aucpr:0.98984+0.00031\ttest-aucpr:0.96766+0.00128\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64767+0.00084\ttest-aucpr:0.64463+0.00373\n",
            "[1]\ttrain-aucpr:0.69181+0.00117\ttest-aucpr:0.68882+0.00400\n",
            "[2]\ttrain-aucpr:0.70693+0.00416\ttest-aucpr:0.70312+0.00656\n",
            "[3]\ttrain-aucpr:0.71828+0.00555\ttest-aucpr:0.71378+0.00674\n",
            "[4]\ttrain-aucpr:0.73122+0.00372\ttest-aucpr:0.72748+0.00376\n",
            "[5]\ttrain-aucpr:0.73653+0.00530\ttest-aucpr:0.73273+0.00504\n",
            "[6]\ttrain-aucpr:0.74282+0.00357\ttest-aucpr:0.73905+0.00288\n",
            "[7]\ttrain-aucpr:0.74469+0.00402\ttest-aucpr:0.74085+0.00317\n",
            "[8]\ttrain-aucpr:0.74884+0.00297\ttest-aucpr:0.74489+0.00197\n",
            "[9]\ttrain-aucpr:0.75033+0.00232\ttest-aucpr:0.74691+0.00165\n",
            "[10]\ttrain-aucpr:0.75296+0.00282\ttest-aucpr:0.74945+0.00248\n",
            "[11]\ttrain-aucpr:0.75573+0.00278\ttest-aucpr:0.75222+0.00411\n",
            "[12]\ttrain-aucpr:0.75820+0.00383\ttest-aucpr:0.75444+0.00365\n",
            "[13]\ttrain-aucpr:0.76035+0.00420\ttest-aucpr:0.75671+0.00403\n",
            "[14]\ttrain-aucpr:0.76426+0.00359\ttest-aucpr:0.76028+0.00461\n",
            "[15]\ttrain-aucpr:0.76773+0.00329\ttest-aucpr:0.76348+0.00360\n",
            "[16]\ttrain-aucpr:0.77092+0.00144\ttest-aucpr:0.76686+0.00233\n",
            "[17]\ttrain-aucpr:0.77383+0.00184\ttest-aucpr:0.76999+0.00250\n",
            "[18]\ttrain-aucpr:0.77867+0.00203\ttest-aucpr:0.77480+0.00317\n",
            "[19]\ttrain-aucpr:0.78227+0.00217\ttest-aucpr:0.77817+0.00216\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76525+0.00256\ttest-aucpr:0.75937+0.00527\n",
            "[1]\ttrain-aucpr:0.80400+0.00583\ttest-aucpr:0.79756+0.00874\n",
            "[2]\ttrain-aucpr:0.82247+0.00367\ttest-aucpr:0.81589+0.00856\n",
            "[3]\ttrain-aucpr:0.82979+0.00227\ttest-aucpr:0.82327+0.00745\n",
            "[4]\ttrain-aucpr:0.83720+0.00158\ttest-aucpr:0.83111+0.00463\n",
            "[5]\ttrain-aucpr:0.84250+0.00191\ttest-aucpr:0.83628+0.00477\n",
            "[6]\ttrain-aucpr:0.84828+0.00217\ttest-aucpr:0.84188+0.00518\n",
            "[7]\ttrain-aucpr:0.85247+0.00169\ttest-aucpr:0.84563+0.00530\n",
            "[8]\ttrain-aucpr:0.85698+0.00222\ttest-aucpr:0.85007+0.00537\n",
            "[9]\ttrain-aucpr:0.86081+0.00283\ttest-aucpr:0.85381+0.00517\n",
            "[10]\ttrain-aucpr:0.86421+0.00210\ttest-aucpr:0.85741+0.00469\n",
            "[11]\ttrain-aucpr:0.86847+0.00132\ttest-aucpr:0.86170+0.00373\n",
            "[12]\ttrain-aucpr:0.87167+0.00156\ttest-aucpr:0.86491+0.00350\n",
            "[13]\ttrain-aucpr:0.87432+0.00181\ttest-aucpr:0.86747+0.00341\n",
            "[14]\ttrain-aucpr:0.87726+0.00169\ttest-aucpr:0.87020+0.00376\n",
            "[15]\ttrain-aucpr:0.88006+0.00189\ttest-aucpr:0.87276+0.00384\n",
            "[16]\ttrain-aucpr:0.88258+0.00209\ttest-aucpr:0.87532+0.00397\n",
            "[17]\ttrain-aucpr:0.88442+0.00206\ttest-aucpr:0.87697+0.00353\n",
            "[18]\ttrain-aucpr:0.88652+0.00213\ttest-aucpr:0.87894+0.00383\n",
            "[19]\ttrain-aucpr:0.88898+0.00173\ttest-aucpr:0.88152+0.00342\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89920+0.00152\ttest-aucpr:0.87556+0.00381\n",
            "[1]\ttrain-aucpr:0.92262+0.00394\ttest-aucpr:0.89941+0.00561\n",
            "[2]\ttrain-aucpr:0.93568+0.00245\ttest-aucpr:0.91372+0.00446\n",
            "[3]\ttrain-aucpr:0.94472+0.00106\ttest-aucpr:0.92365+0.00202\n",
            "[4]\ttrain-aucpr:0.94995+0.00105\ttest-aucpr:0.92959+0.00282\n",
            "[5]\ttrain-aucpr:0.95335+0.00115\ttest-aucpr:0.93317+0.00249\n",
            "[6]\ttrain-aucpr:0.95620+0.00083\ttest-aucpr:0.93629+0.00213\n",
            "[7]\ttrain-aucpr:0.95863+0.00086\ttest-aucpr:0.93893+0.00224\n",
            "[8]\ttrain-aucpr:0.96098+0.00048\ttest-aucpr:0.94126+0.00179\n",
            "[9]\ttrain-aucpr:0.96299+0.00052\ttest-aucpr:0.94342+0.00181\n",
            "[10]\ttrain-aucpr:0.96480+0.00034\ttest-aucpr:0.94538+0.00139\n",
            "[11]\ttrain-aucpr:0.96612+0.00044\ttest-aucpr:0.94669+0.00150\n",
            "[12]\ttrain-aucpr:0.96784+0.00045\ttest-aucpr:0.94848+0.00158\n",
            "[13]\ttrain-aucpr:0.96887+0.00043\ttest-aucpr:0.94955+0.00164\n",
            "[14]\ttrain-aucpr:0.97034+0.00044\ttest-aucpr:0.95100+0.00140\n",
            "[15]\ttrain-aucpr:0.97138+0.00040\ttest-aucpr:0.95211+0.00125\n",
            "[16]\ttrain-aucpr:0.97235+0.00042\ttest-aucpr:0.95320+0.00099\n",
            "[17]\ttrain-aucpr:0.97326+0.00035\ttest-aucpr:0.95419+0.00099\n",
            "[18]\ttrain-aucpr:0.97392+0.00031\ttest-aucpr:0.95483+0.00088\n",
            "[19]\ttrain-aucpr:0.97490+0.00031\ttest-aucpr:0.95587+0.00070\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.97771+0.00083\ttest-aucpr:0.88809+0.00139\n",
            "[1]\ttrain-aucpr:0.98787+0.00091\ttest-aucpr:0.91082+0.00312\n",
            "[2]\ttrain-aucpr:0.99173+0.00090\ttest-aucpr:0.92165+0.00464\n",
            "[3]\ttrain-aucpr:0.99416+0.00073\ttest-aucpr:0.93047+0.00487\n",
            "[4]\ttrain-aucpr:0.99575+0.00067\ttest-aucpr:0.93649+0.00502\n",
            "[5]\ttrain-aucpr:0.99698+0.00036\ttest-aucpr:0.94273+0.00398\n",
            "[6]\ttrain-aucpr:0.99766+0.00022\ttest-aucpr:0.94714+0.00308\n",
            "[7]\ttrain-aucpr:0.99811+0.00013\ttest-aucpr:0.95017+0.00289\n",
            "[8]\ttrain-aucpr:0.99847+0.00006\ttest-aucpr:0.95317+0.00237\n",
            "[9]\ttrain-aucpr:0.99870+0.00007\ttest-aucpr:0.95481+0.00251\n",
            "[10]\ttrain-aucpr:0.99892+0.00005\ttest-aucpr:0.95648+0.00227\n",
            "[11]\ttrain-aucpr:0.99908+0.00004\ttest-aucpr:0.95809+0.00190\n",
            "[12]\ttrain-aucpr:0.99921+0.00003\ttest-aucpr:0.95954+0.00177\n",
            "[13]\ttrain-aucpr:0.99932+0.00002\ttest-aucpr:0.96052+0.00176\n",
            "[14]\ttrain-aucpr:0.99941+0.00002\ttest-aucpr:0.96136+0.00174\n",
            "[15]\ttrain-aucpr:0.99949+0.00004\ttest-aucpr:0.96214+0.00162\n",
            "[16]\ttrain-aucpr:0.99955+0.00004\ttest-aucpr:0.96290+0.00146\n",
            "[17]\ttrain-aucpr:0.99961+0.00004\ttest-aucpr:0.96348+0.00144\n",
            "[18]\ttrain-aucpr:0.99966+0.00003\ttest-aucpr:0.96426+0.00161\n",
            "[19]\ttrain-aucpr:0.99971+0.00002\ttest-aucpr:0.96484+0.00165\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94223+0.00142\ttest-aucpr:0.88912+0.00368\n",
            "[1]\ttrain-aucpr:0.96056+0.00233\ttest-aucpr:0.91002+0.00106\n",
            "[2]\ttrain-aucpr:0.97011+0.00145\ttest-aucpr:0.92257+0.00383\n",
            "[3]\ttrain-aucpr:0.97772+0.00115\ttest-aucpr:0.93301+0.00314\n",
            "[4]\ttrain-aucpr:0.98197+0.00071\ttest-aucpr:0.93945+0.00365\n",
            "[5]\ttrain-aucpr:0.98496+0.00047\ttest-aucpr:0.94474+0.00310\n",
            "[6]\ttrain-aucpr:0.98702+0.00024\ttest-aucpr:0.94798+0.00235\n",
            "[7]\ttrain-aucpr:0.98839+0.00041\ttest-aucpr:0.95010+0.00199\n",
            "[8]\ttrain-aucpr:0.98962+0.00050\ttest-aucpr:0.95209+0.00168\n",
            "[9]\ttrain-aucpr:0.99059+0.00038\ttest-aucpr:0.95407+0.00162\n",
            "[10]\ttrain-aucpr:0.99145+0.00032\ttest-aucpr:0.95562+0.00155\n",
            "[11]\ttrain-aucpr:0.99205+0.00030\ttest-aucpr:0.95680+0.00163\n",
            "[12]\ttrain-aucpr:0.99259+0.00029\ttest-aucpr:0.95785+0.00162\n",
            "[13]\ttrain-aucpr:0.99316+0.00022\ttest-aucpr:0.95917+0.00169\n",
            "[14]\ttrain-aucpr:0.99368+0.00018\ttest-aucpr:0.96026+0.00177\n",
            "[15]\ttrain-aucpr:0.99414+0.00015\ttest-aucpr:0.96118+0.00156\n",
            "[16]\ttrain-aucpr:0.99463+0.00013\ttest-aucpr:0.96212+0.00145\n",
            "[17]\ttrain-aucpr:0.99496+0.00016\ttest-aucpr:0.96283+0.00144\n",
            "[18]\ttrain-aucpr:0.99527+0.00016\ttest-aucpr:0.96352+0.00134\n",
            "[19]\ttrain-aucpr:0.99556+0.00014\ttest-aucpr:0.96410+0.00124\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95385+0.00145\ttest-aucpr:0.89057+0.00365\n",
            "[1]\ttrain-aucpr:0.98005+0.00167\ttest-aucpr:0.92255+0.00436\n",
            "[2]\ttrain-aucpr:0.98902+0.00054\ttest-aucpr:0.93770+0.00177\n",
            "[3]\ttrain-aucpr:0.99273+0.00032\ttest-aucpr:0.94496+0.00105\n",
            "[4]\ttrain-aucpr:0.99502+0.00022\ttest-aucpr:0.94966+0.00082\n",
            "[5]\ttrain-aucpr:0.99657+0.00012\ttest-aucpr:0.95359+0.00091\n",
            "[6]\ttrain-aucpr:0.99742+0.00011\ttest-aucpr:0.95651+0.00090\n",
            "[7]\ttrain-aucpr:0.99807+0.00010\ttest-aucpr:0.95900+0.00083\n",
            "[8]\ttrain-aucpr:0.99853+0.00010\ttest-aucpr:0.96093+0.00080\n",
            "[9]\ttrain-aucpr:0.99894+0.00005\ttest-aucpr:0.96254+0.00081\n",
            "[10]\ttrain-aucpr:0.99920+0.00002\ttest-aucpr:0.96393+0.00094\n",
            "[11]\ttrain-aucpr:0.99939+0.00003\ttest-aucpr:0.96528+0.00101\n",
            "[12]\ttrain-aucpr:0.99953+0.00002\ttest-aucpr:0.96632+0.00099\n",
            "[13]\ttrain-aucpr:0.99964+0.00002\ttest-aucpr:0.96721+0.00110\n",
            "[14]\ttrain-aucpr:0.99973+0.00002\ttest-aucpr:0.96809+0.00104\n",
            "[15]\ttrain-aucpr:0.99979+0.00001\ttest-aucpr:0.96892+0.00109\n",
            "[16]\ttrain-aucpr:0.99984+0.00002\ttest-aucpr:0.96960+0.00101\n",
            "[17]\ttrain-aucpr:0.99988+0.00002\ttest-aucpr:0.97021+0.00103\n",
            "[18]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.97080+0.00101\n",
            "[19]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.97134+0.00087\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76523+0.00257\ttest-aucpr:0.75961+0.00509\n",
            "[1]\ttrain-aucpr:0.81571+0.00372\ttest-aucpr:0.80973+0.00657\n",
            "[2]\ttrain-aucpr:0.83990+0.00520\ttest-aucpr:0.83439+0.00900\n",
            "[3]\ttrain-aucpr:0.85542+0.00467\ttest-aucpr:0.85012+0.00659\n",
            "[4]\ttrain-aucpr:0.86770+0.00443\ttest-aucpr:0.86198+0.00684\n",
            "[5]\ttrain-aucpr:0.87682+0.00372\ttest-aucpr:0.87073+0.00584\n",
            "[6]\ttrain-aucpr:0.88535+0.00186\ttest-aucpr:0.87896+0.00427\n",
            "[7]\ttrain-aucpr:0.89159+0.00284\ttest-aucpr:0.88465+0.00477\n",
            "[8]\ttrain-aucpr:0.89811+0.00324\ttest-aucpr:0.89078+0.00432\n",
            "[9]\ttrain-aucpr:0.90298+0.00306\ttest-aucpr:0.89557+0.00457\n",
            "[10]\ttrain-aucpr:0.90722+0.00210\ttest-aucpr:0.89970+0.00367\n",
            "[11]\ttrain-aucpr:0.91149+0.00353\ttest-aucpr:0.90401+0.00446\n",
            "[12]\ttrain-aucpr:0.91480+0.00302\ttest-aucpr:0.90695+0.00396\n",
            "[13]\ttrain-aucpr:0.91814+0.00250\ttest-aucpr:0.91011+0.00368\n",
            "[14]\ttrain-aucpr:0.92085+0.00229\ttest-aucpr:0.91272+0.00395\n",
            "[15]\ttrain-aucpr:0.92438+0.00196\ttest-aucpr:0.91613+0.00360\n",
            "[16]\ttrain-aucpr:0.92630+0.00100\ttest-aucpr:0.91782+0.00275\n",
            "[17]\ttrain-aucpr:0.92786+0.00139\ttest-aucpr:0.91925+0.00316\n",
            "[18]\ttrain-aucpr:0.93050+0.00142\ttest-aucpr:0.92187+0.00323\n",
            "[19]\ttrain-aucpr:0.93188+0.00133\ttest-aucpr:0.92313+0.00284\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76522+0.00255\ttest-aucpr:0.75963+0.00507\n",
            "[1]\ttrain-aucpr:0.81641+0.00410\ttest-aucpr:0.81055+0.00604\n",
            "[2]\ttrain-aucpr:0.84080+0.00490\ttest-aucpr:0.83557+0.00787\n",
            "[3]\ttrain-aucpr:0.85544+0.00458\ttest-aucpr:0.85024+0.00633\n",
            "[4]\ttrain-aucpr:0.86649+0.00526\ttest-aucpr:0.86088+0.00653\n",
            "[5]\ttrain-aucpr:0.87585+0.00455\ttest-aucpr:0.86991+0.00559\n",
            "[6]\ttrain-aucpr:0.88452+0.00332\ttest-aucpr:0.87888+0.00393\n",
            "[7]\ttrain-aucpr:0.89210+0.00218\ttest-aucpr:0.88635+0.00290\n",
            "[8]\ttrain-aucpr:0.89858+0.00253\ttest-aucpr:0.89249+0.00306\n",
            "[9]\ttrain-aucpr:0.90441+0.00132\ttest-aucpr:0.89804+0.00224\n",
            "[10]\ttrain-aucpr:0.90862+0.00118\ttest-aucpr:0.90204+0.00183\n",
            "[11]\ttrain-aucpr:0.91320+0.00114\ttest-aucpr:0.90656+0.00135\n",
            "[12]\ttrain-aucpr:0.91702+0.00116\ttest-aucpr:0.91035+0.00109\n",
            "[13]\ttrain-aucpr:0.91925+0.00131\ttest-aucpr:0.91253+0.00140\n",
            "[14]\ttrain-aucpr:0.92193+0.00126\ttest-aucpr:0.91501+0.00162\n",
            "[15]\ttrain-aucpr:0.92448+0.00053\ttest-aucpr:0.91732+0.00140\n",
            "[16]\ttrain-aucpr:0.92736+0.00111\ttest-aucpr:0.92020+0.00216\n",
            "[17]\ttrain-aucpr:0.92971+0.00085\ttest-aucpr:0.92259+0.00178\n",
            "[18]\ttrain-aucpr:0.93149+0.00086\ttest-aucpr:0.92424+0.00186\n",
            "[19]\ttrain-aucpr:0.93300+0.00127\ttest-aucpr:0.92568+0.00244\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64767+0.00084\ttest-aucpr:0.64463+0.00373\n",
            "[1]\ttrain-aucpr:0.70081+0.00570\ttest-aucpr:0.69633+0.00766\n",
            "[2]\ttrain-aucpr:0.72032+0.00589\ttest-aucpr:0.71773+0.00690\n",
            "[3]\ttrain-aucpr:0.73278+0.00425\ttest-aucpr:0.72975+0.00304\n",
            "[4]\ttrain-aucpr:0.74280+0.00719\ttest-aucpr:0.73981+0.00607\n",
            "[5]\ttrain-aucpr:0.75304+0.00337\ttest-aucpr:0.74980+0.00377\n",
            "[6]\ttrain-aucpr:0.76702+0.00460\ttest-aucpr:0.76324+0.00391\n",
            "[7]\ttrain-aucpr:0.77548+0.00551\ttest-aucpr:0.77141+0.00340\n",
            "[8]\ttrain-aucpr:0.78255+0.00440\ttest-aucpr:0.77807+0.00384\n",
            "[9]\ttrain-aucpr:0.79044+0.00231\ttest-aucpr:0.78582+0.00272\n",
            "[10]\ttrain-aucpr:0.79437+0.00142\ttest-aucpr:0.79001+0.00245\n",
            "[11]\ttrain-aucpr:0.80148+0.00227\ttest-aucpr:0.79691+0.00147\n",
            "[12]\ttrain-aucpr:0.81214+0.00451\ttest-aucpr:0.80750+0.00596\n",
            "[13]\ttrain-aucpr:0.81892+0.00425\ttest-aucpr:0.81445+0.00458\n",
            "[14]\ttrain-aucpr:0.82513+0.00438\ttest-aucpr:0.82042+0.00542\n",
            "[15]\ttrain-aucpr:0.83043+0.00515\ttest-aucpr:0.82580+0.00617\n",
            "[16]\ttrain-aucpr:0.83551+0.00546\ttest-aucpr:0.83081+0.00699\n",
            "[17]\ttrain-aucpr:0.83925+0.00587\ttest-aucpr:0.83444+0.00742\n",
            "[18]\ttrain-aucpr:0.84311+0.00471\ttest-aucpr:0.83831+0.00602\n",
            "[19]\ttrain-aucpr:0.84662+0.00408\ttest-aucpr:0.84185+0.00579\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64767+0.00084\ttest-aucpr:0.64463+0.00373\n",
            "[1]\ttrain-aucpr:0.70082+0.00569\ttest-aucpr:0.69635+0.00764\n",
            "[2]\ttrain-aucpr:0.72031+0.00589\ttest-aucpr:0.71771+0.00690\n",
            "[3]\ttrain-aucpr:0.73277+0.00425\ttest-aucpr:0.72975+0.00304\n",
            "[4]\ttrain-aucpr:0.74279+0.00718\ttest-aucpr:0.73981+0.00607\n",
            "[5]\ttrain-aucpr:0.75302+0.00336\ttest-aucpr:0.74979+0.00377\n",
            "[6]\ttrain-aucpr:0.76699+0.00461\ttest-aucpr:0.76322+0.00391\n",
            "[7]\ttrain-aucpr:0.77544+0.00551\ttest-aucpr:0.77138+0.00340\n",
            "[8]\ttrain-aucpr:0.78251+0.00441\ttest-aucpr:0.77804+0.00385\n",
            "[9]\ttrain-aucpr:0.79032+0.00232\ttest-aucpr:0.78574+0.00278\n",
            "[10]\ttrain-aucpr:0.79415+0.00153\ttest-aucpr:0.78975+0.00260\n",
            "[11]\ttrain-aucpr:0.80175+0.00183\ttest-aucpr:0.79722+0.00131\n",
            "[12]\ttrain-aucpr:0.80990+0.00293\ttest-aucpr:0.80508+0.00380\n",
            "[13]\ttrain-aucpr:0.81683+0.00379\ttest-aucpr:0.81234+0.00315\n",
            "[14]\ttrain-aucpr:0.82266+0.00371\ttest-aucpr:0.81813+0.00299\n",
            "[15]\ttrain-aucpr:0.82720+0.00327\ttest-aucpr:0.82244+0.00332\n",
            "[16]\ttrain-aucpr:0.83407+0.00376\ttest-aucpr:0.82915+0.00521\n",
            "[17]\ttrain-aucpr:0.83782+0.00429\ttest-aucpr:0.83277+0.00557\n",
            "[18]\ttrain-aucpr:0.84159+0.00383\ttest-aucpr:0.83641+0.00514\n",
            "[19]\ttrain-aucpr:0.84439+0.00351\ttest-aucpr:0.83917+0.00541\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90330+0.00141\ttest-aucpr:0.87617+0.00368\n",
            "[1]\ttrain-aucpr:0.93587+0.00188\ttest-aucpr:0.91219+0.00317\n",
            "[2]\ttrain-aucpr:0.94763+0.00167\ttest-aucpr:0.92471+0.00134\n",
            "[3]\ttrain-aucpr:0.95616+0.00111\ttest-aucpr:0.93364+0.00151\n",
            "[4]\ttrain-aucpr:0.96240+0.00056\ttest-aucpr:0.94004+0.00159\n",
            "[5]\ttrain-aucpr:0.96747+0.00039\ttest-aucpr:0.94502+0.00156\n",
            "[6]\ttrain-aucpr:0.97074+0.00037\ttest-aucpr:0.94841+0.00116\n",
            "[7]\ttrain-aucpr:0.97358+0.00065\ttest-aucpr:0.95132+0.00130\n",
            "[8]\ttrain-aucpr:0.97608+0.00064\ttest-aucpr:0.95406+0.00118\n",
            "[9]\ttrain-aucpr:0.97826+0.00074\ttest-aucpr:0.95610+0.00093\n",
            "[10]\ttrain-aucpr:0.97984+0.00058\ttest-aucpr:0.95776+0.00068\n",
            "[11]\ttrain-aucpr:0.98100+0.00056\ttest-aucpr:0.95907+0.00112\n",
            "[12]\ttrain-aucpr:0.98220+0.00048\ttest-aucpr:0.96075+0.00059\n",
            "[13]\ttrain-aucpr:0.98321+0.00039\ttest-aucpr:0.96193+0.00047\n",
            "[14]\ttrain-aucpr:0.98397+0.00048\ttest-aucpr:0.96293+0.00067\n",
            "[15]\ttrain-aucpr:0.98445+0.00041\ttest-aucpr:0.96346+0.00067\n",
            "[16]\ttrain-aucpr:0.98522+0.00058\ttest-aucpr:0.96447+0.00047\n",
            "[17]\ttrain-aucpr:0.98603+0.00060\ttest-aucpr:0.96535+0.00094\n",
            "[18]\ttrain-aucpr:0.98644+0.00050\ttest-aucpr:0.96587+0.00091\n",
            "[19]\ttrain-aucpr:0.98709+0.00065\ttest-aucpr:0.96655+0.00087\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76522+0.00255\ttest-aucpr:0.75963+0.00507\n",
            "[1]\ttrain-aucpr:0.81641+0.00410\ttest-aucpr:0.81055+0.00604\n",
            "[2]\ttrain-aucpr:0.84080+0.00490\ttest-aucpr:0.83557+0.00787\n",
            "[3]\ttrain-aucpr:0.85544+0.00458\ttest-aucpr:0.85024+0.00633\n",
            "[4]\ttrain-aucpr:0.86649+0.00526\ttest-aucpr:0.86088+0.00653\n",
            "[5]\ttrain-aucpr:0.87585+0.00455\ttest-aucpr:0.86991+0.00559\n",
            "[6]\ttrain-aucpr:0.88452+0.00332\ttest-aucpr:0.87888+0.00393\n",
            "[7]\ttrain-aucpr:0.89210+0.00218\ttest-aucpr:0.88635+0.00290\n",
            "[8]\ttrain-aucpr:0.89859+0.00252\ttest-aucpr:0.89249+0.00305\n",
            "[9]\ttrain-aucpr:0.90430+0.00142\ttest-aucpr:0.89793+0.00223\n",
            "[10]\ttrain-aucpr:0.90772+0.00159\ttest-aucpr:0.90112+0.00076\n",
            "[11]\ttrain-aucpr:0.91284+0.00199\ttest-aucpr:0.90619+0.00090\n",
            "[12]\ttrain-aucpr:0.91656+0.00210\ttest-aucpr:0.91003+0.00084\n",
            "[13]\ttrain-aucpr:0.91860+0.00252\ttest-aucpr:0.91197+0.00105\n",
            "[14]\ttrain-aucpr:0.92132+0.00220\ttest-aucpr:0.91446+0.00087\n",
            "[15]\ttrain-aucpr:0.92445+0.00079\ttest-aucpr:0.91736+0.00122\n",
            "[16]\ttrain-aucpr:0.92689+0.00122\ttest-aucpr:0.91967+0.00233\n",
            "[17]\ttrain-aucpr:0.92941+0.00103\ttest-aucpr:0.92224+0.00163\n",
            "[18]\ttrain-aucpr:0.93119+0.00081\ttest-aucpr:0.92385+0.00150\n",
            "[19]\ttrain-aucpr:0.93280+0.00124\ttest-aucpr:0.92528+0.00146\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76523+0.00257\ttest-aucpr:0.75961+0.00509\n",
            "[1]\ttrain-aucpr:0.81324+0.00433\ttest-aucpr:0.80651+0.00765\n",
            "[2]\ttrain-aucpr:0.83499+0.00457\ttest-aucpr:0.82813+0.00889\n",
            "[3]\ttrain-aucpr:0.84877+0.00400\ttest-aucpr:0.84154+0.00507\n",
            "[4]\ttrain-aucpr:0.85969+0.00323\ttest-aucpr:0.85261+0.00483\n",
            "[5]\ttrain-aucpr:0.86821+0.00277\ttest-aucpr:0.86082+0.00460\n",
            "[6]\ttrain-aucpr:0.87503+0.00169\ttest-aucpr:0.86737+0.00389\n",
            "[7]\ttrain-aucpr:0.88121+0.00113\ttest-aucpr:0.87340+0.00307\n",
            "[8]\ttrain-aucpr:0.88712+0.00111\ttest-aucpr:0.87939+0.00294\n",
            "[9]\ttrain-aucpr:0.89250+0.00088\ttest-aucpr:0.88478+0.00214\n",
            "[10]\ttrain-aucpr:0.89699+0.00124\ttest-aucpr:0.88928+0.00170\n",
            "[11]\ttrain-aucpr:0.90066+0.00129\ttest-aucpr:0.89276+0.00161\n",
            "[12]\ttrain-aucpr:0.90596+0.00126\ttest-aucpr:0.89802+0.00241\n",
            "[13]\ttrain-aucpr:0.90799+0.00155\ttest-aucpr:0.90008+0.00228\n",
            "[14]\ttrain-aucpr:0.91191+0.00223\ttest-aucpr:0.90393+0.00261\n",
            "[15]\ttrain-aucpr:0.91562+0.00215\ttest-aucpr:0.90784+0.00321\n",
            "[16]\ttrain-aucpr:0.91953+0.00237\ttest-aucpr:0.91173+0.00354\n",
            "[17]\ttrain-aucpr:0.92221+0.00207\ttest-aucpr:0.91423+0.00268\n",
            "[18]\ttrain-aucpr:0.92458+0.00232\ttest-aucpr:0.91645+0.00290\n",
            "[19]\ttrain-aucpr:0.92642+0.00156\ttest-aucpr:0.91830+0.00200\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95127+0.00139\ttest-aucpr:0.89189+0.00321\n",
            "[1]\ttrain-aucpr:0.98050+0.00121\ttest-aucpr:0.92602+0.00312\n",
            "[2]\ttrain-aucpr:0.98923+0.00045\ttest-aucpr:0.93987+0.00214\n",
            "[3]\ttrain-aucpr:0.99330+0.00019\ttest-aucpr:0.94807+0.00173\n",
            "[4]\ttrain-aucpr:0.99538+0.00009\ttest-aucpr:0.95338+0.00180\n",
            "[5]\ttrain-aucpr:0.99677+0.00013\ttest-aucpr:0.95742+0.00135\n",
            "[6]\ttrain-aucpr:0.99763+0.00008\ttest-aucpr:0.96010+0.00098\n",
            "[7]\ttrain-aucpr:0.99831+0.00009\ttest-aucpr:0.96225+0.00077\n",
            "[8]\ttrain-aucpr:0.99874+0.00008\ttest-aucpr:0.96422+0.00075\n",
            "[9]\ttrain-aucpr:0.99907+0.00006\ttest-aucpr:0.96593+0.00071\n",
            "[10]\ttrain-aucpr:0.99929+0.00005\ttest-aucpr:0.96730+0.00075\n",
            "[11]\ttrain-aucpr:0.99944+0.00003\ttest-aucpr:0.96827+0.00090\n",
            "[12]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.96929+0.00083\n",
            "[13]\ttrain-aucpr:0.99966+0.00003\ttest-aucpr:0.97003+0.00077\n",
            "[14]\ttrain-aucpr:0.99973+0.00003\ttest-aucpr:0.97074+0.00065\n",
            "[15]\ttrain-aucpr:0.99977+0.00003\ttest-aucpr:0.97109+0.00086\n",
            "[16]\ttrain-aucpr:0.99982+0.00003\ttest-aucpr:0.97164+0.00073\n",
            "[17]\ttrain-aucpr:0.99986+0.00002\ttest-aucpr:0.97205+0.00093\n",
            "[18]\ttrain-aucpr:0.99990+0.00002\ttest-aucpr:0.97234+0.00096\n",
            "[19]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.97251+0.00092\n",
            "result:  0.9725139882659077\n",
            "best result:  0.9725139882659077\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76523+0.00257\ttest-aucpr:0.75960+0.00510\n",
            "[1]\ttrain-aucpr:0.80399+0.00583\ttest-aucpr:0.79755+0.00874\n",
            "[2]\ttrain-aucpr:0.82246+0.00368\ttest-aucpr:0.81583+0.00863\n",
            "[3]\ttrain-aucpr:0.82971+0.00238\ttest-aucpr:0.82355+0.00712\n",
            "[4]\ttrain-aucpr:0.83617+0.00159\ttest-aucpr:0.83002+0.00599\n",
            "[5]\ttrain-aucpr:0.84193+0.00225\ttest-aucpr:0.83563+0.00570\n",
            "[6]\ttrain-aucpr:0.84796+0.00228\ttest-aucpr:0.84162+0.00546\n",
            "[7]\ttrain-aucpr:0.85260+0.00167\ttest-aucpr:0.84591+0.00503\n",
            "[8]\ttrain-aucpr:0.85707+0.00223\ttest-aucpr:0.85029+0.00518\n",
            "[9]\ttrain-aucpr:0.86038+0.00270\ttest-aucpr:0.85339+0.00547\n",
            "[10]\ttrain-aucpr:0.86380+0.00209\ttest-aucpr:0.85696+0.00512\n",
            "[11]\ttrain-aucpr:0.86798+0.00138\ttest-aucpr:0.86113+0.00434\n",
            "[12]\ttrain-aucpr:0.87110+0.00141\ttest-aucpr:0.86429+0.00407\n",
            "[13]\ttrain-aucpr:0.87389+0.00158\ttest-aucpr:0.86691+0.00384\n",
            "[14]\ttrain-aucpr:0.87692+0.00164\ttest-aucpr:0.86973+0.00415\n",
            "[15]\ttrain-aucpr:0.87974+0.00187\ttest-aucpr:0.87238+0.00420\n",
            "[16]\ttrain-aucpr:0.88240+0.00207\ttest-aucpr:0.87518+0.00410\n",
            "[17]\ttrain-aucpr:0.88398+0.00190\ttest-aucpr:0.87657+0.00383\n",
            "[18]\ttrain-aucpr:0.88648+0.00212\ttest-aucpr:0.87891+0.00388\n",
            "[19]\ttrain-aucpr:0.88870+0.00168\ttest-aucpr:0.88126+0.00366\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90218+0.00171\ttest-aucpr:0.87645+0.00346\n",
            "[1]\ttrain-aucpr:0.93675+0.00138\ttest-aucpr:0.91354+0.00327\n",
            "[2]\ttrain-aucpr:0.95010+0.00122\ttest-aucpr:0.92771+0.00251\n",
            "[3]\ttrain-aucpr:0.96026+0.00046\ttest-aucpr:0.93850+0.00178\n",
            "[4]\ttrain-aucpr:0.96571+0.00050\ttest-aucpr:0.94452+0.00057\n",
            "[5]\ttrain-aucpr:0.97012+0.00088\ttest-aucpr:0.94934+0.00069\n",
            "[6]\ttrain-aucpr:0.97334+0.00066\ttest-aucpr:0.95276+0.00045\n",
            "[7]\ttrain-aucpr:0.97593+0.00059\ttest-aucpr:0.95570+0.00071\n",
            "[8]\ttrain-aucpr:0.97759+0.00070\ttest-aucpr:0.95769+0.00081\n",
            "[9]\ttrain-aucpr:0.97878+0.00073\ttest-aucpr:0.95906+0.00088\n",
            "[10]\ttrain-aucpr:0.98001+0.00030\ttest-aucpr:0.96061+0.00114\n",
            "[11]\ttrain-aucpr:0.98101+0.00032\ttest-aucpr:0.96187+0.00103\n",
            "[12]\ttrain-aucpr:0.98219+0.00063\ttest-aucpr:0.96297+0.00138\n",
            "[13]\ttrain-aucpr:0.98321+0.00053\ttest-aucpr:0.96422+0.00159\n",
            "[14]\ttrain-aucpr:0.98387+0.00057\ttest-aucpr:0.96498+0.00160\n",
            "[15]\ttrain-aucpr:0.98474+0.00060\ttest-aucpr:0.96608+0.00149\n",
            "[16]\ttrain-aucpr:0.98511+0.00068\ttest-aucpr:0.96642+0.00144\n",
            "[17]\ttrain-aucpr:0.98577+0.00054\ttest-aucpr:0.96707+0.00126\n",
            "[18]\ttrain-aucpr:0.98662+0.00042\ttest-aucpr:0.96783+0.00126\n",
            "[19]\ttrain-aucpr:0.98729+0.00045\ttest-aucpr:0.96818+0.00140\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.93242+0.00160\ttest-aucpr:0.89095+0.00355\n",
            "[1]\ttrain-aucpr:0.96293+0.00231\ttest-aucpr:0.92446+0.00499\n",
            "[2]\ttrain-aucpr:0.97420+0.00084\ttest-aucpr:0.93889+0.00200\n",
            "[3]\ttrain-aucpr:0.97898+0.00055\ttest-aucpr:0.94624+0.00154\n",
            "[4]\ttrain-aucpr:0.98259+0.00032\ttest-aucpr:0.95134+0.00179\n",
            "[5]\ttrain-aucpr:0.98509+0.00012\ttest-aucpr:0.95528+0.00137\n",
            "[6]\ttrain-aucpr:0.98691+0.00029\ttest-aucpr:0.95794+0.00111\n",
            "[7]\ttrain-aucpr:0.98825+0.00023\ttest-aucpr:0.96043+0.00086\n",
            "[8]\ttrain-aucpr:0.98942+0.00025\ttest-aucpr:0.96236+0.00052\n",
            "[9]\ttrain-aucpr:0.99045+0.00025\ttest-aucpr:0.96415+0.00052\n",
            "[10]\ttrain-aucpr:0.99130+0.00020\ttest-aucpr:0.96553+0.00043\n",
            "[11]\ttrain-aucpr:0.99197+0.00018\ttest-aucpr:0.96675+0.00039\n",
            "[12]\ttrain-aucpr:0.99259+0.00016\ttest-aucpr:0.96794+0.00042\n",
            "[13]\ttrain-aucpr:0.99305+0.00020\ttest-aucpr:0.96887+0.00059\n",
            "[14]\ttrain-aucpr:0.99353+0.00019\ttest-aucpr:0.96976+0.00067\n",
            "[15]\ttrain-aucpr:0.99394+0.00013\ttest-aucpr:0.97060+0.00073\n",
            "[16]\ttrain-aucpr:0.99429+0.00017\ttest-aucpr:0.97123+0.00072\n",
            "[17]\ttrain-aucpr:0.99459+0.00014\ttest-aucpr:0.97183+0.00072\n",
            "[18]\ttrain-aucpr:0.99488+0.00014\ttest-aucpr:0.97239+0.00071\n",
            "[19]\ttrain-aucpr:0.99511+0.00015\ttest-aucpr:0.97280+0.00068\n",
            "result:  0.9727995990155713\n",
            "best result:  0.9727995990155713\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64767+0.00084\ttest-aucpr:0.64463+0.00373\n",
            "[1]\ttrain-aucpr:0.70695+0.00500\ttest-aucpr:0.70186+0.00767\n",
            "[2]\ttrain-aucpr:0.72161+0.00368\ttest-aucpr:0.71765+0.00314\n",
            "[3]\ttrain-aucpr:0.73848+0.00658\ttest-aucpr:0.73476+0.00627\n",
            "[4]\ttrain-aucpr:0.75428+0.00410\ttest-aucpr:0.74961+0.00531\n",
            "[5]\ttrain-aucpr:0.76975+0.00333\ttest-aucpr:0.76520+0.00369\n",
            "[6]\ttrain-aucpr:0.77869+0.00591\ttest-aucpr:0.77462+0.00677\n",
            "[7]\ttrain-aucpr:0.79064+0.00504\ttest-aucpr:0.78635+0.00670\n",
            "[8]\ttrain-aucpr:0.80216+0.00612\ttest-aucpr:0.79738+0.00729\n",
            "[9]\ttrain-aucpr:0.80894+0.00564\ttest-aucpr:0.80427+0.00659\n",
            "[10]\ttrain-aucpr:0.81737+0.00247\ttest-aucpr:0.81242+0.00440\n",
            "[11]\ttrain-aucpr:0.82386+0.00266\ttest-aucpr:0.81893+0.00495\n",
            "[12]\ttrain-aucpr:0.82921+0.00315\ttest-aucpr:0.82409+0.00501\n",
            "[13]\ttrain-aucpr:0.83443+0.00388\ttest-aucpr:0.82894+0.00555\n",
            "[14]\ttrain-aucpr:0.83866+0.00406\ttest-aucpr:0.83316+0.00606\n",
            "[15]\ttrain-aucpr:0.84400+0.00432\ttest-aucpr:0.83891+0.00593\n",
            "[16]\ttrain-aucpr:0.84776+0.00319\ttest-aucpr:0.84234+0.00402\n",
            "[17]\ttrain-aucpr:0.85262+0.00344\ttest-aucpr:0.84711+0.00323\n",
            "[18]\ttrain-aucpr:0.85684+0.00191\ttest-aucpr:0.85110+0.00264\n",
            "[19]\ttrain-aucpr:0.85940+0.00117\ttest-aucpr:0.85370+0.00251\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64767+0.00084\ttest-aucpr:0.64463+0.00373\n",
            "[1]\ttrain-aucpr:0.70081+0.00570\ttest-aucpr:0.69633+0.00766\n",
            "[2]\ttrain-aucpr:0.72032+0.00589\ttest-aucpr:0.71773+0.00690\n",
            "[3]\ttrain-aucpr:0.73277+0.00425\ttest-aucpr:0.72974+0.00303\n",
            "[4]\ttrain-aucpr:0.74280+0.00719\ttest-aucpr:0.73981+0.00607\n",
            "[5]\ttrain-aucpr:0.75303+0.00337\ttest-aucpr:0.74980+0.00378\n",
            "[6]\ttrain-aucpr:0.76701+0.00460\ttest-aucpr:0.76323+0.00391\n",
            "[7]\ttrain-aucpr:0.77548+0.00550\ttest-aucpr:0.77140+0.00340\n",
            "[8]\ttrain-aucpr:0.78255+0.00440\ttest-aucpr:0.77806+0.00384\n",
            "[9]\ttrain-aucpr:0.79044+0.00231\ttest-aucpr:0.78582+0.00272\n",
            "[10]\ttrain-aucpr:0.79437+0.00142\ttest-aucpr:0.79001+0.00245\n",
            "[11]\ttrain-aucpr:0.80148+0.00227\ttest-aucpr:0.79690+0.00147\n",
            "[12]\ttrain-aucpr:0.81213+0.00451\ttest-aucpr:0.80749+0.00596\n",
            "[13]\ttrain-aucpr:0.81892+0.00425\ttest-aucpr:0.81445+0.00458\n",
            "[14]\ttrain-aucpr:0.82513+0.00438\ttest-aucpr:0.82041+0.00542\n",
            "[15]\ttrain-aucpr:0.83042+0.00515\ttest-aucpr:0.82579+0.00617\n",
            "[16]\ttrain-aucpr:0.83550+0.00546\ttest-aucpr:0.83080+0.00699\n",
            "[17]\ttrain-aucpr:0.83924+0.00587\ttest-aucpr:0.83444+0.00742\n",
            "[18]\ttrain-aucpr:0.84310+0.00471\ttest-aucpr:0.83831+0.00602\n",
            "[19]\ttrain-aucpr:0.84661+0.00408\ttest-aucpr:0.84184+0.00579\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96357+0.00199\ttest-aucpr:0.89031+0.00370\n",
            "[1]\ttrain-aucpr:0.97734+0.00183\ttest-aucpr:0.91307+0.00207\n",
            "[2]\ttrain-aucpr:0.98438+0.00113\ttest-aucpr:0.92608+0.00333\n",
            "[3]\ttrain-aucpr:0.98918+0.00135\ttest-aucpr:0.93537+0.00382\n",
            "[4]\ttrain-aucpr:0.99182+0.00037\ttest-aucpr:0.94046+0.00245\n",
            "[5]\ttrain-aucpr:0.99357+0.00035\ttest-aucpr:0.94505+0.00269\n",
            "[6]\ttrain-aucpr:0.99482+0.00023\ttest-aucpr:0.94899+0.00222\n",
            "[7]\ttrain-aucpr:0.99574+0.00016\ttest-aucpr:0.95176+0.00155\n",
            "[8]\ttrain-aucpr:0.99636+0.00011\ttest-aucpr:0.95382+0.00144\n",
            "[9]\ttrain-aucpr:0.99690+0.00005\ttest-aucpr:0.95529+0.00139\n",
            "[10]\ttrain-aucpr:0.99736+0.00005\ttest-aucpr:0.95698+0.00124\n",
            "[11]\ttrain-aucpr:0.99767+0.00004\ttest-aucpr:0.95847+0.00145\n",
            "[12]\ttrain-aucpr:0.99797+0.00006\ttest-aucpr:0.95948+0.00142\n",
            "[13]\ttrain-aucpr:0.99821+0.00007\ttest-aucpr:0.96039+0.00150\n",
            "[14]\ttrain-aucpr:0.99846+0.00010\ttest-aucpr:0.96141+0.00129\n",
            "[15]\ttrain-aucpr:0.99863+0.00009\ttest-aucpr:0.96213+0.00130\n",
            "[16]\ttrain-aucpr:0.99882+0.00006\ttest-aucpr:0.96286+0.00125\n",
            "[17]\ttrain-aucpr:0.99895+0.00008\ttest-aucpr:0.96352+0.00124\n",
            "[18]\ttrain-aucpr:0.99906+0.00008\ttest-aucpr:0.96413+0.00109\n",
            "[19]\ttrain-aucpr:0.99916+0.00009\ttest-aucpr:0.96475+0.00103\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90390+0.00129\ttest-aucpr:0.87676+0.00321\n",
            "[1]\ttrain-aucpr:0.93547+0.00211\ttest-aucpr:0.91139+0.00425\n",
            "[2]\ttrain-aucpr:0.94796+0.00118\ttest-aucpr:0.92515+0.00232\n",
            "[3]\ttrain-aucpr:0.95644+0.00033\ttest-aucpr:0.93460+0.00193\n",
            "[4]\ttrain-aucpr:0.96123+0.00086\ttest-aucpr:0.93962+0.00233\n",
            "[5]\ttrain-aucpr:0.96574+0.00100\ttest-aucpr:0.94431+0.00219\n",
            "[6]\ttrain-aucpr:0.96897+0.00088\ttest-aucpr:0.94765+0.00211\n",
            "[7]\ttrain-aucpr:0.97195+0.00078\ttest-aucpr:0.95114+0.00209\n",
            "[8]\ttrain-aucpr:0.97414+0.00061\ttest-aucpr:0.95372+0.00205\n",
            "[9]\ttrain-aucpr:0.97623+0.00050\ttest-aucpr:0.95605+0.00195\n",
            "[10]\ttrain-aucpr:0.97777+0.00025\ttest-aucpr:0.95795+0.00161\n",
            "[11]\ttrain-aucpr:0.97925+0.00018\ttest-aucpr:0.95976+0.00158\n",
            "[12]\ttrain-aucpr:0.98037+0.00044\ttest-aucpr:0.96107+0.00143\n",
            "[13]\ttrain-aucpr:0.98095+0.00043\ttest-aucpr:0.96180+0.00126\n",
            "[14]\ttrain-aucpr:0.98184+0.00048\ttest-aucpr:0.96292+0.00121\n",
            "[15]\ttrain-aucpr:0.98266+0.00029\ttest-aucpr:0.96394+0.00105\n",
            "[16]\ttrain-aucpr:0.98331+0.00044\ttest-aucpr:0.96479+0.00105\n",
            "[17]\ttrain-aucpr:0.98389+0.00027\ttest-aucpr:0.96552+0.00118\n",
            "[18]\ttrain-aucpr:0.98441+0.00041\ttest-aucpr:0.96608+0.00135\n",
            "[19]\ttrain-aucpr:0.98498+0.00034\ttest-aucpr:0.96670+0.00129\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76482+0.00201\ttest-aucpr:0.75862+0.00396\n",
            "[1]\ttrain-aucpr:0.80119+0.00857\ttest-aucpr:0.79547+0.01023\n",
            "[2]\ttrain-aucpr:0.81962+0.00447\ttest-aucpr:0.81354+0.00174\n",
            "[3]\ttrain-aucpr:0.82875+0.00409\ttest-aucpr:0.82291+0.00393\n",
            "[4]\ttrain-aucpr:0.83627+0.00360\ttest-aucpr:0.82966+0.00315\n",
            "[5]\ttrain-aucpr:0.84330+0.00191\ttest-aucpr:0.83722+0.00165\n",
            "[6]\ttrain-aucpr:0.84888+0.00150\ttest-aucpr:0.84247+0.00191\n",
            "[7]\ttrain-aucpr:0.85503+0.00087\ttest-aucpr:0.84844+0.00228\n",
            "[8]\ttrain-aucpr:0.85845+0.00102\ttest-aucpr:0.85158+0.00332\n",
            "[9]\ttrain-aucpr:0.86257+0.00114\ttest-aucpr:0.85569+0.00291\n",
            "[10]\ttrain-aucpr:0.86585+0.00120\ttest-aucpr:0.85886+0.00298\n",
            "[11]\ttrain-aucpr:0.86890+0.00139\ttest-aucpr:0.86191+0.00281\n",
            "[12]\ttrain-aucpr:0.87181+0.00139\ttest-aucpr:0.86497+0.00235\n",
            "[13]\ttrain-aucpr:0.87488+0.00088\ttest-aucpr:0.86795+0.00208\n",
            "[14]\ttrain-aucpr:0.87786+0.00106\ttest-aucpr:0.87091+0.00236\n",
            "[15]\ttrain-aucpr:0.88064+0.00121\ttest-aucpr:0.87366+0.00296\n",
            "[16]\ttrain-aucpr:0.88332+0.00108\ttest-aucpr:0.87629+0.00249\n",
            "[17]\ttrain-aucpr:0.88532+0.00113\ttest-aucpr:0.87841+0.00229\n",
            "[18]\ttrain-aucpr:0.88791+0.00052\ttest-aucpr:0.88098+0.00163\n",
            "[19]\ttrain-aucpr:0.88969+0.00087\ttest-aucpr:0.88279+0.00113\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76481+0.00201\ttest-aucpr:0.75862+0.00396\n",
            "[1]\ttrain-aucpr:0.81747+0.00482\ttest-aucpr:0.81016+0.00237\n",
            "[2]\ttrain-aucpr:0.84192+0.00463\ttest-aucpr:0.83564+0.00419\n",
            "[3]\ttrain-aucpr:0.85885+0.00221\ttest-aucpr:0.85207+0.00160\n",
            "[4]\ttrain-aucpr:0.87006+0.00173\ttest-aucpr:0.86285+0.00224\n",
            "[5]\ttrain-aucpr:0.87819+0.00245\ttest-aucpr:0.87063+0.00266\n",
            "[6]\ttrain-aucpr:0.88579+0.00231\ttest-aucpr:0.87831+0.00177\n",
            "[7]\ttrain-aucpr:0.89220+0.00372\ttest-aucpr:0.88407+0.00303\n",
            "[8]\ttrain-aucpr:0.89844+0.00215\ttest-aucpr:0.89029+0.00260\n",
            "[9]\ttrain-aucpr:0.90243+0.00128\ttest-aucpr:0.89420+0.00093\n",
            "[10]\ttrain-aucpr:0.90687+0.00151\ttest-aucpr:0.89849+0.00097\n",
            "[11]\ttrain-aucpr:0.91098+0.00217\ttest-aucpr:0.90280+0.00165\n",
            "[12]\ttrain-aucpr:0.91447+0.00188\ttest-aucpr:0.90625+0.00185\n",
            "[13]\ttrain-aucpr:0.91741+0.00234\ttest-aucpr:0.90912+0.00291\n",
            "[14]\ttrain-aucpr:0.92058+0.00128\ttest-aucpr:0.91199+0.00238\n",
            "[15]\ttrain-aucpr:0.92313+0.00066\ttest-aucpr:0.91444+0.00122\n",
            "[16]\ttrain-aucpr:0.92565+0.00168\ttest-aucpr:0.91711+0.00106\n",
            "[17]\ttrain-aucpr:0.92795+0.00229\ttest-aucpr:0.91956+0.00119\n",
            "[18]\ttrain-aucpr:0.92968+0.00300\ttest-aucpr:0.92109+0.00192\n",
            "[19]\ttrain-aucpr:0.93193+0.00261\ttest-aucpr:0.92337+0.00199\n",
            "result:  0.9233671021444962\n",
            "best result:  0.9233671021444962\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95395+0.00049\ttest-aucpr:0.88918+0.00377\n",
            "[1]\ttrain-aucpr:0.98357+0.00077\ttest-aucpr:0.92387+0.00380\n",
            "[2]\ttrain-aucpr:0.99148+0.00061\ttest-aucpr:0.93795+0.00294\n",
            "[3]\ttrain-aucpr:0.99492+0.00033\ttest-aucpr:0.94655+0.00198\n",
            "[4]\ttrain-aucpr:0.99676+0.00019\ttest-aucpr:0.95190+0.00160\n",
            "[5]\ttrain-aucpr:0.99793+0.00013\ttest-aucpr:0.95576+0.00173\n",
            "[6]\ttrain-aucpr:0.99860+0.00009\ttest-aucpr:0.95841+0.00175\n",
            "[7]\ttrain-aucpr:0.99906+0.00004\ttest-aucpr:0.96103+0.00176\n",
            "[8]\ttrain-aucpr:0.99937+0.00003\ttest-aucpr:0.96318+0.00176\n",
            "[9]\ttrain-aucpr:0.99957+0.00004\ttest-aucpr:0.96476+0.00171\n",
            "[10]\ttrain-aucpr:0.99969+0.00003\ttest-aucpr:0.96619+0.00171\n",
            "[11]\ttrain-aucpr:0.99979+0.00002\ttest-aucpr:0.96757+0.00171\n",
            "[12]\ttrain-aucpr:0.99986+0.00001\ttest-aucpr:0.96861+0.00162\n",
            "[13]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.96944+0.00158\n",
            "[14]\ttrain-aucpr:0.99993+0.00001\ttest-aucpr:0.97020+0.00145\n",
            "[15]\ttrain-aucpr:0.99995+0.00000\ttest-aucpr:0.97080+0.00146\n",
            "[16]\ttrain-aucpr:0.99997+0.00000\ttest-aucpr:0.97126+0.00132\n",
            "[17]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97172+0.00130\n",
            "[18]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97208+0.00127\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97249+0.00125\n",
            "result:  0.9724906122695703\n",
            "best result:  0.9724906122695703\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96894+0.00054\ttest-aucpr:0.89444+0.00177\n",
            "[1]\ttrain-aucpr:0.98990+0.00083\ttest-aucpr:0.92394+0.00305\n",
            "[2]\ttrain-aucpr:0.99523+0.00018\ttest-aucpr:0.93802+0.00226\n",
            "[3]\ttrain-aucpr:0.99728+0.00016\ttest-aucpr:0.94696+0.00134\n",
            "[4]\ttrain-aucpr:0.99836+0.00014\ttest-aucpr:0.95211+0.00104\n",
            "[5]\ttrain-aucpr:0.99892+0.00007\ttest-aucpr:0.95629+0.00129\n",
            "[6]\ttrain-aucpr:0.99927+0.00003\ttest-aucpr:0.95904+0.00117\n",
            "[7]\ttrain-aucpr:0.99952+0.00003\ttest-aucpr:0.96141+0.00136\n",
            "[8]\ttrain-aucpr:0.99967+0.00003\ttest-aucpr:0.96329+0.00116\n",
            "[9]\ttrain-aucpr:0.99978+0.00001\ttest-aucpr:0.96476+0.00093\n",
            "[10]\ttrain-aucpr:0.99986+0.00001\ttest-aucpr:0.96618+0.00097\n",
            "[11]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.96735+0.00093\n",
            "[12]\ttrain-aucpr:0.99993+0.00001\ttest-aucpr:0.96843+0.00092\n",
            "[13]\ttrain-aucpr:0.99995+0.00001\ttest-aucpr:0.96932+0.00086\n",
            "[14]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.97003+0.00093\n",
            "[15]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97068+0.00099\n",
            "[16]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97120+0.00086\n",
            "[17]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97143+0.00075\n",
            "[18]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97174+0.00080\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97205+0.00090\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95193+0.00069\ttest-aucpr:0.89058+0.00359\n",
            "[1]\ttrain-aucpr:0.97883+0.00141\ttest-aucpr:0.92377+0.00467\n",
            "[2]\ttrain-aucpr:0.98707+0.00082\ttest-aucpr:0.93732+0.00355\n",
            "[3]\ttrain-aucpr:0.99157+0.00046\ttest-aucpr:0.94630+0.00274\n",
            "[4]\ttrain-aucpr:0.99399+0.00026\ttest-aucpr:0.95137+0.00170\n",
            "[5]\ttrain-aucpr:0.99537+0.00020\ttest-aucpr:0.95522+0.00142\n",
            "[6]\ttrain-aucpr:0.99642+0.00018\ttest-aucpr:0.95786+0.00111\n",
            "[7]\ttrain-aucpr:0.99716+0.00011\ttest-aucpr:0.96025+0.00102\n",
            "[8]\ttrain-aucpr:0.99778+0.00009\ttest-aucpr:0.96232+0.00089\n",
            "[9]\ttrain-aucpr:0.99823+0.00011\ttest-aucpr:0.96421+0.00092\n",
            "[10]\ttrain-aucpr:0.99859+0.00006\ttest-aucpr:0.96547+0.00090\n",
            "[11]\ttrain-aucpr:0.99883+0.00004\ttest-aucpr:0.96664+0.00092\n",
            "[12]\ttrain-aucpr:0.99905+0.00003\ttest-aucpr:0.96781+0.00078\n",
            "[13]\ttrain-aucpr:0.99921+0.00003\ttest-aucpr:0.96878+0.00073\n",
            "[14]\ttrain-aucpr:0.99935+0.00003\ttest-aucpr:0.96958+0.00090\n",
            "[15]\ttrain-aucpr:0.99946+0.00003\ttest-aucpr:0.97030+0.00084\n",
            "[16]\ttrain-aucpr:0.99954+0.00004\ttest-aucpr:0.97091+0.00090\n",
            "[17]\ttrain-aucpr:0.99963+0.00002\ttest-aucpr:0.97153+0.00094\n",
            "[18]\ttrain-aucpr:0.99968+0.00002\ttest-aucpr:0.97199+0.00090\n",
            "[19]\ttrain-aucpr:0.99973+0.00002\ttest-aucpr:0.97236+0.00099\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76427+0.00130\ttest-aucpr:0.75781+0.00423\n",
            "[1]\ttrain-aucpr:0.80114+0.00861\ttest-aucpr:0.79527+0.01047\n",
            "[2]\ttrain-aucpr:0.81961+0.00446\ttest-aucpr:0.81337+0.00153\n",
            "[3]\ttrain-aucpr:0.82885+0.00413\ttest-aucpr:0.82288+0.00377\n",
            "[4]\ttrain-aucpr:0.83617+0.00362\ttest-aucpr:0.82951+0.00319\n",
            "[5]\ttrain-aucpr:0.84312+0.00175\ttest-aucpr:0.83698+0.00181\n",
            "[6]\ttrain-aucpr:0.84864+0.00133\ttest-aucpr:0.84216+0.00217\n",
            "[7]\ttrain-aucpr:0.85469+0.00062\ttest-aucpr:0.84809+0.00268\n",
            "[8]\ttrain-aucpr:0.85881+0.00134\ttest-aucpr:0.85197+0.00339\n",
            "[9]\ttrain-aucpr:0.86219+0.00098\ttest-aucpr:0.85526+0.00288\n",
            "[10]\ttrain-aucpr:0.86557+0.00120\ttest-aucpr:0.85843+0.00309\n",
            "[11]\ttrain-aucpr:0.86893+0.00151\ttest-aucpr:0.86190+0.00287\n",
            "[12]\ttrain-aucpr:0.87096+0.00155\ttest-aucpr:0.86381+0.00269\n",
            "[13]\ttrain-aucpr:0.87424+0.00214\ttest-aucpr:0.86735+0.00333\n",
            "[14]\ttrain-aucpr:0.87730+0.00205\ttest-aucpr:0.87029+0.00330\n",
            "[15]\ttrain-aucpr:0.88067+0.00216\ttest-aucpr:0.87364+0.00353\n",
            "[16]\ttrain-aucpr:0.88291+0.00173\ttest-aucpr:0.87582+0.00309\n",
            "[17]\ttrain-aucpr:0.88513+0.00162\ttest-aucpr:0.87799+0.00294\n",
            "[18]\ttrain-aucpr:0.88778+0.00229\ttest-aucpr:0.88053+0.00341\n",
            "[19]\ttrain-aucpr:0.88992+0.00170\ttest-aucpr:0.88258+0.00277\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65376+0.00713\ttest-aucpr:0.65040+0.00955\n",
            "[1]\ttrain-aucpr:0.71322+0.00388\ttest-aucpr:0.71029+0.00559\n",
            "[2]\ttrain-aucpr:0.72909+0.00433\ttest-aucpr:0.72527+0.00673\n",
            "[3]\ttrain-aucpr:0.73994+0.00419\ttest-aucpr:0.73582+0.00716\n",
            "[4]\ttrain-aucpr:0.76006+0.00379\ttest-aucpr:0.75641+0.00558\n",
            "[5]\ttrain-aucpr:0.77384+0.00281\ttest-aucpr:0.76970+0.00285\n",
            "[6]\ttrain-aucpr:0.78388+0.00377\ttest-aucpr:0.77950+0.00388\n",
            "[7]\ttrain-aucpr:0.79350+0.00207\ttest-aucpr:0.78880+0.00256\n",
            "[8]\ttrain-aucpr:0.80322+0.00340\ttest-aucpr:0.79800+0.00454\n",
            "[9]\ttrain-aucpr:0.80904+0.00443\ttest-aucpr:0.80364+0.00485\n",
            "[10]\ttrain-aucpr:0.81845+0.00274\ttest-aucpr:0.81228+0.00353\n",
            "[11]\ttrain-aucpr:0.82551+0.00377\ttest-aucpr:0.81988+0.00353\n",
            "[12]\ttrain-aucpr:0.82972+0.00311\ttest-aucpr:0.82416+0.00291\n",
            "[13]\ttrain-aucpr:0.83545+0.00272\ttest-aucpr:0.83010+0.00138\n",
            "[14]\ttrain-aucpr:0.83979+0.00281\ttest-aucpr:0.83439+0.00217\n",
            "[15]\ttrain-aucpr:0.84164+0.00275\ttest-aucpr:0.83626+0.00238\n",
            "[16]\ttrain-aucpr:0.84759+0.00553\ttest-aucpr:0.84200+0.00567\n",
            "[17]\ttrain-aucpr:0.85135+0.00583\ttest-aucpr:0.84542+0.00568\n",
            "[18]\ttrain-aucpr:0.85574+0.00416\ttest-aucpr:0.85003+0.00378\n",
            "[19]\ttrain-aucpr:0.85875+0.00414\ttest-aucpr:0.85289+0.00365\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76436+0.00135\ttest-aucpr:0.75788+0.00420\n",
            "[1]\ttrain-aucpr:0.81404+0.00356\ttest-aucpr:0.80735+0.00239\n",
            "[2]\ttrain-aucpr:0.83584+0.00584\ttest-aucpr:0.82903+0.00393\n",
            "[3]\ttrain-aucpr:0.84872+0.00273\ttest-aucpr:0.84145+0.00229\n",
            "[4]\ttrain-aucpr:0.85949+0.00289\ttest-aucpr:0.85236+0.00199\n",
            "[5]\ttrain-aucpr:0.86816+0.00260\ttest-aucpr:0.86100+0.00128\n",
            "[6]\ttrain-aucpr:0.87550+0.00208\ttest-aucpr:0.86819+0.00217\n",
            "[7]\ttrain-aucpr:0.88133+0.00174\ttest-aucpr:0.87438+0.00268\n",
            "[8]\ttrain-aucpr:0.88761+0.00237\ttest-aucpr:0.88047+0.00288\n",
            "[9]\ttrain-aucpr:0.89352+0.00368\ttest-aucpr:0.88620+0.00343\n",
            "[10]\ttrain-aucpr:0.89818+0.00249\ttest-aucpr:0.89061+0.00174\n",
            "[11]\ttrain-aucpr:0.90186+0.00285\ttest-aucpr:0.89429+0.00182\n",
            "[12]\ttrain-aucpr:0.90596+0.00213\ttest-aucpr:0.89827+0.00202\n",
            "[13]\ttrain-aucpr:0.90948+0.00134\ttest-aucpr:0.90165+0.00117\n",
            "[14]\ttrain-aucpr:0.91229+0.00193\ttest-aucpr:0.90442+0.00127\n",
            "[15]\ttrain-aucpr:0.91542+0.00227\ttest-aucpr:0.90756+0.00111\n",
            "[16]\ttrain-aucpr:0.91806+0.00087\ttest-aucpr:0.91021+0.00137\n",
            "[17]\ttrain-aucpr:0.91984+0.00105\ttest-aucpr:0.91183+0.00099\n",
            "[18]\ttrain-aucpr:0.92267+0.00108\ttest-aucpr:0.91451+0.00235\n",
            "[19]\ttrain-aucpr:0.92566+0.00191\ttest-aucpr:0.91741+0.00278\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90676+0.00109\ttest-aucpr:0.87796+0.00289\n",
            "[1]\ttrain-aucpr:0.94026+0.00162\ttest-aucpr:0.91456+0.00257\n",
            "[2]\ttrain-aucpr:0.95346+0.00132\ttest-aucpr:0.92897+0.00237\n",
            "[3]\ttrain-aucpr:0.96155+0.00099\ttest-aucpr:0.93817+0.00219\n",
            "[4]\ttrain-aucpr:0.96729+0.00053\ttest-aucpr:0.94399+0.00207\n",
            "[5]\ttrain-aucpr:0.97195+0.00056\ttest-aucpr:0.94885+0.00171\n",
            "[6]\ttrain-aucpr:0.97515+0.00056\ttest-aucpr:0.95205+0.00140\n",
            "[7]\ttrain-aucpr:0.97766+0.00067\ttest-aucpr:0.95495+0.00108\n",
            "[8]\ttrain-aucpr:0.97979+0.00066\ttest-aucpr:0.95691+0.00131\n",
            "[9]\ttrain-aucpr:0.98166+0.00112\ttest-aucpr:0.95894+0.00160\n",
            "[10]\ttrain-aucpr:0.98244+0.00087\ttest-aucpr:0.96004+0.00155\n",
            "[11]\ttrain-aucpr:0.98384+0.00080\ttest-aucpr:0.96174+0.00099\n",
            "[12]\ttrain-aucpr:0.98507+0.00094\ttest-aucpr:0.96314+0.00128\n",
            "[13]\ttrain-aucpr:0.98612+0.00096\ttest-aucpr:0.96438+0.00134\n",
            "[14]\ttrain-aucpr:0.98679+0.00080\ttest-aucpr:0.96513+0.00126\n",
            "[15]\ttrain-aucpr:0.98749+0.00083\ttest-aucpr:0.96601+0.00122\n",
            "[16]\ttrain-aucpr:0.98806+0.00090\ttest-aucpr:0.96652+0.00162\n",
            "[17]\ttrain-aucpr:0.98883+0.00051\ttest-aucpr:0.96703+0.00172\n",
            "[18]\ttrain-aucpr:0.98925+0.00044\ttest-aucpr:0.96739+0.00168\n",
            "[19]\ttrain-aucpr:0.98980+0.00035\ttest-aucpr:0.96770+0.00157\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65376+0.00713\ttest-aucpr:0.65040+0.00955\n",
            "[1]\ttrain-aucpr:0.68944+0.00644\ttest-aucpr:0.68649+0.00622\n",
            "[2]\ttrain-aucpr:0.71084+0.00223\ttest-aucpr:0.70814+0.00470\n",
            "[3]\ttrain-aucpr:0.72036+0.00218\ttest-aucpr:0.71720+0.00505\n",
            "[4]\ttrain-aucpr:0.73515+0.00279\ttest-aucpr:0.73207+0.00316\n",
            "[5]\ttrain-aucpr:0.73972+0.00292\ttest-aucpr:0.73639+0.00352\n",
            "[6]\ttrain-aucpr:0.74470+0.00262\ttest-aucpr:0.74075+0.00405\n",
            "[7]\ttrain-aucpr:0.74904+0.00264\ttest-aucpr:0.74499+0.00507\n",
            "[8]\ttrain-aucpr:0.75089+0.00242\ttest-aucpr:0.74693+0.00333\n",
            "[9]\ttrain-aucpr:0.75325+0.00281\ttest-aucpr:0.74914+0.00420\n",
            "[10]\ttrain-aucpr:0.75511+0.00378\ttest-aucpr:0.75106+0.00421\n",
            "[11]\ttrain-aucpr:0.75756+0.00288\ttest-aucpr:0.75351+0.00317\n",
            "[12]\ttrain-aucpr:0.75968+0.00347\ttest-aucpr:0.75544+0.00565\n",
            "[13]\ttrain-aucpr:0.76248+0.00441\ttest-aucpr:0.75818+0.00535\n",
            "[14]\ttrain-aucpr:0.76607+0.00263\ttest-aucpr:0.76183+0.00412\n",
            "[15]\ttrain-aucpr:0.76912+0.00169\ttest-aucpr:0.76474+0.00497\n",
            "[16]\ttrain-aucpr:0.77184+0.00264\ttest-aucpr:0.76750+0.00463\n",
            "[17]\ttrain-aucpr:0.77560+0.00188\ttest-aucpr:0.77116+0.00370\n",
            "[18]\ttrain-aucpr:0.77915+0.00099\ttest-aucpr:0.77452+0.00418\n",
            "[19]\ttrain-aucpr:0.78229+0.00150\ttest-aucpr:0.77763+0.00373\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76427+0.00130\ttest-aucpr:0.75781+0.00423\n",
            "[1]\ttrain-aucpr:0.80114+0.00861\ttest-aucpr:0.79527+0.01047\n",
            "[2]\ttrain-aucpr:0.81961+0.00446\ttest-aucpr:0.81337+0.00153\n",
            "[3]\ttrain-aucpr:0.82885+0.00413\ttest-aucpr:0.82288+0.00377\n",
            "[4]\ttrain-aucpr:0.83617+0.00362\ttest-aucpr:0.82951+0.00319\n",
            "[5]\ttrain-aucpr:0.84312+0.00175\ttest-aucpr:0.83698+0.00181\n",
            "[6]\ttrain-aucpr:0.84864+0.00133\ttest-aucpr:0.84216+0.00217\n",
            "[7]\ttrain-aucpr:0.85469+0.00062\ttest-aucpr:0.84809+0.00268\n",
            "[8]\ttrain-aucpr:0.85881+0.00134\ttest-aucpr:0.85197+0.00339\n",
            "[9]\ttrain-aucpr:0.86219+0.00098\ttest-aucpr:0.85526+0.00288\n",
            "[10]\ttrain-aucpr:0.86557+0.00120\ttest-aucpr:0.85843+0.00309\n",
            "[11]\ttrain-aucpr:0.86893+0.00151\ttest-aucpr:0.86190+0.00287\n",
            "[12]\ttrain-aucpr:0.87096+0.00155\ttest-aucpr:0.86381+0.00269\n",
            "[13]\ttrain-aucpr:0.87424+0.00214\ttest-aucpr:0.86735+0.00333\n",
            "[14]\ttrain-aucpr:0.87729+0.00205\ttest-aucpr:0.87029+0.00330\n",
            "[15]\ttrain-aucpr:0.88067+0.00216\ttest-aucpr:0.87364+0.00353\n",
            "[16]\ttrain-aucpr:0.88291+0.00173\ttest-aucpr:0.87582+0.00309\n",
            "[17]\ttrain-aucpr:0.88512+0.00162\ttest-aucpr:0.87799+0.00294\n",
            "[18]\ttrain-aucpr:0.88778+0.00228\ttest-aucpr:0.88053+0.00341\n",
            "[19]\ttrain-aucpr:0.88992+0.00170\ttest-aucpr:0.88258+0.00277\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90042+0.00101\ttest-aucpr:0.87452+0.00418\n",
            "[1]\ttrain-aucpr:0.92747+0.00469\ttest-aucpr:0.90426+0.00744\n",
            "[2]\ttrain-aucpr:0.93693+0.00312\ttest-aucpr:0.91457+0.00539\n",
            "[3]\ttrain-aucpr:0.94560+0.00281\ttest-aucpr:0.92421+0.00514\n",
            "[4]\ttrain-aucpr:0.95036+0.00244\ttest-aucpr:0.92946+0.00464\n",
            "[5]\ttrain-aucpr:0.95388+0.00212\ttest-aucpr:0.93367+0.00396\n",
            "[6]\ttrain-aucpr:0.95698+0.00104\ttest-aucpr:0.93689+0.00274\n",
            "[7]\ttrain-aucpr:0.95905+0.00107\ttest-aucpr:0.93916+0.00261\n",
            "[8]\ttrain-aucpr:0.96074+0.00090\ttest-aucpr:0.94087+0.00260\n",
            "[9]\ttrain-aucpr:0.96295+0.00069\ttest-aucpr:0.94334+0.00223\n",
            "[10]\ttrain-aucpr:0.96456+0.00090\ttest-aucpr:0.94508+0.00238\n",
            "[11]\ttrain-aucpr:0.96604+0.00088\ttest-aucpr:0.94667+0.00228\n",
            "[12]\ttrain-aucpr:0.96740+0.00094\ttest-aucpr:0.94799+0.00223\n",
            "[13]\ttrain-aucpr:0.96890+0.00093\ttest-aucpr:0.94957+0.00230\n",
            "[14]\ttrain-aucpr:0.96990+0.00083\ttest-aucpr:0.95064+0.00193\n",
            "[15]\ttrain-aucpr:0.97104+0.00070\ttest-aucpr:0.95189+0.00190\n",
            "[16]\ttrain-aucpr:0.97207+0.00081\ttest-aucpr:0.95298+0.00177\n",
            "[17]\ttrain-aucpr:0.97297+0.00072\ttest-aucpr:0.95389+0.00167\n",
            "[18]\ttrain-aucpr:0.97390+0.00066\ttest-aucpr:0.95492+0.00178\n",
            "[19]\ttrain-aucpr:0.97469+0.00052\ttest-aucpr:0.95576+0.00154\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.97862+0.00064\ttest-aucpr:0.89024+0.00270\n",
            "[1]\ttrain-aucpr:0.98927+0.00212\ttest-aucpr:0.91599+0.00914\n",
            "[2]\ttrain-aucpr:0.99344+0.00147\ttest-aucpr:0.92853+0.00835\n",
            "[3]\ttrain-aucpr:0.99558+0.00067\ttest-aucpr:0.93703+0.00615\n",
            "[4]\ttrain-aucpr:0.99668+0.00042\ttest-aucpr:0.94218+0.00485\n",
            "[5]\ttrain-aucpr:0.99731+0.00027\ttest-aucpr:0.94548+0.00475\n",
            "[6]\ttrain-aucpr:0.99786+0.00016\ttest-aucpr:0.94814+0.00429\n",
            "[7]\ttrain-aucpr:0.99826+0.00012\ttest-aucpr:0.95120+0.00449\n",
            "[8]\ttrain-aucpr:0.99857+0.00012\ttest-aucpr:0.95379+0.00418\n",
            "[9]\ttrain-aucpr:0.99878+0.00009\ttest-aucpr:0.95545+0.00389\n",
            "[10]\ttrain-aucpr:0.99898+0.00008\ttest-aucpr:0.95679+0.00368\n",
            "[11]\ttrain-aucpr:0.99911+0.00008\ttest-aucpr:0.95831+0.00308\n",
            "[12]\ttrain-aucpr:0.99924+0.00007\ttest-aucpr:0.95945+0.00298\n",
            "[13]\ttrain-aucpr:0.99934+0.00007\ttest-aucpr:0.96054+0.00278\n",
            "[14]\ttrain-aucpr:0.99943+0.00007\ttest-aucpr:0.96142+0.00262\n",
            "[15]\ttrain-aucpr:0.99951+0.00007\ttest-aucpr:0.96210+0.00245\n",
            "[16]\ttrain-aucpr:0.99957+0.00006\ttest-aucpr:0.96294+0.00212\n",
            "[17]\ttrain-aucpr:0.99963+0.00006\ttest-aucpr:0.96366+0.00211\n",
            "[18]\ttrain-aucpr:0.99968+0.00006\ttest-aucpr:0.96425+0.00211\n",
            "[19]\ttrain-aucpr:0.99972+0.00005\ttest-aucpr:0.96490+0.00189\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94301+0.00152\ttest-aucpr:0.88808+0.00376\n",
            "[1]\ttrain-aucpr:0.96689+0.00365\ttest-aucpr:0.91741+0.00699\n",
            "[2]\ttrain-aucpr:0.97406+0.00139\ttest-aucpr:0.92678+0.00512\n",
            "[3]\ttrain-aucpr:0.97976+0.00170\ttest-aucpr:0.93586+0.00526\n",
            "[4]\ttrain-aucpr:0.98274+0.00130\ttest-aucpr:0.94066+0.00445\n",
            "[5]\ttrain-aucpr:0.98523+0.00085\ttest-aucpr:0.94499+0.00437\n",
            "[6]\ttrain-aucpr:0.98693+0.00062\ttest-aucpr:0.94778+0.00377\n",
            "[7]\ttrain-aucpr:0.98830+0.00060\ttest-aucpr:0.94997+0.00365\n",
            "[8]\ttrain-aucpr:0.98946+0.00056\ttest-aucpr:0.95201+0.00312\n",
            "[9]\ttrain-aucpr:0.99057+0.00033\ttest-aucpr:0.95411+0.00255\n",
            "[10]\ttrain-aucpr:0.99138+0.00035\ttest-aucpr:0.95553+0.00252\n",
            "[11]\ttrain-aucpr:0.99213+0.00022\ttest-aucpr:0.95690+0.00217\n",
            "[12]\ttrain-aucpr:0.99280+0.00019\ttest-aucpr:0.95793+0.00214\n",
            "[13]\ttrain-aucpr:0.99334+0.00017\ttest-aucpr:0.95898+0.00200\n",
            "[14]\ttrain-aucpr:0.99387+0.00016\ttest-aucpr:0.96002+0.00185\n",
            "[15]\ttrain-aucpr:0.99429+0.00018\ttest-aucpr:0.96102+0.00178\n",
            "[16]\ttrain-aucpr:0.99468+0.00016\ttest-aucpr:0.96200+0.00172\n",
            "[17]\ttrain-aucpr:0.99504+0.00018\ttest-aucpr:0.96274+0.00160\n",
            "[18]\ttrain-aucpr:0.99535+0.00017\ttest-aucpr:0.96336+0.00153\n",
            "[19]\ttrain-aucpr:0.99567+0.00017\ttest-aucpr:0.96422+0.00148\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95395+0.00049\ttest-aucpr:0.88918+0.00377\n",
            "[1]\ttrain-aucpr:0.98100+0.00098\ttest-aucpr:0.92275+0.00413\n",
            "[2]\ttrain-aucpr:0.98936+0.00078\ttest-aucpr:0.93690+0.00332\n",
            "[3]\ttrain-aucpr:0.99334+0.00040\ttest-aucpr:0.94487+0.00296\n",
            "[4]\ttrain-aucpr:0.99549+0.00024\ttest-aucpr:0.94981+0.00229\n",
            "[5]\ttrain-aucpr:0.99672+0.00018\ttest-aucpr:0.95349+0.00197\n",
            "[6]\ttrain-aucpr:0.99755+0.00015\ttest-aucpr:0.95619+0.00172\n",
            "[7]\ttrain-aucpr:0.99814+0.00014\ttest-aucpr:0.95850+0.00172\n",
            "[8]\ttrain-aucpr:0.99862+0.00012\ttest-aucpr:0.96047+0.00154\n",
            "[9]\ttrain-aucpr:0.99892+0.00011\ttest-aucpr:0.96233+0.00133\n",
            "[10]\ttrain-aucpr:0.99918+0.00007\ttest-aucpr:0.96394+0.00133\n",
            "[11]\ttrain-aucpr:0.99939+0.00005\ttest-aucpr:0.96530+0.00124\n",
            "[12]\ttrain-aucpr:0.99954+0.00004\ttest-aucpr:0.96636+0.00115\n",
            "[13]\ttrain-aucpr:0.99964+0.00004\ttest-aucpr:0.96740+0.00117\n",
            "[14]\ttrain-aucpr:0.99972+0.00003\ttest-aucpr:0.96830+0.00108\n",
            "[15]\ttrain-aucpr:0.99978+0.00003\ttest-aucpr:0.96914+0.00109\n",
            "[16]\ttrain-aucpr:0.99983+0.00002\ttest-aucpr:0.96993+0.00098\n",
            "[17]\ttrain-aucpr:0.99987+0.00002\ttest-aucpr:0.97053+0.00101\n",
            "[18]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.97110+0.00103\n",
            "[19]\ttrain-aucpr:0.99993+0.00001\ttest-aucpr:0.97154+0.00098\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76441+0.00134\ttest-aucpr:0.75815+0.00391\n",
            "[1]\ttrain-aucpr:0.81752+0.00454\ttest-aucpr:0.80996+0.00262\n",
            "[2]\ttrain-aucpr:0.84206+0.00443\ttest-aucpr:0.83559+0.00378\n",
            "[3]\ttrain-aucpr:0.85860+0.00257\ttest-aucpr:0.85168+0.00102\n",
            "[4]\ttrain-aucpr:0.86929+0.00292\ttest-aucpr:0.86211+0.00132\n",
            "[5]\ttrain-aucpr:0.87799+0.00233\ttest-aucpr:0.87026+0.00251\n",
            "[6]\ttrain-aucpr:0.88578+0.00153\ttest-aucpr:0.87809+0.00219\n",
            "[7]\ttrain-aucpr:0.89246+0.00243\ttest-aucpr:0.88446+0.00336\n",
            "[8]\ttrain-aucpr:0.89727+0.00209\ttest-aucpr:0.88918+0.00249\n",
            "[9]\ttrain-aucpr:0.90398+0.00364\ttest-aucpr:0.89571+0.00203\n",
            "[10]\ttrain-aucpr:0.90876+0.00346\ttest-aucpr:0.90024+0.00258\n",
            "[11]\ttrain-aucpr:0.91350+0.00343\ttest-aucpr:0.90500+0.00137\n",
            "[12]\ttrain-aucpr:0.91645+0.00251\ttest-aucpr:0.90798+0.00119\n",
            "[13]\ttrain-aucpr:0.92048+0.00240\ttest-aucpr:0.91202+0.00193\n",
            "[14]\ttrain-aucpr:0.92303+0.00232\ttest-aucpr:0.91449+0.00175\n",
            "[15]\ttrain-aucpr:0.92636+0.00225\ttest-aucpr:0.91808+0.00148\n",
            "[16]\ttrain-aucpr:0.92873+0.00213\ttest-aucpr:0.92043+0.00070\n",
            "[17]\ttrain-aucpr:0.93104+0.00115\ttest-aucpr:0.92253+0.00130\n",
            "[18]\ttrain-aucpr:0.93302+0.00200\ttest-aucpr:0.92449+0.00178\n",
            "[19]\ttrain-aucpr:0.93546+0.00160\ttest-aucpr:0.92671+0.00141\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76427+0.00130\ttest-aucpr:0.75780+0.00423\n",
            "[1]\ttrain-aucpr:0.81731+0.00467\ttest-aucpr:0.80978+0.00250\n",
            "[2]\ttrain-aucpr:0.84182+0.00448\ttest-aucpr:0.83536+0.00379\n",
            "[3]\ttrain-aucpr:0.85865+0.00218\ttest-aucpr:0.85183+0.00154\n",
            "[4]\ttrain-aucpr:0.86979+0.00181\ttest-aucpr:0.86244+0.00223\n",
            "[5]\ttrain-aucpr:0.87820+0.00243\ttest-aucpr:0.87019+0.00240\n",
            "[6]\ttrain-aucpr:0.88573+0.00235\ttest-aucpr:0.87803+0.00158\n",
            "[7]\ttrain-aucpr:0.89255+0.00395\ttest-aucpr:0.88445+0.00343\n",
            "[8]\ttrain-aucpr:0.89886+0.00251\ttest-aucpr:0.89061+0.00300\n",
            "[9]\ttrain-aucpr:0.90479+0.00348\ttest-aucpr:0.89647+0.00219\n",
            "[10]\ttrain-aucpr:0.90875+0.00371\ttest-aucpr:0.90045+0.00231\n",
            "[11]\ttrain-aucpr:0.91287+0.00365\ttest-aucpr:0.90452+0.00241\n",
            "[12]\ttrain-aucpr:0.91592+0.00321\ttest-aucpr:0.90756+0.00175\n",
            "[13]\ttrain-aucpr:0.91909+0.00301\ttest-aucpr:0.91064+0.00159\n",
            "[14]\ttrain-aucpr:0.92193+0.00359\ttest-aucpr:0.91316+0.00247\n",
            "[15]\ttrain-aucpr:0.92457+0.00447\ttest-aucpr:0.91587+0.00338\n",
            "[16]\ttrain-aucpr:0.92676+0.00426\ttest-aucpr:0.91812+0.00319\n",
            "[17]\ttrain-aucpr:0.92891+0.00300\ttest-aucpr:0.92029+0.00195\n",
            "[18]\ttrain-aucpr:0.93122+0.00251\ttest-aucpr:0.92260+0.00168\n",
            "[19]\ttrain-aucpr:0.93340+0.00253\ttest-aucpr:0.92476+0.00214\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65374+0.00714\ttest-aucpr:0.65032+0.00966\n",
            "[1]\ttrain-aucpr:0.70532+0.00565\ttest-aucpr:0.70184+0.00795\n",
            "[2]\ttrain-aucpr:0.72426+0.00415\ttest-aucpr:0.72069+0.00806\n",
            "[3]\ttrain-aucpr:0.73681+0.00309\ttest-aucpr:0.73336+0.00604\n",
            "[4]\ttrain-aucpr:0.74735+0.00283\ttest-aucpr:0.74338+0.00522\n",
            "[5]\ttrain-aucpr:0.75889+0.00333\ttest-aucpr:0.75388+0.00621\n",
            "[6]\ttrain-aucpr:0.76501+0.00280\ttest-aucpr:0.75987+0.00640\n",
            "[7]\ttrain-aucpr:0.77539+0.00411\ttest-aucpr:0.77005+0.00689\n",
            "[8]\ttrain-aucpr:0.78549+0.00389\ttest-aucpr:0.77990+0.00668\n",
            "[9]\ttrain-aucpr:0.79106+0.00345\ttest-aucpr:0.78544+0.00602\n",
            "[10]\ttrain-aucpr:0.79776+0.00328\ttest-aucpr:0.79205+0.00572\n",
            "[11]\ttrain-aucpr:0.80665+0.00355\ttest-aucpr:0.80082+0.00500\n",
            "[12]\ttrain-aucpr:0.81241+0.00367\ttest-aucpr:0.80664+0.00410\n",
            "[13]\ttrain-aucpr:0.81718+0.00454\ttest-aucpr:0.81099+0.00576\n",
            "[14]\ttrain-aucpr:0.82265+0.00429\ttest-aucpr:0.81622+0.00568\n",
            "[15]\ttrain-aucpr:0.82780+0.00500\ttest-aucpr:0.82169+0.00652\n",
            "[16]\ttrain-aucpr:0.83378+0.00533\ttest-aucpr:0.82748+0.00721\n",
            "[17]\ttrain-aucpr:0.83694+0.00507\ttest-aucpr:0.83067+0.00671\n",
            "[18]\ttrain-aucpr:0.83958+0.00467\ttest-aucpr:0.83331+0.00658\n",
            "[19]\ttrain-aucpr:0.84243+0.00565\ttest-aucpr:0.83632+0.00715\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65374+0.00714\ttest-aucpr:0.65032+0.00966\n",
            "[1]\ttrain-aucpr:0.70520+0.00571\ttest-aucpr:0.70173+0.00789\n",
            "[2]\ttrain-aucpr:0.72416+0.00419\ttest-aucpr:0.72061+0.00803\n",
            "[3]\ttrain-aucpr:0.73678+0.00304\ttest-aucpr:0.73332+0.00601\n",
            "[4]\ttrain-aucpr:0.74731+0.00281\ttest-aucpr:0.74334+0.00518\n",
            "[5]\ttrain-aucpr:0.75884+0.00333\ttest-aucpr:0.75383+0.00620\n",
            "[6]\ttrain-aucpr:0.76498+0.00280\ttest-aucpr:0.75986+0.00638\n",
            "[7]\ttrain-aucpr:0.77536+0.00409\ttest-aucpr:0.77013+0.00682\n",
            "[8]\ttrain-aucpr:0.78548+0.00383\ttest-aucpr:0.77999+0.00656\n",
            "[9]\ttrain-aucpr:0.79104+0.00338\ttest-aucpr:0.78550+0.00586\n",
            "[10]\ttrain-aucpr:0.79765+0.00340\ttest-aucpr:0.79202+0.00564\n",
            "[11]\ttrain-aucpr:0.80578+0.00482\ttest-aucpr:0.79996+0.00612\n",
            "[12]\ttrain-aucpr:0.81156+0.00438\ttest-aucpr:0.80576+0.00502\n",
            "[13]\ttrain-aucpr:0.81771+0.00413\ttest-aucpr:0.81153+0.00534\n",
            "[14]\ttrain-aucpr:0.82319+0.00380\ttest-aucpr:0.81696+0.00506\n",
            "[15]\ttrain-aucpr:0.82829+0.00434\ttest-aucpr:0.82227+0.00577\n",
            "[16]\ttrain-aucpr:0.83545+0.00327\ttest-aucpr:0.82928+0.00493\n",
            "[17]\ttrain-aucpr:0.83834+0.00349\ttest-aucpr:0.83224+0.00471\n",
            "[18]\ttrain-aucpr:0.84186+0.00263\ttest-aucpr:0.83581+0.00365\n",
            "[19]\ttrain-aucpr:0.84497+0.00352\ttest-aucpr:0.83906+0.00381\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90500+0.00145\ttest-aucpr:0.87671+0.00321\n",
            "[1]\ttrain-aucpr:0.93662+0.00201\ttest-aucpr:0.91159+0.00415\n",
            "[2]\ttrain-aucpr:0.94923+0.00085\ttest-aucpr:0.92518+0.00210\n",
            "[3]\ttrain-aucpr:0.95843+0.00056\ttest-aucpr:0.93524+0.00131\n",
            "[4]\ttrain-aucpr:0.96321+0.00083\ttest-aucpr:0.94070+0.00106\n",
            "[5]\ttrain-aucpr:0.96774+0.00050\ttest-aucpr:0.94506+0.00127\n",
            "[6]\ttrain-aucpr:0.97090+0.00049\ttest-aucpr:0.94845+0.00131\n",
            "[7]\ttrain-aucpr:0.97357+0.00049\ttest-aucpr:0.95113+0.00111\n",
            "[8]\ttrain-aucpr:0.97596+0.00022\ttest-aucpr:0.95378+0.00092\n",
            "[9]\ttrain-aucpr:0.97834+0.00042\ttest-aucpr:0.95639+0.00082\n",
            "[10]\ttrain-aucpr:0.98000+0.00037\ttest-aucpr:0.95818+0.00090\n",
            "[11]\ttrain-aucpr:0.98113+0.00065\ttest-aucpr:0.95952+0.00114\n",
            "[12]\ttrain-aucpr:0.98208+0.00056\ttest-aucpr:0.96056+0.00087\n",
            "[13]\ttrain-aucpr:0.98335+0.00057\ttest-aucpr:0.96219+0.00120\n",
            "[14]\ttrain-aucpr:0.98395+0.00059\ttest-aucpr:0.96302+0.00125\n",
            "[15]\ttrain-aucpr:0.98496+0.00051\ttest-aucpr:0.96417+0.00121\n",
            "[16]\ttrain-aucpr:0.98557+0.00041\ttest-aucpr:0.96483+0.00132\n",
            "[17]\ttrain-aucpr:0.98627+0.00046\ttest-aucpr:0.96565+0.00112\n",
            "[18]\ttrain-aucpr:0.98683+0.00055\ttest-aucpr:0.96623+0.00097\n",
            "[19]\ttrain-aucpr:0.98750+0.00074\ttest-aucpr:0.96698+0.00079\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76427+0.00130\ttest-aucpr:0.75780+0.00423\n",
            "[1]\ttrain-aucpr:0.81731+0.00467\ttest-aucpr:0.80978+0.00250\n",
            "[2]\ttrain-aucpr:0.84182+0.00448\ttest-aucpr:0.83536+0.00379\n",
            "[3]\ttrain-aucpr:0.85865+0.00218\ttest-aucpr:0.85183+0.00154\n",
            "[4]\ttrain-aucpr:0.86979+0.00181\ttest-aucpr:0.86244+0.00223\n",
            "[5]\ttrain-aucpr:0.87820+0.00243\ttest-aucpr:0.87019+0.00240\n",
            "[6]\ttrain-aucpr:0.88573+0.00235\ttest-aucpr:0.87803+0.00158\n",
            "[7]\ttrain-aucpr:0.89256+0.00395\ttest-aucpr:0.88445+0.00343\n",
            "[8]\ttrain-aucpr:0.89887+0.00251\ttest-aucpr:0.89061+0.00300\n",
            "[9]\ttrain-aucpr:0.90479+0.00348\ttest-aucpr:0.89646+0.00220\n",
            "[10]\ttrain-aucpr:0.90876+0.00370\ttest-aucpr:0.90045+0.00231\n",
            "[11]\ttrain-aucpr:0.91288+0.00364\ttest-aucpr:0.90451+0.00241\n",
            "[12]\ttrain-aucpr:0.91594+0.00321\ttest-aucpr:0.90755+0.00176\n",
            "[13]\ttrain-aucpr:0.91908+0.00300\ttest-aucpr:0.91062+0.00158\n",
            "[14]\ttrain-aucpr:0.92193+0.00360\ttest-aucpr:0.91316+0.00248\n",
            "[15]\ttrain-aucpr:0.92458+0.00447\ttest-aucpr:0.91587+0.00338\n",
            "[16]\ttrain-aucpr:0.92681+0.00416\ttest-aucpr:0.91816+0.00307\n",
            "[17]\ttrain-aucpr:0.92919+0.00292\ttest-aucpr:0.92053+0.00184\n",
            "[18]\ttrain-aucpr:0.93122+0.00225\ttest-aucpr:0.92258+0.00143\n",
            "[19]\ttrain-aucpr:0.93377+0.00267\ttest-aucpr:0.92521+0.00235\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76441+0.00134\ttest-aucpr:0.75815+0.00391\n",
            "[1]\ttrain-aucpr:0.81413+0.00359\ttest-aucpr:0.80747+0.00256\n",
            "[2]\ttrain-aucpr:0.83591+0.00580\ttest-aucpr:0.82910+0.00389\n",
            "[3]\ttrain-aucpr:0.84879+0.00273\ttest-aucpr:0.84152+0.00227\n",
            "[4]\ttrain-aucpr:0.85956+0.00289\ttest-aucpr:0.85243+0.00197\n",
            "[5]\ttrain-aucpr:0.86836+0.00234\ttest-aucpr:0.86121+0.00124\n",
            "[6]\ttrain-aucpr:0.87567+0.00191\ttest-aucpr:0.86837+0.00221\n",
            "[7]\ttrain-aucpr:0.88146+0.00171\ttest-aucpr:0.87454+0.00275\n",
            "[8]\ttrain-aucpr:0.88809+0.00319\ttest-aucpr:0.88104+0.00349\n",
            "[9]\ttrain-aucpr:0.89382+0.00334\ttest-aucpr:0.88650+0.00327\n",
            "[10]\ttrain-aucpr:0.89808+0.00252\ttest-aucpr:0.89052+0.00146\n",
            "[11]\ttrain-aucpr:0.90271+0.00179\ttest-aucpr:0.89511+0.00137\n",
            "[12]\ttrain-aucpr:0.90628+0.00203\ttest-aucpr:0.89845+0.00190\n",
            "[13]\ttrain-aucpr:0.90989+0.00138\ttest-aucpr:0.90189+0.00122\n",
            "[14]\ttrain-aucpr:0.91328+0.00153\ttest-aucpr:0.90531+0.00145\n",
            "[15]\ttrain-aucpr:0.91607+0.00120\ttest-aucpr:0.90812+0.00098\n",
            "[16]\ttrain-aucpr:0.91775+0.00150\ttest-aucpr:0.90975+0.00070\n",
            "[17]\ttrain-aucpr:0.92022+0.00154\ttest-aucpr:0.91212+0.00067\n",
            "[18]\ttrain-aucpr:0.92276+0.00115\ttest-aucpr:0.91455+0.00084\n",
            "[19]\ttrain-aucpr:0.92467+0.00200\ttest-aucpr:0.91640+0.00137\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95193+0.00069\ttest-aucpr:0.89058+0.00359\n",
            "[1]\ttrain-aucpr:0.98114+0.00113\ttest-aucpr:0.92524+0.00392\n",
            "[2]\ttrain-aucpr:0.98974+0.00056\ttest-aucpr:0.93989+0.00187\n",
            "[3]\ttrain-aucpr:0.99348+0.00016\ttest-aucpr:0.94858+0.00100\n",
            "[4]\ttrain-aucpr:0.99546+0.00015\ttest-aucpr:0.95320+0.00071\n",
            "[5]\ttrain-aucpr:0.99674+0.00010\ttest-aucpr:0.95662+0.00056\n",
            "[6]\ttrain-aucpr:0.99767+0.00011\ttest-aucpr:0.95940+0.00060\n",
            "[7]\ttrain-aucpr:0.99826+0.00006\ttest-aucpr:0.96177+0.00078\n",
            "[8]\ttrain-aucpr:0.99870+0.00005\ttest-aucpr:0.96373+0.00057\n",
            "[9]\ttrain-aucpr:0.99904+0.00003\ttest-aucpr:0.96546+0.00082\n",
            "[10]\ttrain-aucpr:0.99926+0.00005\ttest-aucpr:0.96687+0.00079\n",
            "[11]\ttrain-aucpr:0.99943+0.00005\ttest-aucpr:0.96805+0.00088\n",
            "[12]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.96892+0.00096\n",
            "[13]\ttrain-aucpr:0.99967+0.00003\ttest-aucpr:0.96959+0.00082\n",
            "[14]\ttrain-aucpr:0.99974+0.00003\ttest-aucpr:0.97021+0.00080\n",
            "[15]\ttrain-aucpr:0.99979+0.00003\ttest-aucpr:0.97073+0.00077\n",
            "[16]\ttrain-aucpr:0.99984+0.00002\ttest-aucpr:0.97133+0.00079\n",
            "[17]\ttrain-aucpr:0.99986+0.00002\ttest-aucpr:0.97187+0.00071\n",
            "[18]\ttrain-aucpr:0.99990+0.00002\ttest-aucpr:0.97218+0.00070\n",
            "[19]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.97241+0.00069\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76436+0.00135\ttest-aucpr:0.75788+0.00420\n",
            "[1]\ttrain-aucpr:0.80121+0.00853\ttest-aucpr:0.79530+0.01046\n",
            "[2]\ttrain-aucpr:0.81960+0.00446\ttest-aucpr:0.81334+0.00157\n",
            "[3]\ttrain-aucpr:0.82889+0.00410\ttest-aucpr:0.82288+0.00375\n",
            "[4]\ttrain-aucpr:0.83613+0.00363\ttest-aucpr:0.82971+0.00316\n",
            "[5]\ttrain-aucpr:0.84365+0.00205\ttest-aucpr:0.83750+0.00206\n",
            "[6]\ttrain-aucpr:0.84897+0.00182\ttest-aucpr:0.84259+0.00179\n",
            "[7]\ttrain-aucpr:0.85509+0.00075\ttest-aucpr:0.84863+0.00261\n",
            "[8]\ttrain-aucpr:0.85868+0.00121\ttest-aucpr:0.85199+0.00334\n",
            "[9]\ttrain-aucpr:0.86240+0.00143\ttest-aucpr:0.85567+0.00334\n",
            "[10]\ttrain-aucpr:0.86605+0.00176\ttest-aucpr:0.85913+0.00340\n",
            "[11]\ttrain-aucpr:0.86927+0.00182\ttest-aucpr:0.86248+0.00337\n",
            "[12]\ttrain-aucpr:0.87145+0.00211\ttest-aucpr:0.86447+0.00327\n",
            "[13]\ttrain-aucpr:0.87414+0.00204\ttest-aucpr:0.86720+0.00325\n",
            "[14]\ttrain-aucpr:0.87705+0.00160\ttest-aucpr:0.87003+0.00288\n",
            "[15]\ttrain-aucpr:0.87983+0.00184\ttest-aucpr:0.87287+0.00290\n",
            "[16]\ttrain-aucpr:0.88296+0.00184\ttest-aucpr:0.87604+0.00323\n",
            "[17]\ttrain-aucpr:0.88533+0.00190\ttest-aucpr:0.87844+0.00328\n",
            "[18]\ttrain-aucpr:0.88764+0.00215\ttest-aucpr:0.88078+0.00375\n",
            "[19]\ttrain-aucpr:0.88977+0.00163\ttest-aucpr:0.88277+0.00315\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90390+0.00129\ttest-aucpr:0.87676+0.00321\n",
            "[1]\ttrain-aucpr:0.93766+0.00178\ttest-aucpr:0.91298+0.00374\n",
            "[2]\ttrain-aucpr:0.95121+0.00059\ttest-aucpr:0.92794+0.00253\n",
            "[3]\ttrain-aucpr:0.95985+0.00117\ttest-aucpr:0.93736+0.00247\n",
            "[4]\ttrain-aucpr:0.96542+0.00028\ttest-aucpr:0.94345+0.00169\n",
            "[5]\ttrain-aucpr:0.96965+0.00076\ttest-aucpr:0.94771+0.00196\n",
            "[6]\ttrain-aucpr:0.97319+0.00074\ttest-aucpr:0.95197+0.00185\n",
            "[7]\ttrain-aucpr:0.97547+0.00044\ttest-aucpr:0.95471+0.00189\n",
            "[8]\ttrain-aucpr:0.97741+0.00032\ttest-aucpr:0.95715+0.00168\n",
            "[9]\ttrain-aucpr:0.97884+0.00084\ttest-aucpr:0.95884+0.00147\n",
            "[10]\ttrain-aucpr:0.97988+0.00071\ttest-aucpr:0.96021+0.00138\n",
            "[11]\ttrain-aucpr:0.98130+0.00050\ttest-aucpr:0.96173+0.00196\n",
            "[12]\ttrain-aucpr:0.98230+0.00040\ttest-aucpr:0.96290+0.00169\n",
            "[13]\ttrain-aucpr:0.98308+0.00056\ttest-aucpr:0.96389+0.00167\n",
            "[14]\ttrain-aucpr:0.98383+0.00058\ttest-aucpr:0.96478+0.00158\n",
            "[15]\ttrain-aucpr:0.98427+0.00047\ttest-aucpr:0.96519+0.00176\n",
            "[16]\ttrain-aucpr:0.98509+0.00056\ttest-aucpr:0.96599+0.00181\n",
            "[17]\ttrain-aucpr:0.98564+0.00076\ttest-aucpr:0.96650+0.00177\n",
            "[18]\ttrain-aucpr:0.98634+0.00047\ttest-aucpr:0.96707+0.00127\n",
            "[19]\ttrain-aucpr:0.98700+0.00031\ttest-aucpr:0.96743+0.00123\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.93387+0.00143\ttest-aucpr:0.88999+0.00375\n",
            "[1]\ttrain-aucpr:0.96374+0.00125\ttest-aucpr:0.92360+0.00407\n",
            "[2]\ttrain-aucpr:0.97414+0.00119\ttest-aucpr:0.93803+0.00357\n",
            "[3]\ttrain-aucpr:0.97942+0.00067\ttest-aucpr:0.94523+0.00287\n",
            "[4]\ttrain-aucpr:0.98280+0.00035\ttest-aucpr:0.95135+0.00201\n",
            "[5]\ttrain-aucpr:0.98495+0.00037\ttest-aucpr:0.95477+0.00219\n",
            "[6]\ttrain-aucpr:0.98670+0.00035\ttest-aucpr:0.95783+0.00136\n",
            "[7]\ttrain-aucpr:0.98818+0.00031\ttest-aucpr:0.96010+0.00143\n",
            "[8]\ttrain-aucpr:0.98942+0.00025\ttest-aucpr:0.96242+0.00135\n",
            "[9]\ttrain-aucpr:0.99042+0.00025\ttest-aucpr:0.96440+0.00125\n",
            "[10]\ttrain-aucpr:0.99124+0.00021\ttest-aucpr:0.96591+0.00122\n",
            "[11]\ttrain-aucpr:0.99197+0.00023\ttest-aucpr:0.96724+0.00109\n",
            "[12]\ttrain-aucpr:0.99250+0.00021\ttest-aucpr:0.96822+0.00118\n",
            "[13]\ttrain-aucpr:0.99301+0.00016\ttest-aucpr:0.96907+0.00125\n",
            "[14]\ttrain-aucpr:0.99346+0.00017\ttest-aucpr:0.96983+0.00126\n",
            "[15]\ttrain-aucpr:0.99386+0.00015\ttest-aucpr:0.97054+0.00121\n",
            "[16]\ttrain-aucpr:0.99420+0.00011\ttest-aucpr:0.97118+0.00127\n",
            "[17]\ttrain-aucpr:0.99455+0.00011\ttest-aucpr:0.97178+0.00117\n",
            "[18]\ttrain-aucpr:0.99484+0.00013\ttest-aucpr:0.97234+0.00106\n",
            "[19]\ttrain-aucpr:0.99503+0.00012\ttest-aucpr:0.97262+0.00101\n",
            "result:  0.9726213963520657\n",
            "best result:  0.9726213963520657\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65374+0.00714\ttest-aucpr:0.65032+0.00966\n",
            "[1]\ttrain-aucpr:0.71331+0.00384\ttest-aucpr:0.71029+0.00560\n",
            "[2]\ttrain-aucpr:0.72952+0.00489\ttest-aucpr:0.72551+0.00707\n",
            "[3]\ttrain-aucpr:0.73996+0.00429\ttest-aucpr:0.73571+0.00739\n",
            "[4]\ttrain-aucpr:0.76011+0.00381\ttest-aucpr:0.75629+0.00575\n",
            "[5]\ttrain-aucpr:0.77363+0.00307\ttest-aucpr:0.76927+0.00364\n",
            "[6]\ttrain-aucpr:0.78389+0.00380\ttest-aucpr:0.77920+0.00447\n",
            "[7]\ttrain-aucpr:0.79499+0.00292\ttest-aucpr:0.79018+0.00193\n",
            "[8]\ttrain-aucpr:0.80508+0.00345\ttest-aucpr:0.80017+0.00374\n",
            "[9]\ttrain-aucpr:0.81175+0.00375\ttest-aucpr:0.80674+0.00314\n",
            "[10]\ttrain-aucpr:0.81929+0.00269\ttest-aucpr:0.81362+0.00300\n",
            "[11]\ttrain-aucpr:0.82470+0.00334\ttest-aucpr:0.81912+0.00327\n",
            "[12]\ttrain-aucpr:0.82900+0.00285\ttest-aucpr:0.82345+0.00291\n",
            "[13]\ttrain-aucpr:0.83460+0.00275\ttest-aucpr:0.82927+0.00219\n",
            "[14]\ttrain-aucpr:0.83883+0.00288\ttest-aucpr:0.83348+0.00306\n",
            "[15]\ttrain-aucpr:0.84276+0.00240\ttest-aucpr:0.83732+0.00085\n",
            "[16]\ttrain-aucpr:0.84804+0.00509\ttest-aucpr:0.84261+0.00503\n",
            "[17]\ttrain-aucpr:0.85099+0.00444\ttest-aucpr:0.84529+0.00442\n",
            "[18]\ttrain-aucpr:0.85408+0.00460\ttest-aucpr:0.84848+0.00467\n",
            "[19]\ttrain-aucpr:0.85797+0.00519\ttest-aucpr:0.85235+0.00464\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65374+0.00714\ttest-aucpr:0.65032+0.00966\n",
            "[1]\ttrain-aucpr:0.70532+0.00565\ttest-aucpr:0.70184+0.00795\n",
            "[2]\ttrain-aucpr:0.72422+0.00415\ttest-aucpr:0.72065+0.00803\n",
            "[3]\ttrain-aucpr:0.73680+0.00308\ttest-aucpr:0.73335+0.00604\n",
            "[4]\ttrain-aucpr:0.74735+0.00283\ttest-aucpr:0.74337+0.00522\n",
            "[5]\ttrain-aucpr:0.75889+0.00333\ttest-aucpr:0.75388+0.00620\n",
            "[6]\ttrain-aucpr:0.76501+0.00280\ttest-aucpr:0.75987+0.00640\n",
            "[7]\ttrain-aucpr:0.77539+0.00411\ttest-aucpr:0.77005+0.00690\n",
            "[8]\ttrain-aucpr:0.78549+0.00389\ttest-aucpr:0.77990+0.00668\n",
            "[9]\ttrain-aucpr:0.79106+0.00346\ttest-aucpr:0.78543+0.00602\n",
            "[10]\ttrain-aucpr:0.79775+0.00328\ttest-aucpr:0.79205+0.00572\n",
            "[11]\ttrain-aucpr:0.80664+0.00355\ttest-aucpr:0.80082+0.00500\n",
            "[12]\ttrain-aucpr:0.81241+0.00367\ttest-aucpr:0.80664+0.00410\n",
            "[13]\ttrain-aucpr:0.81717+0.00454\ttest-aucpr:0.81098+0.00576\n",
            "[14]\ttrain-aucpr:0.82264+0.00429\ttest-aucpr:0.81622+0.00568\n",
            "[15]\ttrain-aucpr:0.82780+0.00500\ttest-aucpr:0.82169+0.00652\n",
            "[16]\ttrain-aucpr:0.83377+0.00533\ttest-aucpr:0.82747+0.00721\n",
            "[17]\ttrain-aucpr:0.83693+0.00507\ttest-aucpr:0.83066+0.00671\n",
            "[18]\ttrain-aucpr:0.83957+0.00467\ttest-aucpr:0.83331+0.00658\n",
            "[19]\ttrain-aucpr:0.84243+0.00565\ttest-aucpr:0.83632+0.00715\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96447+0.00063\ttest-aucpr:0.88970+0.00284\n",
            "[1]\ttrain-aucpr:0.98031+0.00382\ttest-aucpr:0.91822+0.00933\n",
            "[2]\ttrain-aucpr:0.98643+0.00167\ttest-aucpr:0.92984+0.00657\n",
            "[3]\ttrain-aucpr:0.98991+0.00084\ttest-aucpr:0.93678+0.00451\n",
            "[4]\ttrain-aucpr:0.99226+0.00060\ttest-aucpr:0.94198+0.00415\n",
            "[5]\ttrain-aucpr:0.99378+0.00039\ttest-aucpr:0.94530+0.00371\n",
            "[6]\ttrain-aucpr:0.99497+0.00016\ttest-aucpr:0.94867+0.00352\n",
            "[7]\ttrain-aucpr:0.99576+0.00007\ttest-aucpr:0.95086+0.00329\n",
            "[8]\ttrain-aucpr:0.99646+0.00007\ttest-aucpr:0.95304+0.00281\n",
            "[9]\ttrain-aucpr:0.99693+0.00007\ttest-aucpr:0.95461+0.00289\n",
            "[10]\ttrain-aucpr:0.99740+0.00013\ttest-aucpr:0.95636+0.00264\n",
            "[11]\ttrain-aucpr:0.99774+0.00011\ttest-aucpr:0.95768+0.00260\n",
            "[12]\ttrain-aucpr:0.99802+0.00010\ttest-aucpr:0.95878+0.00250\n",
            "[13]\ttrain-aucpr:0.99830+0.00008\ttest-aucpr:0.95985+0.00216\n",
            "[14]\ttrain-aucpr:0.99848+0.00009\ttest-aucpr:0.96070+0.00194\n",
            "[15]\ttrain-aucpr:0.99864+0.00009\ttest-aucpr:0.96158+0.00180\n",
            "[16]\ttrain-aucpr:0.99878+0.00009\ttest-aucpr:0.96245+0.00156\n",
            "[17]\ttrain-aucpr:0.99891+0.00008\ttest-aucpr:0.96315+0.00161\n",
            "[18]\ttrain-aucpr:0.99903+0.00008\ttest-aucpr:0.96380+0.00165\n",
            "[19]\ttrain-aucpr:0.99914+0.00007\ttest-aucpr:0.96434+0.00157\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90426+0.00110\ttest-aucpr:0.87786+0.00163\n",
            "[1]\ttrain-aucpr:0.93490+0.00348\ttest-aucpr:0.91226+0.00406\n",
            "[2]\ttrain-aucpr:0.94825+0.00118\ttest-aucpr:0.92655+0.00116\n",
            "[3]\ttrain-aucpr:0.95598+0.00103\ttest-aucpr:0.93378+0.00144\n",
            "[4]\ttrain-aucpr:0.96106+0.00061\ttest-aucpr:0.93923+0.00078\n",
            "[5]\ttrain-aucpr:0.96511+0.00021\ttest-aucpr:0.94395+0.00043\n",
            "[6]\ttrain-aucpr:0.96831+0.00038\ttest-aucpr:0.94717+0.00031\n",
            "[7]\ttrain-aucpr:0.97110+0.00050\ttest-aucpr:0.95033+0.00062\n",
            "[8]\ttrain-aucpr:0.97386+0.00048\ttest-aucpr:0.95326+0.00057\n",
            "[9]\ttrain-aucpr:0.97575+0.00053\ttest-aucpr:0.95514+0.00060\n",
            "[10]\ttrain-aucpr:0.97720+0.00061\ttest-aucpr:0.95685+0.00064\n",
            "[11]\ttrain-aucpr:0.97876+0.00083\ttest-aucpr:0.95898+0.00079\n",
            "[12]\ttrain-aucpr:0.97968+0.00068\ttest-aucpr:0.96007+0.00076\n",
            "[13]\ttrain-aucpr:0.98066+0.00062\ttest-aucpr:0.96132+0.00085\n",
            "[14]\ttrain-aucpr:0.98146+0.00072\ttest-aucpr:0.96244+0.00089\n",
            "[15]\ttrain-aucpr:0.98210+0.00072\ttest-aucpr:0.96320+0.00107\n",
            "[16]\ttrain-aucpr:0.98273+0.00061\ttest-aucpr:0.96399+0.00113\n",
            "[17]\ttrain-aucpr:0.98337+0.00047\ttest-aucpr:0.96490+0.00085\n",
            "[18]\ttrain-aucpr:0.98407+0.00046\ttest-aucpr:0.96569+0.00078\n",
            "[19]\ttrain-aucpr:0.98460+0.00034\ttest-aucpr:0.96640+0.00058\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76422+0.00267\ttest-aucpr:0.75763+0.00312\n",
            "[1]\ttrain-aucpr:0.80390+0.00348\ttest-aucpr:0.79822+0.00253\n",
            "[2]\ttrain-aucpr:0.82024+0.00270\ttest-aucpr:0.81412+0.00393\n",
            "[3]\ttrain-aucpr:0.83032+0.00487\ttest-aucpr:0.82424+0.00542\n",
            "[4]\ttrain-aucpr:0.83781+0.00315\ttest-aucpr:0.83205+0.00350\n",
            "[5]\ttrain-aucpr:0.84467+0.00351\ttest-aucpr:0.83881+0.00374\n",
            "[6]\ttrain-aucpr:0.85041+0.00159\ttest-aucpr:0.84468+0.00207\n",
            "[7]\ttrain-aucpr:0.85393+0.00180\ttest-aucpr:0.84769+0.00267\n",
            "[8]\ttrain-aucpr:0.85797+0.00177\ttest-aucpr:0.85139+0.00267\n",
            "[9]\ttrain-aucpr:0.86241+0.00134\ttest-aucpr:0.85585+0.00228\n",
            "[10]\ttrain-aucpr:0.86518+0.00179\ttest-aucpr:0.85877+0.00229\n",
            "[11]\ttrain-aucpr:0.86819+0.00126\ttest-aucpr:0.86166+0.00165\n",
            "[12]\ttrain-aucpr:0.87132+0.00142\ttest-aucpr:0.86457+0.00116\n",
            "[13]\ttrain-aucpr:0.87476+0.00163\ttest-aucpr:0.86803+0.00109\n",
            "[14]\ttrain-aucpr:0.87749+0.00165\ttest-aucpr:0.87052+0.00120\n",
            "[15]\ttrain-aucpr:0.88016+0.00184\ttest-aucpr:0.87314+0.00144\n",
            "[16]\ttrain-aucpr:0.88315+0.00143\ttest-aucpr:0.87623+0.00118\n",
            "[17]\ttrain-aucpr:0.88537+0.00131\ttest-aucpr:0.87821+0.00118\n",
            "[18]\ttrain-aucpr:0.88745+0.00108\ttest-aucpr:0.88034+0.00072\n",
            "[19]\ttrain-aucpr:0.88958+0.00131\ttest-aucpr:0.88235+0.00095\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76411+0.00277\ttest-aucpr:0.75811+0.00245\n",
            "[1]\ttrain-aucpr:0.81747+0.00308\ttest-aucpr:0.81136+0.00467\n",
            "[2]\ttrain-aucpr:0.83967+0.00303\ttest-aucpr:0.83390+0.00334\n",
            "[3]\ttrain-aucpr:0.85359+0.00227\ttest-aucpr:0.84750+0.00305\n",
            "[4]\ttrain-aucpr:0.86742+0.00214\ttest-aucpr:0.86117+0.00206\n",
            "[5]\ttrain-aucpr:0.87623+0.00264\ttest-aucpr:0.86945+0.00256\n",
            "[6]\ttrain-aucpr:0.88609+0.00243\ttest-aucpr:0.87924+0.00251\n",
            "[7]\ttrain-aucpr:0.89274+0.00163\ttest-aucpr:0.88586+0.00121\n",
            "[8]\ttrain-aucpr:0.89855+0.00142\ttest-aucpr:0.89169+0.00099\n",
            "[9]\ttrain-aucpr:0.90281+0.00218\ttest-aucpr:0.89591+0.00186\n",
            "[10]\ttrain-aucpr:0.90670+0.00325\ttest-aucpr:0.89964+0.00275\n",
            "[11]\ttrain-aucpr:0.91125+0.00302\ttest-aucpr:0.90384+0.00290\n",
            "[12]\ttrain-aucpr:0.91486+0.00260\ttest-aucpr:0.90743+0.00301\n",
            "[13]\ttrain-aucpr:0.91944+0.00341\ttest-aucpr:0.91197+0.00336\n",
            "[14]\ttrain-aucpr:0.92242+0.00302\ttest-aucpr:0.91482+0.00203\n",
            "[15]\ttrain-aucpr:0.92407+0.00302\ttest-aucpr:0.91642+0.00233\n",
            "[16]\ttrain-aucpr:0.92686+0.00250\ttest-aucpr:0.91916+0.00214\n",
            "[17]\ttrain-aucpr:0.92848+0.00220\ttest-aucpr:0.92067+0.00169\n",
            "[18]\ttrain-aucpr:0.93016+0.00240\ttest-aucpr:0.92228+0.00164\n",
            "[19]\ttrain-aucpr:0.93232+0.00263\ttest-aucpr:0.92443+0.00220\n",
            "result:  0.9244313331374677\n",
            "best result:  0.9244313331374677\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95490+0.00157\ttest-aucpr:0.89088+0.00187\n",
            "[1]\ttrain-aucpr:0.98357+0.00085\ttest-aucpr:0.92584+0.00234\n",
            "[2]\ttrain-aucpr:0.99156+0.00049\ttest-aucpr:0.93886+0.00114\n",
            "[3]\ttrain-aucpr:0.99493+0.00032\ttest-aucpr:0.94585+0.00165\n",
            "[4]\ttrain-aucpr:0.99678+0.00014\ttest-aucpr:0.95119+0.00096\n",
            "[5]\ttrain-aucpr:0.99788+0.00013\ttest-aucpr:0.95503+0.00083\n",
            "[6]\ttrain-aucpr:0.99858+0.00007\ttest-aucpr:0.95788+0.00075\n",
            "[7]\ttrain-aucpr:0.99907+0.00005\ttest-aucpr:0.96074+0.00112\n",
            "[8]\ttrain-aucpr:0.99936+0.00002\ttest-aucpr:0.96267+0.00126\n",
            "[9]\ttrain-aucpr:0.99955+0.00002\ttest-aucpr:0.96462+0.00121\n",
            "[10]\ttrain-aucpr:0.99969+0.00002\ttest-aucpr:0.96603+0.00114\n",
            "[11]\ttrain-aucpr:0.99979+0.00002\ttest-aucpr:0.96711+0.00115\n",
            "[12]\ttrain-aucpr:0.99985+0.00001\ttest-aucpr:0.96808+0.00112\n",
            "[13]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.96898+0.00102\n",
            "[14]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.96969+0.00107\n",
            "[15]\ttrain-aucpr:0.99995+0.00001\ttest-aucpr:0.97030+0.00094\n",
            "[16]\ttrain-aucpr:0.99996+0.00001\ttest-aucpr:0.97092+0.00092\n",
            "[17]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.97144+0.00090\n",
            "[18]\ttrain-aucpr:0.99998+0.00001\ttest-aucpr:0.97177+0.00095\n",
            "[19]\ttrain-aucpr:0.99999+0.00001\ttest-aucpr:0.97212+0.00084\n",
            "result:  0.9721187317763581\n",
            "best result:  0.9721187317763581\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96911+0.00089\ttest-aucpr:0.89549+0.00183\n",
            "[1]\ttrain-aucpr:0.98967+0.00014\ttest-aucpr:0.92510+0.00173\n",
            "[2]\ttrain-aucpr:0.99513+0.00036\ttest-aucpr:0.93935+0.00212\n",
            "[3]\ttrain-aucpr:0.99729+0.00015\ttest-aucpr:0.94798+0.00186\n",
            "[4]\ttrain-aucpr:0.99830+0.00008\ttest-aucpr:0.95307+0.00136\n",
            "[5]\ttrain-aucpr:0.99893+0.00004\ttest-aucpr:0.95729+0.00120\n",
            "[6]\ttrain-aucpr:0.99928+0.00006\ttest-aucpr:0.95981+0.00097\n",
            "[7]\ttrain-aucpr:0.99951+0.00005\ttest-aucpr:0.96217+0.00094\n",
            "[8]\ttrain-aucpr:0.99969+0.00002\ttest-aucpr:0.96395+0.00132\n",
            "[9]\ttrain-aucpr:0.99979+0.00001\ttest-aucpr:0.96553+0.00137\n",
            "[10]\ttrain-aucpr:0.99986+0.00000\ttest-aucpr:0.96688+0.00110\n",
            "[11]\ttrain-aucpr:0.99991+0.00000\ttest-aucpr:0.96799+0.00104\n",
            "[12]\ttrain-aucpr:0.99994+0.00001\ttest-aucpr:0.96888+0.00095\n",
            "[13]\ttrain-aucpr:0.99996+0.00000\ttest-aucpr:0.96962+0.00086\n",
            "[14]\ttrain-aucpr:0.99997+0.00000\ttest-aucpr:0.97034+0.00083\n",
            "[15]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97078+0.00077\n",
            "[16]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97138+0.00075\n",
            "[17]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97172+0.00073\n",
            "[18]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97204+0.00067\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97239+0.00062\n",
            "result:  0.9723852208572146\n",
            "best result:  0.9723852208572146\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95233+0.00115\ttest-aucpr:0.89153+0.00172\n",
            "[1]\ttrain-aucpr:0.97842+0.00106\ttest-aucpr:0.92409+0.00283\n",
            "[2]\ttrain-aucpr:0.98759+0.00041\ttest-aucpr:0.93910+0.00121\n",
            "[3]\ttrain-aucpr:0.99135+0.00041\ttest-aucpr:0.94586+0.00120\n",
            "[4]\ttrain-aucpr:0.99370+0.00016\ttest-aucpr:0.95111+0.00129\n",
            "[5]\ttrain-aucpr:0.99525+0.00017\ttest-aucpr:0.95445+0.00124\n",
            "[6]\ttrain-aucpr:0.99632+0.00022\ttest-aucpr:0.95725+0.00117\n",
            "[7]\ttrain-aucpr:0.99714+0.00013\ttest-aucpr:0.95981+0.00112\n",
            "[8]\ttrain-aucpr:0.99774+0.00009\ttest-aucpr:0.96193+0.00114\n",
            "[9]\ttrain-aucpr:0.99820+0.00009\ttest-aucpr:0.96358+0.00120\n",
            "[10]\ttrain-aucpr:0.99858+0.00006\ttest-aucpr:0.96496+0.00091\n",
            "[11]\ttrain-aucpr:0.99887+0.00003\ttest-aucpr:0.96632+0.00083\n",
            "[12]\ttrain-aucpr:0.99909+0.00003\ttest-aucpr:0.96751+0.00078\n",
            "[13]\ttrain-aucpr:0.99925+0.00002\ttest-aucpr:0.96850+0.00069\n",
            "[14]\ttrain-aucpr:0.99938+0.00002\ttest-aucpr:0.96928+0.00069\n",
            "[15]\ttrain-aucpr:0.99950+0.00001\ttest-aucpr:0.97012+0.00073\n",
            "[16]\ttrain-aucpr:0.99959+0.00001\ttest-aucpr:0.97088+0.00056\n",
            "[17]\ttrain-aucpr:0.99965+0.00001\ttest-aucpr:0.97140+0.00053\n",
            "[18]\ttrain-aucpr:0.99971+0.00002\ttest-aucpr:0.97184+0.00049\n",
            "[19]\ttrain-aucpr:0.99974+0.00002\ttest-aucpr:0.97230+0.00047\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76422+0.00267\ttest-aucpr:0.75763+0.00312\n",
            "[1]\ttrain-aucpr:0.80387+0.00344\ttest-aucpr:0.79817+0.00252\n",
            "[2]\ttrain-aucpr:0.82020+0.00270\ttest-aucpr:0.81412+0.00397\n",
            "[3]\ttrain-aucpr:0.83029+0.00486\ttest-aucpr:0.82424+0.00544\n",
            "[4]\ttrain-aucpr:0.83779+0.00315\ttest-aucpr:0.83206+0.00351\n",
            "[5]\ttrain-aucpr:0.84460+0.00348\ttest-aucpr:0.83886+0.00387\n",
            "[6]\ttrain-aucpr:0.85066+0.00193\ttest-aucpr:0.84503+0.00240\n",
            "[7]\ttrain-aucpr:0.85444+0.00248\ttest-aucpr:0.84841+0.00344\n",
            "[8]\ttrain-aucpr:0.85794+0.00188\ttest-aucpr:0.85152+0.00302\n",
            "[9]\ttrain-aucpr:0.86192+0.00206\ttest-aucpr:0.85532+0.00322\n",
            "[10]\ttrain-aucpr:0.86529+0.00285\ttest-aucpr:0.85895+0.00355\n",
            "[11]\ttrain-aucpr:0.86822+0.00151\ttest-aucpr:0.86171+0.00218\n",
            "[12]\ttrain-aucpr:0.87148+0.00127\ttest-aucpr:0.86480+0.00149\n",
            "[13]\ttrain-aucpr:0.87429+0.00161\ttest-aucpr:0.86755+0.00172\n",
            "[14]\ttrain-aucpr:0.87721+0.00166\ttest-aucpr:0.87047+0.00154\n",
            "[15]\ttrain-aucpr:0.87970+0.00159\ttest-aucpr:0.87305+0.00168\n",
            "[16]\ttrain-aucpr:0.88242+0.00138\ttest-aucpr:0.87594+0.00155\n",
            "[17]\ttrain-aucpr:0.88541+0.00133\ttest-aucpr:0.87865+0.00112\n",
            "[18]\ttrain-aucpr:0.88779+0.00110\ttest-aucpr:0.88104+0.00097\n",
            "[19]\ttrain-aucpr:0.88962+0.00130\ttest-aucpr:0.88279+0.00089\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64987+0.00634\ttest-aucpr:0.64874+0.00608\n",
            "[1]\ttrain-aucpr:0.70880+0.00264\ttest-aucpr:0.70485+0.00410\n",
            "[2]\ttrain-aucpr:0.72856+0.00612\ttest-aucpr:0.72382+0.00731\n",
            "[3]\ttrain-aucpr:0.74159+0.00631\ttest-aucpr:0.73694+0.00586\n",
            "[4]\ttrain-aucpr:0.75730+0.00352\ttest-aucpr:0.75307+0.00479\n",
            "[5]\ttrain-aucpr:0.76874+0.00529\ttest-aucpr:0.76393+0.00677\n",
            "[6]\ttrain-aucpr:0.78018+0.00363\ttest-aucpr:0.77537+0.00511\n",
            "[7]\ttrain-aucpr:0.79237+0.00795\ttest-aucpr:0.78715+0.00802\n",
            "[8]\ttrain-aucpr:0.80307+0.00639\ttest-aucpr:0.79810+0.00732\n",
            "[9]\ttrain-aucpr:0.81304+0.00720\ttest-aucpr:0.80741+0.00807\n",
            "[10]\ttrain-aucpr:0.82082+0.00731\ttest-aucpr:0.81505+0.00833\n",
            "[11]\ttrain-aucpr:0.82665+0.00566\ttest-aucpr:0.82068+0.00655\n",
            "[12]\ttrain-aucpr:0.83245+0.00551\ttest-aucpr:0.82650+0.00647\n",
            "[13]\ttrain-aucpr:0.83744+0.00538\ttest-aucpr:0.83149+0.00618\n",
            "[14]\ttrain-aucpr:0.84265+0.00810\ttest-aucpr:0.83655+0.00878\n",
            "[15]\ttrain-aucpr:0.84596+0.00756\ttest-aucpr:0.83983+0.00788\n",
            "[16]\ttrain-aucpr:0.84976+0.00733\ttest-aucpr:0.84364+0.00753\n",
            "[17]\ttrain-aucpr:0.85300+0.00743\ttest-aucpr:0.84709+0.00734\n",
            "[18]\ttrain-aucpr:0.85630+0.00707\ttest-aucpr:0.85045+0.00702\n",
            "[19]\ttrain-aucpr:0.85919+0.00627\ttest-aucpr:0.85322+0.00641\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76422+0.00267\ttest-aucpr:0.75763+0.00312\n",
            "[1]\ttrain-aucpr:0.81163+0.00131\ttest-aucpr:0.80549+0.00341\n",
            "[2]\ttrain-aucpr:0.83412+0.00273\ttest-aucpr:0.82743+0.00314\n",
            "[3]\ttrain-aucpr:0.84963+0.00229\ttest-aucpr:0.84290+0.00255\n",
            "[4]\ttrain-aucpr:0.85837+0.00167\ttest-aucpr:0.85168+0.00180\n",
            "[5]\ttrain-aucpr:0.86761+0.00232\ttest-aucpr:0.86086+0.00251\n",
            "[6]\ttrain-aucpr:0.87444+0.00222\ttest-aucpr:0.86752+0.00177\n",
            "[7]\ttrain-aucpr:0.88169+0.00212\ttest-aucpr:0.87472+0.00241\n",
            "[8]\ttrain-aucpr:0.88765+0.00077\ttest-aucpr:0.88057+0.00143\n",
            "[9]\ttrain-aucpr:0.89312+0.00151\ttest-aucpr:0.88575+0.00179\n",
            "[10]\ttrain-aucpr:0.89656+0.00149\ttest-aucpr:0.88908+0.00197\n",
            "[11]\ttrain-aucpr:0.90097+0.00133\ttest-aucpr:0.89355+0.00128\n",
            "[12]\ttrain-aucpr:0.90523+0.00152\ttest-aucpr:0.89769+0.00132\n",
            "[13]\ttrain-aucpr:0.90977+0.00154\ttest-aucpr:0.90216+0.00175\n",
            "[14]\ttrain-aucpr:0.91317+0.00167\ttest-aucpr:0.90543+0.00151\n",
            "[15]\ttrain-aucpr:0.91640+0.00167\ttest-aucpr:0.90865+0.00119\n",
            "[16]\ttrain-aucpr:0.91879+0.00204\ttest-aucpr:0.91107+0.00137\n",
            "[17]\ttrain-aucpr:0.92113+0.00150\ttest-aucpr:0.91354+0.00103\n",
            "[18]\ttrain-aucpr:0.92288+0.00157\ttest-aucpr:0.91531+0.00104\n",
            "[19]\ttrain-aucpr:0.92492+0.00097\ttest-aucpr:0.91715+0.00097\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90671+0.00064\ttest-aucpr:0.87767+0.00210\n",
            "[1]\ttrain-aucpr:0.93907+0.00320\ttest-aucpr:0.91375+0.00329\n",
            "[2]\ttrain-aucpr:0.95335+0.00092\ttest-aucpr:0.92906+0.00092\n",
            "[3]\ttrain-aucpr:0.96185+0.00044\ttest-aucpr:0.93760+0.00088\n",
            "[4]\ttrain-aucpr:0.96815+0.00030\ttest-aucpr:0.94412+0.00106\n",
            "[5]\ttrain-aucpr:0.97239+0.00058\ttest-aucpr:0.94846+0.00070\n",
            "[6]\ttrain-aucpr:0.97566+0.00088\ttest-aucpr:0.95225+0.00083\n",
            "[7]\ttrain-aucpr:0.97830+0.00087\ttest-aucpr:0.95532+0.00083\n",
            "[8]\ttrain-aucpr:0.98009+0.00101\ttest-aucpr:0.95753+0.00105\n",
            "[9]\ttrain-aucpr:0.98161+0.00076\ttest-aucpr:0.95912+0.00087\n",
            "[10]\ttrain-aucpr:0.98305+0.00089\ttest-aucpr:0.96093+0.00064\n",
            "[11]\ttrain-aucpr:0.98434+0.00061\ttest-aucpr:0.96231+0.00037\n",
            "[12]\ttrain-aucpr:0.98558+0.00069\ttest-aucpr:0.96370+0.00014\n",
            "[13]\ttrain-aucpr:0.98654+0.00072\ttest-aucpr:0.96486+0.00036\n",
            "[14]\ttrain-aucpr:0.98701+0.00057\ttest-aucpr:0.96551+0.00022\n",
            "[15]\ttrain-aucpr:0.98771+0.00058\ttest-aucpr:0.96619+0.00037\n",
            "[16]\ttrain-aucpr:0.98808+0.00064\ttest-aucpr:0.96666+0.00038\n",
            "[17]\ttrain-aucpr:0.98880+0.00081\ttest-aucpr:0.96706+0.00074\n",
            "[18]\ttrain-aucpr:0.98948+0.00094\ttest-aucpr:0.96760+0.00083\n",
            "[19]\ttrain-aucpr:0.98995+0.00093\ttest-aucpr:0.96784+0.00080\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64987+0.00634\ttest-aucpr:0.64874+0.00608\n",
            "[1]\ttrain-aucpr:0.69012+0.00154\ttest-aucpr:0.68783+0.00331\n",
            "[2]\ttrain-aucpr:0.70727+0.00298\ttest-aucpr:0.70403+0.00395\n",
            "[3]\ttrain-aucpr:0.71805+0.00434\ttest-aucpr:0.71365+0.00443\n",
            "[4]\ttrain-aucpr:0.73017+0.00335\ttest-aucpr:0.72592+0.00604\n",
            "[5]\ttrain-aucpr:0.73827+0.00277\ttest-aucpr:0.73407+0.00388\n",
            "[6]\ttrain-aucpr:0.74238+0.00141\ttest-aucpr:0.73828+0.00328\n",
            "[7]\ttrain-aucpr:0.74563+0.00197\ttest-aucpr:0.74174+0.00256\n",
            "[8]\ttrain-aucpr:0.75021+0.00231\ttest-aucpr:0.74585+0.00255\n",
            "[9]\ttrain-aucpr:0.75111+0.00169\ttest-aucpr:0.74673+0.00321\n",
            "[10]\ttrain-aucpr:0.75430+0.00147\ttest-aucpr:0.75034+0.00286\n",
            "[11]\ttrain-aucpr:0.75777+0.00290\ttest-aucpr:0.75376+0.00303\n",
            "[12]\ttrain-aucpr:0.76101+0.00261\ttest-aucpr:0.75686+0.00309\n",
            "[13]\ttrain-aucpr:0.76273+0.00186\ttest-aucpr:0.75853+0.00113\n",
            "[14]\ttrain-aucpr:0.76581+0.00199\ttest-aucpr:0.76157+0.00226\n",
            "[15]\ttrain-aucpr:0.76948+0.00131\ttest-aucpr:0.76501+0.00160\n",
            "[16]\ttrain-aucpr:0.77252+0.00188\ttest-aucpr:0.76805+0.00141\n",
            "[17]\ttrain-aucpr:0.77709+0.00170\ttest-aucpr:0.77257+0.00181\n",
            "[18]\ttrain-aucpr:0.78098+0.00244\ttest-aucpr:0.77654+0.00205\n",
            "[19]\ttrain-aucpr:0.78425+0.00204\ttest-aucpr:0.77990+0.00179\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76422+0.00267\ttest-aucpr:0.75763+0.00312\n",
            "[1]\ttrain-aucpr:0.80387+0.00344\ttest-aucpr:0.79817+0.00252\n",
            "[2]\ttrain-aucpr:0.82020+0.00270\ttest-aucpr:0.81412+0.00397\n",
            "[3]\ttrain-aucpr:0.83029+0.00486\ttest-aucpr:0.82424+0.00544\n",
            "[4]\ttrain-aucpr:0.83779+0.00315\ttest-aucpr:0.83206+0.00351\n",
            "[5]\ttrain-aucpr:0.84460+0.00348\ttest-aucpr:0.83886+0.00387\n",
            "[6]\ttrain-aucpr:0.85066+0.00193\ttest-aucpr:0.84503+0.00240\n",
            "[7]\ttrain-aucpr:0.85444+0.00248\ttest-aucpr:0.84841+0.00344\n",
            "[8]\ttrain-aucpr:0.85794+0.00188\ttest-aucpr:0.85152+0.00302\n",
            "[9]\ttrain-aucpr:0.86192+0.00206\ttest-aucpr:0.85532+0.00322\n",
            "[10]\ttrain-aucpr:0.86529+0.00285\ttest-aucpr:0.85895+0.00355\n",
            "[11]\ttrain-aucpr:0.86822+0.00151\ttest-aucpr:0.86171+0.00218\n",
            "[12]\ttrain-aucpr:0.87148+0.00127\ttest-aucpr:0.86480+0.00149\n",
            "[13]\ttrain-aucpr:0.87429+0.00161\ttest-aucpr:0.86755+0.00172\n",
            "[14]\ttrain-aucpr:0.87721+0.00166\ttest-aucpr:0.87047+0.00154\n",
            "[15]\ttrain-aucpr:0.87970+0.00159\ttest-aucpr:0.87305+0.00168\n",
            "[16]\ttrain-aucpr:0.88242+0.00138\ttest-aucpr:0.87594+0.00155\n",
            "[17]\ttrain-aucpr:0.88541+0.00133\ttest-aucpr:0.87865+0.00112\n",
            "[18]\ttrain-aucpr:0.88779+0.00110\ttest-aucpr:0.88104+0.00097\n",
            "[19]\ttrain-aucpr:0.88962+0.00130\ttest-aucpr:0.88279+0.00089\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90144+0.00170\ttest-aucpr:0.87655+0.00207\n",
            "[1]\ttrain-aucpr:0.92702+0.00460\ttest-aucpr:0.90344+0.00555\n",
            "[2]\ttrain-aucpr:0.93870+0.00351\ttest-aucpr:0.91709+0.00456\n",
            "[3]\ttrain-aucpr:0.94627+0.00209\ttest-aucpr:0.92596+0.00199\n",
            "[4]\ttrain-aucpr:0.95069+0.00134\ttest-aucpr:0.93080+0.00140\n",
            "[5]\ttrain-aucpr:0.95384+0.00091\ttest-aucpr:0.93406+0.00127\n",
            "[6]\ttrain-aucpr:0.95706+0.00056\ttest-aucpr:0.93779+0.00089\n",
            "[7]\ttrain-aucpr:0.95928+0.00086\ttest-aucpr:0.93987+0.00116\n",
            "[8]\ttrain-aucpr:0.96104+0.00094\ttest-aucpr:0.94156+0.00085\n",
            "[9]\ttrain-aucpr:0.96273+0.00089\ttest-aucpr:0.94331+0.00088\n",
            "[10]\ttrain-aucpr:0.96441+0.00068\ttest-aucpr:0.94514+0.00052\n",
            "[11]\ttrain-aucpr:0.96597+0.00053\ttest-aucpr:0.94675+0.00054\n",
            "[12]\ttrain-aucpr:0.96716+0.00006\ttest-aucpr:0.94811+0.00047\n",
            "[13]\ttrain-aucpr:0.96863+0.00030\ttest-aucpr:0.94977+0.00014\n",
            "[14]\ttrain-aucpr:0.96975+0.00021\ttest-aucpr:0.95096+0.00023\n",
            "[15]\ttrain-aucpr:0.97070+0.00035\ttest-aucpr:0.95196+0.00045\n",
            "[16]\ttrain-aucpr:0.97192+0.00039\ttest-aucpr:0.95315+0.00060\n",
            "[17]\ttrain-aucpr:0.97277+0.00045\ttest-aucpr:0.95401+0.00057\n",
            "[18]\ttrain-aucpr:0.97362+0.00056\ttest-aucpr:0.95494+0.00050\n",
            "[19]\ttrain-aucpr:0.97440+0.00052\ttest-aucpr:0.95587+0.00050\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.97842+0.00056\ttest-aucpr:0.88865+0.00264\n",
            "[1]\ttrain-aucpr:0.98740+0.00098\ttest-aucpr:0.91021+0.00372\n",
            "[2]\ttrain-aucpr:0.99257+0.00107\ttest-aucpr:0.92476+0.00585\n",
            "[3]\ttrain-aucpr:0.99486+0.00053\ttest-aucpr:0.93395+0.00308\n",
            "[4]\ttrain-aucpr:0.99619+0.00035\ttest-aucpr:0.93926+0.00225\n",
            "[5]\ttrain-aucpr:0.99707+0.00019\ttest-aucpr:0.94414+0.00213\n",
            "[6]\ttrain-aucpr:0.99759+0.00016\ttest-aucpr:0.94759+0.00184\n",
            "[7]\ttrain-aucpr:0.99807+0.00010\ttest-aucpr:0.95078+0.00135\n",
            "[8]\ttrain-aucpr:0.99840+0.00012\ttest-aucpr:0.95251+0.00149\n",
            "[9]\ttrain-aucpr:0.99864+0.00010\ttest-aucpr:0.95424+0.00109\n",
            "[10]\ttrain-aucpr:0.99890+0.00007\ttest-aucpr:0.95665+0.00088\n",
            "[11]\ttrain-aucpr:0.99909+0.00009\ttest-aucpr:0.95812+0.00092\n",
            "[12]\ttrain-aucpr:0.99922+0.00005\ttest-aucpr:0.95924+0.00085\n",
            "[13]\ttrain-aucpr:0.99933+0.00003\ttest-aucpr:0.96052+0.00060\n",
            "[14]\ttrain-aucpr:0.99942+0.00005\ttest-aucpr:0.96132+0.00062\n",
            "[15]\ttrain-aucpr:0.99951+0.00004\ttest-aucpr:0.96212+0.00053\n",
            "[16]\ttrain-aucpr:0.99957+0.00004\ttest-aucpr:0.96285+0.00048\n",
            "[17]\ttrain-aucpr:0.99965+0.00003\ttest-aucpr:0.96358+0.00045\n",
            "[18]\ttrain-aucpr:0.99969+0.00002\ttest-aucpr:0.96414+0.00037\n",
            "[19]\ttrain-aucpr:0.99974+0.00002\ttest-aucpr:0.96469+0.00037\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94434+0.00125\ttest-aucpr:0.89002+0.00154\n",
            "[1]\ttrain-aucpr:0.96416+0.00375\ttest-aucpr:0.91379+0.00502\n",
            "[2]\ttrain-aucpr:0.97433+0.00199\ttest-aucpr:0.92771+0.00399\n",
            "[3]\ttrain-aucpr:0.97991+0.00152\ttest-aucpr:0.93599+0.00321\n",
            "[4]\ttrain-aucpr:0.98320+0.00115\ttest-aucpr:0.94118+0.00252\n",
            "[5]\ttrain-aucpr:0.98551+0.00089\ttest-aucpr:0.94456+0.00244\n",
            "[6]\ttrain-aucpr:0.98716+0.00067\ttest-aucpr:0.94767+0.00191\n",
            "[7]\ttrain-aucpr:0.98882+0.00038\ttest-aucpr:0.95093+0.00153\n",
            "[8]\ttrain-aucpr:0.98985+0.00040\ttest-aucpr:0.95265+0.00143\n",
            "[9]\ttrain-aucpr:0.99082+0.00025\ttest-aucpr:0.95451+0.00100\n",
            "[10]\ttrain-aucpr:0.99151+0.00022\ttest-aucpr:0.95581+0.00102\n",
            "[11]\ttrain-aucpr:0.99222+0.00012\ttest-aucpr:0.95710+0.00074\n",
            "[12]\ttrain-aucpr:0.99282+0.00013\ttest-aucpr:0.95830+0.00068\n",
            "[13]\ttrain-aucpr:0.99330+0.00009\ttest-aucpr:0.95935+0.00067\n",
            "[14]\ttrain-aucpr:0.99385+0.00006\ttest-aucpr:0.96045+0.00062\n",
            "[15]\ttrain-aucpr:0.99423+0.00008\ttest-aucpr:0.96118+0.00060\n",
            "[16]\ttrain-aucpr:0.99464+0.00009\ttest-aucpr:0.96213+0.00057\n",
            "[17]\ttrain-aucpr:0.99499+0.00009\ttest-aucpr:0.96278+0.00062\n",
            "[18]\ttrain-aucpr:0.99533+0.00006\ttest-aucpr:0.96351+0.00071\n",
            "[19]\ttrain-aucpr:0.99564+0.00004\ttest-aucpr:0.96414+0.00068\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95490+0.00157\ttest-aucpr:0.89088+0.00187\n",
            "[1]\ttrain-aucpr:0.98048+0.00101\ttest-aucpr:0.92324+0.00318\n",
            "[2]\ttrain-aucpr:0.98938+0.00039\ttest-aucpr:0.93810+0.00053\n",
            "[3]\ttrain-aucpr:0.99302+0.00039\ttest-aucpr:0.94470+0.00111\n",
            "[4]\ttrain-aucpr:0.99522+0.00030\ttest-aucpr:0.95041+0.00121\n",
            "[5]\ttrain-aucpr:0.99652+0.00017\ttest-aucpr:0.95443+0.00112\n",
            "[6]\ttrain-aucpr:0.99743+0.00016\ttest-aucpr:0.95666+0.00111\n",
            "[7]\ttrain-aucpr:0.99809+0.00011\ttest-aucpr:0.95868+0.00097\n",
            "[8]\ttrain-aucpr:0.99859+0.00006\ttest-aucpr:0.96058+0.00076\n",
            "[9]\ttrain-aucpr:0.99895+0.00005\ttest-aucpr:0.96238+0.00084\n",
            "[10]\ttrain-aucpr:0.99921+0.00004\ttest-aucpr:0.96404+0.00080\n",
            "[11]\ttrain-aucpr:0.99941+0.00003\ttest-aucpr:0.96533+0.00096\n",
            "[12]\ttrain-aucpr:0.99956+0.00002\ttest-aucpr:0.96654+0.00089\n",
            "[13]\ttrain-aucpr:0.99967+0.00001\ttest-aucpr:0.96749+0.00086\n",
            "[14]\ttrain-aucpr:0.99975+0.00001\ttest-aucpr:0.96841+0.00080\n",
            "[15]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.96903+0.00069\n",
            "[16]\ttrain-aucpr:0.99985+0.00001\ttest-aucpr:0.96988+0.00082\n",
            "[17]\ttrain-aucpr:0.99989+0.00000\ttest-aucpr:0.97052+0.00064\n",
            "[18]\ttrain-aucpr:0.99991+0.00000\ttest-aucpr:0.97110+0.00057\n",
            "[19]\ttrain-aucpr:0.99993+0.00000\ttest-aucpr:0.97164+0.00055\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76428+0.00262\ttest-aucpr:0.75761+0.00327\n",
            "[1]\ttrain-aucpr:0.81755+0.00302\ttest-aucpr:0.81147+0.00460\n",
            "[2]\ttrain-aucpr:0.83976+0.00299\ttest-aucpr:0.83413+0.00323\n",
            "[3]\ttrain-aucpr:0.85376+0.00224\ttest-aucpr:0.84766+0.00298\n",
            "[4]\ttrain-aucpr:0.86840+0.00125\ttest-aucpr:0.86225+0.00107\n",
            "[5]\ttrain-aucpr:0.87699+0.00217\ttest-aucpr:0.87018+0.00204\n",
            "[6]\ttrain-aucpr:0.88666+0.00141\ttest-aucpr:0.87994+0.00114\n",
            "[7]\ttrain-aucpr:0.89394+0.00307\ttest-aucpr:0.88725+0.00253\n",
            "[8]\ttrain-aucpr:0.89815+0.00221\ttest-aucpr:0.89142+0.00247\n",
            "[9]\ttrain-aucpr:0.90344+0.00265\ttest-aucpr:0.89666+0.00186\n",
            "[10]\ttrain-aucpr:0.90772+0.00299\ttest-aucpr:0.90087+0.00230\n",
            "[11]\ttrain-aucpr:0.91115+0.00175\ttest-aucpr:0.90397+0.00181\n",
            "[12]\ttrain-aucpr:0.91482+0.00192\ttest-aucpr:0.90729+0.00238\n",
            "[13]\ttrain-aucpr:0.91948+0.00191\ttest-aucpr:0.91199+0.00178\n",
            "[14]\ttrain-aucpr:0.92318+0.00255\ttest-aucpr:0.91538+0.00146\n",
            "[15]\ttrain-aucpr:0.92594+0.00236\ttest-aucpr:0.91810+0.00139\n",
            "[16]\ttrain-aucpr:0.92825+0.00268\ttest-aucpr:0.92044+0.00106\n",
            "[17]\ttrain-aucpr:0.92981+0.00277\ttest-aucpr:0.92182+0.00126\n",
            "[18]\ttrain-aucpr:0.93204+0.00289\ttest-aucpr:0.92394+0.00153\n",
            "[19]\ttrain-aucpr:0.93319+0.00301\ttest-aucpr:0.92505+0.00178\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76422+0.00267\ttest-aucpr:0.75763+0.00312\n",
            "[1]\ttrain-aucpr:0.81741+0.00310\ttest-aucpr:0.81133+0.00469\n",
            "[2]\ttrain-aucpr:0.83963+0.00304\ttest-aucpr:0.83388+0.00336\n",
            "[3]\ttrain-aucpr:0.85356+0.00227\ttest-aucpr:0.84747+0.00307\n",
            "[4]\ttrain-aucpr:0.86739+0.00214\ttest-aucpr:0.86115+0.00206\n",
            "[5]\ttrain-aucpr:0.87620+0.00265\ttest-aucpr:0.86948+0.00254\n",
            "[6]\ttrain-aucpr:0.88608+0.00242\ttest-aucpr:0.87932+0.00243\n",
            "[7]\ttrain-aucpr:0.89265+0.00149\ttest-aucpr:0.88593+0.00104\n",
            "[8]\ttrain-aucpr:0.89837+0.00114\ttest-aucpr:0.89162+0.00085\n",
            "[9]\ttrain-aucpr:0.90273+0.00202\ttest-aucpr:0.89590+0.00158\n",
            "[10]\ttrain-aucpr:0.90644+0.00273\ttest-aucpr:0.89948+0.00206\n",
            "[11]\ttrain-aucpr:0.91189+0.00292\ttest-aucpr:0.90470+0.00248\n",
            "[12]\ttrain-aucpr:0.91556+0.00229\ttest-aucpr:0.90819+0.00234\n",
            "[13]\ttrain-aucpr:0.91784+0.00268\ttest-aucpr:0.91041+0.00305\n",
            "[14]\ttrain-aucpr:0.92052+0.00337\ttest-aucpr:0.91299+0.00372\n",
            "[15]\ttrain-aucpr:0.92392+0.00252\ttest-aucpr:0.91638+0.00233\n",
            "[16]\ttrain-aucpr:0.92634+0.00140\ttest-aucpr:0.91904+0.00168\n",
            "[17]\ttrain-aucpr:0.92938+0.00183\ttest-aucpr:0.92199+0.00151\n",
            "[18]\ttrain-aucpr:0.93155+0.00131\ttest-aucpr:0.92400+0.00128\n",
            "[19]\ttrain-aucpr:0.93277+0.00135\ttest-aucpr:0.92520+0.00176\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64987+0.00634\ttest-aucpr:0.64874+0.00608\n",
            "[1]\ttrain-aucpr:0.70203+0.00170\ttest-aucpr:0.69839+0.00300\n",
            "[2]\ttrain-aucpr:0.71937+0.00397\ttest-aucpr:0.71477+0.00538\n",
            "[3]\ttrain-aucpr:0.73643+0.00335\ttest-aucpr:0.73254+0.00545\n",
            "[4]\ttrain-aucpr:0.74848+0.00401\ttest-aucpr:0.74432+0.00561\n",
            "[5]\ttrain-aucpr:0.75918+0.00293\ttest-aucpr:0.75481+0.00300\n",
            "[6]\ttrain-aucpr:0.76719+0.00221\ttest-aucpr:0.76215+0.00263\n",
            "[7]\ttrain-aucpr:0.77713+0.00102\ttest-aucpr:0.77198+0.00219\n",
            "[8]\ttrain-aucpr:0.78518+0.00279\ttest-aucpr:0.77985+0.00137\n",
            "[9]\ttrain-aucpr:0.79105+0.00343\ttest-aucpr:0.78559+0.00245\n",
            "[10]\ttrain-aucpr:0.79922+0.00179\ttest-aucpr:0.79358+0.00160\n",
            "[11]\ttrain-aucpr:0.80630+0.00320\ttest-aucpr:0.80038+0.00390\n",
            "[12]\ttrain-aucpr:0.81083+0.00192\ttest-aucpr:0.80517+0.00305\n",
            "[13]\ttrain-aucpr:0.81831+0.00242\ttest-aucpr:0.81271+0.00338\n",
            "[14]\ttrain-aucpr:0.82364+0.00407\ttest-aucpr:0.81829+0.00441\n",
            "[15]\ttrain-aucpr:0.82784+0.00334\ttest-aucpr:0.82224+0.00425\n",
            "[16]\ttrain-aucpr:0.83160+0.00320\ttest-aucpr:0.82590+0.00417\n",
            "[17]\ttrain-aucpr:0.83591+0.00404\ttest-aucpr:0.83022+0.00508\n",
            "[18]\ttrain-aucpr:0.83932+0.00400\ttest-aucpr:0.83384+0.00492\n",
            "[19]\ttrain-aucpr:0.84210+0.00367\ttest-aucpr:0.83671+0.00432\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64987+0.00634\ttest-aucpr:0.64874+0.00608\n",
            "[1]\ttrain-aucpr:0.70202+0.00170\ttest-aucpr:0.69830+0.00290\n",
            "[2]\ttrain-aucpr:0.71935+0.00398\ttest-aucpr:0.71472+0.00535\n",
            "[3]\ttrain-aucpr:0.73642+0.00335\ttest-aucpr:0.73251+0.00543\n",
            "[4]\ttrain-aucpr:0.74846+0.00402\ttest-aucpr:0.74429+0.00558\n",
            "[5]\ttrain-aucpr:0.75915+0.00294\ttest-aucpr:0.75477+0.00299\n",
            "[6]\ttrain-aucpr:0.76716+0.00220\ttest-aucpr:0.76207+0.00254\n",
            "[7]\ttrain-aucpr:0.77719+0.00112\ttest-aucpr:0.77213+0.00247\n",
            "[8]\ttrain-aucpr:0.78538+0.00238\ttest-aucpr:0.78001+0.00118\n",
            "[9]\ttrain-aucpr:0.79225+0.00158\ttest-aucpr:0.78679+0.00225\n",
            "[10]\ttrain-aucpr:0.79857+0.00291\ttest-aucpr:0.79326+0.00179\n",
            "[11]\ttrain-aucpr:0.80698+0.00244\ttest-aucpr:0.80139+0.00304\n",
            "[12]\ttrain-aucpr:0.81016+0.00261\ttest-aucpr:0.80439+0.00345\n",
            "[13]\ttrain-aucpr:0.81640+0.00332\ttest-aucpr:0.81082+0.00317\n",
            "[14]\ttrain-aucpr:0.82157+0.00260\ttest-aucpr:0.81624+0.00317\n",
            "[15]\ttrain-aucpr:0.82540+0.00262\ttest-aucpr:0.81994+0.00353\n",
            "[16]\ttrain-aucpr:0.83030+0.00337\ttest-aucpr:0.82473+0.00433\n",
            "[17]\ttrain-aucpr:0.83369+0.00371\ttest-aucpr:0.82809+0.00503\n",
            "[18]\ttrain-aucpr:0.83688+0.00266\ttest-aucpr:0.83139+0.00426\n",
            "[19]\ttrain-aucpr:0.84030+0.00246\ttest-aucpr:0.83481+0.00381\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90528+0.00108\ttest-aucpr:0.87791+0.00174\n",
            "[1]\ttrain-aucpr:0.93645+0.00365\ttest-aucpr:0.91246+0.00443\n",
            "[2]\ttrain-aucpr:0.94966+0.00145\ttest-aucpr:0.92678+0.00123\n",
            "[3]\ttrain-aucpr:0.95776+0.00091\ttest-aucpr:0.93448+0.00081\n",
            "[4]\ttrain-aucpr:0.96296+0.00066\ttest-aucpr:0.93942+0.00100\n",
            "[5]\ttrain-aucpr:0.96725+0.00043\ttest-aucpr:0.94375+0.00028\n",
            "[6]\ttrain-aucpr:0.97084+0.00061\ttest-aucpr:0.94759+0.00074\n",
            "[7]\ttrain-aucpr:0.97373+0.00061\ttest-aucpr:0.95065+0.00049\n",
            "[8]\ttrain-aucpr:0.97616+0.00059\ttest-aucpr:0.95331+0.00039\n",
            "[9]\ttrain-aucpr:0.97815+0.00049\ttest-aucpr:0.95527+0.00061\n",
            "[10]\ttrain-aucpr:0.97976+0.00068\ttest-aucpr:0.95724+0.00095\n",
            "[11]\ttrain-aucpr:0.98134+0.00051\ttest-aucpr:0.95904+0.00091\n",
            "[12]\ttrain-aucpr:0.98249+0.00018\ttest-aucpr:0.96042+0.00050\n",
            "[13]\ttrain-aucpr:0.98346+0.00027\ttest-aucpr:0.96159+0.00073\n",
            "[14]\ttrain-aucpr:0.98413+0.00044\ttest-aucpr:0.96249+0.00093\n",
            "[15]\ttrain-aucpr:0.98464+0.00039\ttest-aucpr:0.96314+0.00074\n",
            "[16]\ttrain-aucpr:0.98537+0.00028\ttest-aucpr:0.96402+0.00067\n",
            "[17]\ttrain-aucpr:0.98608+0.00020\ttest-aucpr:0.96482+0.00063\n",
            "[18]\ttrain-aucpr:0.98641+0.00018\ttest-aucpr:0.96517+0.00064\n",
            "[19]\ttrain-aucpr:0.98705+0.00021\ttest-aucpr:0.96587+0.00081\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76422+0.00267\ttest-aucpr:0.75763+0.00312\n",
            "[1]\ttrain-aucpr:0.81741+0.00310\ttest-aucpr:0.81133+0.00469\n",
            "[2]\ttrain-aucpr:0.83963+0.00304\ttest-aucpr:0.83388+0.00336\n",
            "[3]\ttrain-aucpr:0.85356+0.00227\ttest-aucpr:0.84747+0.00307\n",
            "[4]\ttrain-aucpr:0.86739+0.00214\ttest-aucpr:0.86115+0.00206\n",
            "[5]\ttrain-aucpr:0.87620+0.00265\ttest-aucpr:0.86948+0.00254\n",
            "[6]\ttrain-aucpr:0.88608+0.00242\ttest-aucpr:0.87932+0.00243\n",
            "[7]\ttrain-aucpr:0.89265+0.00149\ttest-aucpr:0.88593+0.00104\n",
            "[8]\ttrain-aucpr:0.89837+0.00114\ttest-aucpr:0.89162+0.00085\n",
            "[9]\ttrain-aucpr:0.90273+0.00202\ttest-aucpr:0.89590+0.00158\n",
            "[10]\ttrain-aucpr:0.90645+0.00273\ttest-aucpr:0.89948+0.00206\n",
            "[11]\ttrain-aucpr:0.91189+0.00292\ttest-aucpr:0.90472+0.00246\n",
            "[12]\ttrain-aucpr:0.91557+0.00229\ttest-aucpr:0.90821+0.00231\n",
            "[13]\ttrain-aucpr:0.91790+0.00262\ttest-aucpr:0.91047+0.00294\n",
            "[14]\ttrain-aucpr:0.92057+0.00335\ttest-aucpr:0.91302+0.00365\n",
            "[15]\ttrain-aucpr:0.92377+0.00272\ttest-aucpr:0.91622+0.00260\n",
            "[16]\ttrain-aucpr:0.92621+0.00200\ttest-aucpr:0.91862+0.00240\n",
            "[17]\ttrain-aucpr:0.92917+0.00181\ttest-aucpr:0.92148+0.00165\n",
            "[18]\ttrain-aucpr:0.93129+0.00151\ttest-aucpr:0.92353+0.00167\n",
            "[19]\ttrain-aucpr:0.93298+0.00182\ttest-aucpr:0.92515+0.00197\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76428+0.00262\ttest-aucpr:0.75761+0.00327\n",
            "[1]\ttrain-aucpr:0.81171+0.00118\ttest-aucpr:0.80565+0.00335\n",
            "[2]\ttrain-aucpr:0.83421+0.00274\ttest-aucpr:0.82761+0.00316\n",
            "[3]\ttrain-aucpr:0.85019+0.00220\ttest-aucpr:0.84366+0.00276\n",
            "[4]\ttrain-aucpr:0.85874+0.00116\ttest-aucpr:0.85221+0.00149\n",
            "[5]\ttrain-aucpr:0.86862+0.00180\ttest-aucpr:0.86210+0.00176\n",
            "[6]\ttrain-aucpr:0.87574+0.00144\ttest-aucpr:0.86863+0.00102\n",
            "[7]\ttrain-aucpr:0.88100+0.00187\ttest-aucpr:0.87371+0.00172\n",
            "[8]\ttrain-aucpr:0.88691+0.00297\ttest-aucpr:0.87945+0.00287\n",
            "[9]\ttrain-aucpr:0.89174+0.00193\ttest-aucpr:0.88415+0.00186\n",
            "[10]\ttrain-aucpr:0.89732+0.00171\ttest-aucpr:0.88980+0.00103\n",
            "[11]\ttrain-aucpr:0.90133+0.00142\ttest-aucpr:0.89362+0.00079\n",
            "[12]\ttrain-aucpr:0.90439+0.00146\ttest-aucpr:0.89669+0.00126\n",
            "[13]\ttrain-aucpr:0.90821+0.00123\ttest-aucpr:0.90032+0.00137\n",
            "[14]\ttrain-aucpr:0.91194+0.00138\ttest-aucpr:0.90413+0.00147\n",
            "[15]\ttrain-aucpr:0.91560+0.00213\ttest-aucpr:0.90770+0.00247\n",
            "[16]\ttrain-aucpr:0.91846+0.00249\ttest-aucpr:0.91043+0.00299\n",
            "[17]\ttrain-aucpr:0.92032+0.00298\ttest-aucpr:0.91222+0.00367\n",
            "[18]\ttrain-aucpr:0.92272+0.00261\ttest-aucpr:0.91453+0.00332\n",
            "[19]\ttrain-aucpr:0.92467+0.00278\ttest-aucpr:0.91641+0.00328\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95233+0.00115\ttest-aucpr:0.89153+0.00172\n",
            "[1]\ttrain-aucpr:0.98090+0.00136\ttest-aucpr:0.92670+0.00339\n",
            "[2]\ttrain-aucpr:0.98970+0.00050\ttest-aucpr:0.94056+0.00214\n",
            "[3]\ttrain-aucpr:0.99324+0.00035\ttest-aucpr:0.94831+0.00113\n",
            "[4]\ttrain-aucpr:0.99539+0.00015\ttest-aucpr:0.95385+0.00101\n",
            "[5]\ttrain-aucpr:0.99669+0.00010\ttest-aucpr:0.95721+0.00075\n",
            "[6]\ttrain-aucpr:0.99760+0.00011\ttest-aucpr:0.95997+0.00072\n",
            "[7]\ttrain-aucpr:0.99829+0.00003\ttest-aucpr:0.96234+0.00102\n",
            "[8]\ttrain-aucpr:0.99874+0.00003\ttest-aucpr:0.96417+0.00089\n",
            "[9]\ttrain-aucpr:0.99905+0.00005\ttest-aucpr:0.96582+0.00095\n",
            "[10]\ttrain-aucpr:0.99926+0.00004\ttest-aucpr:0.96702+0.00087\n",
            "[11]\ttrain-aucpr:0.99943+0.00002\ttest-aucpr:0.96805+0.00090\n",
            "[12]\ttrain-aucpr:0.99955+0.00002\ttest-aucpr:0.96906+0.00093\n",
            "[13]\ttrain-aucpr:0.99964+0.00003\ttest-aucpr:0.96976+0.00086\n",
            "[14]\ttrain-aucpr:0.99971+0.00003\ttest-aucpr:0.97052+0.00072\n",
            "[15]\ttrain-aucpr:0.99977+0.00004\ttest-aucpr:0.97110+0.00076\n",
            "[16]\ttrain-aucpr:0.99982+0.00003\ttest-aucpr:0.97161+0.00078\n",
            "[17]\ttrain-aucpr:0.99985+0.00004\ttest-aucpr:0.97196+0.00071\n",
            "[18]\ttrain-aucpr:0.99988+0.00003\ttest-aucpr:0.97221+0.00086\n",
            "[19]\ttrain-aucpr:0.99991+0.00002\ttest-aucpr:0.97245+0.00076\n",
            "result:  0.972449628509269\n",
            "best result:  0.972449628509269\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76422+0.00267\ttest-aucpr:0.75763+0.00312\n",
            "[1]\ttrain-aucpr:0.80387+0.00344\ttest-aucpr:0.79817+0.00252\n",
            "[2]\ttrain-aucpr:0.82021+0.00270\ttest-aucpr:0.81413+0.00397\n",
            "[3]\ttrain-aucpr:0.83034+0.00488\ttest-aucpr:0.82432+0.00552\n",
            "[4]\ttrain-aucpr:0.83782+0.00315\ttest-aucpr:0.83211+0.00357\n",
            "[5]\ttrain-aucpr:0.84463+0.00347\ttest-aucpr:0.83892+0.00390\n",
            "[6]\ttrain-aucpr:0.85069+0.00193\ttest-aucpr:0.84511+0.00248\n",
            "[7]\ttrain-aucpr:0.85435+0.00247\ttest-aucpr:0.84839+0.00341\n",
            "[8]\ttrain-aucpr:0.85782+0.00185\ttest-aucpr:0.85148+0.00296\n",
            "[9]\ttrain-aucpr:0.86140+0.00217\ttest-aucpr:0.85501+0.00293\n",
            "[10]\ttrain-aucpr:0.86537+0.00283\ttest-aucpr:0.85910+0.00364\n",
            "[11]\ttrain-aucpr:0.86850+0.00155\ttest-aucpr:0.86205+0.00264\n",
            "[12]\ttrain-aucpr:0.87177+0.00099\ttest-aucpr:0.86513+0.00195\n",
            "[13]\ttrain-aucpr:0.87457+0.00149\ttest-aucpr:0.86786+0.00208\n",
            "[14]\ttrain-aucpr:0.87750+0.00153\ttest-aucpr:0.87082+0.00189\n",
            "[15]\ttrain-aucpr:0.87991+0.00158\ttest-aucpr:0.87333+0.00205\n",
            "[16]\ttrain-aucpr:0.88257+0.00140\ttest-aucpr:0.87613+0.00180\n",
            "[17]\ttrain-aucpr:0.88541+0.00133\ttest-aucpr:0.87876+0.00128\n",
            "[18]\ttrain-aucpr:0.88768+0.00114\ttest-aucpr:0.88107+0.00103\n",
            "[19]\ttrain-aucpr:0.88962+0.00132\ttest-aucpr:0.88288+0.00100\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90426+0.00110\ttest-aucpr:0.87786+0.00163\n",
            "[1]\ttrain-aucpr:0.93798+0.00212\ttest-aucpr:0.91527+0.00228\n",
            "[2]\ttrain-aucpr:0.95201+0.00064\ttest-aucpr:0.92992+0.00167\n",
            "[3]\ttrain-aucpr:0.96023+0.00092\ttest-aucpr:0.93771+0.00203\n",
            "[4]\ttrain-aucpr:0.96670+0.00046\ttest-aucpr:0.94462+0.00138\n",
            "[5]\ttrain-aucpr:0.97091+0.00065\ttest-aucpr:0.94939+0.00066\n",
            "[6]\ttrain-aucpr:0.97375+0.00044\ttest-aucpr:0.95242+0.00032\n",
            "[7]\ttrain-aucpr:0.97596+0.00054\ttest-aucpr:0.95486+0.00050\n",
            "[8]\ttrain-aucpr:0.97784+0.00027\ttest-aucpr:0.95721+0.00051\n",
            "[9]\ttrain-aucpr:0.97934+0.00023\ttest-aucpr:0.95889+0.00064\n",
            "[10]\ttrain-aucpr:0.98043+0.00036\ttest-aucpr:0.96039+0.00056\n",
            "[11]\ttrain-aucpr:0.98141+0.00033\ttest-aucpr:0.96148+0.00044\n",
            "[12]\ttrain-aucpr:0.98238+0.00035\ttest-aucpr:0.96269+0.00068\n",
            "[13]\ttrain-aucpr:0.98339+0.00075\ttest-aucpr:0.96363+0.00069\n",
            "[14]\ttrain-aucpr:0.98443+0.00097\ttest-aucpr:0.96486+0.00090\n",
            "[15]\ttrain-aucpr:0.98498+0.00088\ttest-aucpr:0.96561+0.00071\n",
            "[16]\ttrain-aucpr:0.98545+0.00077\ttest-aucpr:0.96614+0.00065\n",
            "[17]\ttrain-aucpr:0.98624+0.00040\ttest-aucpr:0.96693+0.00043\n",
            "[18]\ttrain-aucpr:0.98690+0.00054\ttest-aucpr:0.96754+0.00078\n",
            "[19]\ttrain-aucpr:0.98758+0.00059\ttest-aucpr:0.96821+0.00055\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.93460+0.00124\ttest-aucpr:0.89151+0.00146\n",
            "[1]\ttrain-aucpr:0.96321+0.00275\ttest-aucpr:0.92485+0.00488\n",
            "[2]\ttrain-aucpr:0.97410+0.00082\ttest-aucpr:0.93942+0.00188\n",
            "[3]\ttrain-aucpr:0.97921+0.00064\ttest-aucpr:0.94606+0.00155\n",
            "[4]\ttrain-aucpr:0.98269+0.00046\ttest-aucpr:0.95118+0.00043\n",
            "[5]\ttrain-aucpr:0.98498+0.00036\ttest-aucpr:0.95471+0.00042\n",
            "[6]\ttrain-aucpr:0.98689+0.00034\ttest-aucpr:0.95759+0.00033\n",
            "[7]\ttrain-aucpr:0.98841+0.00033\ttest-aucpr:0.95995+0.00050\n",
            "[8]\ttrain-aucpr:0.98966+0.00023\ttest-aucpr:0.96172+0.00057\n",
            "[9]\ttrain-aucpr:0.99060+0.00022\ttest-aucpr:0.96366+0.00062\n",
            "[10]\ttrain-aucpr:0.99146+0.00014\ttest-aucpr:0.96512+0.00081\n",
            "[11]\ttrain-aucpr:0.99215+0.00012\ttest-aucpr:0.96647+0.00084\n",
            "[12]\ttrain-aucpr:0.99275+0.00008\ttest-aucpr:0.96764+0.00089\n",
            "[13]\ttrain-aucpr:0.99319+0.00014\ttest-aucpr:0.96853+0.00097\n",
            "[14]\ttrain-aucpr:0.99362+0.00012\ttest-aucpr:0.96933+0.00097\n",
            "[15]\ttrain-aucpr:0.99399+0.00016\ttest-aucpr:0.97011+0.00087\n",
            "[16]\ttrain-aucpr:0.99431+0.00016\ttest-aucpr:0.97085+0.00092\n",
            "[17]\ttrain-aucpr:0.99458+0.00014\ttest-aucpr:0.97141+0.00081\n",
            "[18]\ttrain-aucpr:0.99480+0.00018\ttest-aucpr:0.97183+0.00088\n",
            "[19]\ttrain-aucpr:0.99511+0.00017\ttest-aucpr:0.97239+0.00079\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64987+0.00634\ttest-aucpr:0.64874+0.00608\n",
            "[1]\ttrain-aucpr:0.70879+0.00264\ttest-aucpr:0.70485+0.00410\n",
            "[2]\ttrain-aucpr:0.72856+0.00612\ttest-aucpr:0.72381+0.00731\n",
            "[3]\ttrain-aucpr:0.74161+0.00631\ttest-aucpr:0.73695+0.00585\n",
            "[4]\ttrain-aucpr:0.75699+0.00374\ttest-aucpr:0.75279+0.00516\n",
            "[5]\ttrain-aucpr:0.76947+0.00462\ttest-aucpr:0.76484+0.00589\n",
            "[6]\ttrain-aucpr:0.78071+0.00298\ttest-aucpr:0.77583+0.00461\n",
            "[7]\ttrain-aucpr:0.79548+0.00761\ttest-aucpr:0.79015+0.00706\n",
            "[8]\ttrain-aucpr:0.80650+0.00453\ttest-aucpr:0.80144+0.00473\n",
            "[9]\ttrain-aucpr:0.81670+0.00459\ttest-aucpr:0.81119+0.00439\n",
            "[10]\ttrain-aucpr:0.82448+0.00615\ttest-aucpr:0.81883+0.00620\n",
            "[11]\ttrain-aucpr:0.82999+0.00601\ttest-aucpr:0.82430+0.00581\n",
            "[12]\ttrain-aucpr:0.83604+0.00568\ttest-aucpr:0.83010+0.00572\n",
            "[13]\ttrain-aucpr:0.84052+0.00585\ttest-aucpr:0.83438+0.00607\n",
            "[14]\ttrain-aucpr:0.84573+0.00776\ttest-aucpr:0.83950+0.00806\n",
            "[15]\ttrain-aucpr:0.84966+0.00785\ttest-aucpr:0.84331+0.00811\n",
            "[16]\ttrain-aucpr:0.85395+0.00736\ttest-aucpr:0.84770+0.00718\n",
            "[17]\ttrain-aucpr:0.85596+0.00691\ttest-aucpr:0.84995+0.00645\n",
            "[18]\ttrain-aucpr:0.85901+0.00653\ttest-aucpr:0.85285+0.00588\n",
            "[19]\ttrain-aucpr:0.86242+0.00533\ttest-aucpr:0.85624+0.00467\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64987+0.00634\ttest-aucpr:0.64874+0.00608\n",
            "[1]\ttrain-aucpr:0.70203+0.00170\ttest-aucpr:0.69839+0.00300\n",
            "[2]\ttrain-aucpr:0.71936+0.00397\ttest-aucpr:0.71477+0.00538\n",
            "[3]\ttrain-aucpr:0.73644+0.00335\ttest-aucpr:0.73254+0.00545\n",
            "[4]\ttrain-aucpr:0.74848+0.00401\ttest-aucpr:0.74433+0.00561\n",
            "[5]\ttrain-aucpr:0.75918+0.00293\ttest-aucpr:0.75481+0.00300\n",
            "[6]\ttrain-aucpr:0.76719+0.00221\ttest-aucpr:0.76215+0.00264\n",
            "[7]\ttrain-aucpr:0.77713+0.00102\ttest-aucpr:0.77198+0.00219\n",
            "[8]\ttrain-aucpr:0.78517+0.00279\ttest-aucpr:0.77985+0.00137\n",
            "[9]\ttrain-aucpr:0.79105+0.00342\ttest-aucpr:0.78559+0.00245\n",
            "[10]\ttrain-aucpr:0.79922+0.00179\ttest-aucpr:0.79358+0.00160\n",
            "[11]\ttrain-aucpr:0.80629+0.00320\ttest-aucpr:0.80037+0.00390\n",
            "[12]\ttrain-aucpr:0.81083+0.00192\ttest-aucpr:0.80516+0.00305\n",
            "[13]\ttrain-aucpr:0.81830+0.00242\ttest-aucpr:0.81271+0.00338\n",
            "[14]\ttrain-aucpr:0.82364+0.00407\ttest-aucpr:0.81829+0.00441\n",
            "[15]\ttrain-aucpr:0.82784+0.00334\ttest-aucpr:0.82223+0.00425\n",
            "[16]\ttrain-aucpr:0.83160+0.00320\ttest-aucpr:0.82590+0.00417\n",
            "[17]\ttrain-aucpr:0.83590+0.00404\ttest-aucpr:0.83021+0.00508\n",
            "[18]\ttrain-aucpr:0.83931+0.00400\ttest-aucpr:0.83383+0.00492\n",
            "[19]\ttrain-aucpr:0.84209+0.00367\ttest-aucpr:0.83670+0.00432\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96438+0.00113\ttest-aucpr:0.89110+0.00236\n",
            "[1]\ttrain-aucpr:0.97610+0.00143\ttest-aucpr:0.91041+0.00351\n",
            "[2]\ttrain-aucpr:0.98551+0.00187\ttest-aucpr:0.92807+0.00551\n",
            "[3]\ttrain-aucpr:0.98941+0.00101\ttest-aucpr:0.93615+0.00445\n",
            "[4]\ttrain-aucpr:0.99197+0.00071\ttest-aucpr:0.94194+0.00340\n",
            "[5]\ttrain-aucpr:0.99375+0.00039\ttest-aucpr:0.94609+0.00266\n",
            "[6]\ttrain-aucpr:0.99486+0.00043\ttest-aucpr:0.94904+0.00284\n",
            "[7]\ttrain-aucpr:0.99578+0.00017\ttest-aucpr:0.95186+0.00150\n",
            "[8]\ttrain-aucpr:0.99639+0.00016\ttest-aucpr:0.95365+0.00129\n",
            "[9]\ttrain-aucpr:0.99688+0.00009\ttest-aucpr:0.95520+0.00097\n",
            "[10]\ttrain-aucpr:0.99735+0.00011\ttest-aucpr:0.95680+0.00102\n",
            "[11]\ttrain-aucpr:0.99768+0.00009\ttest-aucpr:0.95823+0.00061\n",
            "[12]\ttrain-aucpr:0.99799+0.00009\ttest-aucpr:0.95923+0.00046\n",
            "[13]\ttrain-aucpr:0.99825+0.00006\ttest-aucpr:0.95993+0.00043\n",
            "[14]\ttrain-aucpr:0.99846+0.00008\ttest-aucpr:0.96092+0.00037\n",
            "[15]\ttrain-aucpr:0.99865+0.00007\ttest-aucpr:0.96175+0.00041\n",
            "[16]\ttrain-aucpr:0.99881+0.00006\ttest-aucpr:0.96258+0.00038\n",
            "[17]\ttrain-aucpr:0.99895+0.00008\ttest-aucpr:0.96351+0.00032\n",
            "[18]\ttrain-aucpr:0.99906+0.00009\ttest-aucpr:0.96410+0.00037\n",
            "[19]\ttrain-aucpr:0.99919+0.00007\ttest-aucpr:0.96476+0.00032\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90211+0.00286\ttest-aucpr:0.87367+0.00369\n",
            "[1]\ttrain-aucpr:0.93477+0.00291\ttest-aucpr:0.90960+0.00445\n",
            "[2]\ttrain-aucpr:0.94769+0.00162\ttest-aucpr:0.92411+0.00164\n",
            "[3]\ttrain-aucpr:0.95584+0.00072\ttest-aucpr:0.93334+0.00245\n",
            "[4]\ttrain-aucpr:0.96052+0.00082\ttest-aucpr:0.93819+0.00166\n",
            "[5]\ttrain-aucpr:0.96456+0.00075\ttest-aucpr:0.94259+0.00231\n",
            "[6]\ttrain-aucpr:0.96805+0.00101\ttest-aucpr:0.94654+0.00226\n",
            "[7]\ttrain-aucpr:0.97167+0.00071\ttest-aucpr:0.95056+0.00186\n",
            "[8]\ttrain-aucpr:0.97424+0.00029\ttest-aucpr:0.95368+0.00147\n",
            "[9]\ttrain-aucpr:0.97637+0.00058\ttest-aucpr:0.95598+0.00144\n",
            "[10]\ttrain-aucpr:0.97768+0.00066\ttest-aucpr:0.95754+0.00145\n",
            "[11]\ttrain-aucpr:0.97898+0.00030\ttest-aucpr:0.95919+0.00164\n",
            "[12]\ttrain-aucpr:0.98016+0.00035\ttest-aucpr:0.96067+0.00167\n",
            "[13]\ttrain-aucpr:0.98107+0.00053\ttest-aucpr:0.96175+0.00143\n",
            "[14]\ttrain-aucpr:0.98166+0.00039\ttest-aucpr:0.96258+0.00146\n",
            "[15]\ttrain-aucpr:0.98219+0.00029\ttest-aucpr:0.96322+0.00164\n",
            "[16]\ttrain-aucpr:0.98308+0.00016\ttest-aucpr:0.96436+0.00156\n",
            "[17]\ttrain-aucpr:0.98339+0.00030\ttest-aucpr:0.96476+0.00152\n",
            "[18]\ttrain-aucpr:0.98411+0.00022\ttest-aucpr:0.96548+0.00144\n",
            "[19]\ttrain-aucpr:0.98465+0.00025\ttest-aucpr:0.96622+0.00150\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76179+0.00318\ttest-aucpr:0.75505+0.00109\n",
            "[1]\ttrain-aucpr:0.80135+0.00609\ttest-aucpr:0.79403+0.00496\n",
            "[2]\ttrain-aucpr:0.81745+0.00212\ttest-aucpr:0.81028+0.00305\n",
            "[3]\ttrain-aucpr:0.82777+0.00267\ttest-aucpr:0.82122+0.00306\n",
            "[4]\ttrain-aucpr:0.83720+0.00335\ttest-aucpr:0.83001+0.00323\n",
            "[5]\ttrain-aucpr:0.84430+0.00185\ttest-aucpr:0.83766+0.00072\n",
            "[6]\ttrain-aucpr:0.84996+0.00117\ttest-aucpr:0.84336+0.00146\n",
            "[7]\ttrain-aucpr:0.85404+0.00171\ttest-aucpr:0.84719+0.00026\n",
            "[8]\ttrain-aucpr:0.85829+0.00186\ttest-aucpr:0.85136+0.00076\n",
            "[9]\ttrain-aucpr:0.86154+0.00161\ttest-aucpr:0.85453+0.00140\n",
            "[10]\ttrain-aucpr:0.86474+0.00244\ttest-aucpr:0.85789+0.00201\n",
            "[11]\ttrain-aucpr:0.86758+0.00222\ttest-aucpr:0.86036+0.00155\n",
            "[12]\ttrain-aucpr:0.87088+0.00159\ttest-aucpr:0.86356+0.00118\n",
            "[13]\ttrain-aucpr:0.87336+0.00155\ttest-aucpr:0.86605+0.00112\n",
            "[14]\ttrain-aucpr:0.87589+0.00224\ttest-aucpr:0.86865+0.00159\n",
            "[15]\ttrain-aucpr:0.87891+0.00205\ttest-aucpr:0.87168+0.00134\n",
            "[16]\ttrain-aucpr:0.88113+0.00180\ttest-aucpr:0.87386+0.00176\n",
            "[17]\ttrain-aucpr:0.88302+0.00171\ttest-aucpr:0.87574+0.00135\n",
            "[18]\ttrain-aucpr:0.88515+0.00226\ttest-aucpr:0.87778+0.00218\n",
            "[19]\ttrain-aucpr:0.88780+0.00254\ttest-aucpr:0.88051+0.00247\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76185+0.00311\ttest-aucpr:0.75525+0.00096\n",
            "[1]\ttrain-aucpr:0.81819+0.00309\ttest-aucpr:0.81078+0.00378\n",
            "[2]\ttrain-aucpr:0.83822+0.00170\ttest-aucpr:0.83143+0.00283\n",
            "[3]\ttrain-aucpr:0.85275+0.00205\ttest-aucpr:0.84648+0.00159\n",
            "[4]\ttrain-aucpr:0.86473+0.00190\ttest-aucpr:0.85806+0.00265\n",
            "[5]\ttrain-aucpr:0.87452+0.00258\ttest-aucpr:0.86777+0.00267\n",
            "[6]\ttrain-aucpr:0.88414+0.00369\ttest-aucpr:0.87728+0.00426\n",
            "[7]\ttrain-aucpr:0.89429+0.00168\ttest-aucpr:0.88715+0.00283\n",
            "[8]\ttrain-aucpr:0.90038+0.00153\ttest-aucpr:0.89316+0.00150\n",
            "[9]\ttrain-aucpr:0.90439+0.00117\ttest-aucpr:0.89719+0.00108\n",
            "[10]\ttrain-aucpr:0.90920+0.00211\ttest-aucpr:0.90176+0.00073\n",
            "[11]\ttrain-aucpr:0.91313+0.00266\ttest-aucpr:0.90550+0.00203\n",
            "[12]\ttrain-aucpr:0.91718+0.00115\ttest-aucpr:0.90961+0.00216\n",
            "[13]\ttrain-aucpr:0.92069+0.00214\ttest-aucpr:0.91310+0.00296\n",
            "[14]\ttrain-aucpr:0.92333+0.00156\ttest-aucpr:0.91573+0.00215\n",
            "[15]\ttrain-aucpr:0.92546+0.00205\ttest-aucpr:0.91796+0.00230\n",
            "[16]\ttrain-aucpr:0.92811+0.00134\ttest-aucpr:0.92067+0.00207\n",
            "[17]\ttrain-aucpr:0.92995+0.00141\ttest-aucpr:0.92247+0.00222\n",
            "[18]\ttrain-aucpr:0.93140+0.00153\ttest-aucpr:0.92387+0.00182\n",
            "[19]\ttrain-aucpr:0.93359+0.00085\ttest-aucpr:0.92593+0.00194\n",
            "result:  0.9259258776140795\n",
            "best result:  0.9259258776140795\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95548+0.00086\ttest-aucpr:0.88776+0.00215\n",
            "[1]\ttrain-aucpr:0.98349+0.00068\ttest-aucpr:0.92389+0.00235\n",
            "[2]\ttrain-aucpr:0.99148+0.00045\ttest-aucpr:0.93809+0.00254\n",
            "[3]\ttrain-aucpr:0.99496+0.00042\ttest-aucpr:0.94642+0.00197\n",
            "[4]\ttrain-aucpr:0.99680+0.00019\ttest-aucpr:0.95196+0.00111\n",
            "[5]\ttrain-aucpr:0.99790+0.00012\ttest-aucpr:0.95583+0.00122\n",
            "[6]\ttrain-aucpr:0.99861+0.00006\ttest-aucpr:0.95889+0.00130\n",
            "[7]\ttrain-aucpr:0.99908+0.00005\ttest-aucpr:0.96115+0.00100\n",
            "[8]\ttrain-aucpr:0.99939+0.00005\ttest-aucpr:0.96328+0.00096\n",
            "[9]\ttrain-aucpr:0.99959+0.00006\ttest-aucpr:0.96480+0.00110\n",
            "[10]\ttrain-aucpr:0.99972+0.00004\ttest-aucpr:0.96633+0.00116\n",
            "[11]\ttrain-aucpr:0.99980+0.00002\ttest-aucpr:0.96736+0.00097\n",
            "[12]\ttrain-aucpr:0.99986+0.00002\ttest-aucpr:0.96851+0.00105\n",
            "[13]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.96943+0.00112\n",
            "[14]\ttrain-aucpr:0.99993+0.00001\ttest-aucpr:0.97016+0.00104\n",
            "[15]\ttrain-aucpr:0.99995+0.00001\ttest-aucpr:0.97083+0.00117\n",
            "[16]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.97133+0.00122\n",
            "[17]\ttrain-aucpr:0.99998+0.00001\ttest-aucpr:0.97173+0.00113\n",
            "[18]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97223+0.00106\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97250+0.00110\n",
            "result:  0.9725039654621541\n",
            "best result:  0.9725039654621541\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96888+0.00089\ttest-aucpr:0.89185+0.00225\n",
            "[1]\ttrain-aucpr:0.98995+0.00053\ttest-aucpr:0.92299+0.00211\n",
            "[2]\ttrain-aucpr:0.99509+0.00036\ttest-aucpr:0.93769+0.00224\n",
            "[3]\ttrain-aucpr:0.99712+0.00025\ttest-aucpr:0.94634+0.00242\n",
            "[4]\ttrain-aucpr:0.99822+0.00006\ttest-aucpr:0.95193+0.00187\n",
            "[5]\ttrain-aucpr:0.99888+0.00006\ttest-aucpr:0.95607+0.00116\n",
            "[6]\ttrain-aucpr:0.99927+0.00007\ttest-aucpr:0.95906+0.00087\n",
            "[7]\ttrain-aucpr:0.99953+0.00003\ttest-aucpr:0.96112+0.00095\n",
            "[8]\ttrain-aucpr:0.99969+0.00002\ttest-aucpr:0.96325+0.00089\n",
            "[9]\ttrain-aucpr:0.99980+0.00002\ttest-aucpr:0.96507+0.00044\n",
            "[10]\ttrain-aucpr:0.99986+0.00002\ttest-aucpr:0.96656+0.00061\n",
            "[11]\ttrain-aucpr:0.99991+0.00001\ttest-aucpr:0.96771+0.00057\n",
            "[12]\ttrain-aucpr:0.99994+0.00001\ttest-aucpr:0.96876+0.00067\n",
            "[13]\ttrain-aucpr:0.99996+0.00000\ttest-aucpr:0.96950+0.00074\n",
            "[14]\ttrain-aucpr:0.99997+0.00000\ttest-aucpr:0.97018+0.00081\n",
            "[15]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97072+0.00077\n",
            "[16]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97130+0.00088\n",
            "[17]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97186+0.00072\n",
            "[18]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97210+0.00072\n",
            "[19]\ttrain-aucpr:1.00000+0.00000\ttest-aucpr:0.97249+0.00074\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95236+0.00064\ttest-aucpr:0.88904+0.00219\n",
            "[1]\ttrain-aucpr:0.97868+0.00157\ttest-aucpr:0.92291+0.00452\n",
            "[2]\ttrain-aucpr:0.98675+0.00093\ttest-aucpr:0.93665+0.00286\n",
            "[3]\ttrain-aucpr:0.99111+0.00055\ttest-aucpr:0.94467+0.00296\n",
            "[4]\ttrain-aucpr:0.99353+0.00049\ttest-aucpr:0.94980+0.00261\n",
            "[5]\ttrain-aucpr:0.99511+0.00033\ttest-aucpr:0.95403+0.00198\n",
            "[6]\ttrain-aucpr:0.99628+0.00025\ttest-aucpr:0.95696+0.00166\n",
            "[7]\ttrain-aucpr:0.99712+0.00024\ttest-aucpr:0.95952+0.00133\n",
            "[8]\ttrain-aucpr:0.99774+0.00020\ttest-aucpr:0.96150+0.00147\n",
            "[9]\ttrain-aucpr:0.99822+0.00011\ttest-aucpr:0.96319+0.00136\n",
            "[10]\ttrain-aucpr:0.99856+0.00009\ttest-aucpr:0.96461+0.00115\n",
            "[11]\ttrain-aucpr:0.99883+0.00010\ttest-aucpr:0.96600+0.00084\n",
            "[12]\ttrain-aucpr:0.99904+0.00008\ttest-aucpr:0.96706+0.00083\n",
            "[13]\ttrain-aucpr:0.99922+0.00007\ttest-aucpr:0.96825+0.00078\n",
            "[14]\ttrain-aucpr:0.99937+0.00005\ttest-aucpr:0.96908+0.00074\n",
            "[15]\ttrain-aucpr:0.99947+0.00005\ttest-aucpr:0.96989+0.00072\n",
            "[16]\ttrain-aucpr:0.99955+0.00005\ttest-aucpr:0.97055+0.00068\n",
            "[17]\ttrain-aucpr:0.99962+0.00005\ttest-aucpr:0.97122+0.00064\n",
            "[18]\ttrain-aucpr:0.99969+0.00004\ttest-aucpr:0.97170+0.00056\n",
            "[19]\ttrain-aucpr:0.99973+0.00004\ttest-aucpr:0.97219+0.00052\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76223+0.00304\ttest-aucpr:0.75553+0.00099\n",
            "[1]\ttrain-aucpr:0.80127+0.00607\ttest-aucpr:0.79398+0.00493\n",
            "[2]\ttrain-aucpr:0.81757+0.00210\ttest-aucpr:0.81034+0.00303\n",
            "[3]\ttrain-aucpr:0.82784+0.00276\ttest-aucpr:0.82131+0.00316\n",
            "[4]\ttrain-aucpr:0.83722+0.00336\ttest-aucpr:0.83007+0.00324\n",
            "[5]\ttrain-aucpr:0.84463+0.00135\ttest-aucpr:0.83783+0.00077\n",
            "[6]\ttrain-aucpr:0.85003+0.00105\ttest-aucpr:0.84323+0.00129\n",
            "[7]\ttrain-aucpr:0.85445+0.00098\ttest-aucpr:0.84763+0.00114\n",
            "[8]\ttrain-aucpr:0.85822+0.00172\ttest-aucpr:0.85157+0.00065\n",
            "[9]\ttrain-aucpr:0.86147+0.00129\ttest-aucpr:0.85465+0.00136\n",
            "[10]\ttrain-aucpr:0.86464+0.00198\ttest-aucpr:0.85787+0.00177\n",
            "[11]\ttrain-aucpr:0.86770+0.00178\ttest-aucpr:0.86057+0.00128\n",
            "[12]\ttrain-aucpr:0.87071+0.00152\ttest-aucpr:0.86355+0.00112\n",
            "[13]\ttrain-aucpr:0.87335+0.00139\ttest-aucpr:0.86635+0.00129\n",
            "[14]\ttrain-aucpr:0.87601+0.00205\ttest-aucpr:0.86912+0.00172\n",
            "[15]\ttrain-aucpr:0.87909+0.00179\ttest-aucpr:0.87215+0.00151\n",
            "[16]\ttrain-aucpr:0.88095+0.00177\ttest-aucpr:0.87405+0.00190\n",
            "[17]\ttrain-aucpr:0.88315+0.00206\ttest-aucpr:0.87627+0.00206\n",
            "[18]\ttrain-aucpr:0.88494+0.00190\ttest-aucpr:0.87806+0.00226\n",
            "[19]\ttrain-aucpr:0.88748+0.00280\ttest-aucpr:0.88057+0.00327\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64422+0.00107\ttest-aucpr:0.64079+0.00144\n",
            "[1]\ttrain-aucpr:0.70895+0.00393\ttest-aucpr:0.70606+0.00191\n",
            "[2]\ttrain-aucpr:0.72678+0.00437\ttest-aucpr:0.72420+0.00428\n",
            "[3]\ttrain-aucpr:0.74029+0.00582\ttest-aucpr:0.73711+0.00584\n",
            "[4]\ttrain-aucpr:0.75454+0.00235\ttest-aucpr:0.75093+0.00193\n",
            "[5]\ttrain-aucpr:0.76879+0.00091\ttest-aucpr:0.76492+0.00234\n",
            "[6]\ttrain-aucpr:0.78095+0.00255\ttest-aucpr:0.77665+0.00381\n",
            "[7]\ttrain-aucpr:0.79423+0.00494\ttest-aucpr:0.78998+0.00365\n",
            "[8]\ttrain-aucpr:0.80285+0.00580\ttest-aucpr:0.79872+0.00400\n",
            "[9]\ttrain-aucpr:0.81197+0.00586\ttest-aucpr:0.80737+0.00432\n",
            "[10]\ttrain-aucpr:0.81774+0.00460\ttest-aucpr:0.81285+0.00365\n",
            "[11]\ttrain-aucpr:0.82584+0.00420\ttest-aucpr:0.82091+0.00299\n",
            "[12]\ttrain-aucpr:0.83183+0.00357\ttest-aucpr:0.82674+0.00220\n",
            "[13]\ttrain-aucpr:0.83488+0.00414\ttest-aucpr:0.82965+0.00211\n",
            "[14]\ttrain-aucpr:0.83811+0.00450\ttest-aucpr:0.83287+0.00230\n",
            "[15]\ttrain-aucpr:0.84114+0.00436\ttest-aucpr:0.83600+0.00170\n",
            "[16]\ttrain-aucpr:0.84510+0.00530\ttest-aucpr:0.83992+0.00236\n",
            "[17]\ttrain-aucpr:0.84933+0.00491\ttest-aucpr:0.84383+0.00334\n",
            "[18]\ttrain-aucpr:0.85533+0.00405\ttest-aucpr:0.84995+0.00161\n",
            "[19]\ttrain-aucpr:0.85970+0.00439\ttest-aucpr:0.85425+0.00254\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76223+0.00304\ttest-aucpr:0.75553+0.00099\n",
            "[1]\ttrain-aucpr:0.81217+0.00271\ttest-aucpr:0.80511+0.00383\n",
            "[2]\ttrain-aucpr:0.83159+0.00259\ttest-aucpr:0.82429+0.00294\n",
            "[3]\ttrain-aucpr:0.84767+0.00326\ttest-aucpr:0.83992+0.00426\n",
            "[4]\ttrain-aucpr:0.85763+0.00332\ttest-aucpr:0.85035+0.00390\n",
            "[5]\ttrain-aucpr:0.86537+0.00333\ttest-aucpr:0.85803+0.00394\n",
            "[6]\ttrain-aucpr:0.87270+0.00346\ttest-aucpr:0.86541+0.00376\n",
            "[7]\ttrain-aucpr:0.88031+0.00360\ttest-aucpr:0.87295+0.00456\n",
            "[8]\ttrain-aucpr:0.88553+0.00282\ttest-aucpr:0.87816+0.00368\n",
            "[9]\ttrain-aucpr:0.89118+0.00354\ttest-aucpr:0.88374+0.00442\n",
            "[10]\ttrain-aucpr:0.89712+0.00139\ttest-aucpr:0.88969+0.00304\n",
            "[11]\ttrain-aucpr:0.90065+0.00117\ttest-aucpr:0.89308+0.00296\n",
            "[12]\ttrain-aucpr:0.90420+0.00146\ttest-aucpr:0.89647+0.00340\n",
            "[13]\ttrain-aucpr:0.90814+0.00105\ttest-aucpr:0.90023+0.00271\n",
            "[14]\ttrain-aucpr:0.91126+0.00110\ttest-aucpr:0.90328+0.00304\n",
            "[15]\ttrain-aucpr:0.91317+0.00086\ttest-aucpr:0.90534+0.00295\n",
            "[16]\ttrain-aucpr:0.91584+0.00141\ttest-aucpr:0.90784+0.00187\n",
            "[17]\ttrain-aucpr:0.91880+0.00144\ttest-aucpr:0.91082+0.00264\n",
            "[18]\ttrain-aucpr:0.92097+0.00085\ttest-aucpr:0.91294+0.00260\n",
            "[19]\ttrain-aucpr:0.92325+0.00102\ttest-aucpr:0.91523+0.00209\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90641+0.00280\ttest-aucpr:0.87641+0.00347\n",
            "[1]\ttrain-aucpr:0.93943+0.00162\ttest-aucpr:0.91390+0.00275\n",
            "[2]\ttrain-aucpr:0.95333+0.00066\ttest-aucpr:0.92832+0.00139\n",
            "[3]\ttrain-aucpr:0.96194+0.00050\ttest-aucpr:0.93745+0.00164\n",
            "[4]\ttrain-aucpr:0.96751+0.00024\ttest-aucpr:0.94385+0.00158\n",
            "[5]\ttrain-aucpr:0.97132+0.00041\ttest-aucpr:0.94818+0.00100\n",
            "[6]\ttrain-aucpr:0.97517+0.00045\ttest-aucpr:0.95260+0.00083\n",
            "[7]\ttrain-aucpr:0.97798+0.00074\ttest-aucpr:0.95567+0.00100\n",
            "[8]\ttrain-aucpr:0.97964+0.00070\ttest-aucpr:0.95755+0.00096\n",
            "[9]\ttrain-aucpr:0.98130+0.00042\ttest-aucpr:0.95953+0.00120\n",
            "[10]\ttrain-aucpr:0.98232+0.00036\ttest-aucpr:0.96064+0.00100\n",
            "[11]\ttrain-aucpr:0.98318+0.00048\ttest-aucpr:0.96168+0.00097\n",
            "[12]\ttrain-aucpr:0.98453+0.00066\ttest-aucpr:0.96317+0.00116\n",
            "[13]\ttrain-aucpr:0.98512+0.00055\ttest-aucpr:0.96398+0.00110\n",
            "[14]\ttrain-aucpr:0.98601+0.00050\ttest-aucpr:0.96485+0.00107\n",
            "[15]\ttrain-aucpr:0.98653+0.00039\ttest-aucpr:0.96539+0.00106\n",
            "[16]\ttrain-aucpr:0.98739+0.00071\ttest-aucpr:0.96630+0.00104\n",
            "[17]\ttrain-aucpr:0.98795+0.00070\ttest-aucpr:0.96694+0.00093\n",
            "[18]\ttrain-aucpr:0.98854+0.00054\ttest-aucpr:0.96736+0.00089\n",
            "[19]\ttrain-aucpr:0.98908+0.00075\ttest-aucpr:0.96753+0.00091\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64422+0.00107\ttest-aucpr:0.64079+0.00144\n",
            "[1]\ttrain-aucpr:0.68942+0.00409\ttest-aucpr:0.68620+0.00336\n",
            "[2]\ttrain-aucpr:0.70804+0.00351\ttest-aucpr:0.70549+0.00370\n",
            "[3]\ttrain-aucpr:0.71680+0.00355\ttest-aucpr:0.71388+0.00219\n",
            "[4]\ttrain-aucpr:0.73151+0.00502\ttest-aucpr:0.72845+0.00454\n",
            "[5]\ttrain-aucpr:0.73393+0.00375\ttest-aucpr:0.73048+0.00292\n",
            "[6]\ttrain-aucpr:0.74119+0.00423\ttest-aucpr:0.73757+0.00373\n",
            "[7]\ttrain-aucpr:0.74457+0.00455\ttest-aucpr:0.74054+0.00427\n",
            "[8]\ttrain-aucpr:0.74818+0.00433\ttest-aucpr:0.74450+0.00412\n",
            "[9]\ttrain-aucpr:0.75165+0.00389\ttest-aucpr:0.74804+0.00370\n",
            "[10]\ttrain-aucpr:0.75308+0.00445\ttest-aucpr:0.74914+0.00418\n",
            "[11]\ttrain-aucpr:0.75602+0.00382\ttest-aucpr:0.75202+0.00347\n",
            "[12]\ttrain-aucpr:0.75983+0.00318\ttest-aucpr:0.75590+0.00244\n",
            "[13]\ttrain-aucpr:0.76253+0.00210\ttest-aucpr:0.75855+0.00168\n",
            "[14]\ttrain-aucpr:0.76468+0.00358\ttest-aucpr:0.76075+0.00306\n",
            "[15]\ttrain-aucpr:0.76735+0.00268\ttest-aucpr:0.76323+0.00203\n",
            "[16]\ttrain-aucpr:0.77059+0.00395\ttest-aucpr:0.76644+0.00336\n",
            "[17]\ttrain-aucpr:0.77433+0.00362\ttest-aucpr:0.77006+0.00296\n",
            "[18]\ttrain-aucpr:0.77747+0.00276\ttest-aucpr:0.77308+0.00214\n",
            "[19]\ttrain-aucpr:0.78196+0.00255\ttest-aucpr:0.77730+0.00163\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76223+0.00304\ttest-aucpr:0.75553+0.00099\n",
            "[1]\ttrain-aucpr:0.80127+0.00607\ttest-aucpr:0.79398+0.00493\n",
            "[2]\ttrain-aucpr:0.81757+0.00210\ttest-aucpr:0.81034+0.00303\n",
            "[3]\ttrain-aucpr:0.82784+0.00276\ttest-aucpr:0.82131+0.00316\n",
            "[4]\ttrain-aucpr:0.83722+0.00336\ttest-aucpr:0.83007+0.00324\n",
            "[5]\ttrain-aucpr:0.84463+0.00135\ttest-aucpr:0.83783+0.00077\n",
            "[6]\ttrain-aucpr:0.85003+0.00105\ttest-aucpr:0.84323+0.00129\n",
            "[7]\ttrain-aucpr:0.85445+0.00098\ttest-aucpr:0.84763+0.00114\n",
            "[8]\ttrain-aucpr:0.85822+0.00172\ttest-aucpr:0.85157+0.00065\n",
            "[9]\ttrain-aucpr:0.86147+0.00129\ttest-aucpr:0.85465+0.00136\n",
            "[10]\ttrain-aucpr:0.86464+0.00198\ttest-aucpr:0.85787+0.00177\n",
            "[11]\ttrain-aucpr:0.86770+0.00178\ttest-aucpr:0.86057+0.00128\n",
            "[12]\ttrain-aucpr:0.87071+0.00152\ttest-aucpr:0.86355+0.00112\n",
            "[13]\ttrain-aucpr:0.87335+0.00139\ttest-aucpr:0.86635+0.00129\n",
            "[14]\ttrain-aucpr:0.87601+0.00205\ttest-aucpr:0.86912+0.00172\n",
            "[15]\ttrain-aucpr:0.87909+0.00179\ttest-aucpr:0.87215+0.00151\n",
            "[16]\ttrain-aucpr:0.88095+0.00177\ttest-aucpr:0.87405+0.00190\n",
            "[17]\ttrain-aucpr:0.88315+0.00206\ttest-aucpr:0.87627+0.00206\n",
            "[18]\ttrain-aucpr:0.88494+0.00190\ttest-aucpr:0.87806+0.00226\n",
            "[19]\ttrain-aucpr:0.88748+0.00280\ttest-aucpr:0.88057+0.00327\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89967+0.00310\ttest-aucpr:0.87387+0.00352\n",
            "[1]\ttrain-aucpr:0.92627+0.00342\ttest-aucpr:0.90176+0.00636\n",
            "[2]\ttrain-aucpr:0.93843+0.00277\ttest-aucpr:0.91548+0.00324\n",
            "[3]\ttrain-aucpr:0.94526+0.00273\ttest-aucpr:0.92300+0.00296\n",
            "[4]\ttrain-aucpr:0.94966+0.00195\ttest-aucpr:0.92876+0.00295\n",
            "[5]\ttrain-aucpr:0.95351+0.00202\ttest-aucpr:0.93292+0.00308\n",
            "[6]\ttrain-aucpr:0.95585+0.00184\ttest-aucpr:0.93530+0.00283\n",
            "[7]\ttrain-aucpr:0.95806+0.00085\ttest-aucpr:0.93782+0.00133\n",
            "[8]\ttrain-aucpr:0.96031+0.00100\ttest-aucpr:0.94027+0.00210\n",
            "[9]\ttrain-aucpr:0.96191+0.00085\ttest-aucpr:0.94197+0.00190\n",
            "[10]\ttrain-aucpr:0.96389+0.00011\ttest-aucpr:0.94397+0.00146\n",
            "[11]\ttrain-aucpr:0.96506+0.00013\ttest-aucpr:0.94518+0.00134\n",
            "[12]\ttrain-aucpr:0.96645+0.00044\ttest-aucpr:0.94668+0.00150\n",
            "[13]\ttrain-aucpr:0.96808+0.00036\ttest-aucpr:0.94845+0.00156\n",
            "[14]\ttrain-aucpr:0.96926+0.00047\ttest-aucpr:0.94978+0.00162\n",
            "[15]\ttrain-aucpr:0.97066+0.00026\ttest-aucpr:0.95127+0.00132\n",
            "[16]\ttrain-aucpr:0.97153+0.00031\ttest-aucpr:0.95207+0.00139\n",
            "[17]\ttrain-aucpr:0.97258+0.00043\ttest-aucpr:0.95320+0.00144\n",
            "[18]\ttrain-aucpr:0.97337+0.00046\ttest-aucpr:0.95409+0.00134\n",
            "[19]\ttrain-aucpr:0.97442+0.00031\ttest-aucpr:0.95533+0.00112\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.97867+0.00095\ttest-aucpr:0.88534+0.00277\n",
            "[1]\ttrain-aucpr:0.98948+0.00115\ttest-aucpr:0.91245+0.00589\n",
            "[2]\ttrain-aucpr:0.99275+0.00052\ttest-aucpr:0.92083+0.00423\n",
            "[3]\ttrain-aucpr:0.99541+0.00040\ttest-aucpr:0.93300+0.00461\n",
            "[4]\ttrain-aucpr:0.99651+0.00040\ttest-aucpr:0.93847+0.00582\n",
            "[5]\ttrain-aucpr:0.99735+0.00034\ttest-aucpr:0.94326+0.00521\n",
            "[6]\ttrain-aucpr:0.99783+0.00025\ttest-aucpr:0.94671+0.00397\n",
            "[7]\ttrain-aucpr:0.99824+0.00024\ttest-aucpr:0.94979+0.00322\n",
            "[8]\ttrain-aucpr:0.99851+0.00024\ttest-aucpr:0.95225+0.00328\n",
            "[9]\ttrain-aucpr:0.99872+0.00021\ttest-aucpr:0.95445+0.00235\n",
            "[10]\ttrain-aucpr:0.99895+0.00019\ttest-aucpr:0.95638+0.00237\n",
            "[11]\ttrain-aucpr:0.99910+0.00019\ttest-aucpr:0.95782+0.00208\n",
            "[12]\ttrain-aucpr:0.99923+0.00018\ttest-aucpr:0.95890+0.00196\n",
            "[13]\ttrain-aucpr:0.99936+0.00012\ttest-aucpr:0.95997+0.00163\n",
            "[14]\ttrain-aucpr:0.99945+0.00011\ttest-aucpr:0.96092+0.00164\n",
            "[15]\ttrain-aucpr:0.99952+0.00009\ttest-aucpr:0.96169+0.00130\n",
            "[16]\ttrain-aucpr:0.99958+0.00007\ttest-aucpr:0.96254+0.00132\n",
            "[17]\ttrain-aucpr:0.99965+0.00005\ttest-aucpr:0.96322+0.00123\n",
            "[18]\ttrain-aucpr:0.99970+0.00004\ttest-aucpr:0.96380+0.00121\n",
            "[19]\ttrain-aucpr:0.99974+0.00004\ttest-aucpr:0.96441+0.00110\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94338+0.00087\ttest-aucpr:0.88703+0.00255\n",
            "[1]\ttrain-aucpr:0.96430+0.00352\ttest-aucpr:0.91227+0.00571\n",
            "[2]\ttrain-aucpr:0.97458+0.00313\ttest-aucpr:0.92736+0.00505\n",
            "[3]\ttrain-aucpr:0.97980+0.00158\ttest-aucpr:0.93590+0.00261\n",
            "[4]\ttrain-aucpr:0.98302+0.00121\ttest-aucpr:0.94052+0.00295\n",
            "[5]\ttrain-aucpr:0.98527+0.00084\ttest-aucpr:0.94432+0.00187\n",
            "[6]\ttrain-aucpr:0.98712+0.00054\ttest-aucpr:0.94748+0.00244\n",
            "[7]\ttrain-aucpr:0.98858+0.00055\ttest-aucpr:0.95017+0.00218\n",
            "[8]\ttrain-aucpr:0.98978+0.00030\ttest-aucpr:0.95256+0.00155\n",
            "[9]\ttrain-aucpr:0.99073+0.00030\ttest-aucpr:0.95432+0.00158\n",
            "[10]\ttrain-aucpr:0.99148+0.00025\ttest-aucpr:0.95581+0.00131\n",
            "[11]\ttrain-aucpr:0.99221+0.00031\ttest-aucpr:0.95710+0.00125\n",
            "[12]\ttrain-aucpr:0.99274+0.00027\ttest-aucpr:0.95818+0.00122\n",
            "[13]\ttrain-aucpr:0.99324+0.00028\ttest-aucpr:0.95928+0.00100\n",
            "[14]\ttrain-aucpr:0.99373+0.00027\ttest-aucpr:0.96027+0.00085\n",
            "[15]\ttrain-aucpr:0.99417+0.00025\ttest-aucpr:0.96119+0.00092\n",
            "[16]\ttrain-aucpr:0.99458+0.00026\ttest-aucpr:0.96201+0.00080\n",
            "[17]\ttrain-aucpr:0.99495+0.00022\ttest-aucpr:0.96285+0.00099\n",
            "[18]\ttrain-aucpr:0.99526+0.00021\ttest-aucpr:0.96341+0.00101\n",
            "[19]\ttrain-aucpr:0.99556+0.00022\ttest-aucpr:0.96400+0.00101\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95548+0.00086\ttest-aucpr:0.88776+0.00215\n",
            "[1]\ttrain-aucpr:0.98116+0.00090\ttest-aucpr:0.92214+0.00433\n",
            "[2]\ttrain-aucpr:0.98900+0.00070\ttest-aucpr:0.93596+0.00207\n",
            "[3]\ttrain-aucpr:0.99273+0.00032\ttest-aucpr:0.94448+0.00169\n",
            "[4]\ttrain-aucpr:0.99508+0.00036\ttest-aucpr:0.94982+0.00160\n",
            "[5]\ttrain-aucpr:0.99652+0.00023\ttest-aucpr:0.95361+0.00128\n",
            "[6]\ttrain-aucpr:0.99742+0.00019\ttest-aucpr:0.95621+0.00118\n",
            "[7]\ttrain-aucpr:0.99815+0.00009\ttest-aucpr:0.95874+0.00122\n",
            "[8]\ttrain-aucpr:0.99860+0.00007\ttest-aucpr:0.96065+0.00114\n",
            "[9]\ttrain-aucpr:0.99895+0.00006\ttest-aucpr:0.96247+0.00120\n",
            "[10]\ttrain-aucpr:0.99921+0.00005\ttest-aucpr:0.96384+0.00099\n",
            "[11]\ttrain-aucpr:0.99940+0.00005\ttest-aucpr:0.96502+0.00096\n",
            "[12]\ttrain-aucpr:0.99955+0.00004\ttest-aucpr:0.96609+0.00102\n",
            "[13]\ttrain-aucpr:0.99966+0.00003\ttest-aucpr:0.96724+0.00100\n",
            "[14]\ttrain-aucpr:0.99974+0.00002\ttest-aucpr:0.96821+0.00097\n",
            "[15]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.96887+0.00093\n",
            "[16]\ttrain-aucpr:0.99985+0.00001\ttest-aucpr:0.96942+0.00113\n",
            "[17]\ttrain-aucpr:0.99988+0.00001\ttest-aucpr:0.97008+0.00106\n",
            "[18]\ttrain-aucpr:0.99991+0.00001\ttest-aucpr:0.97065+0.00095\n",
            "[19]\ttrain-aucpr:0.99993+0.00000\ttest-aucpr:0.97118+0.00092\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76221+0.00303\ttest-aucpr:0.75556+0.00101\n",
            "[1]\ttrain-aucpr:0.81845+0.00312\ttest-aucpr:0.81107+0.00423\n",
            "[2]\ttrain-aucpr:0.83837+0.00174\ttest-aucpr:0.83195+0.00333\n",
            "[3]\ttrain-aucpr:0.85385+0.00296\ttest-aucpr:0.84767+0.00289\n",
            "[4]\ttrain-aucpr:0.86476+0.00163\ttest-aucpr:0.85803+0.00259\n",
            "[5]\ttrain-aucpr:0.87415+0.00337\ttest-aucpr:0.86764+0.00343\n",
            "[6]\ttrain-aucpr:0.88560+0.00292\ttest-aucpr:0.87828+0.00286\n",
            "[7]\ttrain-aucpr:0.89444+0.00200\ttest-aucpr:0.88698+0.00182\n",
            "[8]\ttrain-aucpr:0.89810+0.00317\ttest-aucpr:0.89058+0.00333\n",
            "[9]\ttrain-aucpr:0.90309+0.00349\ttest-aucpr:0.89597+0.00306\n",
            "[10]\ttrain-aucpr:0.90768+0.00343\ttest-aucpr:0.90057+0.00262\n",
            "[11]\ttrain-aucpr:0.91147+0.00281\ttest-aucpr:0.90413+0.00204\n",
            "[12]\ttrain-aucpr:0.91565+0.00169\ttest-aucpr:0.90863+0.00265\n",
            "[13]\ttrain-aucpr:0.91843+0.00185\ttest-aucpr:0.91119+0.00166\n",
            "[14]\ttrain-aucpr:0.92119+0.00198\ttest-aucpr:0.91373+0.00248\n",
            "[15]\ttrain-aucpr:0.92400+0.00184\ttest-aucpr:0.91652+0.00225\n",
            "[16]\ttrain-aucpr:0.92721+0.00128\ttest-aucpr:0.91960+0.00202\n",
            "[17]\ttrain-aucpr:0.92871+0.00144\ttest-aucpr:0.92106+0.00176\n",
            "[18]\ttrain-aucpr:0.93093+0.00085\ttest-aucpr:0.92326+0.00224\n",
            "[19]\ttrain-aucpr:0.93256+0.00094\ttest-aucpr:0.92462+0.00285\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76179+0.00318\ttest-aucpr:0.75504+0.00108\n",
            "[1]\ttrain-aucpr:0.81818+0.00311\ttest-aucpr:0.81069+0.00388\n",
            "[2]\ttrain-aucpr:0.83821+0.00170\ttest-aucpr:0.83139+0.00285\n",
            "[3]\ttrain-aucpr:0.85275+0.00205\ttest-aucpr:0.84645+0.00162\n",
            "[4]\ttrain-aucpr:0.86472+0.00190\ttest-aucpr:0.85802+0.00264\n",
            "[5]\ttrain-aucpr:0.87451+0.00257\ttest-aucpr:0.86774+0.00267\n",
            "[6]\ttrain-aucpr:0.88525+0.00262\ttest-aucpr:0.87843+0.00300\n",
            "[7]\ttrain-aucpr:0.89520+0.00149\ttest-aucpr:0.88820+0.00219\n",
            "[8]\ttrain-aucpr:0.90082+0.00179\ttest-aucpr:0.89353+0.00165\n",
            "[9]\ttrain-aucpr:0.90502+0.00175\ttest-aucpr:0.89772+0.00113\n",
            "[10]\ttrain-aucpr:0.90971+0.00269\ttest-aucpr:0.90219+0.00121\n",
            "[11]\ttrain-aucpr:0.91365+0.00261\ttest-aucpr:0.90588+0.00195\n",
            "[12]\ttrain-aucpr:0.91821+0.00174\ttest-aucpr:0.91042+0.00199\n",
            "[13]\ttrain-aucpr:0.92162+0.00219\ttest-aucpr:0.91380+0.00250\n",
            "[14]\ttrain-aucpr:0.92403+0.00173\ttest-aucpr:0.91634+0.00184\n",
            "[15]\ttrain-aucpr:0.92580+0.00197\ttest-aucpr:0.91817+0.00172\n",
            "[16]\ttrain-aucpr:0.92766+0.00167\ttest-aucpr:0.91992+0.00176\n",
            "[17]\ttrain-aucpr:0.92989+0.00076\ttest-aucpr:0.92200+0.00218\n",
            "[18]\ttrain-aucpr:0.93133+0.00077\ttest-aucpr:0.92336+0.00231\n",
            "[19]\ttrain-aucpr:0.93352+0.00079\ttest-aucpr:0.92563+0.00270\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64422+0.00107\ttest-aucpr:0.64079+0.00144\n",
            "[1]\ttrain-aucpr:0.70026+0.00293\ttest-aucpr:0.69600+0.00372\n",
            "[2]\ttrain-aucpr:0.72170+0.00768\ttest-aucpr:0.71745+0.00860\n",
            "[3]\ttrain-aucpr:0.73634+0.00736\ttest-aucpr:0.73203+0.00704\n",
            "[4]\ttrain-aucpr:0.74774+0.00621\ttest-aucpr:0.74279+0.00609\n",
            "[5]\ttrain-aucpr:0.75617+0.00317\ttest-aucpr:0.75047+0.00397\n",
            "[6]\ttrain-aucpr:0.76457+0.00403\ttest-aucpr:0.75954+0.00487\n",
            "[7]\ttrain-aucpr:0.77452+0.00486\ttest-aucpr:0.76894+0.00597\n",
            "[8]\ttrain-aucpr:0.78275+0.00501\ttest-aucpr:0.77710+0.00669\n",
            "[9]\ttrain-aucpr:0.79120+0.00374\ttest-aucpr:0.78551+0.00573\n",
            "[10]\ttrain-aucpr:0.79951+0.00239\ttest-aucpr:0.79384+0.00316\n",
            "[11]\ttrain-aucpr:0.80676+0.00392\ttest-aucpr:0.80089+0.00412\n",
            "[12]\ttrain-aucpr:0.81180+0.00290\ttest-aucpr:0.80594+0.00330\n",
            "[13]\ttrain-aucpr:0.81745+0.00307\ttest-aucpr:0.81114+0.00383\n",
            "[14]\ttrain-aucpr:0.82160+0.00360\ttest-aucpr:0.81537+0.00423\n",
            "[15]\ttrain-aucpr:0.82790+0.00334\ttest-aucpr:0.82145+0.00373\n",
            "[16]\ttrain-aucpr:0.83104+0.00448\ttest-aucpr:0.82455+0.00555\n",
            "[17]\ttrain-aucpr:0.83411+0.00414\ttest-aucpr:0.82768+0.00492\n",
            "[18]\ttrain-aucpr:0.83754+0.00332\ttest-aucpr:0.83126+0.00468\n",
            "[19]\ttrain-aucpr:0.84068+0.00291\ttest-aucpr:0.83454+0.00452\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64422+0.00107\ttest-aucpr:0.64079+0.00144\n",
            "[1]\ttrain-aucpr:0.70025+0.00293\ttest-aucpr:0.69599+0.00372\n",
            "[2]\ttrain-aucpr:0.72170+0.00768\ttest-aucpr:0.71745+0.00860\n",
            "[3]\ttrain-aucpr:0.73632+0.00735\ttest-aucpr:0.73201+0.00704\n",
            "[4]\ttrain-aucpr:0.74771+0.00621\ttest-aucpr:0.74276+0.00609\n",
            "[5]\ttrain-aucpr:0.75615+0.00317\ttest-aucpr:0.75046+0.00397\n",
            "[6]\ttrain-aucpr:0.76453+0.00409\ttest-aucpr:0.75949+0.00490\n",
            "[7]\ttrain-aucpr:0.77449+0.00489\ttest-aucpr:0.76890+0.00598\n",
            "[8]\ttrain-aucpr:0.78270+0.00502\ttest-aucpr:0.77706+0.00671\n",
            "[9]\ttrain-aucpr:0.79115+0.00374\ttest-aucpr:0.78547+0.00574\n",
            "[10]\ttrain-aucpr:0.79953+0.00232\ttest-aucpr:0.79385+0.00311\n",
            "[11]\ttrain-aucpr:0.80677+0.00385\ttest-aucpr:0.80090+0.00407\n",
            "[12]\ttrain-aucpr:0.81179+0.00288\ttest-aucpr:0.80592+0.00330\n",
            "[13]\ttrain-aucpr:0.81801+0.00352\ttest-aucpr:0.81188+0.00472\n",
            "[14]\ttrain-aucpr:0.82207+0.00418\ttest-aucpr:0.81603+0.00529\n",
            "[15]\ttrain-aucpr:0.82865+0.00302\ttest-aucpr:0.82226+0.00405\n",
            "[16]\ttrain-aucpr:0.83099+0.00320\ttest-aucpr:0.82443+0.00399\n",
            "[17]\ttrain-aucpr:0.83453+0.00428\ttest-aucpr:0.82821+0.00512\n",
            "[18]\ttrain-aucpr:0.83852+0.00271\ttest-aucpr:0.83232+0.00401\n",
            "[19]\ttrain-aucpr:0.84122+0.00303\ttest-aucpr:0.83499+0.00446\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90357+0.00294\ttest-aucpr:0.87423+0.00394\n",
            "[1]\ttrain-aucpr:0.93607+0.00275\ttest-aucpr:0.90967+0.00434\n",
            "[2]\ttrain-aucpr:0.94917+0.00163\ttest-aucpr:0.92425+0.00165\n",
            "[3]\ttrain-aucpr:0.95757+0.00086\ttest-aucpr:0.93346+0.00230\n",
            "[4]\ttrain-aucpr:0.96223+0.00088\ttest-aucpr:0.93847+0.00167\n",
            "[5]\ttrain-aucpr:0.96695+0.00077\ttest-aucpr:0.94367+0.00182\n",
            "[6]\ttrain-aucpr:0.97071+0.00033\ttest-aucpr:0.94768+0.00146\n",
            "[7]\ttrain-aucpr:0.97332+0.00052\ttest-aucpr:0.95037+0.00127\n",
            "[8]\ttrain-aucpr:0.97663+0.00038\ttest-aucpr:0.95386+0.00126\n",
            "[9]\ttrain-aucpr:0.97865+0.00068\ttest-aucpr:0.95597+0.00165\n",
            "[10]\ttrain-aucpr:0.98009+0.00086\ttest-aucpr:0.95754+0.00176\n",
            "[11]\ttrain-aucpr:0.98129+0.00085\ttest-aucpr:0.95897+0.00163\n",
            "[12]\ttrain-aucpr:0.98234+0.00097\ttest-aucpr:0.96016+0.00138\n",
            "[13]\ttrain-aucpr:0.98335+0.00086\ttest-aucpr:0.96139+0.00131\n",
            "[14]\ttrain-aucpr:0.98403+0.00078\ttest-aucpr:0.96228+0.00113\n",
            "[15]\ttrain-aucpr:0.98474+0.00077\ttest-aucpr:0.96316+0.00109\n",
            "[16]\ttrain-aucpr:0.98557+0.00067\ttest-aucpr:0.96410+0.00102\n",
            "[17]\ttrain-aucpr:0.98592+0.00057\ttest-aucpr:0.96455+0.00091\n",
            "[18]\ttrain-aucpr:0.98637+0.00057\ttest-aucpr:0.96506+0.00101\n",
            "[19]\ttrain-aucpr:0.98711+0.00056\ttest-aucpr:0.96585+0.00119\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76179+0.00318\ttest-aucpr:0.75504+0.00108\n",
            "[1]\ttrain-aucpr:0.81818+0.00311\ttest-aucpr:0.81069+0.00388\n",
            "[2]\ttrain-aucpr:0.83821+0.00170\ttest-aucpr:0.83139+0.00285\n",
            "[3]\ttrain-aucpr:0.85275+0.00205\ttest-aucpr:0.84645+0.00162\n",
            "[4]\ttrain-aucpr:0.86472+0.00190\ttest-aucpr:0.85802+0.00264\n",
            "[5]\ttrain-aucpr:0.87451+0.00257\ttest-aucpr:0.86774+0.00267\n",
            "[6]\ttrain-aucpr:0.88525+0.00262\ttest-aucpr:0.87843+0.00300\n",
            "[7]\ttrain-aucpr:0.89520+0.00149\ttest-aucpr:0.88820+0.00219\n",
            "[8]\ttrain-aucpr:0.90082+0.00179\ttest-aucpr:0.89353+0.00166\n",
            "[9]\ttrain-aucpr:0.90503+0.00176\ttest-aucpr:0.89773+0.00114\n",
            "[10]\ttrain-aucpr:0.90973+0.00269\ttest-aucpr:0.90219+0.00121\n",
            "[11]\ttrain-aucpr:0.91367+0.00261\ttest-aucpr:0.90588+0.00195\n",
            "[12]\ttrain-aucpr:0.91823+0.00174\ttest-aucpr:0.91042+0.00200\n",
            "[13]\ttrain-aucpr:0.92165+0.00217\ttest-aucpr:0.91382+0.00251\n",
            "[14]\ttrain-aucpr:0.92408+0.00169\ttest-aucpr:0.91637+0.00183\n",
            "[15]\ttrain-aucpr:0.92591+0.00217\ttest-aucpr:0.91824+0.00215\n",
            "[16]\ttrain-aucpr:0.92838+0.00087\ttest-aucpr:0.92060+0.00216\n",
            "[17]\ttrain-aucpr:0.93020+0.00073\ttest-aucpr:0.92235+0.00227\n",
            "[18]\ttrain-aucpr:0.93188+0.00093\ttest-aucpr:0.92383+0.00266\n",
            "[19]\ttrain-aucpr:0.93375+0.00125\ttest-aucpr:0.92562+0.00278\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76221+0.00303\ttest-aucpr:0.75556+0.00101\n",
            "[1]\ttrain-aucpr:0.81229+0.00284\ttest-aucpr:0.80523+0.00397\n",
            "[2]\ttrain-aucpr:0.83127+0.00187\ttest-aucpr:0.82436+0.00294\n",
            "[3]\ttrain-aucpr:0.84664+0.00279\ttest-aucpr:0.83938+0.00410\n",
            "[4]\ttrain-aucpr:0.85680+0.00220\ttest-aucpr:0.84989+0.00339\n",
            "[5]\ttrain-aucpr:0.86402+0.00220\ttest-aucpr:0.85715+0.00328\n",
            "[6]\ttrain-aucpr:0.87150+0.00236\ttest-aucpr:0.86456+0.00302\n",
            "[7]\ttrain-aucpr:0.87816+0.00324\ttest-aucpr:0.87102+0.00344\n",
            "[8]\ttrain-aucpr:0.88483+0.00239\ttest-aucpr:0.87760+0.00326\n",
            "[9]\ttrain-aucpr:0.89064+0.00334\ttest-aucpr:0.88328+0.00426\n",
            "[10]\ttrain-aucpr:0.89628+0.00203\ttest-aucpr:0.88857+0.00326\n",
            "[11]\ttrain-aucpr:0.90154+0.00132\ttest-aucpr:0.89378+0.00245\n",
            "[12]\ttrain-aucpr:0.90470+0.00129\ttest-aucpr:0.89685+0.00249\n",
            "[13]\ttrain-aucpr:0.90766+0.00161\ttest-aucpr:0.89967+0.00259\n",
            "[14]\ttrain-aucpr:0.91028+0.00194\ttest-aucpr:0.90234+0.00278\n",
            "[15]\ttrain-aucpr:0.91281+0.00207\ttest-aucpr:0.90485+0.00247\n",
            "[16]\ttrain-aucpr:0.91588+0.00273\ttest-aucpr:0.90783+0.00303\n",
            "[17]\ttrain-aucpr:0.91761+0.00258\ttest-aucpr:0.90945+0.00323\n",
            "[18]\ttrain-aucpr:0.92049+0.00186\ttest-aucpr:0.91246+0.00275\n",
            "[19]\ttrain-aucpr:0.92353+0.00170\ttest-aucpr:0.91568+0.00226\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95236+0.00064\ttest-aucpr:0.88904+0.00219\n",
            "[1]\ttrain-aucpr:0.98057+0.00076\ttest-aucpr:0.92497+0.00260\n",
            "[2]\ttrain-aucpr:0.98931+0.00068\ttest-aucpr:0.93945+0.00239\n",
            "[3]\ttrain-aucpr:0.99328+0.00033\ttest-aucpr:0.94772+0.00177\n",
            "[4]\ttrain-aucpr:0.99546+0.00026\ttest-aucpr:0.95270+0.00150\n",
            "[5]\ttrain-aucpr:0.99674+0.00017\ttest-aucpr:0.95619+0.00119\n",
            "[6]\ttrain-aucpr:0.99770+0.00010\ttest-aucpr:0.95938+0.00095\n",
            "[7]\ttrain-aucpr:0.99836+0.00008\ttest-aucpr:0.96231+0.00078\n",
            "[8]\ttrain-aucpr:0.99877+0.00005\ttest-aucpr:0.96434+0.00048\n",
            "[9]\ttrain-aucpr:0.99908+0.00005\ttest-aucpr:0.96595+0.00062\n",
            "[10]\ttrain-aucpr:0.99931+0.00004\ttest-aucpr:0.96748+0.00054\n",
            "[11]\ttrain-aucpr:0.99947+0.00003\ttest-aucpr:0.96850+0.00035\n",
            "[12]\ttrain-aucpr:0.99958+0.00003\ttest-aucpr:0.96947+0.00045\n",
            "[13]\ttrain-aucpr:0.99968+0.00003\ttest-aucpr:0.97019+0.00034\n",
            "[14]\ttrain-aucpr:0.99974+0.00002\ttest-aucpr:0.97073+0.00034\n",
            "[15]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.97136+0.00035\n",
            "[16]\ttrain-aucpr:0.99985+0.00001\ttest-aucpr:0.97206+0.00037\n",
            "[17]\ttrain-aucpr:0.99988+0.00001\ttest-aucpr:0.97248+0.00031\n",
            "[18]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.97280+0.00022\n",
            "[19]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.97314+0.00012\n",
            "result:  0.9731432674583994\n",
            "best result:  0.9731432674583994\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76223+0.00304\ttest-aucpr:0.75553+0.00099\n",
            "[1]\ttrain-aucpr:0.80127+0.00607\ttest-aucpr:0.79398+0.00493\n",
            "[2]\ttrain-aucpr:0.81758+0.00210\ttest-aucpr:0.81033+0.00305\n",
            "[3]\ttrain-aucpr:0.82783+0.00278\ttest-aucpr:0.82126+0.00328\n",
            "[4]\ttrain-aucpr:0.83711+0.00324\ttest-aucpr:0.82990+0.00318\n",
            "[5]\ttrain-aucpr:0.84452+0.00114\ttest-aucpr:0.83766+0.00080\n",
            "[6]\ttrain-aucpr:0.84994+0.00098\ttest-aucpr:0.84308+0.00143\n",
            "[7]\ttrain-aucpr:0.85440+0.00087\ttest-aucpr:0.84752+0.00125\n",
            "[8]\ttrain-aucpr:0.85798+0.00159\ttest-aucpr:0.85126+0.00123\n",
            "[9]\ttrain-aucpr:0.86153+0.00129\ttest-aucpr:0.85465+0.00138\n",
            "[10]\ttrain-aucpr:0.86460+0.00197\ttest-aucpr:0.85774+0.00193\n",
            "[11]\ttrain-aucpr:0.86772+0.00179\ttest-aucpr:0.86053+0.00133\n",
            "[12]\ttrain-aucpr:0.87115+0.00200\ttest-aucpr:0.86399+0.00097\n",
            "[13]\ttrain-aucpr:0.87380+0.00190\ttest-aucpr:0.86680+0.00109\n",
            "[14]\ttrain-aucpr:0.87609+0.00211\ttest-aucpr:0.86928+0.00169\n",
            "[15]\ttrain-aucpr:0.87926+0.00192\ttest-aucpr:0.87237+0.00138\n",
            "[16]\ttrain-aucpr:0.88137+0.00215\ttest-aucpr:0.87454+0.00160\n",
            "[17]\ttrain-aucpr:0.88362+0.00244\ttest-aucpr:0.87686+0.00180\n",
            "[18]\ttrain-aucpr:0.88576+0.00272\ttest-aucpr:0.87905+0.00209\n",
            "[19]\ttrain-aucpr:0.88800+0.00307\ttest-aucpr:0.88119+0.00282\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90211+0.00286\ttest-aucpr:0.87367+0.00369\n",
            "[1]\ttrain-aucpr:0.93710+0.00159\ttest-aucpr:0.91265+0.00262\n",
            "[2]\ttrain-aucpr:0.95147+0.00064\ttest-aucpr:0.92789+0.00200\n",
            "[3]\ttrain-aucpr:0.95868+0.00105\ttest-aucpr:0.93564+0.00134\n",
            "[4]\ttrain-aucpr:0.96496+0.00164\ttest-aucpr:0.94241+0.00094\n",
            "[5]\ttrain-aucpr:0.96964+0.00101\ttest-aucpr:0.94736+0.00095\n",
            "[6]\ttrain-aucpr:0.97311+0.00068\ttest-aucpr:0.95138+0.00094\n",
            "[7]\ttrain-aucpr:0.97565+0.00081\ttest-aucpr:0.95439+0.00098\n",
            "[8]\ttrain-aucpr:0.97748+0.00072\ttest-aucpr:0.95676+0.00110\n",
            "[9]\ttrain-aucpr:0.97907+0.00072\ttest-aucpr:0.95874+0.00089\n",
            "[10]\ttrain-aucpr:0.98029+0.00043\ttest-aucpr:0.96030+0.00113\n",
            "[11]\ttrain-aucpr:0.98112+0.00066\ttest-aucpr:0.96150+0.00099\n",
            "[12]\ttrain-aucpr:0.98253+0.00086\ttest-aucpr:0.96290+0.00108\n",
            "[13]\ttrain-aucpr:0.98328+0.00096\ttest-aucpr:0.96386+0.00102\n",
            "[14]\ttrain-aucpr:0.98399+0.00053\ttest-aucpr:0.96454+0.00094\n",
            "[15]\ttrain-aucpr:0.98482+0.00076\ttest-aucpr:0.96536+0.00058\n",
            "[16]\ttrain-aucpr:0.98528+0.00069\ttest-aucpr:0.96583+0.00059\n",
            "[17]\ttrain-aucpr:0.98616+0.00096\ttest-aucpr:0.96662+0.00061\n",
            "[18]\ttrain-aucpr:0.98660+0.00101\ttest-aucpr:0.96702+0.00072\n",
            "[19]\ttrain-aucpr:0.98723+0.00085\ttest-aucpr:0.96759+0.00045\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.93339+0.00089\ttest-aucpr:0.88906+0.00248\n",
            "[1]\ttrain-aucpr:0.96262+0.00292\ttest-aucpr:0.92244+0.00504\n",
            "[2]\ttrain-aucpr:0.97306+0.00051\ttest-aucpr:0.93610+0.00227\n",
            "[3]\ttrain-aucpr:0.97848+0.00042\ttest-aucpr:0.94439+0.00232\n",
            "[4]\ttrain-aucpr:0.98211+0.00018\ttest-aucpr:0.94945+0.00204\n",
            "[5]\ttrain-aucpr:0.98479+0.00023\ttest-aucpr:0.95394+0.00157\n",
            "[6]\ttrain-aucpr:0.98665+0.00027\ttest-aucpr:0.95676+0.00124\n",
            "[7]\ttrain-aucpr:0.98818+0.00022\ttest-aucpr:0.95940+0.00127\n",
            "[8]\ttrain-aucpr:0.98937+0.00023\ttest-aucpr:0.96172+0.00105\n",
            "[9]\ttrain-aucpr:0.99034+0.00022\ttest-aucpr:0.96352+0.00101\n",
            "[10]\ttrain-aucpr:0.99114+0.00016\ttest-aucpr:0.96496+0.00106\n",
            "[11]\ttrain-aucpr:0.99186+0.00017\ttest-aucpr:0.96638+0.00103\n",
            "[12]\ttrain-aucpr:0.99252+0.00017\ttest-aucpr:0.96755+0.00123\n",
            "[13]\ttrain-aucpr:0.99306+0.00022\ttest-aucpr:0.96860+0.00125\n",
            "[14]\ttrain-aucpr:0.99345+0.00022\ttest-aucpr:0.96940+0.00110\n",
            "[15]\ttrain-aucpr:0.99385+0.00018\ttest-aucpr:0.97021+0.00097\n",
            "[16]\ttrain-aucpr:0.99421+0.00012\ttest-aucpr:0.97085+0.00087\n",
            "[17]\ttrain-aucpr:0.99447+0.00016\ttest-aucpr:0.97136+0.00079\n",
            "[18]\ttrain-aucpr:0.99480+0.00017\ttest-aucpr:0.97187+0.00072\n",
            "[19]\ttrain-aucpr:0.99505+0.00015\ttest-aucpr:0.97226+0.00072\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64422+0.00107\ttest-aucpr:0.64079+0.00144\n",
            "[1]\ttrain-aucpr:0.70895+0.00393\ttest-aucpr:0.70605+0.00191\n",
            "[2]\ttrain-aucpr:0.72679+0.00437\ttest-aucpr:0.72420+0.00428\n",
            "[3]\ttrain-aucpr:0.74029+0.00582\ttest-aucpr:0.73712+0.00584\n",
            "[4]\ttrain-aucpr:0.75455+0.00233\ttest-aucpr:0.75095+0.00191\n",
            "[5]\ttrain-aucpr:0.76881+0.00091\ttest-aucpr:0.76494+0.00233\n",
            "[6]\ttrain-aucpr:0.78098+0.00255\ttest-aucpr:0.77668+0.00381\n",
            "[7]\ttrain-aucpr:0.79426+0.00494\ttest-aucpr:0.79000+0.00365\n",
            "[8]\ttrain-aucpr:0.80289+0.00580\ttest-aucpr:0.79877+0.00400\n",
            "[9]\ttrain-aucpr:0.81201+0.00586\ttest-aucpr:0.80742+0.00433\n",
            "[10]\ttrain-aucpr:0.81778+0.00460\ttest-aucpr:0.81291+0.00366\n",
            "[11]\ttrain-aucpr:0.82589+0.00419\ttest-aucpr:0.82091+0.00308\n",
            "[12]\ttrain-aucpr:0.83188+0.00357\ttest-aucpr:0.82673+0.00228\n",
            "[13]\ttrain-aucpr:0.83494+0.00420\ttest-aucpr:0.82974+0.00217\n",
            "[14]\ttrain-aucpr:0.83796+0.00465\ttest-aucpr:0.83271+0.00252\n",
            "[15]\ttrain-aucpr:0.84133+0.00441\ttest-aucpr:0.83612+0.00177\n",
            "[16]\ttrain-aucpr:0.84602+0.00569\ttest-aucpr:0.84087+0.00332\n",
            "[17]\ttrain-aucpr:0.84931+0.00521\ttest-aucpr:0.84375+0.00304\n",
            "[18]\ttrain-aucpr:0.85538+0.00485\ttest-aucpr:0.85012+0.00189\n",
            "[19]\ttrain-aucpr:0.85921+0.00504\ttest-aucpr:0.85397+0.00293\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64422+0.00107\ttest-aucpr:0.64079+0.00144\n",
            "[1]\ttrain-aucpr:0.70026+0.00293\ttest-aucpr:0.69600+0.00372\n",
            "[2]\ttrain-aucpr:0.72170+0.00768\ttest-aucpr:0.71745+0.00860\n",
            "[3]\ttrain-aucpr:0.73635+0.00736\ttest-aucpr:0.73203+0.00704\n",
            "[4]\ttrain-aucpr:0.74774+0.00621\ttest-aucpr:0.74279+0.00609\n",
            "[5]\ttrain-aucpr:0.75617+0.00317\ttest-aucpr:0.75047+0.00396\n",
            "[6]\ttrain-aucpr:0.76457+0.00403\ttest-aucpr:0.75954+0.00487\n",
            "[7]\ttrain-aucpr:0.77452+0.00486\ttest-aucpr:0.76894+0.00597\n",
            "[8]\ttrain-aucpr:0.78276+0.00501\ttest-aucpr:0.77711+0.00669\n",
            "[9]\ttrain-aucpr:0.79116+0.00367\ttest-aucpr:0.78540+0.00558\n",
            "[10]\ttrain-aucpr:0.79961+0.00235\ttest-aucpr:0.79387+0.00304\n",
            "[11]\ttrain-aucpr:0.80679+0.00384\ttest-aucpr:0.80086+0.00401\n",
            "[12]\ttrain-aucpr:0.81181+0.00290\ttest-aucpr:0.80588+0.00328\n",
            "[13]\ttrain-aucpr:0.81747+0.00299\ttest-aucpr:0.81109+0.00369\n",
            "[14]\ttrain-aucpr:0.82162+0.00355\ttest-aucpr:0.81531+0.00413\n",
            "[15]\ttrain-aucpr:0.82823+0.00280\ttest-aucpr:0.82166+0.00327\n",
            "[16]\ttrain-aucpr:0.83220+0.00436\ttest-aucpr:0.82570+0.00596\n",
            "[17]\ttrain-aucpr:0.83495+0.00407\ttest-aucpr:0.82849+0.00526\n",
            "[18]\ttrain-aucpr:0.83906+0.00402\ttest-aucpr:0.83285+0.00561\n",
            "[19]\ttrain-aucpr:0.84134+0.00416\ttest-aucpr:0.83528+0.00577\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96535+0.00147\ttest-aucpr:0.88837+0.00244\n",
            "[1]\ttrain-aucpr:0.97993+0.00205\ttest-aucpr:0.91431+0.00525\n",
            "[2]\ttrain-aucpr:0.98736+0.00136\ttest-aucpr:0.92988+0.00519\n",
            "[3]\ttrain-aucpr:0.99026+0.00111\ttest-aucpr:0.93598+0.00498\n",
            "[4]\ttrain-aucpr:0.99262+0.00076\ttest-aucpr:0.94189+0.00411\n",
            "[5]\ttrain-aucpr:0.99405+0.00053\ttest-aucpr:0.94561+0.00265\n",
            "[6]\ttrain-aucpr:0.99501+0.00051\ttest-aucpr:0.94875+0.00244\n",
            "[7]\ttrain-aucpr:0.99583+0.00052\ttest-aucpr:0.95127+0.00217\n",
            "[8]\ttrain-aucpr:0.99639+0.00041\ttest-aucpr:0.95299+0.00194\n",
            "[9]\ttrain-aucpr:0.99694+0.00032\ttest-aucpr:0.95493+0.00183\n",
            "[10]\ttrain-aucpr:0.99736+0.00029\ttest-aucpr:0.95644+0.00175\n",
            "[11]\ttrain-aucpr:0.99765+0.00030\ttest-aucpr:0.95773+0.00182\n",
            "[12]\ttrain-aucpr:0.99795+0.00029\ttest-aucpr:0.95864+0.00169\n",
            "[13]\ttrain-aucpr:0.99822+0.00017\ttest-aucpr:0.95989+0.00142\n",
            "[14]\ttrain-aucpr:0.99845+0.00015\ttest-aucpr:0.96080+0.00156\n",
            "[15]\ttrain-aucpr:0.99866+0.00011\ttest-aucpr:0.96164+0.00146\n",
            "[16]\ttrain-aucpr:0.99881+0.00011\ttest-aucpr:0.96240+0.00155\n",
            "[17]\ttrain-aucpr:0.99895+0.00010\ttest-aucpr:0.96311+0.00160\n",
            "[18]\ttrain-aucpr:0.99905+0.00008\ttest-aucpr:0.96360+0.00152\n",
            "[19]\ttrain-aucpr:0.99916+0.00006\ttest-aucpr:0.96423+0.00152\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90142+0.00221\ttest-aucpr:0.87266+0.00423\n",
            "[1]\ttrain-aucpr:0.93637+0.00086\ttest-aucpr:0.91242+0.00201\n",
            "[2]\ttrain-aucpr:0.94823+0.00085\ttest-aucpr:0.92552+0.00252\n",
            "[3]\ttrain-aucpr:0.95645+0.00065\ttest-aucpr:0.93471+0.00254\n",
            "[4]\ttrain-aucpr:0.96132+0.00064\ttest-aucpr:0.93983+0.00169\n",
            "[5]\ttrain-aucpr:0.96591+0.00099\ttest-aucpr:0.94465+0.00119\n",
            "[6]\ttrain-aucpr:0.96911+0.00037\ttest-aucpr:0.94789+0.00099\n",
            "[7]\ttrain-aucpr:0.97202+0.00094\ttest-aucpr:0.95088+0.00108\n",
            "[8]\ttrain-aucpr:0.97458+0.00083\ttest-aucpr:0.95368+0.00057\n",
            "[9]\ttrain-aucpr:0.97652+0.00064\ttest-aucpr:0.95580+0.00089\n",
            "[10]\ttrain-aucpr:0.97819+0.00056\ttest-aucpr:0.95766+0.00112\n",
            "[11]\ttrain-aucpr:0.97940+0.00052\ttest-aucpr:0.95916+0.00116\n",
            "[12]\ttrain-aucpr:0.98017+0.00072\ttest-aucpr:0.96015+0.00090\n",
            "[13]\ttrain-aucpr:0.98102+0.00080\ttest-aucpr:0.96143+0.00094\n",
            "[14]\ttrain-aucpr:0.98195+0.00073\ttest-aucpr:0.96272+0.00080\n",
            "[15]\ttrain-aucpr:0.98265+0.00075\ttest-aucpr:0.96352+0.00073\n",
            "[16]\ttrain-aucpr:0.98327+0.00055\ttest-aucpr:0.96419+0.00109\n",
            "[17]\ttrain-aucpr:0.98382+0.00049\ttest-aucpr:0.96498+0.00107\n",
            "[18]\ttrain-aucpr:0.98417+0.00054\ttest-aucpr:0.96536+0.00107\n",
            "[19]\ttrain-aucpr:0.98464+0.00053\ttest-aucpr:0.96594+0.00125\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76321+0.00211\ttest-aucpr:0.75847+0.00409\n",
            "[1]\ttrain-aucpr:0.80346+0.00229\ttest-aucpr:0.79759+0.00396\n",
            "[2]\ttrain-aucpr:0.81672+0.00136\ttest-aucpr:0.81081+0.00214\n",
            "[3]\ttrain-aucpr:0.82902+0.00275\ttest-aucpr:0.82289+0.00149\n",
            "[4]\ttrain-aucpr:0.83501+0.00234\ttest-aucpr:0.82896+0.00170\n",
            "[5]\ttrain-aucpr:0.84236+0.00164\ttest-aucpr:0.83588+0.00211\n",
            "[6]\ttrain-aucpr:0.84716+0.00148\ttest-aucpr:0.84052+0.00195\n",
            "[7]\ttrain-aucpr:0.85234+0.00229\ttest-aucpr:0.84569+0.00228\n",
            "[8]\ttrain-aucpr:0.85703+0.00257\ttest-aucpr:0.85031+0.00248\n",
            "[9]\ttrain-aucpr:0.86067+0.00235\ttest-aucpr:0.85383+0.00228\n",
            "[10]\ttrain-aucpr:0.86435+0.00214\ttest-aucpr:0.85769+0.00262\n",
            "[11]\ttrain-aucpr:0.86736+0.00122\ttest-aucpr:0.86062+0.00162\n",
            "[12]\ttrain-aucpr:0.87081+0.00188\ttest-aucpr:0.86407+0.00230\n",
            "[13]\ttrain-aucpr:0.87405+0.00136\ttest-aucpr:0.86754+0.00179\n",
            "[14]\ttrain-aucpr:0.87688+0.00150\ttest-aucpr:0.87032+0.00185\n",
            "[15]\ttrain-aucpr:0.88003+0.00160\ttest-aucpr:0.87321+0.00172\n",
            "[16]\ttrain-aucpr:0.88330+0.00150\ttest-aucpr:0.87651+0.00141\n",
            "[17]\ttrain-aucpr:0.88571+0.00201\ttest-aucpr:0.87896+0.00187\n",
            "[18]\ttrain-aucpr:0.88837+0.00187\ttest-aucpr:0.88152+0.00202\n",
            "[19]\ttrain-aucpr:0.89066+0.00169\ttest-aucpr:0.88371+0.00180\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76296+0.00190\ttest-aucpr:0.75810+0.00354\n",
            "[1]\ttrain-aucpr:0.81496+0.00392\ttest-aucpr:0.80879+0.00441\n",
            "[2]\ttrain-aucpr:0.83727+0.00104\ttest-aucpr:0.83103+0.00256\n",
            "[3]\ttrain-aucpr:0.85389+0.00312\ttest-aucpr:0.84734+0.00421\n",
            "[4]\ttrain-aucpr:0.86683+0.00420\ttest-aucpr:0.85947+0.00565\n",
            "[5]\ttrain-aucpr:0.87679+0.00268\ttest-aucpr:0.86924+0.00316\n",
            "[6]\ttrain-aucpr:0.88453+0.00315\ttest-aucpr:0.87656+0.00368\n",
            "[7]\ttrain-aucpr:0.88998+0.00317\ttest-aucpr:0.88184+0.00394\n",
            "[8]\ttrain-aucpr:0.89647+0.00398\ttest-aucpr:0.88844+0.00398\n",
            "[9]\ttrain-aucpr:0.90197+0.00427\ttest-aucpr:0.89369+0.00478\n",
            "[10]\ttrain-aucpr:0.90816+0.00465\ttest-aucpr:0.89965+0.00491\n",
            "[11]\ttrain-aucpr:0.91241+0.00317\ttest-aucpr:0.90397+0.00317\n",
            "[12]\ttrain-aucpr:0.91648+0.00275\ttest-aucpr:0.90834+0.00306\n",
            "[13]\ttrain-aucpr:0.91946+0.00248\ttest-aucpr:0.91135+0.00256\n",
            "[14]\ttrain-aucpr:0.92239+0.00278\ttest-aucpr:0.91428+0.00314\n",
            "[15]\ttrain-aucpr:0.92480+0.00233\ttest-aucpr:0.91668+0.00238\n",
            "[16]\ttrain-aucpr:0.92717+0.00128\ttest-aucpr:0.91927+0.00164\n",
            "[17]\ttrain-aucpr:0.92885+0.00074\ttest-aucpr:0.92090+0.00141\n",
            "[18]\ttrain-aucpr:0.93078+0.00074\ttest-aucpr:0.92285+0.00111\n",
            "[19]\ttrain-aucpr:0.93318+0.00096\ttest-aucpr:0.92529+0.00148\n",
            "result:  0.9252918628832619\n",
            "best result:  0.9252918628832619\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95603+0.00193\ttest-aucpr:0.88760+0.00351\n",
            "[1]\ttrain-aucpr:0.98392+0.00058\ttest-aucpr:0.92442+0.00258\n",
            "[2]\ttrain-aucpr:0.99141+0.00034\ttest-aucpr:0.93817+0.00213\n",
            "[3]\ttrain-aucpr:0.99492+0.00018\ttest-aucpr:0.94642+0.00183\n",
            "[4]\ttrain-aucpr:0.99668+0.00015\ttest-aucpr:0.95117+0.00156\n",
            "[5]\ttrain-aucpr:0.99783+0.00018\ttest-aucpr:0.95496+0.00146\n",
            "[6]\ttrain-aucpr:0.99856+0.00008\ttest-aucpr:0.95776+0.00151\n",
            "[7]\ttrain-aucpr:0.99903+0.00010\ttest-aucpr:0.96025+0.00114\n",
            "[8]\ttrain-aucpr:0.99936+0.00006\ttest-aucpr:0.96237+0.00099\n",
            "[9]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.96408+0.00097\n",
            "[10]\ttrain-aucpr:0.99969+0.00003\ttest-aucpr:0.96546+0.00104\n",
            "[11]\ttrain-aucpr:0.99979+0.00002\ttest-aucpr:0.96683+0.00112\n",
            "[12]\ttrain-aucpr:0.99985+0.00002\ttest-aucpr:0.96779+0.00129\n",
            "[13]\ttrain-aucpr:0.99990+0.00002\ttest-aucpr:0.96874+0.00123\n",
            "[14]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.96946+0.00121\n",
            "[15]\ttrain-aucpr:0.99995+0.00001\ttest-aucpr:0.97012+0.00113\n",
            "[16]\ttrain-aucpr:0.99996+0.00001\ttest-aucpr:0.97061+0.00112\n",
            "[17]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.97101+0.00105\n",
            "[18]\ttrain-aucpr:0.99998+0.00001\ttest-aucpr:0.97160+0.00096\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97193+0.00095\n",
            "result:  0.9719303744960284\n",
            "best result:  0.9719303744960284\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96879+0.00105\ttest-aucpr:0.89176+0.00177\n",
            "[1]\ttrain-aucpr:0.99027+0.00065\ttest-aucpr:0.92488+0.00196\n",
            "[2]\ttrain-aucpr:0.99540+0.00029\ttest-aucpr:0.93779+0.00202\n",
            "[3]\ttrain-aucpr:0.99740+0.00019\ttest-aucpr:0.94677+0.00098\n",
            "[4]\ttrain-aucpr:0.99838+0.00011\ttest-aucpr:0.95234+0.00116\n",
            "[5]\ttrain-aucpr:0.99895+0.00007\ttest-aucpr:0.95580+0.00151\n",
            "[6]\ttrain-aucpr:0.99934+0.00004\ttest-aucpr:0.95916+0.00142\n",
            "[7]\ttrain-aucpr:0.99957+0.00001\ttest-aucpr:0.96124+0.00125\n",
            "[8]\ttrain-aucpr:0.99971+0.00001\ttest-aucpr:0.96355+0.00117\n",
            "[9]\ttrain-aucpr:0.99981+0.00001\ttest-aucpr:0.96508+0.00115\n",
            "[10]\ttrain-aucpr:0.99987+0.00001\ttest-aucpr:0.96639+0.00125\n",
            "[11]\ttrain-aucpr:0.99991+0.00000\ttest-aucpr:0.96742+0.00099\n",
            "[12]\ttrain-aucpr:0.99994+0.00000\ttest-aucpr:0.96849+0.00112\n",
            "[13]\ttrain-aucpr:0.99996+0.00000\ttest-aucpr:0.96926+0.00120\n",
            "[14]\ttrain-aucpr:0.99997+0.00000\ttest-aucpr:0.96988+0.00115\n",
            "[15]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97048+0.00095\n",
            "[16]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97084+0.00083\n",
            "[17]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97128+0.00090\n",
            "[18]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97160+0.00090\n",
            "[19]\ttrain-aucpr:1.00000+0.00000\ttest-aucpr:0.97186+0.00099\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95373+0.00179\ttest-aucpr:0.88868+0.00378\n",
            "[1]\ttrain-aucpr:0.98013+0.00056\ttest-aucpr:0.92547+0.00207\n",
            "[2]\ttrain-aucpr:0.98771+0.00041\ttest-aucpr:0.93786+0.00165\n",
            "[3]\ttrain-aucpr:0.99161+0.00035\ttest-aucpr:0.94578+0.00171\n",
            "[4]\ttrain-aucpr:0.99397+0.00009\ttest-aucpr:0.95111+0.00123\n",
            "[5]\ttrain-aucpr:0.99548+0.00012\ttest-aucpr:0.95445+0.00129\n",
            "[6]\ttrain-aucpr:0.99642+0.00010\ttest-aucpr:0.95726+0.00145\n",
            "[7]\ttrain-aucpr:0.99723+0.00012\ttest-aucpr:0.95973+0.00116\n",
            "[8]\ttrain-aucpr:0.99780+0.00012\ttest-aucpr:0.96156+0.00138\n",
            "[9]\ttrain-aucpr:0.99823+0.00010\ttest-aucpr:0.96334+0.00146\n",
            "[10]\ttrain-aucpr:0.99856+0.00010\ttest-aucpr:0.96483+0.00163\n",
            "[11]\ttrain-aucpr:0.99884+0.00005\ttest-aucpr:0.96616+0.00160\n",
            "[12]\ttrain-aucpr:0.99907+0.00004\ttest-aucpr:0.96736+0.00145\n",
            "[13]\ttrain-aucpr:0.99924+0.00003\ttest-aucpr:0.96837+0.00146\n",
            "[14]\ttrain-aucpr:0.99936+0.00003\ttest-aucpr:0.96917+0.00148\n",
            "[15]\ttrain-aucpr:0.99947+0.00001\ttest-aucpr:0.96994+0.00127\n",
            "[16]\ttrain-aucpr:0.99956+0.00001\ttest-aucpr:0.97051+0.00114\n",
            "[17]\ttrain-aucpr:0.99963+0.00001\ttest-aucpr:0.97117+0.00116\n",
            "[18]\ttrain-aucpr:0.99968+0.00002\ttest-aucpr:0.97173+0.00119\n",
            "[19]\ttrain-aucpr:0.99973+0.00002\ttest-aucpr:0.97218+0.00111\n",
            "result:  0.9721751882566718\n",
            "best result:  0.9721751882566718\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76296+0.00196\ttest-aucpr:0.75803+0.00359\n",
            "[1]\ttrain-aucpr:0.80326+0.00236\ttest-aucpr:0.79737+0.00404\n",
            "[2]\ttrain-aucpr:0.81677+0.00140\ttest-aucpr:0.81090+0.00211\n",
            "[3]\ttrain-aucpr:0.82905+0.00280\ttest-aucpr:0.82297+0.00156\n",
            "[4]\ttrain-aucpr:0.83507+0.00251\ttest-aucpr:0.82913+0.00182\n",
            "[5]\ttrain-aucpr:0.84236+0.00135\ttest-aucpr:0.83594+0.00177\n",
            "[6]\ttrain-aucpr:0.84703+0.00121\ttest-aucpr:0.84043+0.00145\n",
            "[7]\ttrain-aucpr:0.85230+0.00222\ttest-aucpr:0.84564+0.00210\n",
            "[8]\ttrain-aucpr:0.85707+0.00246\ttest-aucpr:0.85049+0.00241\n",
            "[9]\ttrain-aucpr:0.86064+0.00229\ttest-aucpr:0.85394+0.00223\n",
            "[10]\ttrain-aucpr:0.86467+0.00235\ttest-aucpr:0.85794+0.00256\n",
            "[11]\ttrain-aucpr:0.86771+0.00152\ttest-aucpr:0.86105+0.00196\n",
            "[12]\ttrain-aucpr:0.87112+0.00171\ttest-aucpr:0.86454+0.00213\n",
            "[13]\ttrain-aucpr:0.87446+0.00143\ttest-aucpr:0.86802+0.00206\n",
            "[14]\ttrain-aucpr:0.87752+0.00188\ttest-aucpr:0.87101+0.00258\n",
            "[15]\ttrain-aucpr:0.88074+0.00172\ttest-aucpr:0.87421+0.00231\n",
            "[16]\ttrain-aucpr:0.88298+0.00188\ttest-aucpr:0.87635+0.00223\n",
            "[17]\ttrain-aucpr:0.88581+0.00178\ttest-aucpr:0.87912+0.00202\n",
            "[18]\ttrain-aucpr:0.88813+0.00092\ttest-aucpr:0.88146+0.00139\n",
            "[19]\ttrain-aucpr:0.89099+0.00155\ttest-aucpr:0.88423+0.00192\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65578+0.00713\ttest-aucpr:0.65365+0.00857\n",
            "[1]\ttrain-aucpr:0.70753+0.00309\ttest-aucpr:0.70440+0.00544\n",
            "[2]\ttrain-aucpr:0.73082+0.00554\ttest-aucpr:0.72756+0.00822\n",
            "[3]\ttrain-aucpr:0.74164+0.00458\ttest-aucpr:0.73813+0.00779\n",
            "[4]\ttrain-aucpr:0.75977+0.00360\ttest-aucpr:0.75607+0.00595\n",
            "[5]\ttrain-aucpr:0.77006+0.00731\ttest-aucpr:0.76595+0.00916\n",
            "[6]\ttrain-aucpr:0.78079+0.00573\ttest-aucpr:0.77612+0.00759\n",
            "[7]\ttrain-aucpr:0.79433+0.00342\ttest-aucpr:0.78940+0.00371\n",
            "[8]\ttrain-aucpr:0.80248+0.00519\ttest-aucpr:0.79722+0.00551\n",
            "[9]\ttrain-aucpr:0.81004+0.00470\ttest-aucpr:0.80482+0.00573\n",
            "[10]\ttrain-aucpr:0.81773+0.00495\ttest-aucpr:0.81247+0.00503\n",
            "[11]\ttrain-aucpr:0.82635+0.00625\ttest-aucpr:0.82126+0.00633\n",
            "[12]\ttrain-aucpr:0.83019+0.00693\ttest-aucpr:0.82513+0.00732\n",
            "[13]\ttrain-aucpr:0.83529+0.00614\ttest-aucpr:0.83040+0.00674\n",
            "[14]\ttrain-aucpr:0.84003+0.00589\ttest-aucpr:0.83504+0.00602\n",
            "[15]\ttrain-aucpr:0.84351+0.00648\ttest-aucpr:0.83818+0.00680\n",
            "[16]\ttrain-aucpr:0.84887+0.00648\ttest-aucpr:0.84341+0.00633\n",
            "[17]\ttrain-aucpr:0.85270+0.00546\ttest-aucpr:0.84753+0.00502\n",
            "[18]\ttrain-aucpr:0.85682+0.00486\ttest-aucpr:0.85178+0.00451\n",
            "[19]\ttrain-aucpr:0.86008+0.00513\ttest-aucpr:0.85509+0.00478\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76297+0.00195\ttest-aucpr:0.75803+0.00359\n",
            "[1]\ttrain-aucpr:0.81099+0.00318\ttest-aucpr:0.80486+0.00372\n",
            "[2]\ttrain-aucpr:0.83254+0.00099\ttest-aucpr:0.82590+0.00123\n",
            "[3]\ttrain-aucpr:0.84828+0.00202\ttest-aucpr:0.84215+0.00242\n",
            "[4]\ttrain-aucpr:0.85876+0.00268\ttest-aucpr:0.85277+0.00363\n",
            "[5]\ttrain-aucpr:0.86776+0.00301\ttest-aucpr:0.86167+0.00329\n",
            "[6]\ttrain-aucpr:0.87430+0.00235\ttest-aucpr:0.86828+0.00291\n",
            "[7]\ttrain-aucpr:0.88147+0.00191\ttest-aucpr:0.87500+0.00321\n",
            "[8]\ttrain-aucpr:0.88892+0.00163\ttest-aucpr:0.88214+0.00230\n",
            "[9]\ttrain-aucpr:0.89418+0.00089\ttest-aucpr:0.88745+0.00162\n",
            "[10]\ttrain-aucpr:0.89882+0.00120\ttest-aucpr:0.89182+0.00095\n",
            "[11]\ttrain-aucpr:0.90308+0.00079\ttest-aucpr:0.89588+0.00177\n",
            "[12]\ttrain-aucpr:0.90632+0.00150\ttest-aucpr:0.89903+0.00196\n",
            "[13]\ttrain-aucpr:0.91017+0.00212\ttest-aucpr:0.90280+0.00250\n",
            "[14]\ttrain-aucpr:0.91391+0.00192\ttest-aucpr:0.90632+0.00261\n",
            "[15]\ttrain-aucpr:0.91607+0.00181\ttest-aucpr:0.90837+0.00303\n",
            "[16]\ttrain-aucpr:0.91849+0.00166\ttest-aucpr:0.91072+0.00273\n",
            "[17]\ttrain-aucpr:0.92139+0.00148\ttest-aucpr:0.91370+0.00288\n",
            "[18]\ttrain-aucpr:0.92339+0.00125\ttest-aucpr:0.91563+0.00248\n",
            "[19]\ttrain-aucpr:0.92501+0.00129\ttest-aucpr:0.91727+0.00255\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90476+0.00234\ttest-aucpr:0.87353+0.00360\n",
            "[1]\ttrain-aucpr:0.93999+0.00127\ttest-aucpr:0.91333+0.00297\n",
            "[2]\ttrain-aucpr:0.95388+0.00077\ttest-aucpr:0.92866+0.00135\n",
            "[3]\ttrain-aucpr:0.96285+0.00058\ttest-aucpr:0.93866+0.00194\n",
            "[4]\ttrain-aucpr:0.96811+0.00059\ttest-aucpr:0.94423+0.00200\n",
            "[5]\ttrain-aucpr:0.97264+0.00096\ttest-aucpr:0.94892+0.00158\n",
            "[6]\ttrain-aucpr:0.97591+0.00094\ttest-aucpr:0.95272+0.00146\n",
            "[7]\ttrain-aucpr:0.97834+0.00081\ttest-aucpr:0.95527+0.00164\n",
            "[8]\ttrain-aucpr:0.97990+0.00044\ttest-aucpr:0.95712+0.00136\n",
            "[9]\ttrain-aucpr:0.98148+0.00032\ttest-aucpr:0.95896+0.00136\n",
            "[10]\ttrain-aucpr:0.98253+0.00070\ttest-aucpr:0.96032+0.00170\n",
            "[11]\ttrain-aucpr:0.98386+0.00067\ttest-aucpr:0.96172+0.00175\n",
            "[12]\ttrain-aucpr:0.98508+0.00086\ttest-aucpr:0.96304+0.00180\n",
            "[13]\ttrain-aucpr:0.98592+0.00124\ttest-aucpr:0.96390+0.00207\n",
            "[14]\ttrain-aucpr:0.98657+0.00111\ttest-aucpr:0.96455+0.00213\n",
            "[15]\ttrain-aucpr:0.98727+0.00082\ttest-aucpr:0.96554+0.00162\n",
            "[16]\ttrain-aucpr:0.98793+0.00066\ttest-aucpr:0.96624+0.00141\n",
            "[17]\ttrain-aucpr:0.98842+0.00076\ttest-aucpr:0.96659+0.00142\n",
            "[18]\ttrain-aucpr:0.98887+0.00082\ttest-aucpr:0.96699+0.00156\n",
            "[19]\ttrain-aucpr:0.98941+0.00073\ttest-aucpr:0.96735+0.00132\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65578+0.00713\ttest-aucpr:0.65365+0.00857\n",
            "[1]\ttrain-aucpr:0.69450+0.00394\ttest-aucpr:0.69206+0.00499\n",
            "[2]\ttrain-aucpr:0.70775+0.00686\ttest-aucpr:0.70449+0.00720\n",
            "[3]\ttrain-aucpr:0.71840+0.00252\ttest-aucpr:0.71514+0.00283\n",
            "[4]\ttrain-aucpr:0.72654+0.00237\ttest-aucpr:0.72353+0.00340\n",
            "[5]\ttrain-aucpr:0.73484+0.00358\ttest-aucpr:0.73144+0.00473\n",
            "[6]\ttrain-aucpr:0.74023+0.00225\ttest-aucpr:0.73680+0.00362\n",
            "[7]\ttrain-aucpr:0.74577+0.00258\ttest-aucpr:0.74199+0.00323\n",
            "[8]\ttrain-aucpr:0.74818+0.00230\ttest-aucpr:0.74437+0.00238\n",
            "[9]\ttrain-aucpr:0.75097+0.00326\ttest-aucpr:0.74733+0.00152\n",
            "[10]\ttrain-aucpr:0.75328+0.00388\ttest-aucpr:0.74966+0.00236\n",
            "[11]\ttrain-aucpr:0.75650+0.00228\ttest-aucpr:0.75276+0.00182\n",
            "[12]\ttrain-aucpr:0.75793+0.00280\ttest-aucpr:0.75414+0.00243\n",
            "[13]\ttrain-aucpr:0.76131+0.00300\ttest-aucpr:0.75740+0.00071\n",
            "[14]\ttrain-aucpr:0.76594+0.00285\ttest-aucpr:0.76205+0.00203\n",
            "[15]\ttrain-aucpr:0.76798+0.00140\ttest-aucpr:0.76379+0.00169\n",
            "[16]\ttrain-aucpr:0.77247+0.00191\ttest-aucpr:0.76824+0.00249\n",
            "[17]\ttrain-aucpr:0.77584+0.00134\ttest-aucpr:0.77158+0.00256\n",
            "[18]\ttrain-aucpr:0.77969+0.00166\ttest-aucpr:0.77516+0.00263\n",
            "[19]\ttrain-aucpr:0.78241+0.00134\ttest-aucpr:0.77793+0.00212\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76296+0.00196\ttest-aucpr:0.75803+0.00359\n",
            "[1]\ttrain-aucpr:0.80326+0.00236\ttest-aucpr:0.79737+0.00404\n",
            "[2]\ttrain-aucpr:0.81677+0.00140\ttest-aucpr:0.81090+0.00211\n",
            "[3]\ttrain-aucpr:0.82905+0.00280\ttest-aucpr:0.82297+0.00156\n",
            "[4]\ttrain-aucpr:0.83507+0.00251\ttest-aucpr:0.82913+0.00182\n",
            "[5]\ttrain-aucpr:0.84236+0.00135\ttest-aucpr:0.83594+0.00177\n",
            "[6]\ttrain-aucpr:0.84703+0.00121\ttest-aucpr:0.84043+0.00145\n",
            "[7]\ttrain-aucpr:0.85230+0.00222\ttest-aucpr:0.84564+0.00210\n",
            "[8]\ttrain-aucpr:0.85707+0.00246\ttest-aucpr:0.85049+0.00241\n",
            "[9]\ttrain-aucpr:0.86064+0.00229\ttest-aucpr:0.85394+0.00223\n",
            "[10]\ttrain-aucpr:0.86467+0.00235\ttest-aucpr:0.85794+0.00256\n",
            "[11]\ttrain-aucpr:0.86771+0.00152\ttest-aucpr:0.86105+0.00196\n",
            "[12]\ttrain-aucpr:0.87112+0.00171\ttest-aucpr:0.86454+0.00213\n",
            "[13]\ttrain-aucpr:0.87446+0.00143\ttest-aucpr:0.86802+0.00206\n",
            "[14]\ttrain-aucpr:0.87752+0.00188\ttest-aucpr:0.87101+0.00258\n",
            "[15]\ttrain-aucpr:0.88074+0.00172\ttest-aucpr:0.87421+0.00231\n",
            "[16]\ttrain-aucpr:0.88298+0.00188\ttest-aucpr:0.87635+0.00223\n",
            "[17]\ttrain-aucpr:0.88581+0.00178\ttest-aucpr:0.87912+0.00202\n",
            "[18]\ttrain-aucpr:0.88813+0.00092\ttest-aucpr:0.88146+0.00139\n",
            "[19]\ttrain-aucpr:0.89099+0.00155\ttest-aucpr:0.88423+0.00192\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89805+0.00186\ttest-aucpr:0.87074+0.00451\n",
            "[1]\ttrain-aucpr:0.92713+0.00359\ttest-aucpr:0.90279+0.00379\n",
            "[2]\ttrain-aucpr:0.94082+0.00097\ttest-aucpr:0.91889+0.00328\n",
            "[3]\ttrain-aucpr:0.94615+0.00145\ttest-aucpr:0.92487+0.00246\n",
            "[4]\ttrain-aucpr:0.95082+0.00143\ttest-aucpr:0.93009+0.00281\n",
            "[5]\ttrain-aucpr:0.95418+0.00088\ttest-aucpr:0.93412+0.00216\n",
            "[6]\ttrain-aucpr:0.95695+0.00084\ttest-aucpr:0.93731+0.00227\n",
            "[7]\ttrain-aucpr:0.95936+0.00070\ttest-aucpr:0.93985+0.00191\n",
            "[8]\ttrain-aucpr:0.96129+0.00048\ttest-aucpr:0.94204+0.00143\n",
            "[9]\ttrain-aucpr:0.96305+0.00091\ttest-aucpr:0.94385+0.00121\n",
            "[10]\ttrain-aucpr:0.96430+0.00084\ttest-aucpr:0.94507+0.00100\n",
            "[11]\ttrain-aucpr:0.96597+0.00037\ttest-aucpr:0.94669+0.00121\n",
            "[12]\ttrain-aucpr:0.96724+0.00065\ttest-aucpr:0.94804+0.00144\n",
            "[13]\ttrain-aucpr:0.96846+0.00053\ttest-aucpr:0.94926+0.00148\n",
            "[14]\ttrain-aucpr:0.96986+0.00061\ttest-aucpr:0.95075+0.00137\n",
            "[15]\ttrain-aucpr:0.97103+0.00050\ttest-aucpr:0.95203+0.00135\n",
            "[16]\ttrain-aucpr:0.97183+0.00039\ttest-aucpr:0.95279+0.00136\n",
            "[17]\ttrain-aucpr:0.97282+0.00041\ttest-aucpr:0.95382+0.00115\n",
            "[18]\ttrain-aucpr:0.97377+0.00027\ttest-aucpr:0.95484+0.00096\n",
            "[19]\ttrain-aucpr:0.97452+0.00027\ttest-aucpr:0.95562+0.00098\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.97832+0.00076\ttest-aucpr:0.88471+0.00091\n",
            "[1]\ttrain-aucpr:0.98837+0.00153\ttest-aucpr:0.90924+0.00682\n",
            "[2]\ttrain-aucpr:0.99300+0.00086\ttest-aucpr:0.92494+0.00469\n",
            "[3]\ttrain-aucpr:0.99527+0.00062\ttest-aucpr:0.93425+0.00198\n",
            "[4]\ttrain-aucpr:0.99660+0.00044\ttest-aucpr:0.94020+0.00158\n",
            "[5]\ttrain-aucpr:0.99742+0.00025\ttest-aucpr:0.94464+0.00156\n",
            "[6]\ttrain-aucpr:0.99795+0.00017\ttest-aucpr:0.94776+0.00146\n",
            "[7]\ttrain-aucpr:0.99837+0.00015\ttest-aucpr:0.95055+0.00188\n",
            "[8]\ttrain-aucpr:0.99861+0.00013\ttest-aucpr:0.95262+0.00173\n",
            "[9]\ttrain-aucpr:0.99886+0.00011\ttest-aucpr:0.95477+0.00149\n",
            "[10]\ttrain-aucpr:0.99902+0.00008\ttest-aucpr:0.95605+0.00130\n",
            "[11]\ttrain-aucpr:0.99916+0.00008\ttest-aucpr:0.95729+0.00113\n",
            "[12]\ttrain-aucpr:0.99929+0.00007\ttest-aucpr:0.95851+0.00114\n",
            "[13]\ttrain-aucpr:0.99939+0.00005\ttest-aucpr:0.95981+0.00102\n",
            "[14]\ttrain-aucpr:0.99947+0.00004\ttest-aucpr:0.96078+0.00084\n",
            "[15]\ttrain-aucpr:0.99953+0.00004\ttest-aucpr:0.96165+0.00084\n",
            "[16]\ttrain-aucpr:0.99959+0.00004\ttest-aucpr:0.96240+0.00066\n",
            "[17]\ttrain-aucpr:0.99964+0.00004\ttest-aucpr:0.96301+0.00066\n",
            "[18]\ttrain-aucpr:0.99969+0.00003\ttest-aucpr:0.96363+0.00060\n",
            "[19]\ttrain-aucpr:0.99974+0.00003\ttest-aucpr:0.96424+0.00064\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94227+0.00113\ttest-aucpr:0.88583+0.00295\n",
            "[1]\ttrain-aucpr:0.96605+0.00240\ttest-aucpr:0.91661+0.00420\n",
            "[2]\ttrain-aucpr:0.97527+0.00303\ttest-aucpr:0.92911+0.00504\n",
            "[3]\ttrain-aucpr:0.98120+0.00104\ttest-aucpr:0.93813+0.00201\n",
            "[4]\ttrain-aucpr:0.98383+0.00078\ttest-aucpr:0.94251+0.00171\n",
            "[5]\ttrain-aucpr:0.98603+0.00054\ttest-aucpr:0.94633+0.00171\n",
            "[6]\ttrain-aucpr:0.98767+0.00042\ttest-aucpr:0.94893+0.00134\n",
            "[7]\ttrain-aucpr:0.98897+0.00033\ttest-aucpr:0.95105+0.00101\n",
            "[8]\ttrain-aucpr:0.99001+0.00017\ttest-aucpr:0.95293+0.00113\n",
            "[9]\ttrain-aucpr:0.99089+0.00024\ttest-aucpr:0.95464+0.00087\n",
            "[10]\ttrain-aucpr:0.99171+0.00022\ttest-aucpr:0.95616+0.00104\n",
            "[11]\ttrain-aucpr:0.99233+0.00023\ttest-aucpr:0.95736+0.00112\n",
            "[12]\ttrain-aucpr:0.99290+0.00018\ttest-aucpr:0.95839+0.00116\n",
            "[13]\ttrain-aucpr:0.99349+0.00008\ttest-aucpr:0.95960+0.00107\n",
            "[14]\ttrain-aucpr:0.99396+0.00010\ttest-aucpr:0.96046+0.00097\n",
            "[15]\ttrain-aucpr:0.99444+0.00007\ttest-aucpr:0.96144+0.00106\n",
            "[16]\ttrain-aucpr:0.99479+0.00009\ttest-aucpr:0.96221+0.00100\n",
            "[17]\ttrain-aucpr:0.99513+0.00010\ttest-aucpr:0.96306+0.00099\n",
            "[18]\ttrain-aucpr:0.99548+0.00007\ttest-aucpr:0.96388+0.00099\n",
            "[19]\ttrain-aucpr:0.99575+0.00006\ttest-aucpr:0.96445+0.00093\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95603+0.00193\ttest-aucpr:0.88760+0.00351\n",
            "[1]\ttrain-aucpr:0.98241+0.00068\ttest-aucpr:0.92476+0.00212\n",
            "[2]\ttrain-aucpr:0.98986+0.00051\ttest-aucpr:0.93666+0.00162\n",
            "[3]\ttrain-aucpr:0.99331+0.00030\ttest-aucpr:0.94472+0.00152\n",
            "[4]\ttrain-aucpr:0.99537+0.00022\ttest-aucpr:0.94990+0.00115\n",
            "[5]\ttrain-aucpr:0.99674+0.00009\ttest-aucpr:0.95350+0.00092\n",
            "[6]\ttrain-aucpr:0.99759+0.00015\ttest-aucpr:0.95616+0.00084\n",
            "[7]\ttrain-aucpr:0.99821+0.00009\ttest-aucpr:0.95873+0.00112\n",
            "[8]\ttrain-aucpr:0.99866+0.00007\ttest-aucpr:0.96059+0.00111\n",
            "[9]\ttrain-aucpr:0.99900+0.00004\ttest-aucpr:0.96229+0.00093\n",
            "[10]\ttrain-aucpr:0.99925+0.00005\ttest-aucpr:0.96405+0.00110\n",
            "[11]\ttrain-aucpr:0.99944+0.00004\ttest-aucpr:0.96530+0.00110\n",
            "[12]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.96649+0.00115\n",
            "[13]\ttrain-aucpr:0.99966+0.00002\ttest-aucpr:0.96751+0.00121\n",
            "[14]\ttrain-aucpr:0.99975+0.00002\ttest-aucpr:0.96839+0.00125\n",
            "[15]\ttrain-aucpr:0.99981+0.00001\ttest-aucpr:0.96922+0.00128\n",
            "[16]\ttrain-aucpr:0.99985+0.00001\ttest-aucpr:0.96985+0.00134\n",
            "[17]\ttrain-aucpr:0.99989+0.00001\ttest-aucpr:0.97040+0.00121\n",
            "[18]\ttrain-aucpr:0.99991+0.00001\ttest-aucpr:0.97090+0.00117\n",
            "[19]\ttrain-aucpr:0.99993+0.00001\ttest-aucpr:0.97145+0.00121\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76300+0.00194\ttest-aucpr:0.75801+0.00366\n",
            "[1]\ttrain-aucpr:0.81512+0.00394\ttest-aucpr:0.80893+0.00447\n",
            "[2]\ttrain-aucpr:0.83744+0.00109\ttest-aucpr:0.83129+0.00268\n",
            "[3]\ttrain-aucpr:0.85424+0.00322\ttest-aucpr:0.84742+0.00423\n",
            "[4]\ttrain-aucpr:0.86639+0.00394\ttest-aucpr:0.85922+0.00531\n",
            "[5]\ttrain-aucpr:0.87673+0.00291\ttest-aucpr:0.86928+0.00262\n",
            "[6]\ttrain-aucpr:0.88558+0.00230\ttest-aucpr:0.87789+0.00276\n",
            "[7]\ttrain-aucpr:0.89128+0.00192\ttest-aucpr:0.88338+0.00233\n",
            "[8]\ttrain-aucpr:0.89733+0.00244\ttest-aucpr:0.88955+0.00232\n",
            "[9]\ttrain-aucpr:0.90184+0.00365\ttest-aucpr:0.89389+0.00352\n",
            "[10]\ttrain-aucpr:0.90797+0.00324\ttest-aucpr:0.89979+0.00334\n",
            "[11]\ttrain-aucpr:0.91149+0.00289\ttest-aucpr:0.90325+0.00330\n",
            "[12]\ttrain-aucpr:0.91564+0.00298\ttest-aucpr:0.90729+0.00315\n",
            "[13]\ttrain-aucpr:0.91883+0.00356\ttest-aucpr:0.91044+0.00357\n",
            "[14]\ttrain-aucpr:0.92279+0.00255\ttest-aucpr:0.91457+0.00247\n",
            "[15]\ttrain-aucpr:0.92555+0.00265\ttest-aucpr:0.91715+0.00284\n",
            "[16]\ttrain-aucpr:0.92753+0.00326\ttest-aucpr:0.91909+0.00372\n",
            "[17]\ttrain-aucpr:0.92948+0.00317\ttest-aucpr:0.92114+0.00361\n",
            "[18]\ttrain-aucpr:0.93205+0.00205\ttest-aucpr:0.92363+0.00280\n",
            "[19]\ttrain-aucpr:0.93368+0.00132\ttest-aucpr:0.92529+0.00224\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76289+0.00196\ttest-aucpr:0.75800+0.00366\n",
            "[1]\ttrain-aucpr:0.81497+0.00395\ttest-aucpr:0.80873+0.00461\n",
            "[2]\ttrain-aucpr:0.83721+0.00115\ttest-aucpr:0.83096+0.00273\n",
            "[3]\ttrain-aucpr:0.85385+0.00321\ttest-aucpr:0.84729+0.00435\n",
            "[4]\ttrain-aucpr:0.86682+0.00419\ttest-aucpr:0.85947+0.00575\n",
            "[5]\ttrain-aucpr:0.87676+0.00267\ttest-aucpr:0.86923+0.00327\n",
            "[6]\ttrain-aucpr:0.88448+0.00309\ttest-aucpr:0.87650+0.00375\n",
            "[7]\ttrain-aucpr:0.88992+0.00313\ttest-aucpr:0.88171+0.00406\n",
            "[8]\ttrain-aucpr:0.89775+0.00437\ttest-aucpr:0.88960+0.00475\n",
            "[9]\ttrain-aucpr:0.90253+0.00485\ttest-aucpr:0.89410+0.00527\n",
            "[10]\ttrain-aucpr:0.90846+0.00481\ttest-aucpr:0.89993+0.00530\n",
            "[11]\ttrain-aucpr:0.91255+0.00488\ttest-aucpr:0.90422+0.00520\n",
            "[12]\ttrain-aucpr:0.91525+0.00440\ttest-aucpr:0.90674+0.00463\n",
            "[13]\ttrain-aucpr:0.91850+0.00422\ttest-aucpr:0.90980+0.00453\n",
            "[14]\ttrain-aucpr:0.92086+0.00362\ttest-aucpr:0.91218+0.00373\n",
            "[15]\ttrain-aucpr:0.92410+0.00433\ttest-aucpr:0.91532+0.00448\n",
            "[16]\ttrain-aucpr:0.92660+0.00380\ttest-aucpr:0.91772+0.00400\n",
            "[17]\ttrain-aucpr:0.92854+0.00364\ttest-aucpr:0.91967+0.00364\n",
            "[18]\ttrain-aucpr:0.93080+0.00296\ttest-aucpr:0.92187+0.00316\n",
            "[19]\ttrain-aucpr:0.93208+0.00316\ttest-aucpr:0.92314+0.00334\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65585+0.00720\ttest-aucpr:0.65372+0.00862\n",
            "[1]\ttrain-aucpr:0.70204+0.00585\ttest-aucpr:0.69894+0.00730\n",
            "[2]\ttrain-aucpr:0.72308+0.00457\ttest-aucpr:0.71940+0.00471\n",
            "[3]\ttrain-aucpr:0.73734+0.00209\ttest-aucpr:0.73275+0.00507\n",
            "[4]\ttrain-aucpr:0.74797+0.00348\ttest-aucpr:0.74356+0.00644\n",
            "[5]\ttrain-aucpr:0.75422+0.00281\ttest-aucpr:0.74987+0.00533\n",
            "[6]\ttrain-aucpr:0.76639+0.00123\ttest-aucpr:0.76197+0.00412\n",
            "[7]\ttrain-aucpr:0.77353+0.00208\ttest-aucpr:0.76931+0.00221\n",
            "[8]\ttrain-aucpr:0.78098+0.00194\ttest-aucpr:0.77676+0.00355\n",
            "[9]\ttrain-aucpr:0.78651+0.00135\ttest-aucpr:0.78199+0.00340\n",
            "[10]\ttrain-aucpr:0.79816+0.00321\ttest-aucpr:0.79377+0.00418\n",
            "[11]\ttrain-aucpr:0.80331+0.00427\ttest-aucpr:0.79890+0.00544\n",
            "[12]\ttrain-aucpr:0.81001+0.00545\ttest-aucpr:0.80523+0.00654\n",
            "[13]\ttrain-aucpr:0.81694+0.00349\ttest-aucpr:0.81200+0.00432\n",
            "[14]\ttrain-aucpr:0.82170+0.00318\ttest-aucpr:0.81653+0.00443\n",
            "[15]\ttrain-aucpr:0.82668+0.00472\ttest-aucpr:0.82130+0.00569\n",
            "[16]\ttrain-aucpr:0.83210+0.00759\ttest-aucpr:0.82660+0.00835\n",
            "[17]\ttrain-aucpr:0.83766+0.00564\ttest-aucpr:0.83209+0.00500\n",
            "[18]\ttrain-aucpr:0.84211+0.00554\ttest-aucpr:0.83665+0.00513\n",
            "[19]\ttrain-aucpr:0.84520+0.00415\ttest-aucpr:0.83977+0.00441\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65578+0.00713\ttest-aucpr:0.65365+0.00857\n",
            "[1]\ttrain-aucpr:0.70204+0.00585\ttest-aucpr:0.69894+0.00729\n",
            "[2]\ttrain-aucpr:0.72309+0.00458\ttest-aucpr:0.71939+0.00471\n",
            "[3]\ttrain-aucpr:0.73718+0.00194\ttest-aucpr:0.73255+0.00502\n",
            "[4]\ttrain-aucpr:0.74795+0.00349\ttest-aucpr:0.74359+0.00638\n",
            "[5]\ttrain-aucpr:0.75426+0.00292\ttest-aucpr:0.75006+0.00551\n",
            "[6]\ttrain-aucpr:0.76642+0.00126\ttest-aucpr:0.76212+0.00412\n",
            "[7]\ttrain-aucpr:0.77353+0.00207\ttest-aucpr:0.76939+0.00215\n",
            "[8]\ttrain-aucpr:0.78084+0.00195\ttest-aucpr:0.77686+0.00358\n",
            "[9]\ttrain-aucpr:0.78633+0.00143\ttest-aucpr:0.78209+0.00342\n",
            "[10]\ttrain-aucpr:0.79580+0.00388\ttest-aucpr:0.79176+0.00506\n",
            "[11]\ttrain-aucpr:0.80329+0.00422\ttest-aucpr:0.79900+0.00545\n",
            "[12]\ttrain-aucpr:0.81000+0.00546\ttest-aucpr:0.80547+0.00662\n",
            "[13]\ttrain-aucpr:0.81661+0.00335\ttest-aucpr:0.81173+0.00425\n",
            "[14]\ttrain-aucpr:0.82141+0.00310\ttest-aucpr:0.81634+0.00441\n",
            "[15]\ttrain-aucpr:0.82629+0.00461\ttest-aucpr:0.82112+0.00568\n",
            "[16]\ttrain-aucpr:0.83219+0.00779\ttest-aucpr:0.82687+0.00845\n",
            "[17]\ttrain-aucpr:0.83781+0.00564\ttest-aucpr:0.83249+0.00479\n",
            "[18]\ttrain-aucpr:0.84209+0.00572\ttest-aucpr:0.83686+0.00513\n",
            "[19]\ttrain-aucpr:0.84556+0.00424\ttest-aucpr:0.84029+0.00417\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90254+0.00197\ttest-aucpr:0.87266+0.00413\n",
            "[1]\ttrain-aucpr:0.93781+0.00071\ttest-aucpr:0.91278+0.00214\n",
            "[2]\ttrain-aucpr:0.94997+0.00113\ttest-aucpr:0.92611+0.00298\n",
            "[3]\ttrain-aucpr:0.95826+0.00069\ttest-aucpr:0.93481+0.00222\n",
            "[4]\ttrain-aucpr:0.96353+0.00065\ttest-aucpr:0.94021+0.00164\n",
            "[5]\ttrain-aucpr:0.96807+0.00057\ttest-aucpr:0.94503+0.00123\n",
            "[6]\ttrain-aucpr:0.97090+0.00070\ttest-aucpr:0.94785+0.00130\n",
            "[7]\ttrain-aucpr:0.97394+0.00071\ttest-aucpr:0.95100+0.00180\n",
            "[8]\ttrain-aucpr:0.97621+0.00062\ttest-aucpr:0.95351+0.00174\n",
            "[9]\ttrain-aucpr:0.97902+0.00059\ttest-aucpr:0.95653+0.00153\n",
            "[10]\ttrain-aucpr:0.98040+0.00055\ttest-aucpr:0.95818+0.00168\n",
            "[11]\ttrain-aucpr:0.98130+0.00062\ttest-aucpr:0.95943+0.00166\n",
            "[12]\ttrain-aucpr:0.98274+0.00074\ttest-aucpr:0.96106+0.00168\n",
            "[13]\ttrain-aucpr:0.98357+0.00053\ttest-aucpr:0.96196+0.00163\n",
            "[14]\ttrain-aucpr:0.98448+0.00032\ttest-aucpr:0.96297+0.00147\n",
            "[15]\ttrain-aucpr:0.98498+0.00024\ttest-aucpr:0.96362+0.00146\n",
            "[16]\ttrain-aucpr:0.98574+0.00057\ttest-aucpr:0.96448+0.00184\n",
            "[17]\ttrain-aucpr:0.98651+0.00041\ttest-aucpr:0.96546+0.00165\n",
            "[18]\ttrain-aucpr:0.98733+0.00040\ttest-aucpr:0.96639+0.00154\n",
            "[19]\ttrain-aucpr:0.98782+0.00045\ttest-aucpr:0.96686+0.00156\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76289+0.00196\ttest-aucpr:0.75800+0.00366\n",
            "[1]\ttrain-aucpr:0.81497+0.00395\ttest-aucpr:0.80873+0.00461\n",
            "[2]\ttrain-aucpr:0.83721+0.00115\ttest-aucpr:0.83096+0.00273\n",
            "[3]\ttrain-aucpr:0.85385+0.00321\ttest-aucpr:0.84729+0.00435\n",
            "[4]\ttrain-aucpr:0.86682+0.00419\ttest-aucpr:0.85947+0.00575\n",
            "[5]\ttrain-aucpr:0.87676+0.00267\ttest-aucpr:0.86923+0.00327\n",
            "[6]\ttrain-aucpr:0.88448+0.00309\ttest-aucpr:0.87650+0.00375\n",
            "[7]\ttrain-aucpr:0.88993+0.00313\ttest-aucpr:0.88171+0.00406\n",
            "[8]\ttrain-aucpr:0.89775+0.00437\ttest-aucpr:0.88960+0.00476\n",
            "[9]\ttrain-aucpr:0.90253+0.00484\ttest-aucpr:0.89410+0.00527\n",
            "[10]\ttrain-aucpr:0.90846+0.00481\ttest-aucpr:0.89993+0.00530\n",
            "[11]\ttrain-aucpr:0.91256+0.00487\ttest-aucpr:0.90422+0.00519\n",
            "[12]\ttrain-aucpr:0.91525+0.00440\ttest-aucpr:0.90674+0.00463\n",
            "[13]\ttrain-aucpr:0.91851+0.00422\ttest-aucpr:0.90980+0.00452\n",
            "[14]\ttrain-aucpr:0.92117+0.00395\ttest-aucpr:0.91236+0.00394\n",
            "[15]\ttrain-aucpr:0.92355+0.00379\ttest-aucpr:0.91466+0.00392\n",
            "[16]\ttrain-aucpr:0.92594+0.00303\ttest-aucpr:0.91695+0.00315\n",
            "[17]\ttrain-aucpr:0.92823+0.00304\ttest-aucpr:0.91937+0.00282\n",
            "[18]\ttrain-aucpr:0.93045+0.00267\ttest-aucpr:0.92156+0.00251\n",
            "[19]\ttrain-aucpr:0.93191+0.00293\ttest-aucpr:0.92299+0.00253\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76300+0.00194\ttest-aucpr:0.75801+0.00366\n",
            "[1]\ttrain-aucpr:0.81102+0.00313\ttest-aucpr:0.80490+0.00374\n",
            "[2]\ttrain-aucpr:0.83256+0.00097\ttest-aucpr:0.82591+0.00119\n",
            "[3]\ttrain-aucpr:0.84830+0.00199\ttest-aucpr:0.84219+0.00240\n",
            "[4]\ttrain-aucpr:0.85897+0.00274\ttest-aucpr:0.85304+0.00378\n",
            "[5]\ttrain-aucpr:0.86811+0.00279\ttest-aucpr:0.86198+0.00346\n",
            "[6]\ttrain-aucpr:0.87439+0.00214\ttest-aucpr:0.86822+0.00303\n",
            "[7]\ttrain-aucpr:0.88128+0.00194\ttest-aucpr:0.87472+0.00328\n",
            "[8]\ttrain-aucpr:0.88883+0.00156\ttest-aucpr:0.88222+0.00114\n",
            "[9]\ttrain-aucpr:0.89379+0.00162\ttest-aucpr:0.88714+0.00117\n",
            "[10]\ttrain-aucpr:0.89842+0.00167\ttest-aucpr:0.89155+0.00100\n",
            "[11]\ttrain-aucpr:0.90260+0.00087\ttest-aucpr:0.89573+0.00189\n",
            "[12]\ttrain-aucpr:0.90634+0.00138\ttest-aucpr:0.89939+0.00278\n",
            "[13]\ttrain-aucpr:0.90963+0.00127\ttest-aucpr:0.90256+0.00238\n",
            "[14]\ttrain-aucpr:0.91327+0.00178\ttest-aucpr:0.90614+0.00295\n",
            "[15]\ttrain-aucpr:0.91598+0.00119\ttest-aucpr:0.90872+0.00249\n",
            "[16]\ttrain-aucpr:0.91883+0.00141\ttest-aucpr:0.91137+0.00179\n",
            "[17]\ttrain-aucpr:0.92154+0.00073\ttest-aucpr:0.91409+0.00138\n",
            "[18]\ttrain-aucpr:0.92292+0.00069\ttest-aucpr:0.91537+0.00099\n",
            "[19]\ttrain-aucpr:0.92548+0.00091\ttest-aucpr:0.91794+0.00145\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95373+0.00179\ttest-aucpr:0.88868+0.00378\n",
            "[1]\ttrain-aucpr:0.98140+0.00033\ttest-aucpr:0.92503+0.00273\n",
            "[2]\ttrain-aucpr:0.98955+0.00035\ttest-aucpr:0.93886+0.00192\n",
            "[3]\ttrain-aucpr:0.99341+0.00017\ttest-aucpr:0.94749+0.00123\n",
            "[4]\ttrain-aucpr:0.99558+0.00013\ttest-aucpr:0.95292+0.00091\n",
            "[5]\ttrain-aucpr:0.99689+0.00010\ttest-aucpr:0.95617+0.00090\n",
            "[6]\ttrain-aucpr:0.99770+0.00009\ttest-aucpr:0.95937+0.00086\n",
            "[7]\ttrain-aucpr:0.99837+0.00006\ttest-aucpr:0.96174+0.00104\n",
            "[8]\ttrain-aucpr:0.99883+0.00002\ttest-aucpr:0.96393+0.00119\n",
            "[9]\ttrain-aucpr:0.99909+0.00005\ttest-aucpr:0.96550+0.00102\n",
            "[10]\ttrain-aucpr:0.99931+0.00004\ttest-aucpr:0.96708+0.00100\n",
            "[11]\ttrain-aucpr:0.99947+0.00004\ttest-aucpr:0.96828+0.00080\n",
            "[12]\ttrain-aucpr:0.99959+0.00003\ttest-aucpr:0.96913+0.00078\n",
            "[13]\ttrain-aucpr:0.99967+0.00003\ttest-aucpr:0.96989+0.00086\n",
            "[14]\ttrain-aucpr:0.99974+0.00002\ttest-aucpr:0.97071+0.00093\n",
            "[15]\ttrain-aucpr:0.99980+0.00002\ttest-aucpr:0.97149+0.00090\n",
            "[16]\ttrain-aucpr:0.99984+0.00002\ttest-aucpr:0.97195+0.00086\n",
            "[17]\ttrain-aucpr:0.99988+0.00002\ttest-aucpr:0.97221+0.00086\n",
            "[18]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.97270+0.00091\n",
            "[19]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.97294+0.00099\n",
            "result:  0.9729446284698151\n",
            "best result:  0.9729446284698151\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76297+0.00195\ttest-aucpr:0.75803+0.00359\n",
            "[1]\ttrain-aucpr:0.80326+0.00236\ttest-aucpr:0.79738+0.00404\n",
            "[2]\ttrain-aucpr:0.81674+0.00138\ttest-aucpr:0.81085+0.00216\n",
            "[3]\ttrain-aucpr:0.82898+0.00273\ttest-aucpr:0.82289+0.00152\n",
            "[4]\ttrain-aucpr:0.83494+0.00239\ttest-aucpr:0.82892+0.00171\n",
            "[5]\ttrain-aucpr:0.84223+0.00151\ttest-aucpr:0.83576+0.00201\n",
            "[6]\ttrain-aucpr:0.84693+0.00137\ttest-aucpr:0.84028+0.00171\n",
            "[7]\ttrain-aucpr:0.85228+0.00220\ttest-aucpr:0.84554+0.00206\n",
            "[8]\ttrain-aucpr:0.85725+0.00241\ttest-aucpr:0.85055+0.00239\n",
            "[9]\ttrain-aucpr:0.86074+0.00226\ttest-aucpr:0.85396+0.00221\n",
            "[10]\ttrain-aucpr:0.86499+0.00211\ttest-aucpr:0.85826+0.00222\n",
            "[11]\ttrain-aucpr:0.86771+0.00153\ttest-aucpr:0.86099+0.00203\n",
            "[12]\ttrain-aucpr:0.87099+0.00190\ttest-aucpr:0.86441+0.00233\n",
            "[13]\ttrain-aucpr:0.87450+0.00139\ttest-aucpr:0.86802+0.00207\n",
            "[14]\ttrain-aucpr:0.87780+0.00155\ttest-aucpr:0.87128+0.00226\n",
            "[15]\ttrain-aucpr:0.88105+0.00146\ttest-aucpr:0.87444+0.00212\n",
            "[16]\ttrain-aucpr:0.88342+0.00180\ttest-aucpr:0.87672+0.00202\n",
            "[17]\ttrain-aucpr:0.88615+0.00187\ttest-aucpr:0.87939+0.00195\n",
            "[18]\ttrain-aucpr:0.88866+0.00089\ttest-aucpr:0.88194+0.00101\n",
            "[19]\ttrain-aucpr:0.89079+0.00153\ttest-aucpr:0.88392+0.00193\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90142+0.00221\ttest-aucpr:0.87266+0.00423\n",
            "[1]\ttrain-aucpr:0.93693+0.00221\ttest-aucpr:0.91295+0.00281\n",
            "[2]\ttrain-aucpr:0.95061+0.00141\ttest-aucpr:0.92746+0.00258\n",
            "[3]\ttrain-aucpr:0.95976+0.00074\ttest-aucpr:0.93735+0.00253\n",
            "[4]\ttrain-aucpr:0.96596+0.00071\ttest-aucpr:0.94414+0.00237\n",
            "[5]\ttrain-aucpr:0.97042+0.00060\ttest-aucpr:0.94914+0.00171\n",
            "[6]\ttrain-aucpr:0.97362+0.00026\ttest-aucpr:0.95305+0.00165\n",
            "[7]\ttrain-aucpr:0.97585+0.00039\ttest-aucpr:0.95560+0.00147\n",
            "[8]\ttrain-aucpr:0.97734+0.00015\ttest-aucpr:0.95744+0.00141\n",
            "[9]\ttrain-aucpr:0.97936+0.00056\ttest-aucpr:0.95967+0.00145\n",
            "[10]\ttrain-aucpr:0.98044+0.00035\ttest-aucpr:0.96077+0.00155\n",
            "[11]\ttrain-aucpr:0.98194+0.00052\ttest-aucpr:0.96247+0.00168\n",
            "[12]\ttrain-aucpr:0.98279+0.00070\ttest-aucpr:0.96361+0.00181\n",
            "[13]\ttrain-aucpr:0.98347+0.00048\ttest-aucpr:0.96438+0.00200\n",
            "[14]\ttrain-aucpr:0.98447+0.00065\ttest-aucpr:0.96543+0.00213\n",
            "[15]\ttrain-aucpr:0.98503+0.00058\ttest-aucpr:0.96608+0.00205\n",
            "[16]\ttrain-aucpr:0.98567+0.00061\ttest-aucpr:0.96669+0.00222\n",
            "[17]\ttrain-aucpr:0.98614+0.00061\ttest-aucpr:0.96702+0.00228\n",
            "[18]\ttrain-aucpr:0.98702+0.00049\ttest-aucpr:0.96746+0.00214\n",
            "[19]\ttrain-aucpr:0.98756+0.00052\ttest-aucpr:0.96797+0.00175\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.93313+0.00101\ttest-aucpr:0.88781+0.00291\n",
            "[1]\ttrain-aucpr:0.96434+0.00125\ttest-aucpr:0.92523+0.00143\n",
            "[2]\ttrain-aucpr:0.97420+0.00098\ttest-aucpr:0.93841+0.00093\n",
            "[3]\ttrain-aucpr:0.97949+0.00071\ttest-aucpr:0.94634+0.00092\n",
            "[4]\ttrain-aucpr:0.98273+0.00059\ttest-aucpr:0.95117+0.00150\n",
            "[5]\ttrain-aucpr:0.98517+0.00053\ttest-aucpr:0.95460+0.00124\n",
            "[6]\ttrain-aucpr:0.98690+0.00050\ttest-aucpr:0.95759+0.00103\n",
            "[7]\ttrain-aucpr:0.98820+0.00045\ttest-aucpr:0.95993+0.00104\n",
            "[8]\ttrain-aucpr:0.98940+0.00037\ttest-aucpr:0.96214+0.00087\n",
            "[9]\ttrain-aucpr:0.99042+0.00037\ttest-aucpr:0.96402+0.00088\n",
            "[10]\ttrain-aucpr:0.99135+0.00026\ttest-aucpr:0.96567+0.00099\n",
            "[11]\ttrain-aucpr:0.99204+0.00025\ttest-aucpr:0.96693+0.00090\n",
            "[12]\ttrain-aucpr:0.99269+0.00027\ttest-aucpr:0.96809+0.00091\n",
            "[13]\ttrain-aucpr:0.99318+0.00027\ttest-aucpr:0.96912+0.00099\n",
            "[14]\ttrain-aucpr:0.99360+0.00023\ttest-aucpr:0.96996+0.00090\n",
            "[15]\ttrain-aucpr:0.99399+0.00022\ttest-aucpr:0.97075+0.00094\n",
            "[16]\ttrain-aucpr:0.99425+0.00022\ttest-aucpr:0.97130+0.00100\n",
            "[17]\ttrain-aucpr:0.99459+0.00016\ttest-aucpr:0.97189+0.00105\n",
            "[18]\ttrain-aucpr:0.99483+0.00017\ttest-aucpr:0.97241+0.00118\n",
            "[19]\ttrain-aucpr:0.99510+0.00013\ttest-aucpr:0.97288+0.00120\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65578+0.00713\ttest-aucpr:0.65365+0.00857\n",
            "[1]\ttrain-aucpr:0.70753+0.00309\ttest-aucpr:0.70440+0.00544\n",
            "[2]\ttrain-aucpr:0.73090+0.00542\ttest-aucpr:0.72769+0.00797\n",
            "[3]\ttrain-aucpr:0.74169+0.00451\ttest-aucpr:0.73824+0.00762\n",
            "[4]\ttrain-aucpr:0.75995+0.00358\ttest-aucpr:0.75623+0.00579\n",
            "[5]\ttrain-aucpr:0.77026+0.00709\ttest-aucpr:0.76605+0.00904\n",
            "[6]\ttrain-aucpr:0.78093+0.00567\ttest-aucpr:0.77624+0.00756\n",
            "[7]\ttrain-aucpr:0.79449+0.00342\ttest-aucpr:0.78955+0.00385\n",
            "[8]\ttrain-aucpr:0.80260+0.00525\ttest-aucpr:0.79734+0.00565\n",
            "[9]\ttrain-aucpr:0.81015+0.00475\ttest-aucpr:0.80492+0.00587\n",
            "[10]\ttrain-aucpr:0.81785+0.00502\ttest-aucpr:0.81256+0.00519\n",
            "[11]\ttrain-aucpr:0.82646+0.00633\ttest-aucpr:0.82130+0.00651\n",
            "[12]\ttrain-aucpr:0.83028+0.00706\ttest-aucpr:0.82516+0.00760\n",
            "[13]\ttrain-aucpr:0.83536+0.00630\ttest-aucpr:0.83042+0.00702\n",
            "[14]\ttrain-aucpr:0.83963+0.00655\ttest-aucpr:0.83457+0.00683\n",
            "[15]\ttrain-aucpr:0.84383+0.00635\ttest-aucpr:0.83850+0.00676\n",
            "[16]\ttrain-aucpr:0.84926+0.00617\ttest-aucpr:0.84378+0.00613\n",
            "[17]\ttrain-aucpr:0.85273+0.00565\ttest-aucpr:0.84756+0.00533\n",
            "[18]\ttrain-aucpr:0.85686+0.00504\ttest-aucpr:0.85190+0.00463\n",
            "[19]\ttrain-aucpr:0.86020+0.00515\ttest-aucpr:0.85520+0.00488\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.65585+0.00720\ttest-aucpr:0.65372+0.00862\n",
            "[1]\ttrain-aucpr:0.70204+0.00585\ttest-aucpr:0.69894+0.00730\n",
            "[2]\ttrain-aucpr:0.72308+0.00457\ttest-aucpr:0.71940+0.00471\n",
            "[3]\ttrain-aucpr:0.73719+0.00193\ttest-aucpr:0.73257+0.00501\n",
            "[4]\ttrain-aucpr:0.74797+0.00349\ttest-aucpr:0.74362+0.00639\n",
            "[5]\ttrain-aucpr:0.75428+0.00292\ttest-aucpr:0.75009+0.00550\n",
            "[6]\ttrain-aucpr:0.76644+0.00126\ttest-aucpr:0.76215+0.00411\n",
            "[7]\ttrain-aucpr:0.77355+0.00207\ttest-aucpr:0.76943+0.00214\n",
            "[8]\ttrain-aucpr:0.78103+0.00196\ttest-aucpr:0.77690+0.00358\n",
            "[9]\ttrain-aucpr:0.78652+0.00137\ttest-aucpr:0.78206+0.00344\n",
            "[10]\ttrain-aucpr:0.79821+0.00317\ttest-aucpr:0.79388+0.00411\n",
            "[11]\ttrain-aucpr:0.80335+0.00424\ttest-aucpr:0.79900+0.00537\n",
            "[12]\ttrain-aucpr:0.81004+0.00541\ttest-aucpr:0.80532+0.00645\n",
            "[13]\ttrain-aucpr:0.81698+0.00351\ttest-aucpr:0.81208+0.00431\n",
            "[14]\ttrain-aucpr:0.82170+0.00318\ttest-aucpr:0.81659+0.00443\n",
            "[15]\ttrain-aucpr:0.82679+0.00481\ttest-aucpr:0.82143+0.00574\n",
            "[16]\ttrain-aucpr:0.83272+0.00784\ttest-aucpr:0.82731+0.00849\n",
            "[17]\ttrain-aucpr:0.83822+0.00565\ttest-aucpr:0.83274+0.00484\n",
            "[18]\ttrain-aucpr:0.84265+0.00568\ttest-aucpr:0.83724+0.00514\n",
            "[19]\ttrain-aucpr:0.84578+0.00424\ttest-aucpr:0.84039+0.00429\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96489+0.00162\ttest-aucpr:0.88812+0.00303\n",
            "[1]\ttrain-aucpr:0.98008+0.00222\ttest-aucpr:0.91400+0.00529\n",
            "[2]\ttrain-aucpr:0.98683+0.00176\ttest-aucpr:0.92824+0.00414\n",
            "[3]\ttrain-aucpr:0.99100+0.00052\ttest-aucpr:0.93813+0.00132\n",
            "[4]\ttrain-aucpr:0.99302+0.00057\ttest-aucpr:0.94339+0.00178\n",
            "[5]\ttrain-aucpr:0.99438+0.00037\ttest-aucpr:0.94703+0.00100\n",
            "[6]\ttrain-aucpr:0.99536+0.00037\ttest-aucpr:0.94982+0.00107\n",
            "[7]\ttrain-aucpr:0.99607+0.00029\ttest-aucpr:0.95187+0.00106\n",
            "[8]\ttrain-aucpr:0.99665+0.00026\ttest-aucpr:0.95400+0.00103\n",
            "[9]\ttrain-aucpr:0.99715+0.00014\ttest-aucpr:0.95557+0.00064\n",
            "[10]\ttrain-aucpr:0.99749+0.00014\ttest-aucpr:0.95687+0.00065\n",
            "[11]\ttrain-aucpr:0.99784+0.00014\ttest-aucpr:0.95798+0.00066\n",
            "[12]\ttrain-aucpr:0.99808+0.00013\ttest-aucpr:0.95897+0.00072\n",
            "[13]\ttrain-aucpr:0.99830+0.00013\ttest-aucpr:0.95990+0.00093\n",
            "[14]\ttrain-aucpr:0.99849+0.00009\ttest-aucpr:0.96070+0.00091\n",
            "[15]\ttrain-aucpr:0.99866+0.00006\ttest-aucpr:0.96147+0.00096\n",
            "[16]\ttrain-aucpr:0.99883+0.00006\ttest-aucpr:0.96218+0.00089\n",
            "[17]\ttrain-aucpr:0.99895+0.00004\ttest-aucpr:0.96285+0.00091\n",
            "[18]\ttrain-aucpr:0.99908+0.00004\ttest-aucpr:0.96350+0.00080\n",
            "[19]\ttrain-aucpr:0.99918+0.00005\ttest-aucpr:0.96406+0.00085\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90357+0.00251\ttest-aucpr:0.87731+0.00336\n",
            "[1]\ttrain-aucpr:0.93591+0.00164\ttest-aucpr:0.91256+0.00215\n",
            "[2]\ttrain-aucpr:0.94881+0.00139\ttest-aucpr:0.92630+0.00223\n",
            "[3]\ttrain-aucpr:0.95732+0.00136\ttest-aucpr:0.93501+0.00117\n",
            "[4]\ttrain-aucpr:0.96252+0.00141\ttest-aucpr:0.94069+0.00076\n",
            "[5]\ttrain-aucpr:0.96653+0.00101\ttest-aucpr:0.94483+0.00121\n",
            "[6]\ttrain-aucpr:0.96954+0.00094\ttest-aucpr:0.94826+0.00108\n",
            "[7]\ttrain-aucpr:0.97229+0.00073\ttest-aucpr:0.95152+0.00105\n",
            "[8]\ttrain-aucpr:0.97461+0.00096\ttest-aucpr:0.95421+0.00071\n",
            "[9]\ttrain-aucpr:0.97654+0.00075\ttest-aucpr:0.95634+0.00083\n",
            "[10]\ttrain-aucpr:0.97795+0.00059\ttest-aucpr:0.95809+0.00095\n",
            "[11]\ttrain-aucpr:0.97936+0.00041\ttest-aucpr:0.95982+0.00123\n",
            "[12]\ttrain-aucpr:0.98057+0.00062\ttest-aucpr:0.96122+0.00165\n",
            "[13]\ttrain-aucpr:0.98116+0.00061\ttest-aucpr:0.96218+0.00147\n",
            "[14]\ttrain-aucpr:0.98218+0.00034\ttest-aucpr:0.96334+0.00152\n",
            "[15]\ttrain-aucpr:0.98259+0.00037\ttest-aucpr:0.96387+0.00152\n",
            "[16]\ttrain-aucpr:0.98349+0.00033\ttest-aucpr:0.96487+0.00152\n",
            "[17]\ttrain-aucpr:0.98394+0.00035\ttest-aucpr:0.96543+0.00151\n",
            "[18]\ttrain-aucpr:0.98456+0.00041\ttest-aucpr:0.96613+0.00163\n",
            "[19]\ttrain-aucpr:0.98508+0.00019\ttest-aucpr:0.96677+0.00141\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76269+0.00307\ttest-aucpr:0.75850+0.00421\n",
            "[1]\ttrain-aucpr:0.80227+0.00682\ttest-aucpr:0.79588+0.00402\n",
            "[2]\ttrain-aucpr:0.81875+0.00301\ttest-aucpr:0.81258+0.00324\n",
            "[3]\ttrain-aucpr:0.83037+0.00304\ttest-aucpr:0.82431+0.00268\n",
            "[4]\ttrain-aucpr:0.83616+0.00278\ttest-aucpr:0.82979+0.00302\n",
            "[5]\ttrain-aucpr:0.84146+0.00235\ttest-aucpr:0.83472+0.00377\n",
            "[6]\ttrain-aucpr:0.84729+0.00216\ttest-aucpr:0.84073+0.00369\n",
            "[7]\ttrain-aucpr:0.85193+0.00160\ttest-aucpr:0.84523+0.00307\n",
            "[8]\ttrain-aucpr:0.85736+0.00182\ttest-aucpr:0.85084+0.00252\n",
            "[9]\ttrain-aucpr:0.86105+0.00221\ttest-aucpr:0.85442+0.00393\n",
            "[10]\ttrain-aucpr:0.86401+0.00210\ttest-aucpr:0.85724+0.00379\n",
            "[11]\ttrain-aucpr:0.86779+0.00186\ttest-aucpr:0.86077+0.00337\n",
            "[12]\ttrain-aucpr:0.87066+0.00148\ttest-aucpr:0.86391+0.00335\n",
            "[13]\ttrain-aucpr:0.87447+0.00129\ttest-aucpr:0.86765+0.00252\n",
            "[14]\ttrain-aucpr:0.87769+0.00157\ttest-aucpr:0.87071+0.00273\n",
            "[15]\ttrain-aucpr:0.88048+0.00156\ttest-aucpr:0.87352+0.00291\n",
            "[16]\ttrain-aucpr:0.88347+0.00156\ttest-aucpr:0.87659+0.00241\n",
            "[17]\ttrain-aucpr:0.88610+0.00166\ttest-aucpr:0.87933+0.00240\n",
            "[18]\ttrain-aucpr:0.88825+0.00076\ttest-aucpr:0.88146+0.00285\n",
            "[19]\ttrain-aucpr:0.89020+0.00100\ttest-aucpr:0.88330+0.00280\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76268+0.00306\ttest-aucpr:0.75841+0.00431\n",
            "[1]\ttrain-aucpr:0.81738+0.00183\ttest-aucpr:0.81182+0.00284\n",
            "[2]\ttrain-aucpr:0.83976+0.00258\ttest-aucpr:0.83442+0.00086\n",
            "[3]\ttrain-aucpr:0.85526+0.00238\ttest-aucpr:0.84964+0.00110\n",
            "[4]\ttrain-aucpr:0.86724+0.00290\ttest-aucpr:0.86145+0.00122\n",
            "[5]\ttrain-aucpr:0.87796+0.00261\ttest-aucpr:0.87194+0.00220\n",
            "[6]\ttrain-aucpr:0.88469+0.00227\ttest-aucpr:0.87840+0.00201\n",
            "[7]\ttrain-aucpr:0.89267+0.00255\ttest-aucpr:0.88624+0.00094\n",
            "[8]\ttrain-aucpr:0.89777+0.00235\ttest-aucpr:0.89122+0.00107\n",
            "[9]\ttrain-aucpr:0.90446+0.00174\ttest-aucpr:0.89747+0.00211\n",
            "[10]\ttrain-aucpr:0.90906+0.00283\ttest-aucpr:0.90165+0.00228\n",
            "[11]\ttrain-aucpr:0.91152+0.00278\ttest-aucpr:0.90396+0.00235\n",
            "[12]\ttrain-aucpr:0.91540+0.00223\ttest-aucpr:0.90789+0.00240\n",
            "[13]\ttrain-aucpr:0.91869+0.00177\ttest-aucpr:0.91120+0.00238\n",
            "[14]\ttrain-aucpr:0.92141+0.00228\ttest-aucpr:0.91391+0.00239\n",
            "[15]\ttrain-aucpr:0.92431+0.00239\ttest-aucpr:0.91659+0.00272\n",
            "[16]\ttrain-aucpr:0.92662+0.00336\ttest-aucpr:0.91879+0.00311\n",
            "[17]\ttrain-aucpr:0.92863+0.00351\ttest-aucpr:0.92069+0.00321\n",
            "[18]\ttrain-aucpr:0.93012+0.00345\ttest-aucpr:0.92205+0.00308\n",
            "[19]\ttrain-aucpr:0.93294+0.00393\ttest-aucpr:0.92479+0.00338\n",
            "result:  0.9247876547842988\n",
            "best result:  0.9247876547842988\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95579+0.00171\ttest-aucpr:0.89194+0.00454\n",
            "[1]\ttrain-aucpr:0.98393+0.00085\ttest-aucpr:0.92671+0.00282\n",
            "[2]\ttrain-aucpr:0.99180+0.00055\ttest-aucpr:0.94014+0.00233\n",
            "[3]\ttrain-aucpr:0.99510+0.00030\ttest-aucpr:0.94733+0.00165\n",
            "[4]\ttrain-aucpr:0.99692+0.00020\ttest-aucpr:0.95216+0.00145\n",
            "[5]\ttrain-aucpr:0.99797+0.00015\ttest-aucpr:0.95570+0.00161\n",
            "[6]\ttrain-aucpr:0.99870+0.00010\ttest-aucpr:0.95909+0.00141\n",
            "[7]\ttrain-aucpr:0.99914+0.00007\ttest-aucpr:0.96157+0.00157\n",
            "[8]\ttrain-aucpr:0.99941+0.00005\ttest-aucpr:0.96349+0.00191\n",
            "[9]\ttrain-aucpr:0.99960+0.00004\ttest-aucpr:0.96511+0.00178\n",
            "[10]\ttrain-aucpr:0.99971+0.00004\ttest-aucpr:0.96653+0.00166\n",
            "[11]\ttrain-aucpr:0.99980+0.00003\ttest-aucpr:0.96765+0.00163\n",
            "[12]\ttrain-aucpr:0.99986+0.00002\ttest-aucpr:0.96851+0.00165\n",
            "[13]\ttrain-aucpr:0.99991+0.00001\ttest-aucpr:0.96944+0.00159\n",
            "[14]\ttrain-aucpr:0.99993+0.00001\ttest-aucpr:0.97022+0.00153\n",
            "[15]\ttrain-aucpr:0.99995+0.00001\ttest-aucpr:0.97079+0.00146\n",
            "[16]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.97145+0.00136\n",
            "[17]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97184+0.00139\n",
            "[18]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97232+0.00139\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97279+0.00132\n",
            "result:  0.9727907454710939\n",
            "best result:  0.9727907454710939\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96885+0.00086\ttest-aucpr:0.89404+0.00316\n",
            "[1]\ttrain-aucpr:0.99044+0.00029\ttest-aucpr:0.92602+0.00279\n",
            "[2]\ttrain-aucpr:0.99538+0.00026\ttest-aucpr:0.93900+0.00267\n",
            "[3]\ttrain-aucpr:0.99733+0.00015\ttest-aucpr:0.94713+0.00172\n",
            "[4]\ttrain-aucpr:0.99836+0.00009\ttest-aucpr:0.95279+0.00184\n",
            "[5]\ttrain-aucpr:0.99896+0.00010\ttest-aucpr:0.95702+0.00162\n",
            "[6]\ttrain-aucpr:0.99930+0.00009\ttest-aucpr:0.95994+0.00157\n",
            "[7]\ttrain-aucpr:0.99955+0.00005\ttest-aucpr:0.96204+0.00182\n",
            "[8]\ttrain-aucpr:0.99970+0.00004\ttest-aucpr:0.96385+0.00170\n",
            "[9]\ttrain-aucpr:0.99980+0.00003\ttest-aucpr:0.96538+0.00169\n",
            "[10]\ttrain-aucpr:0.99987+0.00002\ttest-aucpr:0.96677+0.00181\n",
            "[11]\ttrain-aucpr:0.99991+0.00002\ttest-aucpr:0.96786+0.00173\n",
            "[12]\ttrain-aucpr:0.99994+0.00001\ttest-aucpr:0.96866+0.00162\n",
            "[13]\ttrain-aucpr:0.99996+0.00001\ttest-aucpr:0.96964+0.00143\n",
            "[14]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.97023+0.00143\n",
            "[15]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97093+0.00146\n",
            "[16]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97142+0.00134\n",
            "[17]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97174+0.00129\n",
            "[18]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97198+0.00128\n",
            "[19]\ttrain-aucpr:1.00000+0.00000\ttest-aucpr:0.97231+0.00126\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95312+0.00105\ttest-aucpr:0.89305+0.00439\n",
            "[1]\ttrain-aucpr:0.98009+0.00095\ttest-aucpr:0.92684+0.00287\n",
            "[2]\ttrain-aucpr:0.98788+0.00082\ttest-aucpr:0.93869+0.00216\n",
            "[3]\ttrain-aucpr:0.99158+0.00072\ttest-aucpr:0.94626+0.00202\n",
            "[4]\ttrain-aucpr:0.99394+0.00034\ttest-aucpr:0.95122+0.00181\n",
            "[5]\ttrain-aucpr:0.99552+0.00017\ttest-aucpr:0.95487+0.00175\n",
            "[6]\ttrain-aucpr:0.99652+0.00015\ttest-aucpr:0.95785+0.00193\n",
            "[7]\ttrain-aucpr:0.99730+0.00008\ttest-aucpr:0.96050+0.00185\n",
            "[8]\ttrain-aucpr:0.99784+0.00011\ttest-aucpr:0.96239+0.00184\n",
            "[9]\ttrain-aucpr:0.99826+0.00010\ttest-aucpr:0.96396+0.00162\n",
            "[10]\ttrain-aucpr:0.99858+0.00010\ttest-aucpr:0.96527+0.00152\n",
            "[11]\ttrain-aucpr:0.99886+0.00010\ttest-aucpr:0.96661+0.00138\n",
            "[12]\ttrain-aucpr:0.99908+0.00007\ttest-aucpr:0.96788+0.00138\n",
            "[13]\ttrain-aucpr:0.99925+0.00005\ttest-aucpr:0.96882+0.00116\n",
            "[14]\ttrain-aucpr:0.99938+0.00004\ttest-aucpr:0.96953+0.00122\n",
            "[15]\ttrain-aucpr:0.99949+0.00003\ttest-aucpr:0.97016+0.00121\n",
            "[16]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.97080+0.00104\n",
            "[17]\ttrain-aucpr:0.99965+0.00002\ttest-aucpr:0.97140+0.00088\n",
            "[18]\ttrain-aucpr:0.99971+0.00002\ttest-aucpr:0.97197+0.00092\n",
            "[19]\ttrain-aucpr:0.99976+0.00002\ttest-aucpr:0.97238+0.00094\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76269+0.00306\ttest-aucpr:0.75850+0.00421\n",
            "[1]\ttrain-aucpr:0.80224+0.00684\ttest-aucpr:0.79581+0.00408\n",
            "[2]\ttrain-aucpr:0.81869+0.00302\ttest-aucpr:0.81253+0.00321\n",
            "[3]\ttrain-aucpr:0.83025+0.00308\ttest-aucpr:0.82426+0.00274\n",
            "[4]\ttrain-aucpr:0.83608+0.00284\ttest-aucpr:0.82978+0.00305\n",
            "[5]\ttrain-aucpr:0.84110+0.00301\ttest-aucpr:0.83437+0.00413\n",
            "[6]\ttrain-aucpr:0.84742+0.00254\ttest-aucpr:0.84097+0.00324\n",
            "[7]\ttrain-aucpr:0.85215+0.00200\ttest-aucpr:0.84567+0.00278\n",
            "[8]\ttrain-aucpr:0.85697+0.00191\ttest-aucpr:0.85043+0.00300\n",
            "[9]\ttrain-aucpr:0.86132+0.00299\ttest-aucpr:0.85456+0.00332\n",
            "[10]\ttrain-aucpr:0.86440+0.00260\ttest-aucpr:0.85766+0.00314\n",
            "[11]\ttrain-aucpr:0.86865+0.00193\ttest-aucpr:0.86187+0.00252\n",
            "[12]\ttrain-aucpr:0.87150+0.00214\ttest-aucpr:0.86497+0.00236\n",
            "[13]\ttrain-aucpr:0.87534+0.00120\ttest-aucpr:0.86894+0.00248\n",
            "[14]\ttrain-aucpr:0.87838+0.00134\ttest-aucpr:0.87184+0.00199\n",
            "[15]\ttrain-aucpr:0.88139+0.00193\ttest-aucpr:0.87489+0.00238\n",
            "[16]\ttrain-aucpr:0.88417+0.00201\ttest-aucpr:0.87754+0.00226\n",
            "[17]\ttrain-aucpr:0.88685+0.00197\ttest-aucpr:0.88022+0.00267\n",
            "[18]\ttrain-aucpr:0.88920+0.00195\ttest-aucpr:0.88248+0.00270\n",
            "[19]\ttrain-aucpr:0.89106+0.00202\ttest-aucpr:0.88422+0.00249\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64861+0.00600\ttest-aucpr:0.64839+0.00888\n",
            "[1]\ttrain-aucpr:0.70831+0.00569\ttest-aucpr:0.70700+0.00532\n",
            "[2]\ttrain-aucpr:0.72600+0.00264\ttest-aucpr:0.72517+0.00421\n",
            "[3]\ttrain-aucpr:0.73567+0.00452\ttest-aucpr:0.73362+0.00680\n",
            "[4]\ttrain-aucpr:0.75717+0.00336\ttest-aucpr:0.75460+0.00541\n",
            "[5]\ttrain-aucpr:0.76613+0.00368\ttest-aucpr:0.76322+0.00642\n",
            "[6]\ttrain-aucpr:0.77922+0.00300\ttest-aucpr:0.77604+0.00611\n",
            "[7]\ttrain-aucpr:0.79158+0.00220\ttest-aucpr:0.78771+0.00301\n",
            "[8]\ttrain-aucpr:0.79774+0.00204\ttest-aucpr:0.79376+0.00513\n",
            "[9]\ttrain-aucpr:0.80673+0.00413\ttest-aucpr:0.80256+0.00567\n",
            "[10]\ttrain-aucpr:0.81370+0.00353\ttest-aucpr:0.80902+0.00530\n",
            "[11]\ttrain-aucpr:0.82086+0.00378\ttest-aucpr:0.81593+0.00444\n",
            "[12]\ttrain-aucpr:0.82817+0.00452\ttest-aucpr:0.82293+0.00264\n",
            "[13]\ttrain-aucpr:0.83111+0.00481\ttest-aucpr:0.82592+0.00262\n",
            "[14]\ttrain-aucpr:0.83733+0.00199\ttest-aucpr:0.83202+0.00285\n",
            "[15]\ttrain-aucpr:0.84091+0.00179\ttest-aucpr:0.83556+0.00309\n",
            "[16]\ttrain-aucpr:0.84377+0.00185\ttest-aucpr:0.83814+0.00247\n",
            "[17]\ttrain-aucpr:0.84849+0.00286\ttest-aucpr:0.84279+0.00312\n",
            "[18]\ttrain-aucpr:0.85399+0.00199\ttest-aucpr:0.84805+0.00398\n",
            "[19]\ttrain-aucpr:0.85737+0.00313\ttest-aucpr:0.85145+0.00406\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76269+0.00306\ttest-aucpr:0.75850+0.00421\n",
            "[1]\ttrain-aucpr:0.81308+0.00249\ttest-aucpr:0.80740+0.00219\n",
            "[2]\ttrain-aucpr:0.83323+0.00308\ttest-aucpr:0.82754+0.00321\n",
            "[3]\ttrain-aucpr:0.84774+0.00341\ttest-aucpr:0.84188+0.00238\n",
            "[4]\ttrain-aucpr:0.85844+0.00240\ttest-aucpr:0.85273+0.00243\n",
            "[5]\ttrain-aucpr:0.86678+0.00167\ttest-aucpr:0.86058+0.00272\n",
            "[6]\ttrain-aucpr:0.87541+0.00257\ttest-aucpr:0.86905+0.00276\n",
            "[7]\ttrain-aucpr:0.88162+0.00264\ttest-aucpr:0.87521+0.00287\n",
            "[8]\ttrain-aucpr:0.88841+0.00097\ttest-aucpr:0.88190+0.00282\n",
            "[9]\ttrain-aucpr:0.89174+0.00049\ttest-aucpr:0.88507+0.00226\n",
            "[10]\ttrain-aucpr:0.89756+0.00199\ttest-aucpr:0.89062+0.00358\n",
            "[11]\ttrain-aucpr:0.90172+0.00215\ttest-aucpr:0.89465+0.00378\n",
            "[12]\ttrain-aucpr:0.90551+0.00254\ttest-aucpr:0.89829+0.00415\n",
            "[13]\ttrain-aucpr:0.91020+0.00182\ttest-aucpr:0.90296+0.00358\n",
            "[14]\ttrain-aucpr:0.91359+0.00184\ttest-aucpr:0.90630+0.00340\n",
            "[15]\ttrain-aucpr:0.91685+0.00219\ttest-aucpr:0.90974+0.00280\n",
            "[16]\ttrain-aucpr:0.91929+0.00203\ttest-aucpr:0.91222+0.00291\n",
            "[17]\ttrain-aucpr:0.92112+0.00144\ttest-aucpr:0.91396+0.00224\n",
            "[18]\ttrain-aucpr:0.92332+0.00145\ttest-aucpr:0.91609+0.00246\n",
            "[19]\ttrain-aucpr:0.92508+0.00172\ttest-aucpr:0.91771+0.00273\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90734+0.00277\ttest-aucpr:0.87871+0.00344\n",
            "[1]\ttrain-aucpr:0.93952+0.00150\ttest-aucpr:0.91388+0.00184\n",
            "[2]\ttrain-aucpr:0.95421+0.00175\ttest-aucpr:0.92945+0.00086\n",
            "[3]\ttrain-aucpr:0.96241+0.00088\ttest-aucpr:0.93862+0.00135\n",
            "[4]\ttrain-aucpr:0.96793+0.00018\ttest-aucpr:0.94402+0.00176\n",
            "[5]\ttrain-aucpr:0.97209+0.00062\ttest-aucpr:0.94821+0.00147\n",
            "[6]\ttrain-aucpr:0.97574+0.00023\ttest-aucpr:0.95200+0.00118\n",
            "[7]\ttrain-aucpr:0.97827+0.00041\ttest-aucpr:0.95509+0.00168\n",
            "[8]\ttrain-aucpr:0.97995+0.00052\ttest-aucpr:0.95695+0.00202\n",
            "[9]\ttrain-aucpr:0.98195+0.00048\ttest-aucpr:0.95926+0.00151\n",
            "[10]\ttrain-aucpr:0.98288+0.00041\ttest-aucpr:0.96049+0.00154\n",
            "[11]\ttrain-aucpr:0.98404+0.00046\ttest-aucpr:0.96187+0.00128\n",
            "[12]\ttrain-aucpr:0.98495+0.00029\ttest-aucpr:0.96308+0.00115\n",
            "[13]\ttrain-aucpr:0.98574+0.00057\ttest-aucpr:0.96387+0.00126\n",
            "[14]\ttrain-aucpr:0.98621+0.00052\ttest-aucpr:0.96441+0.00136\n",
            "[15]\ttrain-aucpr:0.98681+0.00055\ttest-aucpr:0.96484+0.00144\n",
            "[16]\ttrain-aucpr:0.98733+0.00051\ttest-aucpr:0.96547+0.00162\n",
            "[17]\ttrain-aucpr:0.98825+0.00057\ttest-aucpr:0.96656+0.00146\n",
            "[18]\ttrain-aucpr:0.98871+0.00055\ttest-aucpr:0.96691+0.00141\n",
            "[19]\ttrain-aucpr:0.98935+0.00081\ttest-aucpr:0.96729+0.00123\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64861+0.00600\ttest-aucpr:0.64839+0.00888\n",
            "[1]\ttrain-aucpr:0.68364+0.01133\ttest-aucpr:0.68113+0.01079\n",
            "[2]\ttrain-aucpr:0.70416+0.00375\ttest-aucpr:0.70147+0.00443\n",
            "[3]\ttrain-aucpr:0.71699+0.00237\ttest-aucpr:0.71320+0.00310\n",
            "[4]\ttrain-aucpr:0.72640+0.00324\ttest-aucpr:0.72264+0.00390\n",
            "[5]\ttrain-aucpr:0.73855+0.00263\ttest-aucpr:0.73488+0.00187\n",
            "[6]\ttrain-aucpr:0.74119+0.00152\ttest-aucpr:0.73728+0.00271\n",
            "[7]\ttrain-aucpr:0.74555+0.00187\ttest-aucpr:0.74126+0.00443\n",
            "[8]\ttrain-aucpr:0.74829+0.00279\ttest-aucpr:0.74419+0.00374\n",
            "[9]\ttrain-aucpr:0.75136+0.00273\ttest-aucpr:0.74703+0.00358\n",
            "[10]\ttrain-aucpr:0.75404+0.00104\ttest-aucpr:0.74995+0.00412\n",
            "[11]\ttrain-aucpr:0.75788+0.00208\ttest-aucpr:0.75393+0.00409\n",
            "[12]\ttrain-aucpr:0.76013+0.00259\ttest-aucpr:0.75606+0.00357\n",
            "[13]\ttrain-aucpr:0.76112+0.00287\ttest-aucpr:0.75705+0.00353\n",
            "[14]\ttrain-aucpr:0.76343+0.00274\ttest-aucpr:0.75930+0.00496\n",
            "[15]\ttrain-aucpr:0.76706+0.00247\ttest-aucpr:0.76292+0.00455\n",
            "[16]\ttrain-aucpr:0.76983+0.00193\ttest-aucpr:0.76547+0.00514\n",
            "[17]\ttrain-aucpr:0.77413+0.00218\ttest-aucpr:0.76971+0.00500\n",
            "[18]\ttrain-aucpr:0.77765+0.00264\ttest-aucpr:0.77327+0.00544\n",
            "[19]\ttrain-aucpr:0.78059+0.00158\ttest-aucpr:0.77619+0.00461\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76269+0.00306\ttest-aucpr:0.75850+0.00421\n",
            "[1]\ttrain-aucpr:0.80224+0.00684\ttest-aucpr:0.79581+0.00408\n",
            "[2]\ttrain-aucpr:0.81869+0.00302\ttest-aucpr:0.81253+0.00321\n",
            "[3]\ttrain-aucpr:0.83025+0.00308\ttest-aucpr:0.82426+0.00274\n",
            "[4]\ttrain-aucpr:0.83608+0.00284\ttest-aucpr:0.82978+0.00305\n",
            "[5]\ttrain-aucpr:0.84110+0.00301\ttest-aucpr:0.83437+0.00413\n",
            "[6]\ttrain-aucpr:0.84742+0.00254\ttest-aucpr:0.84097+0.00324\n",
            "[7]\ttrain-aucpr:0.85215+0.00200\ttest-aucpr:0.84567+0.00278\n",
            "[8]\ttrain-aucpr:0.85697+0.00191\ttest-aucpr:0.85043+0.00300\n",
            "[9]\ttrain-aucpr:0.86132+0.00299\ttest-aucpr:0.85456+0.00332\n",
            "[10]\ttrain-aucpr:0.86440+0.00260\ttest-aucpr:0.85766+0.00314\n",
            "[11]\ttrain-aucpr:0.86865+0.00193\ttest-aucpr:0.86187+0.00252\n",
            "[12]\ttrain-aucpr:0.87150+0.00214\ttest-aucpr:0.86497+0.00236\n",
            "[13]\ttrain-aucpr:0.87534+0.00120\ttest-aucpr:0.86894+0.00248\n",
            "[14]\ttrain-aucpr:0.87838+0.00134\ttest-aucpr:0.87184+0.00199\n",
            "[15]\ttrain-aucpr:0.88139+0.00193\ttest-aucpr:0.87489+0.00238\n",
            "[16]\ttrain-aucpr:0.88417+0.00201\ttest-aucpr:0.87754+0.00226\n",
            "[17]\ttrain-aucpr:0.88685+0.00197\ttest-aucpr:0.88022+0.00267\n",
            "[18]\ttrain-aucpr:0.88920+0.00195\ttest-aucpr:0.88248+0.00270\n",
            "[19]\ttrain-aucpr:0.89106+0.00202\ttest-aucpr:0.88422+0.00249\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90138+0.00261\ttest-aucpr:0.87613+0.00400\n",
            "[1]\ttrain-aucpr:0.92634+0.00572\ttest-aucpr:0.90234+0.00698\n",
            "[2]\ttrain-aucpr:0.94003+0.00222\ttest-aucpr:0.91756+0.00363\n",
            "[3]\ttrain-aucpr:0.94557+0.00252\ttest-aucpr:0.92424+0.00345\n",
            "[4]\ttrain-aucpr:0.95035+0.00217\ttest-aucpr:0.92948+0.00291\n",
            "[5]\ttrain-aucpr:0.95389+0.00226\ttest-aucpr:0.93294+0.00357\n",
            "[6]\ttrain-aucpr:0.95660+0.00189\ttest-aucpr:0.93582+0.00359\n",
            "[7]\ttrain-aucpr:0.95944+0.00119\ttest-aucpr:0.93900+0.00277\n",
            "[8]\ttrain-aucpr:0.96143+0.00113\ttest-aucpr:0.94119+0.00264\n",
            "[9]\ttrain-aucpr:0.96338+0.00151\ttest-aucpr:0.94353+0.00285\n",
            "[10]\ttrain-aucpr:0.96510+0.00101\ttest-aucpr:0.94515+0.00237\n",
            "[11]\ttrain-aucpr:0.96626+0.00094\ttest-aucpr:0.94640+0.00220\n",
            "[12]\ttrain-aucpr:0.96794+0.00078\ttest-aucpr:0.94809+0.00243\n",
            "[13]\ttrain-aucpr:0.96904+0.00079\ttest-aucpr:0.94933+0.00231\n",
            "[14]\ttrain-aucpr:0.97020+0.00041\ttest-aucpr:0.95071+0.00209\n",
            "[15]\ttrain-aucpr:0.97118+0.00030\ttest-aucpr:0.95168+0.00199\n",
            "[16]\ttrain-aucpr:0.97238+0.00053\ttest-aucpr:0.95302+0.00197\n",
            "[17]\ttrain-aucpr:0.97327+0.00045\ttest-aucpr:0.95396+0.00187\n",
            "[18]\ttrain-aucpr:0.97425+0.00032\ttest-aucpr:0.95501+0.00188\n",
            "[19]\ttrain-aucpr:0.97519+0.00046\ttest-aucpr:0.95604+0.00190\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.97849+0.00106\ttest-aucpr:0.88970+0.00404\n",
            "[1]\ttrain-aucpr:0.98861+0.00199\ttest-aucpr:0.91239+0.00891\n",
            "[2]\ttrain-aucpr:0.99280+0.00141\ttest-aucpr:0.92466+0.00823\n",
            "[3]\ttrain-aucpr:0.99559+0.00069\ttest-aucpr:0.93690+0.00550\n",
            "[4]\ttrain-aucpr:0.99660+0.00049\ttest-aucpr:0.94087+0.00500\n",
            "[5]\ttrain-aucpr:0.99741+0.00037\ttest-aucpr:0.94552+0.00427\n",
            "[6]\ttrain-aucpr:0.99791+0.00033\ttest-aucpr:0.94899+0.00381\n",
            "[7]\ttrain-aucpr:0.99831+0.00022\ttest-aucpr:0.95156+0.00345\n",
            "[8]\ttrain-aucpr:0.99861+0.00017\ttest-aucpr:0.95360+0.00338\n",
            "[9]\ttrain-aucpr:0.99881+0.00016\ttest-aucpr:0.95515+0.00355\n",
            "[10]\ttrain-aucpr:0.99903+0.00015\ttest-aucpr:0.95702+0.00341\n",
            "[11]\ttrain-aucpr:0.99915+0.00016\ttest-aucpr:0.95837+0.00308\n",
            "[12]\ttrain-aucpr:0.99930+0.00011\ttest-aucpr:0.95964+0.00279\n",
            "[13]\ttrain-aucpr:0.99940+0.00009\ttest-aucpr:0.96060+0.00268\n",
            "[14]\ttrain-aucpr:0.99950+0.00007\ttest-aucpr:0.96164+0.00256\n",
            "[15]\ttrain-aucpr:0.99957+0.00006\ttest-aucpr:0.96244+0.00233\n",
            "[16]\ttrain-aucpr:0.99963+0.00005\ttest-aucpr:0.96309+0.00231\n",
            "[17]\ttrain-aucpr:0.99969+0.00004\ttest-aucpr:0.96370+0.00227\n",
            "[18]\ttrain-aucpr:0.99973+0.00003\ttest-aucpr:0.96436+0.00223\n",
            "[19]\ttrain-aucpr:0.99977+0.00003\ttest-aucpr:0.96509+0.00209\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94407+0.00154\ttest-aucpr:0.89026+0.00377\n",
            "[1]\ttrain-aucpr:0.96405+0.00420\ttest-aucpr:0.91378+0.00773\n",
            "[2]\ttrain-aucpr:0.97364+0.00135\ttest-aucpr:0.92745+0.00433\n",
            "[3]\ttrain-aucpr:0.97984+0.00120\ttest-aucpr:0.93688+0.00359\n",
            "[4]\ttrain-aucpr:0.98340+0.00076\ttest-aucpr:0.94219+0.00377\n",
            "[5]\ttrain-aucpr:0.98571+0.00053\ttest-aucpr:0.94578+0.00339\n",
            "[6]\ttrain-aucpr:0.98748+0.00050\ttest-aucpr:0.94839+0.00288\n",
            "[7]\ttrain-aucpr:0.98892+0.00054\ttest-aucpr:0.95072+0.00310\n",
            "[8]\ttrain-aucpr:0.99001+0.00052\ttest-aucpr:0.95245+0.00305\n",
            "[9]\ttrain-aucpr:0.99097+0.00049\ttest-aucpr:0.95436+0.00296\n",
            "[10]\ttrain-aucpr:0.99174+0.00044\ttest-aucpr:0.95585+0.00293\n",
            "[11]\ttrain-aucpr:0.99247+0.00032\ttest-aucpr:0.95738+0.00266\n",
            "[12]\ttrain-aucpr:0.99304+0.00027\ttest-aucpr:0.95869+0.00262\n",
            "[13]\ttrain-aucpr:0.99354+0.00027\ttest-aucpr:0.95977+0.00253\n",
            "[14]\ttrain-aucpr:0.99397+0.00022\ttest-aucpr:0.96070+0.00231\n",
            "[15]\ttrain-aucpr:0.99439+0.00016\ttest-aucpr:0.96141+0.00239\n",
            "[16]\ttrain-aucpr:0.99479+0.00013\ttest-aucpr:0.96248+0.00250\n",
            "[17]\ttrain-aucpr:0.99512+0.00012\ttest-aucpr:0.96317+0.00246\n",
            "[18]\ttrain-aucpr:0.99544+0.00012\ttest-aucpr:0.96385+0.00247\n",
            "[19]\ttrain-aucpr:0.99572+0.00012\ttest-aucpr:0.96458+0.00233\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95579+0.00171\ttest-aucpr:0.89194+0.00454\n",
            "[1]\ttrain-aucpr:0.98190+0.00073\ttest-aucpr:0.92569+0.00345\n",
            "[2]\ttrain-aucpr:0.98946+0.00063\ttest-aucpr:0.93705+0.00299\n",
            "[3]\ttrain-aucpr:0.99321+0.00036\ttest-aucpr:0.94424+0.00275\n",
            "[4]\ttrain-aucpr:0.99540+0.00023\ttest-aucpr:0.94958+0.00260\n",
            "[5]\ttrain-aucpr:0.99666+0.00017\ttest-aucpr:0.95344+0.00197\n",
            "[6]\ttrain-aucpr:0.99756+0.00009\ttest-aucpr:0.95652+0.00193\n",
            "[7]\ttrain-aucpr:0.99821+0.00012\ttest-aucpr:0.95884+0.00180\n",
            "[8]\ttrain-aucpr:0.99865+0.00009\ttest-aucpr:0.96077+0.00216\n",
            "[9]\ttrain-aucpr:0.99899+0.00006\ttest-aucpr:0.96268+0.00208\n",
            "[10]\ttrain-aucpr:0.99924+0.00005\ttest-aucpr:0.96431+0.00193\n",
            "[11]\ttrain-aucpr:0.99942+0.00004\ttest-aucpr:0.96564+0.00188\n",
            "[12]\ttrain-aucpr:0.99956+0.00003\ttest-aucpr:0.96688+0.00192\n",
            "[13]\ttrain-aucpr:0.99966+0.00003\ttest-aucpr:0.96787+0.00187\n",
            "[14]\ttrain-aucpr:0.99974+0.00002\ttest-aucpr:0.96873+0.00184\n",
            "[15]\ttrain-aucpr:0.99981+0.00002\ttest-aucpr:0.96956+0.00181\n",
            "[16]\ttrain-aucpr:0.99985+0.00002\ttest-aucpr:0.97025+0.00177\n",
            "[17]\ttrain-aucpr:0.99989+0.00001\ttest-aucpr:0.97101+0.00162\n",
            "[18]\ttrain-aucpr:0.99991+0.00001\ttest-aucpr:0.97151+0.00154\n",
            "[19]\ttrain-aucpr:0.99993+0.00001\ttest-aucpr:0.97197+0.00153\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76272+0.00302\ttest-aucpr:0.75848+0.00411\n",
            "[1]\ttrain-aucpr:0.81746+0.00184\ttest-aucpr:0.81184+0.00285\n",
            "[2]\ttrain-aucpr:0.83974+0.00256\ttest-aucpr:0.83424+0.00111\n",
            "[3]\ttrain-aucpr:0.85517+0.00251\ttest-aucpr:0.84937+0.00140\n",
            "[4]\ttrain-aucpr:0.86702+0.00352\ttest-aucpr:0.86123+0.00167\n",
            "[5]\ttrain-aucpr:0.87761+0.00244\ttest-aucpr:0.87135+0.00115\n",
            "[6]\ttrain-aucpr:0.88497+0.00161\ttest-aucpr:0.87827+0.00116\n",
            "[7]\ttrain-aucpr:0.89446+0.00174\ttest-aucpr:0.88773+0.00103\n",
            "[8]\ttrain-aucpr:0.90123+0.00144\ttest-aucpr:0.89425+0.00206\n",
            "[9]\ttrain-aucpr:0.90561+0.00079\ttest-aucpr:0.89859+0.00250\n",
            "[10]\ttrain-aucpr:0.91145+0.00153\ttest-aucpr:0.90405+0.00273\n",
            "[11]\ttrain-aucpr:0.91621+0.00168\ttest-aucpr:0.90870+0.00231\n",
            "[12]\ttrain-aucpr:0.91870+0.00208\ttest-aucpr:0.91098+0.00229\n",
            "[13]\ttrain-aucpr:0.92235+0.00175\ttest-aucpr:0.91438+0.00173\n",
            "[14]\ttrain-aucpr:0.92480+0.00118\ttest-aucpr:0.91684+0.00076\n",
            "[15]\ttrain-aucpr:0.92726+0.00115\ttest-aucpr:0.91918+0.00121\n",
            "[16]\ttrain-aucpr:0.92988+0.00109\ttest-aucpr:0.92181+0.00193\n",
            "[17]\ttrain-aucpr:0.93146+0.00128\ttest-aucpr:0.92323+0.00190\n",
            "[18]\ttrain-aucpr:0.93310+0.00093\ttest-aucpr:0.92489+0.00190\n",
            "[19]\ttrain-aucpr:0.93489+0.00061\ttest-aucpr:0.92671+0.00147\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76268+0.00306\ttest-aucpr:0.75842+0.00430\n",
            "[1]\ttrain-aucpr:0.81736+0.00183\ttest-aucpr:0.81178+0.00286\n",
            "[2]\ttrain-aucpr:0.83965+0.00256\ttest-aucpr:0.83422+0.00114\n",
            "[3]\ttrain-aucpr:0.85500+0.00238\ttest-aucpr:0.84936+0.00148\n",
            "[4]\ttrain-aucpr:0.86745+0.00303\ttest-aucpr:0.86159+0.00131\n",
            "[5]\ttrain-aucpr:0.87730+0.00292\ttest-aucpr:0.87096+0.00166\n",
            "[6]\ttrain-aucpr:0.88555+0.00358\ttest-aucpr:0.87910+0.00162\n",
            "[7]\ttrain-aucpr:0.89396+0.00279\ttest-aucpr:0.88707+0.00154\n",
            "[8]\ttrain-aucpr:0.89964+0.00246\ttest-aucpr:0.89259+0.00165\n",
            "[9]\ttrain-aucpr:0.90578+0.00202\ttest-aucpr:0.89884+0.00194\n",
            "[10]\ttrain-aucpr:0.90978+0.00168\ttest-aucpr:0.90247+0.00204\n",
            "[11]\ttrain-aucpr:0.91286+0.00157\ttest-aucpr:0.90528+0.00152\n",
            "[12]\ttrain-aucpr:0.91684+0.00090\ttest-aucpr:0.90896+0.00082\n",
            "[13]\ttrain-aucpr:0.91993+0.00112\ttest-aucpr:0.91176+0.00064\n",
            "[14]\ttrain-aucpr:0.92208+0.00148\ttest-aucpr:0.91402+0.00116\n",
            "[15]\ttrain-aucpr:0.92415+0.00160\ttest-aucpr:0.91599+0.00121\n",
            "[16]\ttrain-aucpr:0.92622+0.00173\ttest-aucpr:0.91794+0.00160\n",
            "[17]\ttrain-aucpr:0.92808+0.00119\ttest-aucpr:0.91972+0.00099\n",
            "[18]\ttrain-aucpr:0.93004+0.00055\ttest-aucpr:0.92171+0.00054\n",
            "[19]\ttrain-aucpr:0.93190+0.00090\ttest-aucpr:0.92348+0.00100\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64861+0.00600\ttest-aucpr:0.64839+0.00888\n",
            "[1]\ttrain-aucpr:0.70100+0.00435\ttest-aucpr:0.69952+0.00816\n",
            "[2]\ttrain-aucpr:0.72202+0.00206\ttest-aucpr:0.71929+0.00586\n",
            "[3]\ttrain-aucpr:0.73668+0.00235\ttest-aucpr:0.73410+0.00614\n",
            "[4]\ttrain-aucpr:0.75013+0.00443\ttest-aucpr:0.74774+0.00640\n",
            "[5]\ttrain-aucpr:0.75635+0.00299\ttest-aucpr:0.75330+0.00656\n",
            "[6]\ttrain-aucpr:0.76557+0.00396\ttest-aucpr:0.76212+0.00710\n",
            "[7]\ttrain-aucpr:0.77479+0.00411\ttest-aucpr:0.77114+0.00708\n",
            "[8]\ttrain-aucpr:0.78353+0.00245\ttest-aucpr:0.77975+0.00596\n",
            "[9]\ttrain-aucpr:0.79147+0.00354\ttest-aucpr:0.78777+0.00376\n",
            "[10]\ttrain-aucpr:0.79824+0.00340\ttest-aucpr:0.79431+0.00521\n",
            "[11]\ttrain-aucpr:0.80369+0.00390\ttest-aucpr:0.79974+0.00565\n",
            "[12]\ttrain-aucpr:0.81174+0.00462\ttest-aucpr:0.80773+0.00727\n",
            "[13]\ttrain-aucpr:0.81651+0.00435\ttest-aucpr:0.81251+0.00647\n",
            "[14]\ttrain-aucpr:0.82147+0.00434\ttest-aucpr:0.81737+0.00536\n",
            "[15]\ttrain-aucpr:0.82818+0.00402\ttest-aucpr:0.82382+0.00590\n",
            "[16]\ttrain-aucpr:0.83130+0.00342\ttest-aucpr:0.82705+0.00520\n",
            "[17]\ttrain-aucpr:0.83520+0.00282\ttest-aucpr:0.83082+0.00428\n",
            "[18]\ttrain-aucpr:0.83932+0.00466\ttest-aucpr:0.83480+0.00521\n",
            "[19]\ttrain-aucpr:0.84243+0.00531\ttest-aucpr:0.83756+0.00583\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64861+0.00600\ttest-aucpr:0.64839+0.00888\n",
            "[1]\ttrain-aucpr:0.70100+0.00435\ttest-aucpr:0.69953+0.00817\n",
            "[2]\ttrain-aucpr:0.72203+0.00205\ttest-aucpr:0.71930+0.00585\n",
            "[3]\ttrain-aucpr:0.73671+0.00232\ttest-aucpr:0.73412+0.00615\n",
            "[4]\ttrain-aucpr:0.75013+0.00443\ttest-aucpr:0.74774+0.00640\n",
            "[5]\ttrain-aucpr:0.75634+0.00299\ttest-aucpr:0.75329+0.00656\n",
            "[6]\ttrain-aucpr:0.76554+0.00396\ttest-aucpr:0.76209+0.00711\n",
            "[7]\ttrain-aucpr:0.77476+0.00411\ttest-aucpr:0.77111+0.00708\n",
            "[8]\ttrain-aucpr:0.78351+0.00245\ttest-aucpr:0.77973+0.00597\n",
            "[9]\ttrain-aucpr:0.79144+0.00354\ttest-aucpr:0.78773+0.00376\n",
            "[10]\ttrain-aucpr:0.79819+0.00340\ttest-aucpr:0.79424+0.00525\n",
            "[11]\ttrain-aucpr:0.80393+0.00354\ttest-aucpr:0.80001+0.00514\n",
            "[12]\ttrain-aucpr:0.81149+0.00487\ttest-aucpr:0.80752+0.00748\n",
            "[13]\ttrain-aucpr:0.81676+0.00382\ttest-aucpr:0.81271+0.00603\n",
            "[14]\ttrain-aucpr:0.82138+0.00437\ttest-aucpr:0.81714+0.00566\n",
            "[15]\ttrain-aucpr:0.82703+0.00530\ttest-aucpr:0.82273+0.00732\n",
            "[16]\ttrain-aucpr:0.83121+0.00342\ttest-aucpr:0.82686+0.00532\n",
            "[17]\ttrain-aucpr:0.83511+0.00282\ttest-aucpr:0.83060+0.00442\n",
            "[18]\ttrain-aucpr:0.83929+0.00463\ttest-aucpr:0.83461+0.00530\n",
            "[19]\ttrain-aucpr:0.84228+0.00536\ttest-aucpr:0.83728+0.00604\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90510+0.00265\ttest-aucpr:0.87720+0.00302\n",
            "[1]\ttrain-aucpr:0.93717+0.00171\ttest-aucpr:0.91231+0.00244\n",
            "[2]\ttrain-aucpr:0.95014+0.00179\ttest-aucpr:0.92589+0.00234\n",
            "[3]\ttrain-aucpr:0.95866+0.00109\ttest-aucpr:0.93442+0.00120\n",
            "[4]\ttrain-aucpr:0.96410+0.00110\ttest-aucpr:0.94048+0.00108\n",
            "[5]\ttrain-aucpr:0.96841+0.00082\ttest-aucpr:0.94509+0.00154\n",
            "[6]\ttrain-aucpr:0.97113+0.00061\ttest-aucpr:0.94804+0.00178\n",
            "[7]\ttrain-aucpr:0.97389+0.00047\ttest-aucpr:0.95101+0.00168\n",
            "[8]\ttrain-aucpr:0.97612+0.00047\ttest-aucpr:0.95364+0.00157\n",
            "[9]\ttrain-aucpr:0.97838+0.00066\ttest-aucpr:0.95601+0.00132\n",
            "[10]\ttrain-aucpr:0.98008+0.00066\ttest-aucpr:0.95792+0.00132\n",
            "[11]\ttrain-aucpr:0.98128+0.00063\ttest-aucpr:0.95942+0.00118\n",
            "[12]\ttrain-aucpr:0.98256+0.00057\ttest-aucpr:0.96077+0.00117\n",
            "[13]\ttrain-aucpr:0.98359+0.00053\ttest-aucpr:0.96196+0.00124\n",
            "[14]\ttrain-aucpr:0.98446+0.00023\ttest-aucpr:0.96329+0.00156\n",
            "[15]\ttrain-aucpr:0.98516+0.00040\ttest-aucpr:0.96422+0.00154\n",
            "[16]\ttrain-aucpr:0.98582+0.00032\ttest-aucpr:0.96505+0.00148\n",
            "[17]\ttrain-aucpr:0.98624+0.00025\ttest-aucpr:0.96557+0.00134\n",
            "[18]\ttrain-aucpr:0.98701+0.00055\ttest-aucpr:0.96639+0.00128\n",
            "[19]\ttrain-aucpr:0.98752+0.00049\ttest-aucpr:0.96695+0.00144\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76268+0.00306\ttest-aucpr:0.75842+0.00430\n",
            "[1]\ttrain-aucpr:0.81736+0.00183\ttest-aucpr:0.81178+0.00286\n",
            "[2]\ttrain-aucpr:0.83965+0.00256\ttest-aucpr:0.83422+0.00114\n",
            "[3]\ttrain-aucpr:0.85500+0.00238\ttest-aucpr:0.84936+0.00148\n",
            "[4]\ttrain-aucpr:0.86745+0.00303\ttest-aucpr:0.86159+0.00131\n",
            "[5]\ttrain-aucpr:0.87730+0.00291\ttest-aucpr:0.87096+0.00166\n",
            "[6]\ttrain-aucpr:0.88555+0.00358\ttest-aucpr:0.87910+0.00162\n",
            "[7]\ttrain-aucpr:0.89397+0.00279\ttest-aucpr:0.88707+0.00154\n",
            "[8]\ttrain-aucpr:0.89965+0.00246\ttest-aucpr:0.89259+0.00165\n",
            "[9]\ttrain-aucpr:0.90578+0.00202\ttest-aucpr:0.89884+0.00194\n",
            "[10]\ttrain-aucpr:0.90979+0.00168\ttest-aucpr:0.90247+0.00204\n",
            "[11]\ttrain-aucpr:0.91287+0.00157\ttest-aucpr:0.90529+0.00152\n",
            "[12]\ttrain-aucpr:0.91683+0.00089\ttest-aucpr:0.90896+0.00080\n",
            "[13]\ttrain-aucpr:0.92025+0.00121\ttest-aucpr:0.91209+0.00112\n",
            "[14]\ttrain-aucpr:0.92234+0.00163\ttest-aucpr:0.91424+0.00143\n",
            "[15]\ttrain-aucpr:0.92482+0.00199\ttest-aucpr:0.91664+0.00195\n",
            "[16]\ttrain-aucpr:0.92679+0.00212\ttest-aucpr:0.91848+0.00221\n",
            "[17]\ttrain-aucpr:0.92855+0.00157\ttest-aucpr:0.92016+0.00164\n",
            "[18]\ttrain-aucpr:0.93073+0.00130\ttest-aucpr:0.92235+0.00153\n",
            "[19]\ttrain-aucpr:0.93272+0.00164\ttest-aucpr:0.92444+0.00197\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76272+0.00302\ttest-aucpr:0.75848+0.00411\n",
            "[1]\ttrain-aucpr:0.81310+0.00248\ttest-aucpr:0.80740+0.00211\n",
            "[2]\ttrain-aucpr:0.83336+0.00314\ttest-aucpr:0.82762+0.00308\n",
            "[3]\ttrain-aucpr:0.84786+0.00345\ttest-aucpr:0.84195+0.00223\n",
            "[4]\ttrain-aucpr:0.85855+0.00244\ttest-aucpr:0.85277+0.00242\n",
            "[5]\ttrain-aucpr:0.86702+0.00169\ttest-aucpr:0.86089+0.00288\n",
            "[6]\ttrain-aucpr:0.87559+0.00265\ttest-aucpr:0.86924+0.00286\n",
            "[7]\ttrain-aucpr:0.88169+0.00270\ttest-aucpr:0.87522+0.00290\n",
            "[8]\ttrain-aucpr:0.88856+0.00100\ttest-aucpr:0.88205+0.00292\n",
            "[9]\ttrain-aucpr:0.89246+0.00104\ttest-aucpr:0.88581+0.00272\n",
            "[10]\ttrain-aucpr:0.89707+0.00113\ttest-aucpr:0.89024+0.00309\n",
            "[11]\ttrain-aucpr:0.90224+0.00148\ttest-aucpr:0.89543+0.00354\n",
            "[12]\ttrain-aucpr:0.90520+0.00153\ttest-aucpr:0.89814+0.00349\n",
            "[13]\ttrain-aucpr:0.90947+0.00099\ttest-aucpr:0.90234+0.00270\n",
            "[14]\ttrain-aucpr:0.91396+0.00120\ttest-aucpr:0.90647+0.00281\n",
            "[15]\ttrain-aucpr:0.91719+0.00196\ttest-aucpr:0.90979+0.00242\n",
            "[16]\ttrain-aucpr:0.91916+0.00186\ttest-aucpr:0.91158+0.00222\n",
            "[17]\ttrain-aucpr:0.92084+0.00153\ttest-aucpr:0.91322+0.00219\n",
            "[18]\ttrain-aucpr:0.92304+0.00168\ttest-aucpr:0.91535+0.00236\n",
            "[19]\ttrain-aucpr:0.92511+0.00239\ttest-aucpr:0.91733+0.00323\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95312+0.00105\ttest-aucpr:0.89305+0.00439\n",
            "[1]\ttrain-aucpr:0.98162+0.00057\ttest-aucpr:0.92838+0.00310\n",
            "[2]\ttrain-aucpr:0.98955+0.00051\ttest-aucpr:0.94045+0.00235\n",
            "[3]\ttrain-aucpr:0.99350+0.00035\ttest-aucpr:0.94824+0.00252\n",
            "[4]\ttrain-aucpr:0.99556+0.00020\ttest-aucpr:0.95344+0.00227\n",
            "[5]\ttrain-aucpr:0.99693+0.00014\ttest-aucpr:0.95763+0.00227\n",
            "[6]\ttrain-aucpr:0.99774+0.00014\ttest-aucpr:0.96031+0.00182\n",
            "[7]\ttrain-aucpr:0.99838+0.00009\ttest-aucpr:0.96277+0.00154\n",
            "[8]\ttrain-aucpr:0.99879+0.00006\ttest-aucpr:0.96481+0.00139\n",
            "[9]\ttrain-aucpr:0.99911+0.00004\ttest-aucpr:0.96646+0.00122\n",
            "[10]\ttrain-aucpr:0.99932+0.00004\ttest-aucpr:0.96775+0.00124\n",
            "[11]\ttrain-aucpr:0.99948+0.00003\ttest-aucpr:0.96887+0.00110\n",
            "[12]\ttrain-aucpr:0.99960+0.00002\ttest-aucpr:0.96974+0.00102\n",
            "[13]\ttrain-aucpr:0.99968+0.00002\ttest-aucpr:0.97049+0.00112\n",
            "[14]\ttrain-aucpr:0.99974+0.00001\ttest-aucpr:0.97115+0.00102\n",
            "[15]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.97162+0.00096\n",
            "[16]\ttrain-aucpr:0.99983+0.00001\ttest-aucpr:0.97191+0.00095\n",
            "[17]\ttrain-aucpr:0.99987+0.00001\ttest-aucpr:0.97228+0.00114\n",
            "[18]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.97259+0.00105\n",
            "[19]\ttrain-aucpr:0.99992+0.00000\ttest-aucpr:0.97279+0.00088\n",
            "result:  0.9727912647259572\n",
            "best result:  0.9727912647259572\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76269+0.00306\ttest-aucpr:0.75850+0.00421\n",
            "[1]\ttrain-aucpr:0.80224+0.00684\ttest-aucpr:0.79581+0.00407\n",
            "[2]\ttrain-aucpr:0.81872+0.00301\ttest-aucpr:0.81255+0.00322\n",
            "[3]\ttrain-aucpr:0.83029+0.00313\ttest-aucpr:0.82429+0.00268\n",
            "[4]\ttrain-aucpr:0.83612+0.00287\ttest-aucpr:0.82981+0.00301\n",
            "[5]\ttrain-aucpr:0.84112+0.00302\ttest-aucpr:0.83439+0.00409\n",
            "[6]\ttrain-aucpr:0.84746+0.00257\ttest-aucpr:0.84102+0.00327\n",
            "[7]\ttrain-aucpr:0.85170+0.00143\ttest-aucpr:0.84519+0.00321\n",
            "[8]\ttrain-aucpr:0.85685+0.00132\ttest-aucpr:0.85021+0.00344\n",
            "[9]\ttrain-aucpr:0.86141+0.00241\ttest-aucpr:0.85470+0.00351\n",
            "[10]\ttrain-aucpr:0.86457+0.00255\ttest-aucpr:0.85777+0.00309\n",
            "[11]\ttrain-aucpr:0.86816+0.00180\ttest-aucpr:0.86127+0.00266\n",
            "[12]\ttrain-aucpr:0.87122+0.00158\ttest-aucpr:0.86441+0.00248\n",
            "[13]\ttrain-aucpr:0.87488+0.00089\ttest-aucpr:0.86806+0.00245\n",
            "[14]\ttrain-aucpr:0.87836+0.00148\ttest-aucpr:0.87130+0.00220\n",
            "[15]\ttrain-aucpr:0.88092+0.00159\ttest-aucpr:0.87389+0.00256\n",
            "[16]\ttrain-aucpr:0.88380+0.00195\ttest-aucpr:0.87672+0.00266\n",
            "[17]\ttrain-aucpr:0.88640+0.00115\ttest-aucpr:0.87948+0.00288\n",
            "[18]\ttrain-aucpr:0.88902+0.00146\ttest-aucpr:0.88204+0.00308\n",
            "[19]\ttrain-aucpr:0.89073+0.00170\ttest-aucpr:0.88373+0.00301\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90357+0.00251\ttest-aucpr:0.87731+0.00336\n",
            "[1]\ttrain-aucpr:0.93731+0.00134\ttest-aucpr:0.91386+0.00168\n",
            "[2]\ttrain-aucpr:0.95229+0.00162\ttest-aucpr:0.92909+0.00081\n",
            "[3]\ttrain-aucpr:0.96039+0.00058\ttest-aucpr:0.93815+0.00148\n",
            "[4]\ttrain-aucpr:0.96571+0.00088\ttest-aucpr:0.94370+0.00138\n",
            "[5]\ttrain-aucpr:0.96932+0.00068\ttest-aucpr:0.94758+0.00108\n",
            "[6]\ttrain-aucpr:0.97251+0.00056\ttest-aucpr:0.95137+0.00137\n",
            "[7]\ttrain-aucpr:0.97520+0.00083\ttest-aucpr:0.95422+0.00163\n",
            "[8]\ttrain-aucpr:0.97752+0.00087\ttest-aucpr:0.95668+0.00189\n",
            "[9]\ttrain-aucpr:0.97928+0.00096\ttest-aucpr:0.95896+0.00144\n",
            "[10]\ttrain-aucpr:0.98061+0.00089\ttest-aucpr:0.96057+0.00092\n",
            "[11]\ttrain-aucpr:0.98170+0.00113\ttest-aucpr:0.96182+0.00088\n",
            "[12]\ttrain-aucpr:0.98274+0.00076\ttest-aucpr:0.96301+0.00058\n",
            "[13]\ttrain-aucpr:0.98362+0.00029\ttest-aucpr:0.96405+0.00083\n",
            "[14]\ttrain-aucpr:0.98479+0.00012\ttest-aucpr:0.96526+0.00089\n",
            "[15]\ttrain-aucpr:0.98543+0.00036\ttest-aucpr:0.96604+0.00103\n",
            "[16]\ttrain-aucpr:0.98624+0.00051\ttest-aucpr:0.96684+0.00095\n",
            "[17]\ttrain-aucpr:0.98676+0.00054\ttest-aucpr:0.96732+0.00102\n",
            "[18]\ttrain-aucpr:0.98742+0.00072\ttest-aucpr:0.96779+0.00071\n",
            "[19]\ttrain-aucpr:0.98796+0.00066\ttest-aucpr:0.96801+0.00070\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.93492+0.00146\ttest-aucpr:0.89194+0.00374\n",
            "[1]\ttrain-aucpr:0.96489+0.00081\ttest-aucpr:0.92694+0.00257\n",
            "[2]\ttrain-aucpr:0.97452+0.00082\ttest-aucpr:0.93841+0.00144\n",
            "[3]\ttrain-aucpr:0.97975+0.00052\ttest-aucpr:0.94683+0.00120\n",
            "[4]\ttrain-aucpr:0.98302+0.00044\ttest-aucpr:0.95217+0.00138\n",
            "[5]\ttrain-aucpr:0.98543+0.00033\ttest-aucpr:0.95582+0.00225\n",
            "[6]\ttrain-aucpr:0.98712+0.00022\ttest-aucpr:0.95865+0.00220\n",
            "[7]\ttrain-aucpr:0.98844+0.00019\ttest-aucpr:0.96080+0.00204\n",
            "[8]\ttrain-aucpr:0.98959+0.00023\ttest-aucpr:0.96286+0.00164\n",
            "[9]\ttrain-aucpr:0.99061+0.00027\ttest-aucpr:0.96462+0.00143\n",
            "[10]\ttrain-aucpr:0.99145+0.00024\ttest-aucpr:0.96600+0.00134\n",
            "[11]\ttrain-aucpr:0.99213+0.00020\ttest-aucpr:0.96721+0.00139\n",
            "[12]\ttrain-aucpr:0.99269+0.00022\ttest-aucpr:0.96817+0.00129\n",
            "[13]\ttrain-aucpr:0.99319+0.00021\ttest-aucpr:0.96907+0.00139\n",
            "[14]\ttrain-aucpr:0.99360+0.00020\ttest-aucpr:0.96984+0.00134\n",
            "[15]\ttrain-aucpr:0.99399+0.00015\ttest-aucpr:0.97064+0.00125\n",
            "[16]\ttrain-aucpr:0.99438+0.00014\ttest-aucpr:0.97151+0.00123\n",
            "[17]\ttrain-aucpr:0.99465+0.00019\ttest-aucpr:0.97208+0.00114\n",
            "[18]\ttrain-aucpr:0.99491+0.00017\ttest-aucpr:0.97252+0.00103\n",
            "[19]\ttrain-aucpr:0.99512+0.00020\ttest-aucpr:0.97291+0.00098\n",
            "result:  0.9729062433671576\n",
            "best result:  0.9729062433671576\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64861+0.00600\ttest-aucpr:0.64839+0.00888\n",
            "[1]\ttrain-aucpr:0.70908+0.00640\ttest-aucpr:0.70785+0.00641\n",
            "[2]\ttrain-aucpr:0.72604+0.00266\ttest-aucpr:0.72512+0.00412\n",
            "[3]\ttrain-aucpr:0.73563+0.00368\ttest-aucpr:0.73308+0.00531\n",
            "[4]\ttrain-aucpr:0.75670+0.00333\ttest-aucpr:0.75364+0.00547\n",
            "[5]\ttrain-aucpr:0.76683+0.00441\ttest-aucpr:0.76331+0.00743\n",
            "[6]\ttrain-aucpr:0.77936+0.00370\ttest-aucpr:0.77572+0.00703\n",
            "[7]\ttrain-aucpr:0.79178+0.00600\ttest-aucpr:0.78782+0.00899\n",
            "[8]\ttrain-aucpr:0.79814+0.00537\ttest-aucpr:0.79408+0.00833\n",
            "[9]\ttrain-aucpr:0.80695+0.00580\ttest-aucpr:0.80292+0.00758\n",
            "[10]\ttrain-aucpr:0.81466+0.00588\ttest-aucpr:0.80991+0.00789\n",
            "[11]\ttrain-aucpr:0.82080+0.00592\ttest-aucpr:0.81615+0.00742\n",
            "[12]\ttrain-aucpr:0.82881+0.00455\ttest-aucpr:0.82393+0.00403\n",
            "[13]\ttrain-aucpr:0.83266+0.00561\ttest-aucpr:0.82767+0.00398\n",
            "[14]\ttrain-aucpr:0.83845+0.00323\ttest-aucpr:0.83305+0.00275\n",
            "[15]\ttrain-aucpr:0.84233+0.00353\ttest-aucpr:0.83696+0.00220\n",
            "[16]\ttrain-aucpr:0.84574+0.00463\ttest-aucpr:0.84001+0.00276\n",
            "[17]\ttrain-aucpr:0.85060+0.00494\ttest-aucpr:0.84496+0.00288\n",
            "[18]\ttrain-aucpr:0.85588+0.00340\ttest-aucpr:0.85016+0.00145\n",
            "[19]\ttrain-aucpr:0.86001+0.00407\ttest-aucpr:0.85416+0.00195\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64861+0.00600\ttest-aucpr:0.64839+0.00888\n",
            "[1]\ttrain-aucpr:0.70100+0.00435\ttest-aucpr:0.69952+0.00816\n",
            "[2]\ttrain-aucpr:0.72203+0.00205\ttest-aucpr:0.71930+0.00585\n",
            "[3]\ttrain-aucpr:0.73668+0.00235\ttest-aucpr:0.73411+0.00613\n",
            "[4]\ttrain-aucpr:0.75013+0.00443\ttest-aucpr:0.74774+0.00639\n",
            "[5]\ttrain-aucpr:0.75635+0.00299\ttest-aucpr:0.75330+0.00656\n",
            "[6]\ttrain-aucpr:0.76556+0.00396\ttest-aucpr:0.76212+0.00710\n",
            "[7]\ttrain-aucpr:0.77479+0.00411\ttest-aucpr:0.77114+0.00708\n",
            "[8]\ttrain-aucpr:0.78353+0.00245\ttest-aucpr:0.77975+0.00596\n",
            "[9]\ttrain-aucpr:0.79147+0.00354\ttest-aucpr:0.78777+0.00376\n",
            "[10]\ttrain-aucpr:0.79824+0.00340\ttest-aucpr:0.79430+0.00521\n",
            "[11]\ttrain-aucpr:0.80368+0.00390\ttest-aucpr:0.79973+0.00565\n",
            "[12]\ttrain-aucpr:0.81174+0.00462\ttest-aucpr:0.80772+0.00727\n",
            "[13]\ttrain-aucpr:0.81650+0.00435\ttest-aucpr:0.81250+0.00646\n",
            "[14]\ttrain-aucpr:0.82147+0.00434\ttest-aucpr:0.81737+0.00536\n",
            "[15]\ttrain-aucpr:0.82817+0.00402\ttest-aucpr:0.82381+0.00590\n",
            "[16]\ttrain-aucpr:0.83128+0.00342\ttest-aucpr:0.82700+0.00521\n",
            "[17]\ttrain-aucpr:0.83519+0.00281\ttest-aucpr:0.83077+0.00429\n",
            "[18]\ttrain-aucpr:0.83931+0.00466\ttest-aucpr:0.83475+0.00522\n",
            "[19]\ttrain-aucpr:0.84242+0.00531\ttest-aucpr:0.83752+0.00584\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96472+0.00158\ttest-aucpr:0.89121+0.00469\n",
            "[1]\ttrain-aucpr:0.97845+0.00302\ttest-aucpr:0.91322+0.00877\n",
            "[2]\ttrain-aucpr:0.98541+0.00255\ttest-aucpr:0.92715+0.00692\n",
            "[3]\ttrain-aucpr:0.99038+0.00089\ttest-aucpr:0.93791+0.00406\n",
            "[4]\ttrain-aucpr:0.99242+0.00057\ttest-aucpr:0.94249+0.00340\n",
            "[5]\ttrain-aucpr:0.99402+0.00021\ttest-aucpr:0.94647+0.00267\n",
            "[6]\ttrain-aucpr:0.99509+0.00024\ttest-aucpr:0.94936+0.00248\n",
            "[7]\ttrain-aucpr:0.99596+0.00023\ttest-aucpr:0.95150+0.00248\n",
            "[8]\ttrain-aucpr:0.99657+0.00026\ttest-aucpr:0.95374+0.00234\n",
            "[9]\ttrain-aucpr:0.99709+0.00018\ttest-aucpr:0.95507+0.00205\n",
            "[10]\ttrain-aucpr:0.99755+0.00012\ttest-aucpr:0.95668+0.00215\n",
            "[11]\ttrain-aucpr:0.99790+0.00015\ttest-aucpr:0.95801+0.00226\n",
            "[12]\ttrain-aucpr:0.99817+0.00015\ttest-aucpr:0.95928+0.00236\n",
            "[13]\ttrain-aucpr:0.99843+0.00009\ttest-aucpr:0.96013+0.00215\n",
            "[14]\ttrain-aucpr:0.99861+0.00008\ttest-aucpr:0.96122+0.00199\n",
            "[15]\ttrain-aucpr:0.99878+0.00006\ttest-aucpr:0.96208+0.00181\n",
            "[16]\ttrain-aucpr:0.99892+0.00005\ttest-aucpr:0.96276+0.00181\n",
            "[17]\ttrain-aucpr:0.99903+0.00005\ttest-aucpr:0.96345+0.00185\n",
            "[18]\ttrain-aucpr:0.99914+0.00005\ttest-aucpr:0.96402+0.00177\n",
            "[19]\ttrain-aucpr:0.99924+0.00004\ttest-aucpr:0.96468+0.00175\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90178+0.00199\ttest-aucpr:0.87428+0.00398\n",
            "[1]\ttrain-aucpr:0.93486+0.00373\ttest-aucpr:0.91059+0.00587\n",
            "[2]\ttrain-aucpr:0.94891+0.00132\ttest-aucpr:0.92615+0.00201\n",
            "[3]\ttrain-aucpr:0.95569+0.00143\ttest-aucpr:0.93359+0.00154\n",
            "[4]\ttrain-aucpr:0.96063+0.00081\ttest-aucpr:0.93895+0.00156\n",
            "[5]\ttrain-aucpr:0.96526+0.00076\ttest-aucpr:0.94360+0.00082\n",
            "[6]\ttrain-aucpr:0.96886+0.00087\ttest-aucpr:0.94783+0.00137\n",
            "[7]\ttrain-aucpr:0.97181+0.00074\ttest-aucpr:0.95109+0.00121\n",
            "[8]\ttrain-aucpr:0.97387+0.00059\ttest-aucpr:0.95339+0.00090\n",
            "[9]\ttrain-aucpr:0.97577+0.00076\ttest-aucpr:0.95553+0.00116\n",
            "[10]\ttrain-aucpr:0.97760+0.00085\ttest-aucpr:0.95758+0.00129\n",
            "[11]\ttrain-aucpr:0.97911+0.00054\ttest-aucpr:0.95933+0.00140\n",
            "[12]\ttrain-aucpr:0.97991+0.00056\ttest-aucpr:0.96038+0.00139\n",
            "[13]\ttrain-aucpr:0.98103+0.00033\ttest-aucpr:0.96176+0.00127\n",
            "[14]\ttrain-aucpr:0.98172+0.00028\ttest-aucpr:0.96263+0.00138\n",
            "[15]\ttrain-aucpr:0.98260+0.00043\ttest-aucpr:0.96370+0.00158\n",
            "[16]\ttrain-aucpr:0.98339+0.00047\ttest-aucpr:0.96474+0.00145\n",
            "[17]\ttrain-aucpr:0.98371+0.00045\ttest-aucpr:0.96526+0.00157\n",
            "[18]\ttrain-aucpr:0.98461+0.00041\ttest-aucpr:0.96623+0.00154\n",
            "[19]\ttrain-aucpr:0.98505+0.00046\ttest-aucpr:0.96679+0.00152\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76558+0.00049\ttest-aucpr:0.75805+0.00288\n",
            "[1]\ttrain-aucpr:0.80170+0.00589\ttest-aucpr:0.79546+0.00876\n",
            "[2]\ttrain-aucpr:0.81884+0.00273\ttest-aucpr:0.81246+0.00477\n",
            "[3]\ttrain-aucpr:0.82768+0.00334\ttest-aucpr:0.82116+0.00530\n",
            "[4]\ttrain-aucpr:0.83580+0.00377\ttest-aucpr:0.82896+0.00659\n",
            "[5]\ttrain-aucpr:0.84040+0.00113\ttest-aucpr:0.83358+0.00303\n",
            "[6]\ttrain-aucpr:0.84605+0.00180\ttest-aucpr:0.83902+0.00309\n",
            "[7]\ttrain-aucpr:0.85060+0.00213\ttest-aucpr:0.84362+0.00252\n",
            "[8]\ttrain-aucpr:0.85549+0.00223\ttest-aucpr:0.84873+0.00256\n",
            "[9]\ttrain-aucpr:0.85980+0.00111\ttest-aucpr:0.85294+0.00267\n",
            "[10]\ttrain-aucpr:0.86356+0.00040\ttest-aucpr:0.85684+0.00290\n",
            "[11]\ttrain-aucpr:0.86664+0.00042\ttest-aucpr:0.85962+0.00297\n",
            "[12]\ttrain-aucpr:0.87015+0.00102\ttest-aucpr:0.86315+0.00356\n",
            "[13]\ttrain-aucpr:0.87272+0.00097\ttest-aucpr:0.86567+0.00369\n",
            "[14]\ttrain-aucpr:0.87595+0.00117\ttest-aucpr:0.86897+0.00355\n",
            "[15]\ttrain-aucpr:0.87881+0.00149\ttest-aucpr:0.87199+0.00363\n",
            "[16]\ttrain-aucpr:0.88141+0.00118\ttest-aucpr:0.87456+0.00352\n",
            "[17]\ttrain-aucpr:0.88415+0.00137\ttest-aucpr:0.87735+0.00368\n",
            "[18]\ttrain-aucpr:0.88699+0.00122\ttest-aucpr:0.88019+0.00340\n",
            "[19]\ttrain-aucpr:0.88950+0.00110\ttest-aucpr:0.88266+0.00331\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76528+0.00057\ttest-aucpr:0.75841+0.00318\n",
            "[1]\ttrain-aucpr:0.81896+0.00268\ttest-aucpr:0.81261+0.00406\n",
            "[2]\ttrain-aucpr:0.83963+0.00329\ttest-aucpr:0.83273+0.00448\n",
            "[3]\ttrain-aucpr:0.85432+0.00288\ttest-aucpr:0.84733+0.00326\n",
            "[4]\ttrain-aucpr:0.86535+0.00205\ttest-aucpr:0.85805+0.00164\n",
            "[5]\ttrain-aucpr:0.87572+0.00146\ttest-aucpr:0.86805+0.00162\n",
            "[6]\ttrain-aucpr:0.88507+0.00143\ttest-aucpr:0.87729+0.00207\n",
            "[7]\ttrain-aucpr:0.89242+0.00131\ttest-aucpr:0.88402+0.00306\n",
            "[8]\ttrain-aucpr:0.89845+0.00168\ttest-aucpr:0.88995+0.00194\n",
            "[9]\ttrain-aucpr:0.90232+0.00170\ttest-aucpr:0.89353+0.00251\n",
            "[10]\ttrain-aucpr:0.90631+0.00173\ttest-aucpr:0.89731+0.00193\n",
            "[11]\ttrain-aucpr:0.91061+0.00090\ttest-aucpr:0.90159+0.00151\n",
            "[12]\ttrain-aucpr:0.91389+0.00074\ttest-aucpr:0.90495+0.00117\n",
            "[13]\ttrain-aucpr:0.91685+0.00122\ttest-aucpr:0.90775+0.00148\n",
            "[14]\ttrain-aucpr:0.92006+0.00138\ttest-aucpr:0.91087+0.00065\n",
            "[15]\ttrain-aucpr:0.92232+0.00156\ttest-aucpr:0.91311+0.00062\n",
            "[16]\ttrain-aucpr:0.92526+0.00204\ttest-aucpr:0.91592+0.00176\n",
            "[17]\ttrain-aucpr:0.92772+0.00241\ttest-aucpr:0.91851+0.00186\n",
            "[18]\ttrain-aucpr:0.93032+0.00204\ttest-aucpr:0.92114+0.00161\n",
            "[19]\ttrain-aucpr:0.93181+0.00206\ttest-aucpr:0.92264+0.00179\n",
            "result:  0.9226384593742105\n",
            "best result:  0.9226384593742105\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95368+0.00208\ttest-aucpr:0.88813+0.00280\n",
            "[1]\ttrain-aucpr:0.98315+0.00090\ttest-aucpr:0.92358+0.00302\n",
            "[2]\ttrain-aucpr:0.99152+0.00077\ttest-aucpr:0.93787+0.00251\n",
            "[3]\ttrain-aucpr:0.99501+0.00026\ttest-aucpr:0.94603+0.00127\n",
            "[4]\ttrain-aucpr:0.99695+0.00012\ttest-aucpr:0.95142+0.00093\n",
            "[5]\ttrain-aucpr:0.99798+0.00009\ttest-aucpr:0.95537+0.00095\n",
            "[6]\ttrain-aucpr:0.99865+0.00006\ttest-aucpr:0.95842+0.00077\n",
            "[7]\ttrain-aucpr:0.99910+0.00003\ttest-aucpr:0.96084+0.00103\n",
            "[8]\ttrain-aucpr:0.99937+0.00002\ttest-aucpr:0.96276+0.00105\n",
            "[9]\ttrain-aucpr:0.99956+0.00003\ttest-aucpr:0.96444+0.00113\n",
            "[10]\ttrain-aucpr:0.99970+0.00002\ttest-aucpr:0.96599+0.00121\n",
            "[11]\ttrain-aucpr:0.99979+0.00002\ttest-aucpr:0.96720+0.00138\n",
            "[12]\ttrain-aucpr:0.99985+0.00001\ttest-aucpr:0.96815+0.00144\n",
            "[13]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.96891+0.00136\n",
            "[14]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.96968+0.00129\n",
            "[15]\ttrain-aucpr:0.99995+0.00001\ttest-aucpr:0.97036+0.00134\n",
            "[16]\ttrain-aucpr:0.99996+0.00001\ttest-aucpr:0.97097+0.00129\n",
            "[17]\ttrain-aucpr:0.99998+0.00001\ttest-aucpr:0.97137+0.00132\n",
            "[18]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97172+0.00125\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97207+0.00129\n",
            "result:  0.9720667775348568\n",
            "best result:  0.9720667775348568\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96805+0.00048\ttest-aucpr:0.89086+0.00387\n",
            "[1]\ttrain-aucpr:0.98938+0.00081\ttest-aucpr:0.92289+0.00294\n",
            "[2]\ttrain-aucpr:0.99526+0.00028\ttest-aucpr:0.93772+0.00272\n",
            "[3]\ttrain-aucpr:0.99734+0.00013\ttest-aucpr:0.94668+0.00209\n",
            "[4]\ttrain-aucpr:0.99832+0.00005\ttest-aucpr:0.95187+0.00161\n",
            "[5]\ttrain-aucpr:0.99890+0.00008\ttest-aucpr:0.95604+0.00135\n",
            "[6]\ttrain-aucpr:0.99926+0.00007\ttest-aucpr:0.95872+0.00099\n",
            "[7]\ttrain-aucpr:0.99951+0.00005\ttest-aucpr:0.96084+0.00093\n",
            "[8]\ttrain-aucpr:0.99969+0.00003\ttest-aucpr:0.96291+0.00091\n",
            "[9]\ttrain-aucpr:0.99980+0.00002\ttest-aucpr:0.96471+0.00078\n",
            "[10]\ttrain-aucpr:0.99986+0.00001\ttest-aucpr:0.96625+0.00080\n",
            "[11]\ttrain-aucpr:0.99991+0.00001\ttest-aucpr:0.96729+0.00082\n",
            "[12]\ttrain-aucpr:0.99994+0.00000\ttest-aucpr:0.96833+0.00113\n",
            "[13]\ttrain-aucpr:0.99996+0.00000\ttest-aucpr:0.96905+0.00105\n",
            "[14]\ttrain-aucpr:0.99997+0.00000\ttest-aucpr:0.96981+0.00101\n",
            "[15]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97040+0.00091\n",
            "[16]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97098+0.00095\n",
            "[17]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97151+0.00096\n",
            "[18]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97182+0.00099\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97209+0.00105\n",
            "result:  0.9720875118978473\n",
            "best result:  0.9720875118978473\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95143+0.00164\ttest-aucpr:0.88971+0.00300\n",
            "[1]\ttrain-aucpr:0.97734+0.00169\ttest-aucpr:0.92141+0.00306\n",
            "[2]\ttrain-aucpr:0.98712+0.00094\ttest-aucpr:0.93762+0.00271\n",
            "[3]\ttrain-aucpr:0.99150+0.00040\ttest-aucpr:0.94580+0.00188\n",
            "[4]\ttrain-aucpr:0.99376+0.00028\ttest-aucpr:0.95020+0.00223\n",
            "[5]\ttrain-aucpr:0.99543+0.00007\ttest-aucpr:0.95426+0.00153\n",
            "[6]\ttrain-aucpr:0.99653+0.00012\ttest-aucpr:0.95736+0.00149\n",
            "[7]\ttrain-aucpr:0.99726+0.00010\ttest-aucpr:0.95990+0.00124\n",
            "[8]\ttrain-aucpr:0.99782+0.00004\ttest-aucpr:0.96178+0.00148\n",
            "[9]\ttrain-aucpr:0.99825+0.00003\ttest-aucpr:0.96340+0.00114\n",
            "[10]\ttrain-aucpr:0.99857+0.00005\ttest-aucpr:0.96516+0.00081\n",
            "[11]\ttrain-aucpr:0.99884+0.00003\ttest-aucpr:0.96649+0.00099\n",
            "[12]\ttrain-aucpr:0.99907+0.00002\ttest-aucpr:0.96761+0.00131\n",
            "[13]\ttrain-aucpr:0.99924+0.00003\ttest-aucpr:0.96854+0.00136\n",
            "[14]\ttrain-aucpr:0.99937+0.00002\ttest-aucpr:0.96949+0.00121\n",
            "[15]\ttrain-aucpr:0.99947+0.00002\ttest-aucpr:0.97020+0.00118\n",
            "[16]\ttrain-aucpr:0.99957+0.00002\ttest-aucpr:0.97088+0.00114\n",
            "[17]\ttrain-aucpr:0.99964+0.00002\ttest-aucpr:0.97149+0.00113\n",
            "[18]\ttrain-aucpr:0.99969+0.00002\ttest-aucpr:0.97200+0.00106\n",
            "[19]\ttrain-aucpr:0.99974+0.00002\ttest-aucpr:0.97249+0.00111\n",
            "result:  0.9724892838782907\n",
            "best result:  0.9724892838782907\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76558+0.00049\ttest-aucpr:0.75805+0.00289\n",
            "[1]\ttrain-aucpr:0.80168+0.00589\ttest-aucpr:0.79545+0.00878\n",
            "[2]\ttrain-aucpr:0.81881+0.00273\ttest-aucpr:0.81245+0.00477\n",
            "[3]\ttrain-aucpr:0.82814+0.00349\ttest-aucpr:0.82173+0.00536\n",
            "[4]\ttrain-aucpr:0.83617+0.00390\ttest-aucpr:0.82941+0.00664\n",
            "[5]\ttrain-aucpr:0.84080+0.00124\ttest-aucpr:0.83414+0.00310\n",
            "[6]\ttrain-aucpr:0.84649+0.00215\ttest-aucpr:0.84002+0.00374\n",
            "[7]\ttrain-aucpr:0.85152+0.00160\ttest-aucpr:0.84484+0.00329\n",
            "[8]\ttrain-aucpr:0.85596+0.00099\ttest-aucpr:0.84923+0.00306\n",
            "[9]\ttrain-aucpr:0.86009+0.00124\ttest-aucpr:0.85348+0.00327\n",
            "[10]\ttrain-aucpr:0.86395+0.00120\ttest-aucpr:0.85730+0.00364\n",
            "[11]\ttrain-aucpr:0.86707+0.00090\ttest-aucpr:0.86026+0.00364\n",
            "[12]\ttrain-aucpr:0.87054+0.00119\ttest-aucpr:0.86360+0.00407\n",
            "[13]\ttrain-aucpr:0.87343+0.00121\ttest-aucpr:0.86619+0.00390\n",
            "[14]\ttrain-aucpr:0.87668+0.00127\ttest-aucpr:0.86924+0.00390\n",
            "[15]\ttrain-aucpr:0.87999+0.00158\ttest-aucpr:0.87263+0.00427\n",
            "[16]\ttrain-aucpr:0.88229+0.00157\ttest-aucpr:0.87508+0.00405\n",
            "[17]\ttrain-aucpr:0.88421+0.00181\ttest-aucpr:0.87695+0.00424\n",
            "[18]\ttrain-aucpr:0.88739+0.00145\ttest-aucpr:0.88013+0.00342\n",
            "[19]\ttrain-aucpr:0.88915+0.00105\ttest-aucpr:0.88193+0.00333\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64725+0.00200\ttest-aucpr:0.64342+0.00256\n",
            "[1]\ttrain-aucpr:0.70987+0.00289\ttest-aucpr:0.70515+0.00597\n",
            "[2]\ttrain-aucpr:0.72490+0.00419\ttest-aucpr:0.72106+0.00518\n",
            "[3]\ttrain-aucpr:0.73778+0.00565\ttest-aucpr:0.73405+0.00360\n",
            "[4]\ttrain-aucpr:0.75707+0.00532\ttest-aucpr:0.75269+0.00393\n",
            "[5]\ttrain-aucpr:0.76853+0.00293\ttest-aucpr:0.76307+0.00476\n",
            "[6]\ttrain-aucpr:0.78053+0.00451\ttest-aucpr:0.77450+0.00509\n",
            "[7]\ttrain-aucpr:0.79075+0.00460\ttest-aucpr:0.78426+0.00589\n",
            "[8]\ttrain-aucpr:0.80314+0.00412\ttest-aucpr:0.79652+0.00490\n",
            "[9]\ttrain-aucpr:0.80970+0.00725\ttest-aucpr:0.80311+0.00787\n",
            "[10]\ttrain-aucpr:0.81756+0.00537\ttest-aucpr:0.81097+0.00626\n",
            "[11]\ttrain-aucpr:0.82410+0.00243\ttest-aucpr:0.81803+0.00196\n",
            "[12]\ttrain-aucpr:0.82819+0.00170\ttest-aucpr:0.82209+0.00174\n",
            "[13]\ttrain-aucpr:0.83251+0.00319\ttest-aucpr:0.82664+0.00327\n",
            "[14]\ttrain-aucpr:0.83649+0.00416\ttest-aucpr:0.83037+0.00358\n",
            "[15]\ttrain-aucpr:0.84048+0.00344\ttest-aucpr:0.83420+0.00287\n",
            "[16]\ttrain-aucpr:0.84496+0.00358\ttest-aucpr:0.83863+0.00259\n",
            "[17]\ttrain-aucpr:0.85010+0.00446\ttest-aucpr:0.84380+0.00345\n",
            "[18]\ttrain-aucpr:0.85426+0.00643\ttest-aucpr:0.84808+0.00580\n",
            "[19]\ttrain-aucpr:0.85904+0.00591\ttest-aucpr:0.85296+0.00494\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76558+0.00049\ttest-aucpr:0.75805+0.00289\n",
            "[1]\ttrain-aucpr:0.81544+0.00272\ttest-aucpr:0.80919+0.00337\n",
            "[2]\ttrain-aucpr:0.83551+0.00125\ttest-aucpr:0.82958+0.00243\n",
            "[3]\ttrain-aucpr:0.84981+0.00271\ttest-aucpr:0.84352+0.00358\n",
            "[4]\ttrain-aucpr:0.86056+0.00202\ttest-aucpr:0.85421+0.00329\n",
            "[5]\ttrain-aucpr:0.86909+0.00343\ttest-aucpr:0.86215+0.00458\n",
            "[6]\ttrain-aucpr:0.87687+0.00177\ttest-aucpr:0.86947+0.00302\n",
            "[7]\ttrain-aucpr:0.88192+0.00228\ttest-aucpr:0.87455+0.00377\n",
            "[8]\ttrain-aucpr:0.88906+0.00233\ttest-aucpr:0.88144+0.00378\n",
            "[9]\ttrain-aucpr:0.89382+0.00242\ttest-aucpr:0.88616+0.00370\n",
            "[10]\ttrain-aucpr:0.89835+0.00177\ttest-aucpr:0.89073+0.00390\n",
            "[11]\ttrain-aucpr:0.90256+0.00203\ttest-aucpr:0.89502+0.00353\n",
            "[12]\ttrain-aucpr:0.90666+0.00086\ttest-aucpr:0.89902+0.00254\n",
            "[13]\ttrain-aucpr:0.91047+0.00141\ttest-aucpr:0.90266+0.00129\n",
            "[14]\ttrain-aucpr:0.91397+0.00127\ttest-aucpr:0.90596+0.00191\n",
            "[15]\ttrain-aucpr:0.91662+0.00128\ttest-aucpr:0.90861+0.00182\n",
            "[16]\ttrain-aucpr:0.91963+0.00170\ttest-aucpr:0.91151+0.00324\n",
            "[17]\ttrain-aucpr:0.92244+0.00127\ttest-aucpr:0.91436+0.00330\n",
            "[18]\ttrain-aucpr:0.92404+0.00127\ttest-aucpr:0.91597+0.00303\n",
            "[19]\ttrain-aucpr:0.92619+0.00101\ttest-aucpr:0.91798+0.00273\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90482+0.00195\ttest-aucpr:0.87482+0.00396\n",
            "[1]\ttrain-aucpr:0.93969+0.00244\ttest-aucpr:0.91320+0.00378\n",
            "[2]\ttrain-aucpr:0.95408+0.00019\ttest-aucpr:0.92940+0.00063\n",
            "[3]\ttrain-aucpr:0.96192+0.00077\ttest-aucpr:0.93760+0.00035\n",
            "[4]\ttrain-aucpr:0.96776+0.00100\ttest-aucpr:0.94334+0.00107\n",
            "[5]\ttrain-aucpr:0.97303+0.00032\ttest-aucpr:0.94916+0.00101\n",
            "[6]\ttrain-aucpr:0.97610+0.00040\ttest-aucpr:0.95292+0.00085\n",
            "[7]\ttrain-aucpr:0.97848+0.00042\ttest-aucpr:0.95542+0.00112\n",
            "[8]\ttrain-aucpr:0.98015+0.00059\ttest-aucpr:0.95742+0.00113\n",
            "[9]\ttrain-aucpr:0.98175+0.00058\ttest-aucpr:0.95942+0.00130\n",
            "[10]\ttrain-aucpr:0.98327+0.00063\ttest-aucpr:0.96142+0.00143\n",
            "[11]\ttrain-aucpr:0.98434+0.00085\ttest-aucpr:0.96273+0.00121\n",
            "[12]\ttrain-aucpr:0.98535+0.00037\ttest-aucpr:0.96371+0.00114\n",
            "[13]\ttrain-aucpr:0.98603+0.00077\ttest-aucpr:0.96454+0.00102\n",
            "[14]\ttrain-aucpr:0.98690+0.00069\ttest-aucpr:0.96542+0.00102\n",
            "[15]\ttrain-aucpr:0.98753+0.00059\ttest-aucpr:0.96609+0.00062\n",
            "[16]\ttrain-aucpr:0.98828+0.00050\ttest-aucpr:0.96679+0.00074\n",
            "[17]\ttrain-aucpr:0.98887+0.00055\ttest-aucpr:0.96735+0.00103\n",
            "[18]\ttrain-aucpr:0.98924+0.00054\ttest-aucpr:0.96749+0.00114\n",
            "[19]\ttrain-aucpr:0.98992+0.00038\ttest-aucpr:0.96793+0.00112\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64725+0.00200\ttest-aucpr:0.64342+0.00256\n",
            "[1]\ttrain-aucpr:0.68768+0.00588\ttest-aucpr:0.68570+0.00849\n",
            "[2]\ttrain-aucpr:0.70353+0.00386\ttest-aucpr:0.70075+0.00498\n",
            "[3]\ttrain-aucpr:0.71358+0.00360\ttest-aucpr:0.71051+0.00363\n",
            "[4]\ttrain-aucpr:0.72815+0.00349\ttest-aucpr:0.72552+0.00575\n",
            "[5]\ttrain-aucpr:0.73571+0.00309\ttest-aucpr:0.73276+0.00282\n",
            "[6]\ttrain-aucpr:0.73991+0.00302\ttest-aucpr:0.73643+0.00373\n",
            "[7]\ttrain-aucpr:0.74537+0.00265\ttest-aucpr:0.74140+0.00381\n",
            "[8]\ttrain-aucpr:0.74672+0.00272\ttest-aucpr:0.74256+0.00397\n",
            "[9]\ttrain-aucpr:0.74924+0.00277\ttest-aucpr:0.74510+0.00415\n",
            "[10]\ttrain-aucpr:0.75221+0.00206\ttest-aucpr:0.74822+0.00486\n",
            "[11]\ttrain-aucpr:0.75370+0.00225\ttest-aucpr:0.74964+0.00318\n",
            "[12]\ttrain-aucpr:0.75615+0.00263\ttest-aucpr:0.75193+0.00429\n",
            "[13]\ttrain-aucpr:0.75885+0.00351\ttest-aucpr:0.75447+0.00343\n",
            "[14]\ttrain-aucpr:0.76213+0.00275\ttest-aucpr:0.75789+0.00329\n",
            "[15]\ttrain-aucpr:0.76554+0.00255\ttest-aucpr:0.76119+0.00357\n",
            "[16]\ttrain-aucpr:0.76878+0.00404\ttest-aucpr:0.76431+0.00428\n",
            "[17]\ttrain-aucpr:0.77270+0.00370\ttest-aucpr:0.76848+0.00421\n",
            "[18]\ttrain-aucpr:0.77560+0.00376\ttest-aucpr:0.77121+0.00350\n",
            "[19]\ttrain-aucpr:0.77920+0.00332\ttest-aucpr:0.77474+0.00314\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76558+0.00049\ttest-aucpr:0.75805+0.00289\n",
            "[1]\ttrain-aucpr:0.80168+0.00589\ttest-aucpr:0.79545+0.00878\n",
            "[2]\ttrain-aucpr:0.81881+0.00273\ttest-aucpr:0.81245+0.00477\n",
            "[3]\ttrain-aucpr:0.82814+0.00349\ttest-aucpr:0.82173+0.00536\n",
            "[4]\ttrain-aucpr:0.83617+0.00390\ttest-aucpr:0.82941+0.00664\n",
            "[5]\ttrain-aucpr:0.84080+0.00124\ttest-aucpr:0.83414+0.00310\n",
            "[6]\ttrain-aucpr:0.84649+0.00215\ttest-aucpr:0.84002+0.00374\n",
            "[7]\ttrain-aucpr:0.85152+0.00160\ttest-aucpr:0.84484+0.00329\n",
            "[8]\ttrain-aucpr:0.85596+0.00099\ttest-aucpr:0.84923+0.00306\n",
            "[9]\ttrain-aucpr:0.86009+0.00124\ttest-aucpr:0.85348+0.00327\n",
            "[10]\ttrain-aucpr:0.86395+0.00120\ttest-aucpr:0.85730+0.00364\n",
            "[11]\ttrain-aucpr:0.86707+0.00090\ttest-aucpr:0.86026+0.00364\n",
            "[12]\ttrain-aucpr:0.87054+0.00119\ttest-aucpr:0.86360+0.00407\n",
            "[13]\ttrain-aucpr:0.87343+0.00121\ttest-aucpr:0.86619+0.00390\n",
            "[14]\ttrain-aucpr:0.87668+0.00127\ttest-aucpr:0.86924+0.00390\n",
            "[15]\ttrain-aucpr:0.87999+0.00158\ttest-aucpr:0.87263+0.00427\n",
            "[16]\ttrain-aucpr:0.88229+0.00157\ttest-aucpr:0.87508+0.00405\n",
            "[17]\ttrain-aucpr:0.88421+0.00181\ttest-aucpr:0.87695+0.00424\n",
            "[18]\ttrain-aucpr:0.88739+0.00145\ttest-aucpr:0.88013+0.00342\n",
            "[19]\ttrain-aucpr:0.88915+0.00105\ttest-aucpr:0.88193+0.00333\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89860+0.00123\ttest-aucpr:0.87341+0.00307\n",
            "[1]\ttrain-aucpr:0.92220+0.00313\ttest-aucpr:0.89937+0.00419\n",
            "[2]\ttrain-aucpr:0.93943+0.00318\ttest-aucpr:0.91814+0.00556\n",
            "[3]\ttrain-aucpr:0.94443+0.00278\ttest-aucpr:0.92327+0.00534\n",
            "[4]\ttrain-aucpr:0.94973+0.00061\ttest-aucpr:0.92906+0.00213\n",
            "[5]\ttrain-aucpr:0.95399+0.00083\ttest-aucpr:0.93340+0.00204\n",
            "[6]\ttrain-aucpr:0.95661+0.00071\ttest-aucpr:0.93631+0.00234\n",
            "[7]\ttrain-aucpr:0.95916+0.00131\ttest-aucpr:0.93901+0.00278\n",
            "[8]\ttrain-aucpr:0.96114+0.00066\ttest-aucpr:0.94106+0.00190\n",
            "[9]\ttrain-aucpr:0.96282+0.00091\ttest-aucpr:0.94284+0.00220\n",
            "[10]\ttrain-aucpr:0.96461+0.00050\ttest-aucpr:0.94483+0.00137\n",
            "[11]\ttrain-aucpr:0.96571+0.00053\ttest-aucpr:0.94588+0.00132\n",
            "[12]\ttrain-aucpr:0.96700+0.00040\ttest-aucpr:0.94713+0.00150\n",
            "[13]\ttrain-aucpr:0.96849+0.00033\ttest-aucpr:0.94874+0.00138\n",
            "[14]\ttrain-aucpr:0.96958+0.00049\ttest-aucpr:0.95000+0.00152\n",
            "[15]\ttrain-aucpr:0.97070+0.00055\ttest-aucpr:0.95125+0.00144\n",
            "[16]\ttrain-aucpr:0.97207+0.00040\ttest-aucpr:0.95258+0.00165\n",
            "[17]\ttrain-aucpr:0.97285+0.00050\ttest-aucpr:0.95331+0.00155\n",
            "[18]\ttrain-aucpr:0.97393+0.00033\ttest-aucpr:0.95444+0.00127\n",
            "[19]\ttrain-aucpr:0.97472+0.00036\ttest-aucpr:0.95536+0.00135\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.97840+0.00074\ttest-aucpr:0.88610+0.00421\n",
            "[1]\ttrain-aucpr:0.98741+0.00103\ttest-aucpr:0.90814+0.00437\n",
            "[2]\ttrain-aucpr:0.99218+0.00035\ttest-aucpr:0.92215+0.00327\n",
            "[3]\ttrain-aucpr:0.99426+0.00049\ttest-aucpr:0.92928+0.00324\n",
            "[4]\ttrain-aucpr:0.99565+0.00028\ttest-aucpr:0.93488+0.00200\n",
            "[5]\ttrain-aucpr:0.99672+0.00026\ttest-aucpr:0.93996+0.00305\n",
            "[6]\ttrain-aucpr:0.99755+0.00025\ttest-aucpr:0.94519+0.00383\n",
            "[7]\ttrain-aucpr:0.99805+0.00023\ttest-aucpr:0.94875+0.00386\n",
            "[8]\ttrain-aucpr:0.99843+0.00020\ttest-aucpr:0.95119+0.00414\n",
            "[9]\ttrain-aucpr:0.99875+0.00016\ttest-aucpr:0.95359+0.00378\n",
            "[10]\ttrain-aucpr:0.99897+0.00016\ttest-aucpr:0.95533+0.00355\n",
            "[11]\ttrain-aucpr:0.99911+0.00014\ttest-aucpr:0.95654+0.00332\n",
            "[12]\ttrain-aucpr:0.99925+0.00013\ttest-aucpr:0.95796+0.00301\n",
            "[13]\ttrain-aucpr:0.99936+0.00012\ttest-aucpr:0.95919+0.00297\n",
            "[14]\ttrain-aucpr:0.99946+0.00009\ttest-aucpr:0.96045+0.00278\n",
            "[15]\ttrain-aucpr:0.99954+0.00007\ttest-aucpr:0.96135+0.00282\n",
            "[16]\ttrain-aucpr:0.99960+0.00006\ttest-aucpr:0.96208+0.00281\n",
            "[17]\ttrain-aucpr:0.99966+0.00006\ttest-aucpr:0.96308+0.00237\n",
            "[18]\ttrain-aucpr:0.99970+0.00005\ttest-aucpr:0.96351+0.00239\n",
            "[19]\ttrain-aucpr:0.99975+0.00003\ttest-aucpr:0.96425+0.00220\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94299+0.00135\ttest-aucpr:0.88660+0.00189\n",
            "[1]\ttrain-aucpr:0.96164+0.00334\ttest-aucpr:0.91033+0.00436\n",
            "[2]\ttrain-aucpr:0.96932+0.00312\ttest-aucpr:0.91967+0.00355\n",
            "[3]\ttrain-aucpr:0.97710+0.00153\ttest-aucpr:0.93019+0.00288\n",
            "[4]\ttrain-aucpr:0.98201+0.00135\ttest-aucpr:0.93781+0.00359\n",
            "[5]\ttrain-aucpr:0.98515+0.00109\ttest-aucpr:0.94362+0.00333\n",
            "[6]\ttrain-aucpr:0.98717+0.00106\ttest-aucpr:0.94666+0.00341\n",
            "[7]\ttrain-aucpr:0.98883+0.00059\ttest-aucpr:0.94996+0.00230\n",
            "[8]\ttrain-aucpr:0.98998+0.00039\ttest-aucpr:0.95229+0.00191\n",
            "[9]\ttrain-aucpr:0.99086+0.00038\ttest-aucpr:0.95408+0.00163\n",
            "[10]\ttrain-aucpr:0.99156+0.00037\ttest-aucpr:0.95546+0.00145\n",
            "[11]\ttrain-aucpr:0.99231+0.00033\ttest-aucpr:0.95688+0.00136\n",
            "[12]\ttrain-aucpr:0.99289+0.00021\ttest-aucpr:0.95795+0.00102\n",
            "[13]\ttrain-aucpr:0.99343+0.00018\ttest-aucpr:0.95889+0.00102\n",
            "[14]\ttrain-aucpr:0.99391+0.00015\ttest-aucpr:0.96005+0.00094\n",
            "[15]\ttrain-aucpr:0.99432+0.00016\ttest-aucpr:0.96100+0.00100\n",
            "[16]\ttrain-aucpr:0.99473+0.00012\ttest-aucpr:0.96197+0.00096\n",
            "[17]\ttrain-aucpr:0.99506+0.00009\ttest-aucpr:0.96255+0.00085\n",
            "[18]\ttrain-aucpr:0.99536+0.00011\ttest-aucpr:0.96333+0.00084\n",
            "[19]\ttrain-aucpr:0.99561+0.00009\ttest-aucpr:0.96396+0.00093\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95368+0.00208\ttest-aucpr:0.88813+0.00280\n",
            "[1]\ttrain-aucpr:0.98001+0.00200\ttest-aucpr:0.92081+0.00258\n",
            "[2]\ttrain-aucpr:0.98918+0.00095\ttest-aucpr:0.93629+0.00300\n",
            "[3]\ttrain-aucpr:0.99311+0.00036\ttest-aucpr:0.94476+0.00192\n",
            "[4]\ttrain-aucpr:0.99540+0.00020\ttest-aucpr:0.94975+0.00160\n",
            "[5]\ttrain-aucpr:0.99668+0.00017\ttest-aucpr:0.95357+0.00117\n",
            "[6]\ttrain-aucpr:0.99758+0.00018\ttest-aucpr:0.95620+0.00130\n",
            "[7]\ttrain-aucpr:0.99822+0.00012\ttest-aucpr:0.95873+0.00109\n",
            "[8]\ttrain-aucpr:0.99864+0.00010\ttest-aucpr:0.96048+0.00114\n",
            "[9]\ttrain-aucpr:0.99897+0.00007\ttest-aucpr:0.96228+0.00105\n",
            "[10]\ttrain-aucpr:0.99921+0.00005\ttest-aucpr:0.96371+0.00115\n",
            "[11]\ttrain-aucpr:0.99939+0.00004\ttest-aucpr:0.96522+0.00112\n",
            "[12]\ttrain-aucpr:0.99954+0.00003\ttest-aucpr:0.96640+0.00096\n",
            "[13]\ttrain-aucpr:0.99965+0.00002\ttest-aucpr:0.96743+0.00090\n",
            "[14]\ttrain-aucpr:0.99973+0.00002\ttest-aucpr:0.96836+0.00088\n",
            "[15]\ttrain-aucpr:0.99979+0.00001\ttest-aucpr:0.96902+0.00094\n",
            "[16]\ttrain-aucpr:0.99984+0.00001\ttest-aucpr:0.96972+0.00096\n",
            "[17]\ttrain-aucpr:0.99988+0.00001\ttest-aucpr:0.97033+0.00085\n",
            "[18]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.97081+0.00081\n",
            "[19]\ttrain-aucpr:0.99993+0.00000\ttest-aucpr:0.97126+0.00070\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76558+0.00049\ttest-aucpr:0.75804+0.00289\n",
            "[1]\ttrain-aucpr:0.81945+0.00219\ttest-aucpr:0.81304+0.00382\n",
            "[2]\ttrain-aucpr:0.83983+0.00306\ttest-aucpr:0.83283+0.00468\n",
            "[3]\ttrain-aucpr:0.85497+0.00224\ttest-aucpr:0.84760+0.00338\n",
            "[4]\ttrain-aucpr:0.86621+0.00248\ttest-aucpr:0.85866+0.00390\n",
            "[5]\ttrain-aucpr:0.87676+0.00334\ttest-aucpr:0.86858+0.00469\n",
            "[6]\ttrain-aucpr:0.88461+0.00376\ttest-aucpr:0.87651+0.00515\n",
            "[7]\ttrain-aucpr:0.89237+0.00231\ttest-aucpr:0.88396+0.00418\n",
            "[8]\ttrain-aucpr:0.89819+0.00266\ttest-aucpr:0.88983+0.00363\n",
            "[9]\ttrain-aucpr:0.90328+0.00168\ttest-aucpr:0.89483+0.00288\n",
            "[10]\ttrain-aucpr:0.90632+0.00143\ttest-aucpr:0.89775+0.00237\n",
            "[11]\ttrain-aucpr:0.90956+0.00095\ttest-aucpr:0.90111+0.00159\n",
            "[12]\ttrain-aucpr:0.91449+0.00228\ttest-aucpr:0.90590+0.00354\n",
            "[13]\ttrain-aucpr:0.91797+0.00234\ttest-aucpr:0.90931+0.00324\n",
            "[14]\ttrain-aucpr:0.92083+0.00188\ttest-aucpr:0.91229+0.00321\n",
            "[15]\ttrain-aucpr:0.92341+0.00189\ttest-aucpr:0.91460+0.00337\n",
            "[16]\ttrain-aucpr:0.92590+0.00193\ttest-aucpr:0.91695+0.00277\n",
            "[17]\ttrain-aucpr:0.92838+0.00213\ttest-aucpr:0.91937+0.00328\n",
            "[18]\ttrain-aucpr:0.93118+0.00207\ttest-aucpr:0.92220+0.00306\n",
            "[19]\ttrain-aucpr:0.93227+0.00209\ttest-aucpr:0.92323+0.00317\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76527+0.00055\ttest-aucpr:0.75834+0.00321\n",
            "[1]\ttrain-aucpr:0.81904+0.00234\ttest-aucpr:0.81267+0.00402\n",
            "[2]\ttrain-aucpr:0.83970+0.00304\ttest-aucpr:0.83237+0.00468\n",
            "[3]\ttrain-aucpr:0.85474+0.00233\ttest-aucpr:0.84722+0.00328\n",
            "[4]\ttrain-aucpr:0.86580+0.00221\ttest-aucpr:0.85814+0.00323\n",
            "[5]\ttrain-aucpr:0.87514+0.00137\ttest-aucpr:0.86723+0.00269\n",
            "[6]\ttrain-aucpr:0.88382+0.00317\ttest-aucpr:0.87564+0.00420\n",
            "[7]\ttrain-aucpr:0.89173+0.00190\ttest-aucpr:0.88330+0.00355\n",
            "[8]\ttrain-aucpr:0.89795+0.00275\ttest-aucpr:0.88951+0.00349\n",
            "[9]\ttrain-aucpr:0.90220+0.00184\ttest-aucpr:0.89373+0.00279\n",
            "[10]\ttrain-aucpr:0.90705+0.00372\ttest-aucpr:0.89840+0.00469\n",
            "[11]\ttrain-aucpr:0.91068+0.00274\ttest-aucpr:0.90208+0.00377\n",
            "[12]\ttrain-aucpr:0.91392+0.00230\ttest-aucpr:0.90521+0.00332\n",
            "[13]\ttrain-aucpr:0.91750+0.00280\ttest-aucpr:0.90870+0.00364\n",
            "[14]\ttrain-aucpr:0.92139+0.00322\ttest-aucpr:0.91262+0.00413\n",
            "[15]\ttrain-aucpr:0.92436+0.00295\ttest-aucpr:0.91571+0.00371\n",
            "[16]\ttrain-aucpr:0.92636+0.00282\ttest-aucpr:0.91763+0.00322\n",
            "[17]\ttrain-aucpr:0.92892+0.00267\ttest-aucpr:0.92027+0.00265\n",
            "[18]\ttrain-aucpr:0.93022+0.00212\ttest-aucpr:0.92167+0.00206\n",
            "[19]\ttrain-aucpr:0.93259+0.00222\ttest-aucpr:0.92410+0.00212\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64743+0.00200\ttest-aucpr:0.64357+0.00268\n",
            "[1]\ttrain-aucpr:0.70113+0.00349\ttest-aucpr:0.69748+0.00609\n",
            "[2]\ttrain-aucpr:0.72549+0.00408\ttest-aucpr:0.72132+0.00700\n",
            "[3]\ttrain-aucpr:0.73553+0.00354\ttest-aucpr:0.73086+0.00459\n",
            "[4]\ttrain-aucpr:0.74843+0.00227\ttest-aucpr:0.74403+0.00311\n",
            "[5]\ttrain-aucpr:0.75550+0.00184\ttest-aucpr:0.75159+0.00424\n",
            "[6]\ttrain-aucpr:0.76490+0.00421\ttest-aucpr:0.76039+0.00739\n",
            "[7]\ttrain-aucpr:0.77378+0.00336\ttest-aucpr:0.76895+0.00634\n",
            "[8]\ttrain-aucpr:0.78120+0.00333\ttest-aucpr:0.77629+0.00560\n",
            "[9]\ttrain-aucpr:0.78963+0.00371\ttest-aucpr:0.78460+0.00494\n",
            "[10]\ttrain-aucpr:0.79956+0.00565\ttest-aucpr:0.79478+0.00715\n",
            "[11]\ttrain-aucpr:0.80613+0.00454\ttest-aucpr:0.80083+0.00580\n",
            "[12]\ttrain-aucpr:0.81044+0.00452\ttest-aucpr:0.80511+0.00577\n",
            "[13]\ttrain-aucpr:0.81683+0.00589\ttest-aucpr:0.81153+0.00649\n",
            "[14]\ttrain-aucpr:0.82162+0.00537\ttest-aucpr:0.81639+0.00688\n",
            "[15]\ttrain-aucpr:0.82848+0.00538\ttest-aucpr:0.82357+0.00674\n",
            "[16]\ttrain-aucpr:0.83141+0.00509\ttest-aucpr:0.82643+0.00606\n",
            "[17]\ttrain-aucpr:0.83413+0.00558\ttest-aucpr:0.82928+0.00642\n",
            "[18]\ttrain-aucpr:0.83787+0.00504\ttest-aucpr:0.83264+0.00611\n",
            "[19]\ttrain-aucpr:0.84097+0.00495\ttest-aucpr:0.83574+0.00584\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64725+0.00200\ttest-aucpr:0.64342+0.00256\n",
            "[1]\ttrain-aucpr:0.70096+0.00355\ttest-aucpr:0.69716+0.00591\n",
            "[2]\ttrain-aucpr:0.72539+0.00425\ttest-aucpr:0.72114+0.00698\n",
            "[3]\ttrain-aucpr:0.73537+0.00351\ttest-aucpr:0.73066+0.00435\n",
            "[4]\ttrain-aucpr:0.74847+0.00226\ttest-aucpr:0.74414+0.00331\n",
            "[5]\ttrain-aucpr:0.75548+0.00185\ttest-aucpr:0.75161+0.00428\n",
            "[6]\ttrain-aucpr:0.76488+0.00421\ttest-aucpr:0.76042+0.00744\n",
            "[7]\ttrain-aucpr:0.77376+0.00337\ttest-aucpr:0.76895+0.00639\n",
            "[8]\ttrain-aucpr:0.78119+0.00325\ttest-aucpr:0.77633+0.00553\n",
            "[9]\ttrain-aucpr:0.78963+0.00364\ttest-aucpr:0.78462+0.00486\n",
            "[10]\ttrain-aucpr:0.79955+0.00554\ttest-aucpr:0.79483+0.00697\n",
            "[11]\ttrain-aucpr:0.80596+0.00468\ttest-aucpr:0.80076+0.00585\n",
            "[12]\ttrain-aucpr:0.81070+0.00424\ttest-aucpr:0.80548+0.00514\n",
            "[13]\ttrain-aucpr:0.81667+0.00596\ttest-aucpr:0.81149+0.00646\n",
            "[14]\ttrain-aucpr:0.82163+0.00528\ttest-aucpr:0.81662+0.00644\n",
            "[15]\ttrain-aucpr:0.82788+0.00572\ttest-aucpr:0.82290+0.00688\n",
            "[16]\ttrain-aucpr:0.83155+0.00485\ttest-aucpr:0.82646+0.00561\n",
            "[17]\ttrain-aucpr:0.83441+0.00506\ttest-aucpr:0.82923+0.00577\n",
            "[18]\ttrain-aucpr:0.83728+0.00505\ttest-aucpr:0.83204+0.00597\n",
            "[19]\ttrain-aucpr:0.84040+0.00496\ttest-aucpr:0.83508+0.00591\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90275+0.00189\ttest-aucpr:0.87423+0.00388\n",
            "[1]\ttrain-aucpr:0.93622+0.00349\ttest-aucpr:0.91072+0.00530\n",
            "[2]\ttrain-aucpr:0.95026+0.00176\ttest-aucpr:0.92589+0.00207\n",
            "[3]\ttrain-aucpr:0.95724+0.00159\ttest-aucpr:0.93321+0.00190\n",
            "[4]\ttrain-aucpr:0.96281+0.00124\ttest-aucpr:0.93914+0.00186\n",
            "[5]\ttrain-aucpr:0.96673+0.00096\ttest-aucpr:0.94321+0.00171\n",
            "[6]\ttrain-aucpr:0.97052+0.00117\ttest-aucpr:0.94742+0.00127\n",
            "[7]\ttrain-aucpr:0.97339+0.00084\ttest-aucpr:0.95088+0.00121\n",
            "[8]\ttrain-aucpr:0.97595+0.00029\ttest-aucpr:0.95377+0.00104\n",
            "[9]\ttrain-aucpr:0.97813+0.00058\ttest-aucpr:0.95609+0.00127\n",
            "[10]\ttrain-aucpr:0.97996+0.00046\ttest-aucpr:0.95795+0.00105\n",
            "[11]\ttrain-aucpr:0.98105+0.00048\ttest-aucpr:0.95927+0.00108\n",
            "[12]\ttrain-aucpr:0.98251+0.00064\ttest-aucpr:0.96087+0.00109\n",
            "[13]\ttrain-aucpr:0.98329+0.00072\ttest-aucpr:0.96182+0.00127\n",
            "[14]\ttrain-aucpr:0.98431+0.00093\ttest-aucpr:0.96309+0.00150\n",
            "[15]\ttrain-aucpr:0.98488+0.00077\ttest-aucpr:0.96380+0.00113\n",
            "[16]\ttrain-aucpr:0.98549+0.00072\ttest-aucpr:0.96448+0.00133\n",
            "[17]\ttrain-aucpr:0.98609+0.00074\ttest-aucpr:0.96512+0.00136\n",
            "[18]\ttrain-aucpr:0.98679+0.00066\ttest-aucpr:0.96592+0.00109\n",
            "[19]\ttrain-aucpr:0.98739+0.00068\ttest-aucpr:0.96654+0.00105\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76527+0.00055\ttest-aucpr:0.75834+0.00321\n",
            "[1]\ttrain-aucpr:0.81904+0.00234\ttest-aucpr:0.81267+0.00402\n",
            "[2]\ttrain-aucpr:0.83970+0.00304\ttest-aucpr:0.83237+0.00468\n",
            "[3]\ttrain-aucpr:0.85474+0.00233\ttest-aucpr:0.84722+0.00328\n",
            "[4]\ttrain-aucpr:0.86580+0.00221\ttest-aucpr:0.85814+0.00323\n",
            "[5]\ttrain-aucpr:0.87514+0.00137\ttest-aucpr:0.86723+0.00269\n",
            "[6]\ttrain-aucpr:0.88382+0.00317\ttest-aucpr:0.87564+0.00420\n",
            "[7]\ttrain-aucpr:0.89174+0.00190\ttest-aucpr:0.88330+0.00355\n",
            "[8]\ttrain-aucpr:0.89795+0.00275\ttest-aucpr:0.88951+0.00349\n",
            "[9]\ttrain-aucpr:0.90220+0.00184\ttest-aucpr:0.89373+0.00279\n",
            "[10]\ttrain-aucpr:0.90706+0.00372\ttest-aucpr:0.89841+0.00468\n",
            "[11]\ttrain-aucpr:0.91069+0.00273\ttest-aucpr:0.90208+0.00377\n",
            "[12]\ttrain-aucpr:0.91394+0.00230\ttest-aucpr:0.90521+0.00332\n",
            "[13]\ttrain-aucpr:0.91752+0.00279\ttest-aucpr:0.90871+0.00364\n",
            "[14]\ttrain-aucpr:0.92140+0.00322\ttest-aucpr:0.91258+0.00411\n",
            "[15]\ttrain-aucpr:0.92457+0.00274\ttest-aucpr:0.91590+0.00351\n",
            "[16]\ttrain-aucpr:0.92636+0.00285\ttest-aucpr:0.91760+0.00325\n",
            "[17]\ttrain-aucpr:0.92876+0.00280\ttest-aucpr:0.91998+0.00266\n",
            "[18]\ttrain-aucpr:0.92997+0.00261\ttest-aucpr:0.92126+0.00256\n",
            "[19]\ttrain-aucpr:0.93182+0.00327\ttest-aucpr:0.92313+0.00317\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76558+0.00049\ttest-aucpr:0.75804+0.00289\n",
            "[1]\ttrain-aucpr:0.81418+0.00172\ttest-aucpr:0.80784+0.00461\n",
            "[2]\ttrain-aucpr:0.83448+0.00210\ttest-aucpr:0.82848+0.00446\n",
            "[3]\ttrain-aucpr:0.84878+0.00368\ttest-aucpr:0.84206+0.00590\n",
            "[4]\ttrain-aucpr:0.86023+0.00217\ttest-aucpr:0.85346+0.00472\n",
            "[5]\ttrain-aucpr:0.86868+0.00354\ttest-aucpr:0.86137+0.00569\n",
            "[6]\ttrain-aucpr:0.87647+0.00272\ttest-aucpr:0.86900+0.00473\n",
            "[7]\ttrain-aucpr:0.88243+0.00265\ttest-aucpr:0.87488+0.00454\n",
            "[8]\ttrain-aucpr:0.88921+0.00326\ttest-aucpr:0.88127+0.00492\n",
            "[9]\ttrain-aucpr:0.89331+0.00222\ttest-aucpr:0.88545+0.00292\n",
            "[10]\ttrain-aucpr:0.89871+0.00246\ttest-aucpr:0.89093+0.00341\n",
            "[11]\ttrain-aucpr:0.90204+0.00220\ttest-aucpr:0.89409+0.00303\n",
            "[12]\ttrain-aucpr:0.90588+0.00155\ttest-aucpr:0.89795+0.00251\n",
            "[13]\ttrain-aucpr:0.90835+0.00154\ttest-aucpr:0.90038+0.00262\n",
            "[14]\ttrain-aucpr:0.91143+0.00203\ttest-aucpr:0.90335+0.00277\n",
            "[15]\ttrain-aucpr:0.91466+0.00139\ttest-aucpr:0.90656+0.00281\n",
            "[16]\ttrain-aucpr:0.91697+0.00083\ttest-aucpr:0.90883+0.00219\n",
            "[17]\ttrain-aucpr:0.92027+0.00110\ttest-aucpr:0.91210+0.00245\n",
            "[18]\ttrain-aucpr:0.92225+0.00145\ttest-aucpr:0.91396+0.00290\n",
            "[19]\ttrain-aucpr:0.92419+0.00161\ttest-aucpr:0.91586+0.00300\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95143+0.00164\ttest-aucpr:0.88971+0.00300\n",
            "[1]\ttrain-aucpr:0.98070+0.00091\ttest-aucpr:0.92469+0.00325\n",
            "[2]\ttrain-aucpr:0.98940+0.00053\ttest-aucpr:0.93897+0.00203\n",
            "[3]\ttrain-aucpr:0.99334+0.00029\ttest-aucpr:0.94702+0.00184\n",
            "[4]\ttrain-aucpr:0.99552+0.00015\ttest-aucpr:0.95274+0.00115\n",
            "[5]\ttrain-aucpr:0.99681+0.00010\ttest-aucpr:0.95636+0.00082\n",
            "[6]\ttrain-aucpr:0.99767+0.00009\ttest-aucpr:0.95915+0.00066\n",
            "[7]\ttrain-aucpr:0.99831+0.00007\ttest-aucpr:0.96197+0.00082\n",
            "[8]\ttrain-aucpr:0.99873+0.00008\ttest-aucpr:0.96424+0.00076\n",
            "[9]\ttrain-aucpr:0.99903+0.00007\ttest-aucpr:0.96600+0.00101\n",
            "[10]\ttrain-aucpr:0.99926+0.00006\ttest-aucpr:0.96733+0.00097\n",
            "[11]\ttrain-aucpr:0.99942+0.00006\ttest-aucpr:0.96855+0.00094\n",
            "[12]\ttrain-aucpr:0.99954+0.00005\ttest-aucpr:0.96942+0.00086\n",
            "[13]\ttrain-aucpr:0.99964+0.00004\ttest-aucpr:0.97033+0.00086\n",
            "[14]\ttrain-aucpr:0.99971+0.00002\ttest-aucpr:0.97093+0.00098\n",
            "[15]\ttrain-aucpr:0.99977+0.00002\ttest-aucpr:0.97163+0.00089\n",
            "[16]\ttrain-aucpr:0.99981+0.00002\ttest-aucpr:0.97206+0.00090\n",
            "[17]\ttrain-aucpr:0.99985+0.00002\ttest-aucpr:0.97243+0.00095\n",
            "[18]\ttrain-aucpr:0.99988+0.00002\ttest-aucpr:0.97269+0.00089\n",
            "[19]\ttrain-aucpr:0.99991+0.00001\ttest-aucpr:0.97294+0.00093\n",
            "result:  0.9729393692256016\n",
            "best result:  0.9729393692256016\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76558+0.00049\ttest-aucpr:0.75805+0.00289\n",
            "[1]\ttrain-aucpr:0.80171+0.00591\ttest-aucpr:0.79546+0.00878\n",
            "[2]\ttrain-aucpr:0.81883+0.00274\ttest-aucpr:0.81246+0.00478\n",
            "[3]\ttrain-aucpr:0.82770+0.00340\ttest-aucpr:0.82123+0.00541\n",
            "[4]\ttrain-aucpr:0.83593+0.00381\ttest-aucpr:0.82916+0.00662\n",
            "[5]\ttrain-aucpr:0.84096+0.00138\ttest-aucpr:0.83418+0.00310\n",
            "[6]\ttrain-aucpr:0.84661+0.00231\ttest-aucpr:0.84001+0.00372\n",
            "[7]\ttrain-aucpr:0.85165+0.00175\ttest-aucpr:0.84488+0.00331\n",
            "[8]\ttrain-aucpr:0.85647+0.00097\ttest-aucpr:0.84965+0.00298\n",
            "[9]\ttrain-aucpr:0.86080+0.00148\ttest-aucpr:0.85410+0.00326\n",
            "[10]\ttrain-aucpr:0.86497+0.00167\ttest-aucpr:0.85824+0.00368\n",
            "[11]\ttrain-aucpr:0.86801+0.00151\ttest-aucpr:0.86121+0.00372\n",
            "[12]\ttrain-aucpr:0.87129+0.00141\ttest-aucpr:0.86441+0.00411\n",
            "[13]\ttrain-aucpr:0.87432+0.00140\ttest-aucpr:0.86721+0.00393\n",
            "[14]\ttrain-aucpr:0.87727+0.00119\ttest-aucpr:0.86998+0.00386\n",
            "[15]\ttrain-aucpr:0.88059+0.00152\ttest-aucpr:0.87336+0.00420\n",
            "[16]\ttrain-aucpr:0.88309+0.00111\ttest-aucpr:0.87598+0.00381\n",
            "[17]\ttrain-aucpr:0.88509+0.00131\ttest-aucpr:0.87798+0.00397\n",
            "[18]\ttrain-aucpr:0.88767+0.00125\ttest-aucpr:0.88066+0.00320\n",
            "[19]\ttrain-aucpr:0.88979+0.00130\ttest-aucpr:0.88268+0.00334\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90178+0.00199\ttest-aucpr:0.87428+0.00398\n",
            "[1]\ttrain-aucpr:0.93747+0.00285\ttest-aucpr:0.91222+0.00416\n",
            "[2]\ttrain-aucpr:0.95225+0.00039\ttest-aucpr:0.92861+0.00096\n",
            "[3]\ttrain-aucpr:0.95927+0.00104\ttest-aucpr:0.93614+0.00082\n",
            "[4]\ttrain-aucpr:0.96601+0.00067\ttest-aucpr:0.94335+0.00099\n",
            "[5]\ttrain-aucpr:0.96989+0.00062\ttest-aucpr:0.94789+0.00110\n",
            "[6]\ttrain-aucpr:0.97314+0.00059\ttest-aucpr:0.95191+0.00114\n",
            "[7]\ttrain-aucpr:0.97596+0.00049\ttest-aucpr:0.95488+0.00147\n",
            "[8]\ttrain-aucpr:0.97823+0.00044\ttest-aucpr:0.95773+0.00135\n",
            "[9]\ttrain-aucpr:0.97964+0.00057\ttest-aucpr:0.95962+0.00113\n",
            "[10]\ttrain-aucpr:0.98072+0.00062\ttest-aucpr:0.96092+0.00128\n",
            "[11]\ttrain-aucpr:0.98156+0.00047\ttest-aucpr:0.96186+0.00092\n",
            "[12]\ttrain-aucpr:0.98246+0.00078\ttest-aucpr:0.96295+0.00096\n",
            "[13]\ttrain-aucpr:0.98329+0.00068\ttest-aucpr:0.96394+0.00084\n",
            "[14]\ttrain-aucpr:0.98408+0.00059\ttest-aucpr:0.96509+0.00099\n",
            "[15]\ttrain-aucpr:0.98469+0.00066\ttest-aucpr:0.96586+0.00115\n",
            "[16]\ttrain-aucpr:0.98525+0.00044\ttest-aucpr:0.96646+0.00091\n",
            "[17]\ttrain-aucpr:0.98596+0.00051\ttest-aucpr:0.96719+0.00114\n",
            "[18]\ttrain-aucpr:0.98677+0.00080\ttest-aucpr:0.96778+0.00122\n",
            "[19]\ttrain-aucpr:0.98720+0.00084\ttest-aucpr:0.96805+0.00119\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.93319+0.00126\ttest-aucpr:0.88887+0.00252\n",
            "[1]\ttrain-aucpr:0.96296+0.00142\ttest-aucpr:0.92322+0.00400\n",
            "[2]\ttrain-aucpr:0.97380+0.00152\ttest-aucpr:0.93756+0.00383\n",
            "[3]\ttrain-aucpr:0.97922+0.00070\ttest-aucpr:0.94568+0.00280\n",
            "[4]\ttrain-aucpr:0.98274+0.00027\ttest-aucpr:0.95066+0.00215\n",
            "[5]\ttrain-aucpr:0.98504+0.00020\ttest-aucpr:0.95410+0.00137\n",
            "[6]\ttrain-aucpr:0.98677+0.00023\ttest-aucpr:0.95703+0.00131\n",
            "[7]\ttrain-aucpr:0.98828+0.00023\ttest-aucpr:0.95932+0.00156\n",
            "[8]\ttrain-aucpr:0.98955+0.00019\ttest-aucpr:0.96138+0.00151\n",
            "[9]\ttrain-aucpr:0.99060+0.00022\ttest-aucpr:0.96329+0.00133\n",
            "[10]\ttrain-aucpr:0.99147+0.00023\ttest-aucpr:0.96501+0.00133\n",
            "[11]\ttrain-aucpr:0.99217+0.00022\ttest-aucpr:0.96621+0.00134\n",
            "[12]\ttrain-aucpr:0.99277+0.00011\ttest-aucpr:0.96751+0.00135\n",
            "[13]\ttrain-aucpr:0.99325+0.00014\ttest-aucpr:0.96857+0.00124\n",
            "[14]\ttrain-aucpr:0.99369+0.00014\ttest-aucpr:0.96938+0.00128\n",
            "[15]\ttrain-aucpr:0.99410+0.00011\ttest-aucpr:0.97023+0.00130\n",
            "[16]\ttrain-aucpr:0.99447+0.00008\ttest-aucpr:0.97103+0.00114\n",
            "[17]\ttrain-aucpr:0.99473+0.00008\ttest-aucpr:0.97161+0.00103\n",
            "[18]\ttrain-aucpr:0.99500+0.00009\ttest-aucpr:0.97215+0.00092\n",
            "[19]\ttrain-aucpr:0.99525+0.00006\ttest-aucpr:0.97254+0.00090\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64725+0.00200\ttest-aucpr:0.64342+0.00256\n",
            "[1]\ttrain-aucpr:0.70987+0.00289\ttest-aucpr:0.70516+0.00597\n",
            "[2]\ttrain-aucpr:0.72488+0.00418\ttest-aucpr:0.72105+0.00519\n",
            "[3]\ttrain-aucpr:0.73780+0.00563\ttest-aucpr:0.73408+0.00357\n",
            "[4]\ttrain-aucpr:0.75708+0.00532\ttest-aucpr:0.75272+0.00392\n",
            "[5]\ttrain-aucpr:0.76857+0.00291\ttest-aucpr:0.76310+0.00474\n",
            "[6]\ttrain-aucpr:0.78057+0.00451\ttest-aucpr:0.77451+0.00508\n",
            "[7]\ttrain-aucpr:0.79047+0.00500\ttest-aucpr:0.78400+0.00625\n",
            "[8]\ttrain-aucpr:0.80174+0.00363\ttest-aucpr:0.79515+0.00497\n",
            "[9]\ttrain-aucpr:0.80711+0.00508\ttest-aucpr:0.80045+0.00624\n",
            "[10]\ttrain-aucpr:0.81518+0.00362\ttest-aucpr:0.80850+0.00532\n",
            "[11]\ttrain-aucpr:0.82179+0.00277\ttest-aucpr:0.81566+0.00368\n",
            "[12]\ttrain-aucpr:0.82632+0.00228\ttest-aucpr:0.82004+0.00351\n",
            "[13]\ttrain-aucpr:0.83025+0.00272\ttest-aucpr:0.82430+0.00395\n",
            "[14]\ttrain-aucpr:0.83372+0.00288\ttest-aucpr:0.82752+0.00355\n",
            "[15]\ttrain-aucpr:0.83834+0.00182\ttest-aucpr:0.83193+0.00257\n",
            "[16]\ttrain-aucpr:0.84294+0.00391\ttest-aucpr:0.83651+0.00379\n",
            "[17]\ttrain-aucpr:0.84854+0.00429\ttest-aucpr:0.84234+0.00381\n",
            "[18]\ttrain-aucpr:0.85153+0.00478\ttest-aucpr:0.84525+0.00451\n",
            "[19]\ttrain-aucpr:0.85669+0.00505\ttest-aucpr:0.85037+0.00471\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64743+0.00200\ttest-aucpr:0.64357+0.00268\n",
            "[1]\ttrain-aucpr:0.70113+0.00349\ttest-aucpr:0.69748+0.00609\n",
            "[2]\ttrain-aucpr:0.72549+0.00408\ttest-aucpr:0.72132+0.00700\n",
            "[3]\ttrain-aucpr:0.73554+0.00354\ttest-aucpr:0.73087+0.00459\n",
            "[4]\ttrain-aucpr:0.74843+0.00227\ttest-aucpr:0.74403+0.00311\n",
            "[5]\ttrain-aucpr:0.75550+0.00185\ttest-aucpr:0.75159+0.00424\n",
            "[6]\ttrain-aucpr:0.76490+0.00421\ttest-aucpr:0.76039+0.00739\n",
            "[7]\ttrain-aucpr:0.77378+0.00336\ttest-aucpr:0.76894+0.00634\n",
            "[8]\ttrain-aucpr:0.78120+0.00334\ttest-aucpr:0.77629+0.00560\n",
            "[9]\ttrain-aucpr:0.78963+0.00371\ttest-aucpr:0.78460+0.00493\n",
            "[10]\ttrain-aucpr:0.79955+0.00565\ttest-aucpr:0.79477+0.00715\n",
            "[11]\ttrain-aucpr:0.80613+0.00454\ttest-aucpr:0.80082+0.00580\n",
            "[12]\ttrain-aucpr:0.81044+0.00452\ttest-aucpr:0.80510+0.00577\n",
            "[13]\ttrain-aucpr:0.81682+0.00589\ttest-aucpr:0.81152+0.00649\n",
            "[14]\ttrain-aucpr:0.82162+0.00537\ttest-aucpr:0.81639+0.00688\n",
            "[15]\ttrain-aucpr:0.82848+0.00538\ttest-aucpr:0.82356+0.00674\n",
            "[16]\ttrain-aucpr:0.83140+0.00509\ttest-aucpr:0.82642+0.00606\n",
            "[17]\ttrain-aucpr:0.83413+0.00559\ttest-aucpr:0.82927+0.00642\n",
            "[18]\ttrain-aucpr:0.83786+0.00504\ttest-aucpr:0.83263+0.00611\n",
            "[19]\ttrain-aucpr:0.84097+0.00495\ttest-aucpr:0.83574+0.00584\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96463+0.00116\ttest-aucpr:0.88902+0.00208\n",
            "[1]\ttrain-aucpr:0.97791+0.00254\ttest-aucpr:0.91043+0.00684\n",
            "[2]\ttrain-aucpr:0.98403+0.00133\ttest-aucpr:0.92196+0.00554\n",
            "[3]\ttrain-aucpr:0.98851+0.00074\ttest-aucpr:0.93171+0.00288\n",
            "[4]\ttrain-aucpr:0.99143+0.00089\ttest-aucpr:0.93756+0.00397\n",
            "[5]\ttrain-aucpr:0.99346+0.00065\ttest-aucpr:0.94286+0.00403\n",
            "[6]\ttrain-aucpr:0.99490+0.00053\ttest-aucpr:0.94685+0.00397\n",
            "[7]\ttrain-aucpr:0.99585+0.00047\ttest-aucpr:0.94999+0.00401\n",
            "[8]\ttrain-aucpr:0.99659+0.00032\ttest-aucpr:0.95272+0.00286\n",
            "[9]\ttrain-aucpr:0.99706+0.00025\ttest-aucpr:0.95450+0.00253\n",
            "[10]\ttrain-aucpr:0.99747+0.00018\ttest-aucpr:0.95632+0.00215\n",
            "[11]\ttrain-aucpr:0.99780+0.00016\ttest-aucpr:0.95755+0.00180\n",
            "[12]\ttrain-aucpr:0.99808+0.00015\ttest-aucpr:0.95883+0.00192\n",
            "[13]\ttrain-aucpr:0.99829+0.00013\ttest-aucpr:0.95984+0.00167\n",
            "[14]\ttrain-aucpr:0.99850+0.00014\ttest-aucpr:0.96087+0.00154\n",
            "[15]\ttrain-aucpr:0.99870+0.00008\ttest-aucpr:0.96157+0.00141\n",
            "[16]\ttrain-aucpr:0.99885+0.00008\ttest-aucpr:0.96226+0.00142\n",
            "[17]\ttrain-aucpr:0.99899+0.00006\ttest-aucpr:0.96310+0.00132\n",
            "[18]\ttrain-aucpr:0.99911+0.00005\ttest-aucpr:0.96367+0.00136\n",
            "[19]\ttrain-aucpr:0.99921+0.00004\ttest-aucpr:0.96427+0.00133\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90225+0.00189\ttest-aucpr:0.87476+0.00325\n",
            "[1]\ttrain-aucpr:0.93381+0.00272\ttest-aucpr:0.90930+0.00455\n",
            "[2]\ttrain-aucpr:0.94879+0.00187\ttest-aucpr:0.92652+0.00263\n",
            "[3]\ttrain-aucpr:0.95638+0.00097\ttest-aucpr:0.93486+0.00301\n",
            "[4]\ttrain-aucpr:0.96102+0.00104\ttest-aucpr:0.93943+0.00233\n",
            "[5]\ttrain-aucpr:0.96576+0.00089\ttest-aucpr:0.94448+0.00224\n",
            "[6]\ttrain-aucpr:0.96891+0.00102\ttest-aucpr:0.94780+0.00165\n",
            "[7]\ttrain-aucpr:0.97211+0.00106\ttest-aucpr:0.95129+0.00178\n",
            "[8]\ttrain-aucpr:0.97454+0.00105\ttest-aucpr:0.95391+0.00146\n",
            "[9]\ttrain-aucpr:0.97632+0.00049\ttest-aucpr:0.95588+0.00111\n",
            "[10]\ttrain-aucpr:0.97771+0.00073\ttest-aucpr:0.95755+0.00112\n",
            "[11]\ttrain-aucpr:0.97916+0.00078\ttest-aucpr:0.95919+0.00113\n",
            "[12]\ttrain-aucpr:0.97998+0.00070\ttest-aucpr:0.96027+0.00092\n",
            "[13]\ttrain-aucpr:0.98090+0.00078\ttest-aucpr:0.96142+0.00102\n",
            "[14]\ttrain-aucpr:0.98167+0.00073\ttest-aucpr:0.96238+0.00107\n",
            "[15]\ttrain-aucpr:0.98237+0.00057\ttest-aucpr:0.96313+0.00096\n",
            "[16]\ttrain-aucpr:0.98294+0.00049\ttest-aucpr:0.96398+0.00110\n",
            "[17]\ttrain-aucpr:0.98350+0.00043\ttest-aucpr:0.96468+0.00119\n",
            "[18]\ttrain-aucpr:0.98406+0.00032\ttest-aucpr:0.96535+0.00115\n",
            "[19]\ttrain-aucpr:0.98453+0.00046\ttest-aucpr:0.96600+0.00096\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76528+0.00122\ttest-aucpr:0.75665+0.00418\n",
            "[1]\ttrain-aucpr:0.79959+0.00356\ttest-aucpr:0.79161+0.00705\n",
            "[2]\ttrain-aucpr:0.81922+0.00258\ttest-aucpr:0.81183+0.00503\n",
            "[3]\ttrain-aucpr:0.82841+0.00239\ttest-aucpr:0.82160+0.00622\n",
            "[4]\ttrain-aucpr:0.83425+0.00245\ttest-aucpr:0.82789+0.00683\n",
            "[5]\ttrain-aucpr:0.84182+0.00201\ttest-aucpr:0.83547+0.00628\n",
            "[6]\ttrain-aucpr:0.84758+0.00236\ttest-aucpr:0.84136+0.00648\n",
            "[7]\ttrain-aucpr:0.85289+0.00095\ttest-aucpr:0.84640+0.00524\n",
            "[8]\ttrain-aucpr:0.85628+0.00177\ttest-aucpr:0.84980+0.00569\n",
            "[9]\ttrain-aucpr:0.86005+0.00091\ttest-aucpr:0.85340+0.00398\n",
            "[10]\ttrain-aucpr:0.86358+0.00087\ttest-aucpr:0.85695+0.00437\n",
            "[11]\ttrain-aucpr:0.86704+0.00082\ttest-aucpr:0.86055+0.00365\n",
            "[12]\ttrain-aucpr:0.86985+0.00129\ttest-aucpr:0.86322+0.00349\n",
            "[13]\ttrain-aucpr:0.87321+0.00112\ttest-aucpr:0.86647+0.00374\n",
            "[14]\ttrain-aucpr:0.87617+0.00150\ttest-aucpr:0.86937+0.00390\n",
            "[15]\ttrain-aucpr:0.87890+0.00171\ttest-aucpr:0.87205+0.00394\n",
            "[16]\ttrain-aucpr:0.88208+0.00145\ttest-aucpr:0.87530+0.00387\n",
            "[17]\ttrain-aucpr:0.88442+0.00127\ttest-aucpr:0.87772+0.00369\n",
            "[18]\ttrain-aucpr:0.88740+0.00220\ttest-aucpr:0.88078+0.00369\n",
            "[19]\ttrain-aucpr:0.89007+0.00168\ttest-aucpr:0.88326+0.00347\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76527+0.00123\ttest-aucpr:0.75654+0.00408\n",
            "[1]\ttrain-aucpr:0.81575+0.00270\ttest-aucpr:0.80814+0.00385\n",
            "[2]\ttrain-aucpr:0.83613+0.00412\ttest-aucpr:0.82882+0.00447\n",
            "[3]\ttrain-aucpr:0.85274+0.00416\ttest-aucpr:0.84624+0.00473\n",
            "[4]\ttrain-aucpr:0.86755+0.00290\ttest-aucpr:0.86149+0.00420\n",
            "[5]\ttrain-aucpr:0.87697+0.00212\ttest-aucpr:0.87064+0.00288\n",
            "[6]\ttrain-aucpr:0.88499+0.00193\ttest-aucpr:0.87828+0.00412\n",
            "[7]\ttrain-aucpr:0.89193+0.00096\ttest-aucpr:0.88487+0.00322\n",
            "[8]\ttrain-aucpr:0.89898+0.00232\ttest-aucpr:0.89154+0.00511\n",
            "[9]\ttrain-aucpr:0.90533+0.00258\ttest-aucpr:0.89748+0.00538\n",
            "[10]\ttrain-aucpr:0.91041+0.00178\ttest-aucpr:0.90263+0.00373\n",
            "[11]\ttrain-aucpr:0.91369+0.00178\ttest-aucpr:0.90574+0.00327\n",
            "[12]\ttrain-aucpr:0.91673+0.00075\ttest-aucpr:0.90875+0.00314\n",
            "[13]\ttrain-aucpr:0.91969+0.00145\ttest-aucpr:0.91172+0.00298\n",
            "[14]\ttrain-aucpr:0.92220+0.00150\ttest-aucpr:0.91396+0.00259\n",
            "[15]\ttrain-aucpr:0.92397+0.00164\ttest-aucpr:0.91566+0.00183\n",
            "[16]\ttrain-aucpr:0.92667+0.00143\ttest-aucpr:0.91840+0.00212\n",
            "[17]\ttrain-aucpr:0.92838+0.00098\ttest-aucpr:0.92002+0.00256\n",
            "[18]\ttrain-aucpr:0.92981+0.00106\ttest-aucpr:0.92126+0.00255\n",
            "[19]\ttrain-aucpr:0.93264+0.00155\ttest-aucpr:0.92403+0.00259\n",
            "result:  0.9240326015831253\n",
            "best result:  0.9240326015831253\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95505+0.00126\ttest-aucpr:0.88979+0.00278\n",
            "[1]\ttrain-aucpr:0.98308+0.00062\ttest-aucpr:0.92367+0.00454\n",
            "[2]\ttrain-aucpr:0.99148+0.00030\ttest-aucpr:0.93860+0.00260\n",
            "[3]\ttrain-aucpr:0.99494+0.00014\ttest-aucpr:0.94739+0.00180\n",
            "[4]\ttrain-aucpr:0.99680+0.00011\ttest-aucpr:0.95232+0.00187\n",
            "[5]\ttrain-aucpr:0.99788+0.00010\ttest-aucpr:0.95624+0.00192\n",
            "[6]\ttrain-aucpr:0.99863+0.00009\ttest-aucpr:0.95887+0.00161\n",
            "[7]\ttrain-aucpr:0.99908+0.00003\ttest-aucpr:0.96150+0.00166\n",
            "[8]\ttrain-aucpr:0.99937+0.00004\ttest-aucpr:0.96345+0.00157\n",
            "[9]\ttrain-aucpr:0.99958+0.00003\ttest-aucpr:0.96513+0.00148\n",
            "[10]\ttrain-aucpr:0.99971+0.00002\ttest-aucpr:0.96654+0.00134\n",
            "[11]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.96770+0.00117\n",
            "[12]\ttrain-aucpr:0.99987+0.00001\ttest-aucpr:0.96878+0.00115\n",
            "[13]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.96961+0.00116\n",
            "[14]\ttrain-aucpr:0.99993+0.00001\ttest-aucpr:0.97047+0.00112\n",
            "[15]\ttrain-aucpr:0.99995+0.00000\ttest-aucpr:0.97108+0.00100\n",
            "[16]\ttrain-aucpr:0.99997+0.00000\ttest-aucpr:0.97150+0.00091\n",
            "[17]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97198+0.00085\n",
            "[18]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97233+0.00084\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97268+0.00095\n",
            "result:  0.9726843082087274\n",
            "best result:  0.9726843082087274\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96931+0.00070\ttest-aucpr:0.89360+0.00280\n",
            "[1]\ttrain-aucpr:0.98994+0.00085\ttest-aucpr:0.92250+0.00434\n",
            "[2]\ttrain-aucpr:0.99511+0.00036\ttest-aucpr:0.93765+0.00387\n",
            "[3]\ttrain-aucpr:0.99724+0.00015\ttest-aucpr:0.94693+0.00238\n",
            "[4]\ttrain-aucpr:0.99830+0.00006\ttest-aucpr:0.95230+0.00151\n",
            "[5]\ttrain-aucpr:0.99890+0.00004\ttest-aucpr:0.95634+0.00155\n",
            "[6]\ttrain-aucpr:0.99930+0.00006\ttest-aucpr:0.95937+0.00147\n",
            "[7]\ttrain-aucpr:0.99953+0.00003\ttest-aucpr:0.96184+0.00131\n",
            "[8]\ttrain-aucpr:0.99969+0.00002\ttest-aucpr:0.96376+0.00133\n",
            "[9]\ttrain-aucpr:0.99979+0.00001\ttest-aucpr:0.96527+0.00131\n",
            "[10]\ttrain-aucpr:0.99986+0.00000\ttest-aucpr:0.96666+0.00129\n",
            "[11]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.96783+0.00128\n",
            "[12]\ttrain-aucpr:0.99994+0.00000\ttest-aucpr:0.96880+0.00123\n",
            "[13]\ttrain-aucpr:0.99996+0.00000\ttest-aucpr:0.96960+0.00117\n",
            "[14]\ttrain-aucpr:0.99997+0.00000\ttest-aucpr:0.97042+0.00115\n",
            "[15]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97102+0.00108\n",
            "[16]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97144+0.00103\n",
            "[17]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97167+0.00094\n",
            "[18]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97204+0.00094\n",
            "[19]\ttrain-aucpr:0.99999+0.00000\ttest-aucpr:0.97238+0.00085\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95273+0.00113\ttest-aucpr:0.89067+0.00252\n",
            "[1]\ttrain-aucpr:0.97853+0.00122\ttest-aucpr:0.92207+0.00393\n",
            "[2]\ttrain-aucpr:0.98750+0.00054\ttest-aucpr:0.93739+0.00389\n",
            "[3]\ttrain-aucpr:0.99142+0.00038\ttest-aucpr:0.94512+0.00317\n",
            "[4]\ttrain-aucpr:0.99371+0.00030\ttest-aucpr:0.95039+0.00262\n",
            "[5]\ttrain-aucpr:0.99523+0.00017\ttest-aucpr:0.95454+0.00200\n",
            "[6]\ttrain-aucpr:0.99632+0.00004\ttest-aucpr:0.95779+0.00165\n",
            "[7]\ttrain-aucpr:0.99713+0.00014\ttest-aucpr:0.96028+0.00165\n",
            "[8]\ttrain-aucpr:0.99774+0.00011\ttest-aucpr:0.96239+0.00153\n",
            "[9]\ttrain-aucpr:0.99821+0.00009\ttest-aucpr:0.96400+0.00144\n",
            "[10]\ttrain-aucpr:0.99855+0.00006\ttest-aucpr:0.96545+0.00142\n",
            "[11]\ttrain-aucpr:0.99885+0.00004\ttest-aucpr:0.96667+0.00135\n",
            "[12]\ttrain-aucpr:0.99908+0.00003\ttest-aucpr:0.96768+0.00127\n",
            "[13]\ttrain-aucpr:0.99924+0.00003\ttest-aucpr:0.96864+0.00134\n",
            "[14]\ttrain-aucpr:0.99936+0.00002\ttest-aucpr:0.96949+0.00130\n",
            "[15]\ttrain-aucpr:0.99947+0.00002\ttest-aucpr:0.97016+0.00120\n",
            "[16]\ttrain-aucpr:0.99956+0.00002\ttest-aucpr:0.97093+0.00114\n",
            "[17]\ttrain-aucpr:0.99964+0.00001\ttest-aucpr:0.97158+0.00104\n",
            "[18]\ttrain-aucpr:0.99970+0.00001\ttest-aucpr:0.97212+0.00098\n",
            "[19]\ttrain-aucpr:0.99974+0.00002\ttest-aucpr:0.97263+0.00094\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76527+0.00123\ttest-aucpr:0.75655+0.00409\n",
            "[1]\ttrain-aucpr:0.79945+0.00342\ttest-aucpr:0.79149+0.00693\n",
            "[2]\ttrain-aucpr:0.81908+0.00262\ttest-aucpr:0.81169+0.00509\n",
            "[3]\ttrain-aucpr:0.82821+0.00244\ttest-aucpr:0.82152+0.00628\n",
            "[4]\ttrain-aucpr:0.83443+0.00241\ttest-aucpr:0.82840+0.00665\n",
            "[5]\ttrain-aucpr:0.84203+0.00198\ttest-aucpr:0.83594+0.00614\n",
            "[6]\ttrain-aucpr:0.84739+0.00248\ttest-aucpr:0.84127+0.00647\n",
            "[7]\ttrain-aucpr:0.85161+0.00254\ttest-aucpr:0.84520+0.00585\n",
            "[8]\ttrain-aucpr:0.85532+0.00194\ttest-aucpr:0.84894+0.00528\n",
            "[9]\ttrain-aucpr:0.85943+0.00149\ttest-aucpr:0.85352+0.00384\n",
            "[10]\ttrain-aucpr:0.86385+0.00157\ttest-aucpr:0.85803+0.00420\n",
            "[11]\ttrain-aucpr:0.86694+0.00130\ttest-aucpr:0.86100+0.00389\n",
            "[12]\ttrain-aucpr:0.86949+0.00123\ttest-aucpr:0.86329+0.00348\n",
            "[13]\ttrain-aucpr:0.87309+0.00175\ttest-aucpr:0.86660+0.00389\n",
            "[14]\ttrain-aucpr:0.87608+0.00154\ttest-aucpr:0.86958+0.00384\n",
            "[15]\ttrain-aucpr:0.87874+0.00146\ttest-aucpr:0.87220+0.00363\n",
            "[16]\ttrain-aucpr:0.88186+0.00087\ttest-aucpr:0.87536+0.00397\n",
            "[17]\ttrain-aucpr:0.88417+0.00108\ttest-aucpr:0.87776+0.00395\n",
            "[18]\ttrain-aucpr:0.88654+0.00190\ttest-aucpr:0.88023+0.00346\n",
            "[19]\ttrain-aucpr:0.88912+0.00168\ttest-aucpr:0.88274+0.00354\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64834+0.00290\ttest-aucpr:0.64546+0.00189\n",
            "[1]\ttrain-aucpr:0.71023+0.00278\ttest-aucpr:0.70584+0.00522\n",
            "[2]\ttrain-aucpr:0.72481+0.00240\ttest-aucpr:0.72112+0.00518\n",
            "[3]\ttrain-aucpr:0.74071+0.00824\ttest-aucpr:0.73743+0.01018\n",
            "[4]\ttrain-aucpr:0.75583+0.00434\ttest-aucpr:0.75231+0.00700\n",
            "[5]\ttrain-aucpr:0.77033+0.00355\ttest-aucpr:0.76556+0.00787\n",
            "[6]\ttrain-aucpr:0.78133+0.00271\ttest-aucpr:0.77655+0.00598\n",
            "[7]\ttrain-aucpr:0.79127+0.00235\ttest-aucpr:0.78634+0.00635\n",
            "[8]\ttrain-aucpr:0.80100+0.00465\ttest-aucpr:0.79567+0.00901\n",
            "[9]\ttrain-aucpr:0.81028+0.00775\ttest-aucpr:0.80488+0.01179\n",
            "[10]\ttrain-aucpr:0.81976+0.00597\ttest-aucpr:0.81386+0.01045\n",
            "[11]\ttrain-aucpr:0.82712+0.00682\ttest-aucpr:0.82132+0.01033\n",
            "[12]\ttrain-aucpr:0.83240+0.00647\ttest-aucpr:0.82660+0.00943\n",
            "[13]\ttrain-aucpr:0.83751+0.00666\ttest-aucpr:0.83156+0.00961\n",
            "[14]\ttrain-aucpr:0.84196+0.00667\ttest-aucpr:0.83601+0.01057\n",
            "[15]\ttrain-aucpr:0.84532+0.00719\ttest-aucpr:0.83933+0.01089\n",
            "[16]\ttrain-aucpr:0.84870+0.00598\ttest-aucpr:0.84269+0.01005\n",
            "[17]\ttrain-aucpr:0.85165+0.00532\ttest-aucpr:0.84573+0.00920\n",
            "[18]\ttrain-aucpr:0.85555+0.00530\ttest-aucpr:0.84955+0.00928\n",
            "[19]\ttrain-aucpr:0.85928+0.00556\ttest-aucpr:0.85328+0.00960\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76527+0.00123\ttest-aucpr:0.75655+0.00409\n",
            "[1]\ttrain-aucpr:0.81196+0.00356\ttest-aucpr:0.80501+0.00440\n",
            "[2]\ttrain-aucpr:0.83249+0.00268\ttest-aucpr:0.82593+0.00366\n",
            "[3]\ttrain-aucpr:0.84530+0.00211\ttest-aucpr:0.83832+0.00489\n",
            "[4]\ttrain-aucpr:0.85960+0.00037\ttest-aucpr:0.85273+0.00341\n",
            "[5]\ttrain-aucpr:0.86636+0.00095\ttest-aucpr:0.85917+0.00384\n",
            "[6]\ttrain-aucpr:0.87480+0.00150\ttest-aucpr:0.86750+0.00292\n",
            "[7]\ttrain-aucpr:0.88250+0.00190\ttest-aucpr:0.87511+0.00383\n",
            "[8]\ttrain-aucpr:0.88887+0.00287\ttest-aucpr:0.88138+0.00545\n",
            "[9]\ttrain-aucpr:0.89289+0.00266\ttest-aucpr:0.88550+0.00544\n",
            "[10]\ttrain-aucpr:0.89828+0.00358\ttest-aucpr:0.89108+0.00602\n",
            "[11]\ttrain-aucpr:0.90189+0.00298\ttest-aucpr:0.89475+0.00553\n",
            "[12]\ttrain-aucpr:0.90692+0.00311\ttest-aucpr:0.89954+0.00494\n",
            "[13]\ttrain-aucpr:0.90963+0.00245\ttest-aucpr:0.90237+0.00486\n",
            "[14]\ttrain-aucpr:0.91301+0.00231\ttest-aucpr:0.90568+0.00524\n",
            "[15]\ttrain-aucpr:0.91577+0.00222\ttest-aucpr:0.90826+0.00507\n",
            "[16]\ttrain-aucpr:0.91880+0.00248\ttest-aucpr:0.91129+0.00484\n",
            "[17]\ttrain-aucpr:0.92140+0.00210\ttest-aucpr:0.91376+0.00440\n",
            "[18]\ttrain-aucpr:0.92399+0.00170\ttest-aucpr:0.91615+0.00437\n",
            "[19]\ttrain-aucpr:0.92569+0.00154\ttest-aucpr:0.91779+0.00392\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90471+0.00173\ttest-aucpr:0.87485+0.00355\n",
            "[1]\ttrain-aucpr:0.93909+0.00138\ttest-aucpr:0.91225+0.00285\n",
            "[2]\ttrain-aucpr:0.95330+0.00238\ttest-aucpr:0.92816+0.00111\n",
            "[3]\ttrain-aucpr:0.96152+0.00206\ttest-aucpr:0.93695+0.00126\n",
            "[4]\ttrain-aucpr:0.96719+0.00105\ttest-aucpr:0.94286+0.00135\n",
            "[5]\ttrain-aucpr:0.97175+0.00048\ttest-aucpr:0.94810+0.00189\n",
            "[6]\ttrain-aucpr:0.97511+0.00076\ttest-aucpr:0.95124+0.00177\n",
            "[7]\ttrain-aucpr:0.97803+0.00077\ttest-aucpr:0.95472+0.00153\n",
            "[8]\ttrain-aucpr:0.97984+0.00045\ttest-aucpr:0.95690+0.00116\n",
            "[9]\ttrain-aucpr:0.98117+0.00064\ttest-aucpr:0.95848+0.00169\n",
            "[10]\ttrain-aucpr:0.98249+0.00058\ttest-aucpr:0.95979+0.00131\n",
            "[11]\ttrain-aucpr:0.98356+0.00075\ttest-aucpr:0.96121+0.00113\n",
            "[12]\ttrain-aucpr:0.98467+0.00102\ttest-aucpr:0.96254+0.00154\n",
            "[13]\ttrain-aucpr:0.98570+0.00109\ttest-aucpr:0.96366+0.00195\n",
            "[14]\ttrain-aucpr:0.98626+0.00086\ttest-aucpr:0.96434+0.00178\n",
            "[15]\ttrain-aucpr:0.98698+0.00105\ttest-aucpr:0.96509+0.00186\n",
            "[16]\ttrain-aucpr:0.98771+0.00061\ttest-aucpr:0.96577+0.00191\n",
            "[17]\ttrain-aucpr:0.98813+0.00062\ttest-aucpr:0.96612+0.00200\n",
            "[18]\ttrain-aucpr:0.98844+0.00060\ttest-aucpr:0.96636+0.00175\n",
            "[19]\ttrain-aucpr:0.98875+0.00061\ttest-aucpr:0.96661+0.00168\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64834+0.00290\ttest-aucpr:0.64546+0.00189\n",
            "[1]\ttrain-aucpr:0.68896+0.00507\ttest-aucpr:0.68607+0.00769\n",
            "[2]\ttrain-aucpr:0.70965+0.00272\ttest-aucpr:0.70645+0.00503\n",
            "[3]\ttrain-aucpr:0.71869+0.00265\ttest-aucpr:0.71515+0.00441\n",
            "[4]\ttrain-aucpr:0.72892+0.00647\ttest-aucpr:0.72542+0.00796\n",
            "[5]\ttrain-aucpr:0.73620+0.00443\ttest-aucpr:0.73280+0.00558\n",
            "[6]\ttrain-aucpr:0.74070+0.00319\ttest-aucpr:0.73706+0.00536\n",
            "[7]\ttrain-aucpr:0.74429+0.00186\ttest-aucpr:0.74092+0.00574\n",
            "[8]\ttrain-aucpr:0.74960+0.00320\ttest-aucpr:0.74644+0.00423\n",
            "[9]\ttrain-aucpr:0.75056+0.00312\ttest-aucpr:0.74739+0.00424\n",
            "[10]\ttrain-aucpr:0.75291+0.00287\ttest-aucpr:0.74975+0.00501\n",
            "[11]\ttrain-aucpr:0.75453+0.00257\ttest-aucpr:0.75129+0.00488\n",
            "[12]\ttrain-aucpr:0.75847+0.00475\ttest-aucpr:0.75527+0.00136\n",
            "[13]\ttrain-aucpr:0.76236+0.00396\ttest-aucpr:0.75926+0.00443\n",
            "[14]\ttrain-aucpr:0.76535+0.00238\ttest-aucpr:0.76203+0.00475\n",
            "[15]\ttrain-aucpr:0.76598+0.00180\ttest-aucpr:0.76250+0.00481\n",
            "[16]\ttrain-aucpr:0.77064+0.00217\ttest-aucpr:0.76676+0.00514\n",
            "[17]\ttrain-aucpr:0.77362+0.00211\ttest-aucpr:0.76958+0.00578\n",
            "[18]\ttrain-aucpr:0.77916+0.00209\ttest-aucpr:0.77491+0.00625\n",
            "[19]\ttrain-aucpr:0.78251+0.00181\ttest-aucpr:0.77828+0.00572\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76527+0.00123\ttest-aucpr:0.75655+0.00409\n",
            "[1]\ttrain-aucpr:0.79945+0.00342\ttest-aucpr:0.79149+0.00693\n",
            "[2]\ttrain-aucpr:0.81908+0.00262\ttest-aucpr:0.81169+0.00509\n",
            "[3]\ttrain-aucpr:0.82821+0.00244\ttest-aucpr:0.82152+0.00628\n",
            "[4]\ttrain-aucpr:0.83443+0.00241\ttest-aucpr:0.82840+0.00665\n",
            "[5]\ttrain-aucpr:0.84203+0.00198\ttest-aucpr:0.83594+0.00614\n",
            "[6]\ttrain-aucpr:0.84739+0.00248\ttest-aucpr:0.84127+0.00647\n",
            "[7]\ttrain-aucpr:0.85161+0.00254\ttest-aucpr:0.84520+0.00585\n",
            "[8]\ttrain-aucpr:0.85532+0.00194\ttest-aucpr:0.84894+0.00528\n",
            "[9]\ttrain-aucpr:0.85943+0.00149\ttest-aucpr:0.85352+0.00384\n",
            "[10]\ttrain-aucpr:0.86385+0.00157\ttest-aucpr:0.85803+0.00420\n",
            "[11]\ttrain-aucpr:0.86694+0.00130\ttest-aucpr:0.86100+0.00389\n",
            "[12]\ttrain-aucpr:0.86949+0.00123\ttest-aucpr:0.86329+0.00348\n",
            "[13]\ttrain-aucpr:0.87309+0.00175\ttest-aucpr:0.86660+0.00389\n",
            "[14]\ttrain-aucpr:0.87608+0.00154\ttest-aucpr:0.86958+0.00384\n",
            "[15]\ttrain-aucpr:0.87874+0.00146\ttest-aucpr:0.87220+0.00363\n",
            "[16]\ttrain-aucpr:0.88186+0.00087\ttest-aucpr:0.87536+0.00397\n",
            "[17]\ttrain-aucpr:0.88417+0.00108\ttest-aucpr:0.87776+0.00395\n",
            "[18]\ttrain-aucpr:0.88654+0.00190\ttest-aucpr:0.88023+0.00346\n",
            "[19]\ttrain-aucpr:0.88912+0.00168\ttest-aucpr:0.88274+0.00354\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89888+0.00159\ttest-aucpr:0.87294+0.00449\n",
            "[1]\ttrain-aucpr:0.92259+0.00484\ttest-aucpr:0.89802+0.00453\n",
            "[2]\ttrain-aucpr:0.93676+0.00363\ttest-aucpr:0.91463+0.00635\n",
            "[3]\ttrain-aucpr:0.94434+0.00233\ttest-aucpr:0.92254+0.00532\n",
            "[4]\ttrain-aucpr:0.94902+0.00161\ttest-aucpr:0.92767+0.00322\n",
            "[5]\ttrain-aucpr:0.95241+0.00120\ttest-aucpr:0.93150+0.00330\n",
            "[6]\ttrain-aucpr:0.95577+0.00114\ttest-aucpr:0.93526+0.00377\n",
            "[7]\ttrain-aucpr:0.95805+0.00108\ttest-aucpr:0.93766+0.00372\n",
            "[8]\ttrain-aucpr:0.96061+0.00087\ttest-aucpr:0.94056+0.00315\n",
            "[9]\ttrain-aucpr:0.96256+0.00046\ttest-aucpr:0.94292+0.00258\n",
            "[10]\ttrain-aucpr:0.96399+0.00051\ttest-aucpr:0.94452+0.00248\n",
            "[11]\ttrain-aucpr:0.96560+0.00026\ttest-aucpr:0.94619+0.00230\n",
            "[12]\ttrain-aucpr:0.96700+0.00043\ttest-aucpr:0.94761+0.00230\n",
            "[13]\ttrain-aucpr:0.96804+0.00041\ttest-aucpr:0.94865+0.00228\n",
            "[14]\ttrain-aucpr:0.96924+0.00033\ttest-aucpr:0.94998+0.00211\n",
            "[15]\ttrain-aucpr:0.97047+0.00066\ttest-aucpr:0.95124+0.00207\n",
            "[16]\ttrain-aucpr:0.97159+0.00047\ttest-aucpr:0.95247+0.00201\n",
            "[17]\ttrain-aucpr:0.97252+0.00045\ttest-aucpr:0.95351+0.00190\n",
            "[18]\ttrain-aucpr:0.97352+0.00052\ttest-aucpr:0.95459+0.00190\n",
            "[19]\ttrain-aucpr:0.97454+0.00032\ttest-aucpr:0.95564+0.00185\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.97870+0.00089\ttest-aucpr:0.88793+0.00330\n",
            "[1]\ttrain-aucpr:0.98810+0.00074\ttest-aucpr:0.91153+0.00393\n",
            "[2]\ttrain-aucpr:0.99184+0.00045\ttest-aucpr:0.92262+0.00365\n",
            "[3]\ttrain-aucpr:0.99447+0.00052\ttest-aucpr:0.93243+0.00398\n",
            "[4]\ttrain-aucpr:0.99597+0.00046\ttest-aucpr:0.93886+0.00231\n",
            "[5]\ttrain-aucpr:0.99694+0.00040\ttest-aucpr:0.94420+0.00357\n",
            "[6]\ttrain-aucpr:0.99754+0.00040\ttest-aucpr:0.94722+0.00348\n",
            "[7]\ttrain-aucpr:0.99804+0.00028\ttest-aucpr:0.95030+0.00326\n",
            "[8]\ttrain-aucpr:0.99836+0.00021\ttest-aucpr:0.95224+0.00303\n",
            "[9]\ttrain-aucpr:0.99866+0.00018\ttest-aucpr:0.95407+0.00288\n",
            "[10]\ttrain-aucpr:0.99885+0.00017\ttest-aucpr:0.95541+0.00308\n",
            "[11]\ttrain-aucpr:0.99905+0.00012\ttest-aucpr:0.95704+0.00260\n",
            "[12]\ttrain-aucpr:0.99921+0.00009\ttest-aucpr:0.95818+0.00281\n",
            "[13]\ttrain-aucpr:0.99932+0.00008\ttest-aucpr:0.95924+0.00260\n",
            "[14]\ttrain-aucpr:0.99942+0.00007\ttest-aucpr:0.96057+0.00224\n",
            "[15]\ttrain-aucpr:0.99951+0.00007\ttest-aucpr:0.96163+0.00222\n",
            "[16]\ttrain-aucpr:0.99958+0.00006\ttest-aucpr:0.96246+0.00217\n",
            "[17]\ttrain-aucpr:0.99964+0.00005\ttest-aucpr:0.96317+0.00190\n",
            "[18]\ttrain-aucpr:0.99969+0.00004\ttest-aucpr:0.96385+0.00176\n",
            "[19]\ttrain-aucpr:0.99975+0.00002\ttest-aucpr:0.96460+0.00165\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94304+0.00263\ttest-aucpr:0.88785+0.00356\n",
            "[1]\ttrain-aucpr:0.96373+0.00341\ttest-aucpr:0.91231+0.00227\n",
            "[2]\ttrain-aucpr:0.97405+0.00199\ttest-aucpr:0.92700+0.00265\n",
            "[3]\ttrain-aucpr:0.97846+0.00193\ttest-aucpr:0.93374+0.00374\n",
            "[4]\ttrain-aucpr:0.98203+0.00188\ttest-aucpr:0.93921+0.00450\n",
            "[5]\ttrain-aucpr:0.98522+0.00101\ttest-aucpr:0.94394+0.00389\n",
            "[6]\ttrain-aucpr:0.98710+0.00075\ttest-aucpr:0.94735+0.00342\n",
            "[7]\ttrain-aucpr:0.98861+0.00059\ttest-aucpr:0.94981+0.00315\n",
            "[8]\ttrain-aucpr:0.98981+0.00046\ttest-aucpr:0.95202+0.00318\n",
            "[9]\ttrain-aucpr:0.99061+0.00045\ttest-aucpr:0.95337+0.00299\n",
            "[10]\ttrain-aucpr:0.99143+0.00028\ttest-aucpr:0.95517+0.00272\n",
            "[11]\ttrain-aucpr:0.99222+0.00026\ttest-aucpr:0.95669+0.00230\n",
            "[12]\ttrain-aucpr:0.99278+0.00021\ttest-aucpr:0.95794+0.00227\n",
            "[13]\ttrain-aucpr:0.99332+0.00022\ttest-aucpr:0.95903+0.00230\n",
            "[14]\ttrain-aucpr:0.99381+0.00025\ttest-aucpr:0.96011+0.00214\n",
            "[15]\ttrain-aucpr:0.99423+0.00022\ttest-aucpr:0.96105+0.00204\n",
            "[16]\ttrain-aucpr:0.99458+0.00020\ttest-aucpr:0.96188+0.00220\n",
            "[17]\ttrain-aucpr:0.99496+0.00016\ttest-aucpr:0.96275+0.00207\n",
            "[18]\ttrain-aucpr:0.99529+0.00016\ttest-aucpr:0.96360+0.00201\n",
            "[19]\ttrain-aucpr:0.99563+0.00013\ttest-aucpr:0.96421+0.00191\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95505+0.00126\ttest-aucpr:0.88979+0.00278\n",
            "[1]\ttrain-aucpr:0.98087+0.00126\ttest-aucpr:0.92238+0.00482\n",
            "[2]\ttrain-aucpr:0.98941+0.00085\ttest-aucpr:0.93663+0.00355\n",
            "[3]\ttrain-aucpr:0.99318+0.00041\ttest-aucpr:0.94523+0.00256\n",
            "[4]\ttrain-aucpr:0.99532+0.00030\ttest-aucpr:0.95012+0.00243\n",
            "[5]\ttrain-aucpr:0.99662+0.00022\ttest-aucpr:0.95366+0.00209\n",
            "[6]\ttrain-aucpr:0.99748+0.00015\ttest-aucpr:0.95631+0.00213\n",
            "[7]\ttrain-aucpr:0.99816+0.00010\ttest-aucpr:0.95868+0.00204\n",
            "[8]\ttrain-aucpr:0.99863+0.00008\ttest-aucpr:0.96079+0.00179\n",
            "[9]\ttrain-aucpr:0.99897+0.00008\ttest-aucpr:0.96232+0.00173\n",
            "[10]\ttrain-aucpr:0.99923+0.00005\ttest-aucpr:0.96381+0.00158\n",
            "[11]\ttrain-aucpr:0.99942+0.00004\ttest-aucpr:0.96516+0.00143\n",
            "[12]\ttrain-aucpr:0.99956+0.00002\ttest-aucpr:0.96639+0.00151\n",
            "[13]\ttrain-aucpr:0.99966+0.00002\ttest-aucpr:0.96728+0.00139\n",
            "[14]\ttrain-aucpr:0.99974+0.00001\ttest-aucpr:0.96811+0.00130\n",
            "[15]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.96905+0.00124\n",
            "[16]\ttrain-aucpr:0.99985+0.00001\ttest-aucpr:0.96980+0.00121\n",
            "[17]\ttrain-aucpr:0.99989+0.00000\ttest-aucpr:0.97040+0.00117\n",
            "[18]\ttrain-aucpr:0.99991+0.00000\ttest-aucpr:0.97089+0.00114\n",
            "[19]\ttrain-aucpr:0.99993+0.00000\ttest-aucpr:0.97138+0.00112\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76529+0.00122\ttest-aucpr:0.75668+0.00419\n",
            "[1]\ttrain-aucpr:0.81592+0.00291\ttest-aucpr:0.80830+0.00418\n",
            "[2]\ttrain-aucpr:0.83633+0.00420\ttest-aucpr:0.82892+0.00451\n",
            "[3]\ttrain-aucpr:0.85313+0.00400\ttest-aucpr:0.84648+0.00469\n",
            "[4]\ttrain-aucpr:0.86672+0.00355\ttest-aucpr:0.86026+0.00410\n",
            "[5]\ttrain-aucpr:0.87847+0.00316\ttest-aucpr:0.87114+0.00236\n",
            "[6]\ttrain-aucpr:0.88692+0.00335\ttest-aucpr:0.87936+0.00249\n",
            "[7]\ttrain-aucpr:0.89353+0.00306\ttest-aucpr:0.88586+0.00194\n",
            "[8]\ttrain-aucpr:0.89882+0.00286\ttest-aucpr:0.89100+0.00221\n",
            "[9]\ttrain-aucpr:0.90441+0.00231\ttest-aucpr:0.89672+0.00262\n",
            "[10]\ttrain-aucpr:0.90895+0.00273\ttest-aucpr:0.90115+0.00321\n",
            "[11]\ttrain-aucpr:0.91174+0.00266\ttest-aucpr:0.90369+0.00254\n",
            "[12]\ttrain-aucpr:0.91669+0.00270\ttest-aucpr:0.90882+0.00232\n",
            "[13]\ttrain-aucpr:0.91909+0.00241\ttest-aucpr:0.91121+0.00223\n",
            "[14]\ttrain-aucpr:0.92199+0.00306\ttest-aucpr:0.91386+0.00304\n",
            "[15]\ttrain-aucpr:0.92403+0.00264\ttest-aucpr:0.91588+0.00234\n",
            "[16]\ttrain-aucpr:0.92603+0.00208\ttest-aucpr:0.91778+0.00257\n",
            "[17]\ttrain-aucpr:0.92834+0.00171\ttest-aucpr:0.92001+0.00191\n",
            "[18]\ttrain-aucpr:0.93065+0.00169\ttest-aucpr:0.92232+0.00176\n",
            "[19]\ttrain-aucpr:0.93321+0.00144\ttest-aucpr:0.92479+0.00203\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76527+0.00123\ttest-aucpr:0.75654+0.00408\n",
            "[1]\ttrain-aucpr:0.81571+0.00267\ttest-aucpr:0.80812+0.00384\n",
            "[2]\ttrain-aucpr:0.83608+0.00414\ttest-aucpr:0.82874+0.00445\n",
            "[3]\ttrain-aucpr:0.85289+0.00399\ttest-aucpr:0.84631+0.00471\n",
            "[4]\ttrain-aucpr:0.86799+0.00363\ttest-aucpr:0.86156+0.00426\n",
            "[5]\ttrain-aucpr:0.87844+0.00231\ttest-aucpr:0.87145+0.00235\n",
            "[6]\ttrain-aucpr:0.88593+0.00163\ttest-aucpr:0.87885+0.00243\n",
            "[7]\ttrain-aucpr:0.89385+0.00381\ttest-aucpr:0.88675+0.00311\n",
            "[8]\ttrain-aucpr:0.89963+0.00319\ttest-aucpr:0.89214+0.00384\n",
            "[9]\ttrain-aucpr:0.90579+0.00270\ttest-aucpr:0.89812+0.00354\n",
            "[10]\ttrain-aucpr:0.91026+0.00238\ttest-aucpr:0.90264+0.00322\n",
            "[11]\ttrain-aucpr:0.91306+0.00227\ttest-aucpr:0.90515+0.00257\n",
            "[12]\ttrain-aucpr:0.91660+0.00179\ttest-aucpr:0.90869+0.00265\n",
            "[13]\ttrain-aucpr:0.91919+0.00233\ttest-aucpr:0.91111+0.00228\n",
            "[14]\ttrain-aucpr:0.92164+0.00274\ttest-aucpr:0.91344+0.00195\n",
            "[15]\ttrain-aucpr:0.92464+0.00182\ttest-aucpr:0.91644+0.00323\n",
            "[16]\ttrain-aucpr:0.92737+0.00133\ttest-aucpr:0.91905+0.00314\n",
            "[17]\ttrain-aucpr:0.92956+0.00222\ttest-aucpr:0.92134+0.00352\n",
            "[18]\ttrain-aucpr:0.93154+0.00265\ttest-aucpr:0.92307+0.00352\n",
            "[19]\ttrain-aucpr:0.93295+0.00260\ttest-aucpr:0.92435+0.00338\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64834+0.00290\ttest-aucpr:0.64546+0.00189\n",
            "[1]\ttrain-aucpr:0.69565+0.00240\ttest-aucpr:0.69225+0.00310\n",
            "[2]\ttrain-aucpr:0.72090+0.00486\ttest-aucpr:0.71680+0.00380\n",
            "[3]\ttrain-aucpr:0.73653+0.00315\ttest-aucpr:0.73138+0.00303\n",
            "[4]\ttrain-aucpr:0.74696+0.00197\ttest-aucpr:0.74224+0.00466\n",
            "[5]\ttrain-aucpr:0.75238+0.00300\ttest-aucpr:0.74792+0.00630\n",
            "[6]\ttrain-aucpr:0.76412+0.00481\ttest-aucpr:0.75929+0.00749\n",
            "[7]\ttrain-aucpr:0.77155+0.00430\ttest-aucpr:0.76658+0.00695\n",
            "[8]\ttrain-aucpr:0.78197+0.00353\ttest-aucpr:0.77690+0.00656\n",
            "[9]\ttrain-aucpr:0.78700+0.00417\ttest-aucpr:0.78184+0.00575\n",
            "[10]\ttrain-aucpr:0.79259+0.00503\ttest-aucpr:0.78743+0.00819\n",
            "[11]\ttrain-aucpr:0.79799+0.00421\ttest-aucpr:0.79290+0.00726\n",
            "[12]\ttrain-aucpr:0.80640+0.00259\ttest-aucpr:0.80110+0.00654\n",
            "[13]\ttrain-aucpr:0.81217+0.00253\ttest-aucpr:0.80714+0.00598\n",
            "[14]\ttrain-aucpr:0.81651+0.00274\ttest-aucpr:0.81159+0.00638\n",
            "[15]\ttrain-aucpr:0.82043+0.00223\ttest-aucpr:0.81530+0.00548\n",
            "[16]\ttrain-aucpr:0.82455+0.00194\ttest-aucpr:0.81909+0.00508\n",
            "[17]\ttrain-aucpr:0.82982+0.00248\ttest-aucpr:0.82445+0.00351\n",
            "[18]\ttrain-aucpr:0.83419+0.00242\ttest-aucpr:0.82867+0.00389\n",
            "[19]\ttrain-aucpr:0.83834+0.00275\ttest-aucpr:0.83302+0.00384\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64834+0.00290\ttest-aucpr:0.64546+0.00189\n",
            "[1]\ttrain-aucpr:0.69566+0.00240\ttest-aucpr:0.69228+0.00308\n",
            "[2]\ttrain-aucpr:0.72089+0.00487\ttest-aucpr:0.71679+0.00380\n",
            "[3]\ttrain-aucpr:0.73653+0.00314\ttest-aucpr:0.73139+0.00303\n",
            "[4]\ttrain-aucpr:0.74696+0.00197\ttest-aucpr:0.74224+0.00467\n",
            "[5]\ttrain-aucpr:0.75237+0.00300\ttest-aucpr:0.74790+0.00631\n",
            "[6]\ttrain-aucpr:0.76410+0.00481\ttest-aucpr:0.75928+0.00750\n",
            "[7]\ttrain-aucpr:0.77152+0.00430\ttest-aucpr:0.76656+0.00694\n",
            "[8]\ttrain-aucpr:0.78192+0.00350\ttest-aucpr:0.77689+0.00659\n",
            "[9]\ttrain-aucpr:0.78729+0.00490\ttest-aucpr:0.78220+0.00676\n",
            "[10]\ttrain-aucpr:0.79339+0.00457\ttest-aucpr:0.78842+0.00789\n",
            "[11]\ttrain-aucpr:0.79946+0.00322\ttest-aucpr:0.79425+0.00667\n",
            "[12]\ttrain-aucpr:0.80581+0.00376\ttest-aucpr:0.80041+0.00782\n",
            "[13]\ttrain-aucpr:0.81107+0.00291\ttest-aucpr:0.80564+0.00698\n",
            "[14]\ttrain-aucpr:0.81586+0.00297\ttest-aucpr:0.81056+0.00711\n",
            "[15]\ttrain-aucpr:0.82199+0.00538\ttest-aucpr:0.81658+0.00827\n",
            "[16]\ttrain-aucpr:0.82603+0.00595\ttest-aucpr:0.82033+0.00859\n",
            "[17]\ttrain-aucpr:0.83051+0.00587\ttest-aucpr:0.82481+0.00761\n",
            "[18]\ttrain-aucpr:0.83576+0.00470\ttest-aucpr:0.83004+0.00666\n",
            "[19]\ttrain-aucpr:0.84026+0.00291\ttest-aucpr:0.83450+0.00652\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90335+0.00190\ttest-aucpr:0.87476+0.00332\n",
            "[1]\ttrain-aucpr:0.93514+0.00262\ttest-aucpr:0.90924+0.00439\n",
            "[2]\ttrain-aucpr:0.95013+0.00171\ttest-aucpr:0.92573+0.00233\n",
            "[3]\ttrain-aucpr:0.95770+0.00077\ttest-aucpr:0.93399+0.00243\n",
            "[4]\ttrain-aucpr:0.96250+0.00108\ttest-aucpr:0.93887+0.00214\n",
            "[5]\ttrain-aucpr:0.96743+0.00091\ttest-aucpr:0.94416+0.00197\n",
            "[6]\ttrain-aucpr:0.97100+0.00065\ttest-aucpr:0.94817+0.00196\n",
            "[7]\ttrain-aucpr:0.97415+0.00106\ttest-aucpr:0.95175+0.00156\n",
            "[8]\ttrain-aucpr:0.97642+0.00102\ttest-aucpr:0.95406+0.00164\n",
            "[9]\ttrain-aucpr:0.97867+0.00064\ttest-aucpr:0.95644+0.00121\n",
            "[10]\ttrain-aucpr:0.98033+0.00068\ttest-aucpr:0.95815+0.00132\n",
            "[11]\ttrain-aucpr:0.98166+0.00041\ttest-aucpr:0.95964+0.00168\n",
            "[12]\ttrain-aucpr:0.98268+0.00050\ttest-aucpr:0.96083+0.00152\n",
            "[13]\ttrain-aucpr:0.98362+0.00048\ttest-aucpr:0.96194+0.00147\n",
            "[14]\ttrain-aucpr:0.98447+0.00056\ttest-aucpr:0.96283+0.00171\n",
            "[15]\ttrain-aucpr:0.98519+0.00068\ttest-aucpr:0.96385+0.00160\n",
            "[16]\ttrain-aucpr:0.98571+0.00076\ttest-aucpr:0.96447+0.00168\n",
            "[17]\ttrain-aucpr:0.98642+0.00047\ttest-aucpr:0.96532+0.00145\n",
            "[18]\ttrain-aucpr:0.98709+0.00035\ttest-aucpr:0.96605+0.00148\n",
            "[19]\ttrain-aucpr:0.98747+0.00022\ttest-aucpr:0.96656+0.00149\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76527+0.00123\ttest-aucpr:0.75654+0.00408\n",
            "[1]\ttrain-aucpr:0.81571+0.00267\ttest-aucpr:0.80812+0.00384\n",
            "[2]\ttrain-aucpr:0.83608+0.00414\ttest-aucpr:0.82874+0.00445\n",
            "[3]\ttrain-aucpr:0.85289+0.00399\ttest-aucpr:0.84631+0.00471\n",
            "[4]\ttrain-aucpr:0.86799+0.00363\ttest-aucpr:0.86156+0.00426\n",
            "[5]\ttrain-aucpr:0.87844+0.00231\ttest-aucpr:0.87145+0.00234\n",
            "[6]\ttrain-aucpr:0.88594+0.00163\ttest-aucpr:0.87884+0.00244\n",
            "[7]\ttrain-aucpr:0.89386+0.00380\ttest-aucpr:0.88674+0.00311\n",
            "[8]\ttrain-aucpr:0.89963+0.00319\ttest-aucpr:0.89212+0.00387\n",
            "[9]\ttrain-aucpr:0.90578+0.00270\ttest-aucpr:0.89807+0.00361\n",
            "[10]\ttrain-aucpr:0.91027+0.00239\ttest-aucpr:0.90261+0.00330\n",
            "[11]\ttrain-aucpr:0.91307+0.00226\ttest-aucpr:0.90512+0.00266\n",
            "[12]\ttrain-aucpr:0.91671+0.00197\ttest-aucpr:0.90885+0.00271\n",
            "[13]\ttrain-aucpr:0.91909+0.00207\ttest-aucpr:0.91110+0.00224\n",
            "[14]\ttrain-aucpr:0.92163+0.00232\ttest-aucpr:0.91327+0.00185\n",
            "[15]\ttrain-aucpr:0.92462+0.00160\ttest-aucpr:0.91618+0.00254\n",
            "[16]\ttrain-aucpr:0.92718+0.00127\ttest-aucpr:0.91880+0.00255\n",
            "[17]\ttrain-aucpr:0.92983+0.00256\ttest-aucpr:0.92131+0.00287\n",
            "[18]\ttrain-aucpr:0.93154+0.00308\ttest-aucpr:0.92285+0.00339\n",
            "[19]\ttrain-aucpr:0.93344+0.00315\ttest-aucpr:0.92470+0.00232\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76529+0.00122\ttest-aucpr:0.75668+0.00419\n",
            "[1]\ttrain-aucpr:0.81197+0.00357\ttest-aucpr:0.80497+0.00457\n",
            "[2]\ttrain-aucpr:0.83230+0.00261\ttest-aucpr:0.82590+0.00375\n",
            "[3]\ttrain-aucpr:0.84528+0.00217\ttest-aucpr:0.83850+0.00474\n",
            "[4]\ttrain-aucpr:0.85959+0.00036\ttest-aucpr:0.85290+0.00329\n",
            "[5]\ttrain-aucpr:0.86657+0.00096\ttest-aucpr:0.85933+0.00363\n",
            "[6]\ttrain-aucpr:0.87500+0.00158\ttest-aucpr:0.86767+0.00272\n",
            "[7]\ttrain-aucpr:0.88219+0.00200\ttest-aucpr:0.87489+0.00347\n",
            "[8]\ttrain-aucpr:0.88836+0.00159\ttest-aucpr:0.88074+0.00377\n",
            "[9]\ttrain-aucpr:0.89222+0.00152\ttest-aucpr:0.88449+0.00428\n",
            "[10]\ttrain-aucpr:0.89663+0.00101\ttest-aucpr:0.88909+0.00418\n",
            "[11]\ttrain-aucpr:0.90048+0.00116\ttest-aucpr:0.89271+0.00363\n",
            "[12]\ttrain-aucpr:0.90476+0.00131\ttest-aucpr:0.89661+0.00371\n",
            "[13]\ttrain-aucpr:0.90782+0.00114\ttest-aucpr:0.89956+0.00432\n",
            "[14]\ttrain-aucpr:0.91102+0.00126\ttest-aucpr:0.90265+0.00435\n",
            "[15]\ttrain-aucpr:0.91380+0.00143\ttest-aucpr:0.90534+0.00449\n",
            "[16]\ttrain-aucpr:0.91594+0.00142\ttest-aucpr:0.90751+0.00412\n",
            "[17]\ttrain-aucpr:0.91925+0.00073\ttest-aucpr:0.91087+0.00362\n",
            "[18]\ttrain-aucpr:0.92136+0.00094\ttest-aucpr:0.91295+0.00404\n",
            "[19]\ttrain-aucpr:0.92333+0.00087\ttest-aucpr:0.91502+0.00337\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95273+0.00113\ttest-aucpr:0.89067+0.00252\n",
            "[1]\ttrain-aucpr:0.98061+0.00079\ttest-aucpr:0.92449+0.00403\n",
            "[2]\ttrain-aucpr:0.98945+0.00041\ttest-aucpr:0.93959+0.00286\n",
            "[3]\ttrain-aucpr:0.99306+0.00025\ttest-aucpr:0.94797+0.00256\n",
            "[4]\ttrain-aucpr:0.99532+0.00025\ttest-aucpr:0.95358+0.00263\n",
            "[5]\ttrain-aucpr:0.99668+0.00012\ttest-aucpr:0.95732+0.00231\n",
            "[6]\ttrain-aucpr:0.99764+0.00011\ttest-aucpr:0.96008+0.00209\n",
            "[7]\ttrain-aucpr:0.99828+0.00012\ttest-aucpr:0.96244+0.00179\n",
            "[8]\ttrain-aucpr:0.99876+0.00007\ttest-aucpr:0.96447+0.00160\n",
            "[9]\ttrain-aucpr:0.99907+0.00004\ttest-aucpr:0.96612+0.00149\n",
            "[10]\ttrain-aucpr:0.99928+0.00005\ttest-aucpr:0.96749+0.00126\n",
            "[11]\ttrain-aucpr:0.99944+0.00005\ttest-aucpr:0.96866+0.00140\n",
            "[12]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.96969+0.00117\n",
            "[13]\ttrain-aucpr:0.99966+0.00003\ttest-aucpr:0.97055+0.00109\n",
            "[14]\ttrain-aucpr:0.99973+0.00002\ttest-aucpr:0.97109+0.00110\n",
            "[15]\ttrain-aucpr:0.99979+0.00002\ttest-aucpr:0.97163+0.00110\n",
            "[16]\ttrain-aucpr:0.99983+0.00002\ttest-aucpr:0.97212+0.00099\n",
            "[17]\ttrain-aucpr:0.99987+0.00002\ttest-aucpr:0.97235+0.00105\n",
            "[18]\ttrain-aucpr:0.99990+0.00001\ttest-aucpr:0.97272+0.00103\n",
            "[19]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.97302+0.00094\n",
            "result:  0.9730231212641547\n",
            "best result:  0.9730231212641547\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76527+0.00123\ttest-aucpr:0.75655+0.00409\n",
            "[1]\ttrain-aucpr:0.79945+0.00342\ttest-aucpr:0.79149+0.00693\n",
            "[2]\ttrain-aucpr:0.81909+0.00262\ttest-aucpr:0.81169+0.00509\n",
            "[3]\ttrain-aucpr:0.82822+0.00243\ttest-aucpr:0.82154+0.00628\n",
            "[4]\ttrain-aucpr:0.83443+0.00241\ttest-aucpr:0.82840+0.00665\n",
            "[5]\ttrain-aucpr:0.84204+0.00197\ttest-aucpr:0.83595+0.00614\n",
            "[6]\ttrain-aucpr:0.84736+0.00253\ttest-aucpr:0.84126+0.00649\n",
            "[7]\ttrain-aucpr:0.85185+0.00211\ttest-aucpr:0.84546+0.00563\n",
            "[8]\ttrain-aucpr:0.85555+0.00176\ttest-aucpr:0.84919+0.00522\n",
            "[9]\ttrain-aucpr:0.85983+0.00114\ttest-aucpr:0.85390+0.00374\n",
            "[10]\ttrain-aucpr:0.86393+0.00152\ttest-aucpr:0.85818+0.00418\n",
            "[11]\ttrain-aucpr:0.86727+0.00106\ttest-aucpr:0.86142+0.00384\n",
            "[12]\ttrain-aucpr:0.86990+0.00095\ttest-aucpr:0.86380+0.00345\n",
            "[13]\ttrain-aucpr:0.87351+0.00125\ttest-aucpr:0.86715+0.00373\n",
            "[14]\ttrain-aucpr:0.87636+0.00127\ttest-aucpr:0.86991+0.00377\n",
            "[15]\ttrain-aucpr:0.87890+0.00137\ttest-aucpr:0.87242+0.00361\n",
            "[16]\ttrain-aucpr:0.88142+0.00131\ttest-aucpr:0.87502+0.00401\n",
            "[17]\ttrain-aucpr:0.88389+0.00124\ttest-aucpr:0.87749+0.00396\n",
            "[18]\ttrain-aucpr:0.88571+0.00212\ttest-aucpr:0.87943+0.00359\n",
            "[19]\ttrain-aucpr:0.88872+0.00256\ttest-aucpr:0.88232+0.00377\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90225+0.00189\ttest-aucpr:0.87476+0.00325\n",
            "[1]\ttrain-aucpr:0.93666+0.00146\ttest-aucpr:0.91245+0.00422\n",
            "[2]\ttrain-aucpr:0.95160+0.00224\ttest-aucpr:0.92869+0.00300\n",
            "[3]\ttrain-aucpr:0.96043+0.00081\ttest-aucpr:0.93752+0.00272\n",
            "[4]\ttrain-aucpr:0.96636+0.00095\ttest-aucpr:0.94389+0.00301\n",
            "[5]\ttrain-aucpr:0.97020+0.00084\ttest-aucpr:0.94824+0.00267\n",
            "[6]\ttrain-aucpr:0.97374+0.00074\ttest-aucpr:0.95218+0.00215\n",
            "[7]\ttrain-aucpr:0.97636+0.00105\ttest-aucpr:0.95525+0.00205\n",
            "[8]\ttrain-aucpr:0.97848+0.00095\ttest-aucpr:0.95749+0.00196\n",
            "[9]\ttrain-aucpr:0.97969+0.00074\ttest-aucpr:0.95914+0.00189\n",
            "[10]\ttrain-aucpr:0.98084+0.00088\ttest-aucpr:0.96059+0.00189\n",
            "[11]\ttrain-aucpr:0.98210+0.00073\ttest-aucpr:0.96213+0.00145\n",
            "[12]\ttrain-aucpr:0.98265+0.00085\ttest-aucpr:0.96312+0.00111\n",
            "[13]\ttrain-aucpr:0.98345+0.00054\ttest-aucpr:0.96397+0.00141\n",
            "[14]\ttrain-aucpr:0.98454+0.00047\ttest-aucpr:0.96513+0.00147\n",
            "[15]\ttrain-aucpr:0.98528+0.00043\ttest-aucpr:0.96570+0.00122\n",
            "[16]\ttrain-aucpr:0.98582+0.00040\ttest-aucpr:0.96638+0.00141\n",
            "[17]\ttrain-aucpr:0.98638+0.00035\ttest-aucpr:0.96695+0.00157\n",
            "[18]\ttrain-aucpr:0.98671+0.00029\ttest-aucpr:0.96722+0.00148\n",
            "[19]\ttrain-aucpr:0.98728+0.00028\ttest-aucpr:0.96757+0.00135\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.93334+0.00277\ttest-aucpr:0.88956+0.00341\n",
            "[1]\ttrain-aucpr:0.96222+0.00218\ttest-aucpr:0.92371+0.00493\n",
            "[2]\ttrain-aucpr:0.97439+0.00097\ttest-aucpr:0.93886+0.00323\n",
            "[3]\ttrain-aucpr:0.97939+0.00067\ttest-aucpr:0.94590+0.00276\n",
            "[4]\ttrain-aucpr:0.98278+0.00049\ttest-aucpr:0.95158+0.00189\n",
            "[5]\ttrain-aucpr:0.98511+0.00045\ttest-aucpr:0.95497+0.00196\n",
            "[6]\ttrain-aucpr:0.98687+0.00027\ttest-aucpr:0.95786+0.00164\n",
            "[7]\ttrain-aucpr:0.98830+0.00018\ttest-aucpr:0.96020+0.00156\n",
            "[8]\ttrain-aucpr:0.98945+0.00013\ttest-aucpr:0.96201+0.00153\n",
            "[9]\ttrain-aucpr:0.99043+0.00017\ttest-aucpr:0.96375+0.00144\n",
            "[10]\ttrain-aucpr:0.99132+0.00014\ttest-aucpr:0.96524+0.00146\n",
            "[11]\ttrain-aucpr:0.99204+0.00015\ttest-aucpr:0.96679+0.00125\n",
            "[12]\ttrain-aucpr:0.99274+0.00018\ttest-aucpr:0.96799+0.00111\n",
            "[13]\ttrain-aucpr:0.99323+0.00016\ttest-aucpr:0.96888+0.00105\n",
            "[14]\ttrain-aucpr:0.99368+0.00013\ttest-aucpr:0.96974+0.00084\n",
            "[15]\ttrain-aucpr:0.99401+0.00008\ttest-aucpr:0.97034+0.00086\n",
            "[16]\ttrain-aucpr:0.99439+0.00011\ttest-aucpr:0.97094+0.00082\n",
            "[17]\ttrain-aucpr:0.99470+0.00012\ttest-aucpr:0.97136+0.00083\n",
            "[18]\ttrain-aucpr:0.99491+0.00017\ttest-aucpr:0.97191+0.00079\n",
            "[19]\ttrain-aucpr:0.99517+0.00020\ttest-aucpr:0.97241+0.00080\n",
            "{'objective': 'binary:logistic', 'eta': 0.35, 'max_depth': 3, 'gamma': 1, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64834+0.00290\ttest-aucpr:0.64546+0.00189\n",
            "[1]\ttrain-aucpr:0.71023+0.00278\ttest-aucpr:0.70584+0.00522\n",
            "[2]\ttrain-aucpr:0.72479+0.00241\ttest-aucpr:0.72112+0.00518\n",
            "[3]\ttrain-aucpr:0.74071+0.00825\ttest-aucpr:0.73744+0.01019\n",
            "[4]\ttrain-aucpr:0.75592+0.00438\ttest-aucpr:0.75242+0.00702\n",
            "[5]\ttrain-aucpr:0.77044+0.00362\ttest-aucpr:0.76566+0.00789\n",
            "[6]\ttrain-aucpr:0.78149+0.00267\ttest-aucpr:0.77668+0.00600\n",
            "[7]\ttrain-aucpr:0.79143+0.00242\ttest-aucpr:0.78647+0.00640\n",
            "[8]\ttrain-aucpr:0.80116+0.00461\ttest-aucpr:0.79584+0.00902\n",
            "[9]\ttrain-aucpr:0.81043+0.00776\ttest-aucpr:0.80504+0.01176\n",
            "[10]\ttrain-aucpr:0.81990+0.00591\ttest-aucpr:0.81402+0.01038\n",
            "[11]\ttrain-aucpr:0.82721+0.00666\ttest-aucpr:0.82132+0.01008\n",
            "[12]\ttrain-aucpr:0.83186+0.00608\ttest-aucpr:0.82601+0.00929\n",
            "[13]\ttrain-aucpr:0.83641+0.00521\ttest-aucpr:0.83030+0.00842\n",
            "[14]\ttrain-aucpr:0.84094+0.00486\ttest-aucpr:0.83478+0.00886\n",
            "[15]\ttrain-aucpr:0.84446+0.00548\ttest-aucpr:0.83830+0.00906\n",
            "[16]\ttrain-aucpr:0.84821+0.00404\ttest-aucpr:0.84199+0.00816\n",
            "[17]\ttrain-aucpr:0.85238+0.00426\ttest-aucpr:0.84633+0.00795\n",
            "[18]\ttrain-aucpr:0.85553+0.00375\ttest-aucpr:0.84933+0.00798\n",
            "[19]\ttrain-aucpr:0.85879+0.00440\ttest-aucpr:0.85247+0.00920\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64834+0.00290\ttest-aucpr:0.64546+0.00189\n",
            "[1]\ttrain-aucpr:0.69565+0.00240\ttest-aucpr:0.69225+0.00310\n",
            "[2]\ttrain-aucpr:0.72090+0.00486\ttest-aucpr:0.71680+0.00380\n",
            "[3]\ttrain-aucpr:0.73653+0.00315\ttest-aucpr:0.73138+0.00303\n",
            "[4]\ttrain-aucpr:0.74696+0.00197\ttest-aucpr:0.74224+0.00466\n",
            "[5]\ttrain-aucpr:0.75238+0.00300\ttest-aucpr:0.74792+0.00630\n",
            "[6]\ttrain-aucpr:0.76411+0.00481\ttest-aucpr:0.75929+0.00749\n",
            "[7]\ttrain-aucpr:0.77155+0.00430\ttest-aucpr:0.76658+0.00695\n",
            "[8]\ttrain-aucpr:0.78197+0.00353\ttest-aucpr:0.77690+0.00656\n",
            "[9]\ttrain-aucpr:0.78700+0.00417\ttest-aucpr:0.78183+0.00575\n",
            "[10]\ttrain-aucpr:0.79258+0.00503\ttest-aucpr:0.78742+0.00818\n",
            "[11]\ttrain-aucpr:0.79799+0.00421\ttest-aucpr:0.79290+0.00726\n",
            "[12]\ttrain-aucpr:0.80639+0.00259\ttest-aucpr:0.80110+0.00654\n",
            "[13]\ttrain-aucpr:0.81216+0.00253\ttest-aucpr:0.80713+0.00598\n",
            "[14]\ttrain-aucpr:0.81650+0.00275\ttest-aucpr:0.81159+0.00638\n",
            "[15]\ttrain-aucpr:0.82042+0.00223\ttest-aucpr:0.81530+0.00548\n",
            "[16]\ttrain-aucpr:0.82454+0.00194\ttest-aucpr:0.81909+0.00508\n",
            "[17]\ttrain-aucpr:0.82982+0.00248\ttest-aucpr:0.82444+0.00351\n",
            "[18]\ttrain-aucpr:0.83418+0.00242\ttest-aucpr:0.82867+0.00389\n",
            "[19]\ttrain-aucpr:0.83833+0.00275\ttest-aucpr:0.83302+0.00384\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96367+0.00058\ttest-aucpr:0.88928+0.00230\n",
            "[1]\ttrain-aucpr:0.97865+0.00237\ttest-aucpr:0.91413+0.00414\n",
            "[2]\ttrain-aucpr:0.98482+0.00117\ttest-aucpr:0.92677+0.00330\n",
            "[3]\ttrain-aucpr:0.98906+0.00081\ttest-aucpr:0.93488+0.00298\n",
            "[4]\ttrain-aucpr:0.99185+0.00065\ttest-aucpr:0.94059+0.00398\n",
            "[5]\ttrain-aucpr:0.99368+0.00049\ttest-aucpr:0.94533+0.00296\n",
            "[6]\ttrain-aucpr:0.99483+0.00031\ttest-aucpr:0.94808+0.00313\n",
            "[7]\ttrain-aucpr:0.99570+0.00028\ttest-aucpr:0.95064+0.00311\n",
            "[8]\ttrain-aucpr:0.99638+0.00022\ttest-aucpr:0.95297+0.00255\n",
            "[9]\ttrain-aucpr:0.99690+0.00019\ttest-aucpr:0.95439+0.00300\n",
            "[10]\ttrain-aucpr:0.99743+0.00012\ttest-aucpr:0.95610+0.00256\n",
            "[11]\ttrain-aucpr:0.99777+0.00009\ttest-aucpr:0.95726+0.00218\n",
            "[12]\ttrain-aucpr:0.99802+0.00010\ttest-aucpr:0.95856+0.00208\n",
            "[13]\ttrain-aucpr:0.99825+0.00009\ttest-aucpr:0.95965+0.00191\n",
            "[14]\ttrain-aucpr:0.99847+0.00009\ttest-aucpr:0.96071+0.00192\n",
            "[15]\ttrain-aucpr:0.99862+0.00011\ttest-aucpr:0.96147+0.00194\n",
            "[16]\ttrain-aucpr:0.99883+0.00007\ttest-aucpr:0.96235+0.00180\n",
            "[17]\ttrain-aucpr:0.99896+0.00007\ttest-aucpr:0.96311+0.00186\n",
            "[18]\ttrain-aucpr:0.99910+0.00006\ttest-aucpr:0.96374+0.00184\n",
            "[19]\ttrain-aucpr:0.99922+0.00004\ttest-aucpr:0.96446+0.00172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "id": "xXJEj4W_8T-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5142a3-b4af-4af9-9112-7aa425b9de85"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'objective': 'binary:logistic',\n",
              " 'eta': 0.35,\n",
              " 'max_depth': 20,\n",
              " 'gamma': 1,\n",
              " 'lambda': 3,\n",
              " 'alpha': 0.0,\n",
              " 'eval_metric': 'aucpr'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aucpr_params = {'objective': 'binary:logistic',\n",
        "         'eta': 0.35,\n",
        "         'max_depth': 20,\n",
        "         'gamma': 1,\n",
        "         'lambda': 3,\n",
        "         'alpha': 0,\n",
        "         'eval_metric': 'aucpr'}"
      ],
      "metadata": {
        "id": "_RjSFnb1SXl7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_results = {}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "    dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "    dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "    evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "    tr=xgb.train(params=aucpr_params,\n",
        "                 num_boost_round=222,\n",
        "                 dtrain=dtrain,\n",
        "                 verbose_eval=1,\n",
        "                 evals=evallist,\n",
        "                 early_stopping_rounds = 3\n",
        "             )\n",
        "\n",
        "    preds_XGB = np.round(tr.predict(dtest), 0)\n",
        "\n",
        "    classification_report(y[test_index],np.round(preds_XGB, 0),output_dict=True)\n",
        "    fold_results.update({i:{'predictions':preds_XGB,'index':test_index,'y_true':y[test_index]}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQFpdGo4cZNV",
        "outputId": "00ae59e0-d006-4a88-d4a1-260877e0dd1c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-aucpr:0.95451\teval-aucpr:0.89678\n",
            "[1]\ttrain-aucpr:0.98137\teval-aucpr:0.93020\n",
            "[2]\ttrain-aucpr:0.98963\teval-aucpr:0.94414\n",
            "[3]\ttrain-aucpr:0.99313\teval-aucpr:0.95214\n",
            "[4]\ttrain-aucpr:0.99546\teval-aucpr:0.95807\n",
            "[5]\ttrain-aucpr:0.99679\teval-aucpr:0.96031\n",
            "[6]\ttrain-aucpr:0.99757\teval-aucpr:0.96260\n",
            "[7]\ttrain-aucpr:0.99828\teval-aucpr:0.96501\n",
            "[8]\ttrain-aucpr:0.99869\teval-aucpr:0.96676\n",
            "[9]\ttrain-aucpr:0.99902\teval-aucpr:0.96823\n",
            "[10]\ttrain-aucpr:0.99926\teval-aucpr:0.96946\n",
            "[11]\ttrain-aucpr:0.99942\teval-aucpr:0.97015\n",
            "[12]\ttrain-aucpr:0.99955\teval-aucpr:0.97095\n",
            "[13]\ttrain-aucpr:0.99964\teval-aucpr:0.97189\n",
            "[14]\ttrain-aucpr:0.99970\teval-aucpr:0.97236\n",
            "[15]\ttrain-aucpr:0.99976\teval-aucpr:0.97304\n",
            "[16]\ttrain-aucpr:0.99977\teval-aucpr:0.97341\n",
            "[17]\ttrain-aucpr:0.99983\teval-aucpr:0.97367\n",
            "[18]\ttrain-aucpr:0.99986\teval-aucpr:0.97406\n",
            "[19]\ttrain-aucpr:0.99988\teval-aucpr:0.97439\n",
            "[20]\ttrain-aucpr:0.99992\teval-aucpr:0.97433\n",
            "[21]\ttrain-aucpr:0.99993\teval-aucpr:0.97472\n",
            "[22]\ttrain-aucpr:0.99995\teval-aucpr:0.97487\n",
            "[23]\ttrain-aucpr:0.99996\teval-aucpr:0.97517\n",
            "[24]\ttrain-aucpr:0.99997\teval-aucpr:0.97520\n",
            "[25]\ttrain-aucpr:0.99997\teval-aucpr:0.97530\n",
            "[26]\ttrain-aucpr:0.99998\teval-aucpr:0.97544\n",
            "[27]\ttrain-aucpr:0.99998\teval-aucpr:0.97539\n",
            "[28]\ttrain-aucpr:0.99999\teval-aucpr:0.97523\n",
            "[29]\ttrain-aucpr:0.99999\teval-aucpr:0.97544\n",
            "[0]\ttrain-aucpr:0.95265\teval-aucpr:0.89535\n",
            "[1]\ttrain-aucpr:0.97920\teval-aucpr:0.92327\n",
            "[2]\ttrain-aucpr:0.98875\teval-aucpr:0.93923\n",
            "[3]\ttrain-aucpr:0.99292\teval-aucpr:0.94883\n",
            "[4]\ttrain-aucpr:0.99518\teval-aucpr:0.95308\n",
            "[5]\ttrain-aucpr:0.99658\teval-aucpr:0.95750\n",
            "[6]\ttrain-aucpr:0.99752\teval-aucpr:0.96014\n",
            "[7]\ttrain-aucpr:0.99821\teval-aucpr:0.96333\n",
            "[8]\ttrain-aucpr:0.99867\teval-aucpr:0.96528\n",
            "[9]\ttrain-aucpr:0.99897\teval-aucpr:0.96664\n",
            "[10]\ttrain-aucpr:0.99919\teval-aucpr:0.96818\n",
            "[11]\ttrain-aucpr:0.99941\teval-aucpr:0.96913\n",
            "[12]\ttrain-aucpr:0.99953\teval-aucpr:0.96996\n",
            "[13]\ttrain-aucpr:0.99959\teval-aucpr:0.97067\n",
            "[14]\ttrain-aucpr:0.99967\teval-aucpr:0.97116\n",
            "[15]\ttrain-aucpr:0.99975\teval-aucpr:0.97195\n",
            "[16]\ttrain-aucpr:0.99980\teval-aucpr:0.97218\n",
            "[17]\ttrain-aucpr:0.99982\teval-aucpr:0.97275\n",
            "[18]\ttrain-aucpr:0.99987\teval-aucpr:0.97341\n",
            "[19]\ttrain-aucpr:0.99989\teval-aucpr:0.97357\n",
            "[20]\ttrain-aucpr:0.99990\teval-aucpr:0.97340\n",
            "[21]\ttrain-aucpr:0.99992\teval-aucpr:0.97354\n",
            "[22]\ttrain-aucpr:0.99993\teval-aucpr:0.97351\n",
            "[0]\ttrain-aucpr:0.95421\teval-aucpr:0.89621\n",
            "[1]\ttrain-aucpr:0.98023\teval-aucpr:0.93120\n",
            "[2]\ttrain-aucpr:0.98936\teval-aucpr:0.94577\n",
            "[3]\ttrain-aucpr:0.99356\teval-aucpr:0.95336\n",
            "[4]\ttrain-aucpr:0.99577\teval-aucpr:0.95858\n",
            "[5]\ttrain-aucpr:0.99696\teval-aucpr:0.96173\n",
            "[6]\ttrain-aucpr:0.99771\teval-aucpr:0.96500\n",
            "[7]\ttrain-aucpr:0.99823\teval-aucpr:0.96680\n",
            "[8]\ttrain-aucpr:0.99871\teval-aucpr:0.96863\n",
            "[9]\ttrain-aucpr:0.99908\teval-aucpr:0.96989\n",
            "[10]\ttrain-aucpr:0.99932\teval-aucpr:0.97099\n",
            "[11]\ttrain-aucpr:0.99946\teval-aucpr:0.97172\n",
            "[12]\ttrain-aucpr:0.99959\teval-aucpr:0.97232\n",
            "[13]\ttrain-aucpr:0.99965\teval-aucpr:0.97270\n",
            "[14]\ttrain-aucpr:0.99974\teval-aucpr:0.97331\n",
            "[15]\ttrain-aucpr:0.99978\teval-aucpr:0.97364\n",
            "[16]\ttrain-aucpr:0.99982\teval-aucpr:0.97432\n",
            "[17]\ttrain-aucpr:0.99986\teval-aucpr:0.97433\n",
            "[18]\ttrain-aucpr:0.99988\teval-aucpr:0.97464\n",
            "[19]\ttrain-aucpr:0.99990\teval-aucpr:0.97441\n",
            "[20]\ttrain-aucpr:0.99993\teval-aucpr:0.97483\n",
            "[21]\ttrain-aucpr:0.99995\teval-aucpr:0.97507\n",
            "[22]\ttrain-aucpr:0.99996\teval-aucpr:0.97537\n",
            "[23]\ttrain-aucpr:0.99997\teval-aucpr:0.97546\n",
            "[24]\ttrain-aucpr:0.99997\teval-aucpr:0.97576\n",
            "[25]\ttrain-aucpr:0.99998\teval-aucpr:0.97601\n",
            "[26]\ttrain-aucpr:0.99999\teval-aucpr:0.97609\n",
            "[27]\ttrain-aucpr:0.99999\teval-aucpr:0.97594\n",
            "[28]\ttrain-aucpr:0.99999\teval-aucpr:0.97590\n",
            "[29]\ttrain-aucpr:0.99999\teval-aucpr:0.97602\n",
            "[0]\ttrain-aucpr:0.95211\teval-aucpr:0.88910\n",
            "[1]\ttrain-aucpr:0.98136\teval-aucpr:0.92896\n",
            "[2]\ttrain-aucpr:0.98981\teval-aucpr:0.94290\n",
            "[3]\ttrain-aucpr:0.99327\teval-aucpr:0.94989\n",
            "[4]\ttrain-aucpr:0.99522\teval-aucpr:0.95435\n",
            "[5]\ttrain-aucpr:0.99674\teval-aucpr:0.95816\n",
            "[6]\ttrain-aucpr:0.99761\teval-aucpr:0.96121\n",
            "[7]\ttrain-aucpr:0.99825\teval-aucpr:0.96369\n",
            "[8]\ttrain-aucpr:0.99861\teval-aucpr:0.96490\n",
            "[9]\ttrain-aucpr:0.99895\teval-aucpr:0.96619\n",
            "[10]\ttrain-aucpr:0.99922\teval-aucpr:0.96768\n",
            "[11]\ttrain-aucpr:0.99939\teval-aucpr:0.96855\n",
            "[12]\ttrain-aucpr:0.99954\teval-aucpr:0.96989\n",
            "[13]\ttrain-aucpr:0.99961\teval-aucpr:0.97106\n",
            "[14]\ttrain-aucpr:0.99969\teval-aucpr:0.97169\n",
            "[15]\ttrain-aucpr:0.99978\teval-aucpr:0.97245\n",
            "[16]\ttrain-aucpr:0.99982\teval-aucpr:0.97325\n",
            "[17]\ttrain-aucpr:0.99986\teval-aucpr:0.97353\n",
            "[18]\ttrain-aucpr:0.99989\teval-aucpr:0.97383\n",
            "[19]\ttrain-aucpr:0.99990\teval-aucpr:0.97414\n",
            "[20]\ttrain-aucpr:0.99992\teval-aucpr:0.97416\n",
            "[21]\ttrain-aucpr:0.99993\teval-aucpr:0.97422\n",
            "[22]\ttrain-aucpr:0.99994\teval-aucpr:0.97472\n",
            "[23]\ttrain-aucpr:0.99995\teval-aucpr:0.97485\n",
            "[24]\ttrain-aucpr:0.99996\teval-aucpr:0.97502\n",
            "[25]\ttrain-aucpr:0.99997\teval-aucpr:0.97509\n",
            "[26]\ttrain-aucpr:0.99998\teval-aucpr:0.97502\n",
            "[27]\ttrain-aucpr:0.99998\teval-aucpr:0.97522\n",
            "[28]\ttrain-aucpr:0.99998\teval-aucpr:0.97536\n",
            "[29]\ttrain-aucpr:0.99999\teval-aucpr:0.97528\n",
            "[30]\ttrain-aucpr:0.99999\teval-aucpr:0.97549\n",
            "[31]\ttrain-aucpr:0.99999\teval-aucpr:0.97571\n",
            "[32]\ttrain-aucpr:0.99999\teval-aucpr:0.97578\n",
            "[33]\ttrain-aucpr:1.00000\teval-aucpr:0.97584\n",
            "[34]\ttrain-aucpr:1.00000\teval-aucpr:0.97580\n",
            "[35]\ttrain-aucpr:1.00000\teval-aucpr:0.97597\n",
            "[36]\ttrain-aucpr:1.00000\teval-aucpr:0.97611\n",
            "[37]\ttrain-aucpr:1.00000\teval-aucpr:0.97641\n",
            "[38]\ttrain-aucpr:1.00000\teval-aucpr:0.97640\n",
            "[39]\ttrain-aucpr:1.00000\teval-aucpr:0.97641\n",
            "[40]\ttrain-aucpr:1.00000\teval-aucpr:0.97644\n",
            "[41]\ttrain-aucpr:1.00000\teval-aucpr:0.97638\n",
            "[42]\ttrain-aucpr:1.00000\teval-aucpr:0.97640\n",
            "[0]\ttrain-aucpr:0.95309\teval-aucpr:0.89390\n",
            "[1]\ttrain-aucpr:0.98119\teval-aucpr:0.92813\n",
            "[2]\ttrain-aucpr:0.98925\teval-aucpr:0.94014\n",
            "[3]\ttrain-aucpr:0.99340\teval-aucpr:0.95101\n",
            "[4]\ttrain-aucpr:0.99544\teval-aucpr:0.95644\n",
            "[5]\ttrain-aucpr:0.99674\teval-aucpr:0.96093\n",
            "[6]\ttrain-aucpr:0.99759\teval-aucpr:0.96339\n",
            "[7]\ttrain-aucpr:0.99824\teval-aucpr:0.96590\n",
            "[8]\ttrain-aucpr:0.99868\teval-aucpr:0.96762\n",
            "[9]\ttrain-aucpr:0.99899\teval-aucpr:0.96881\n",
            "[10]\ttrain-aucpr:0.99923\teval-aucpr:0.96966\n",
            "[11]\ttrain-aucpr:0.99941\teval-aucpr:0.97096\n",
            "[12]\ttrain-aucpr:0.99954\teval-aucpr:0.97170\n",
            "[13]\ttrain-aucpr:0.99962\teval-aucpr:0.97208\n",
            "[14]\ttrain-aucpr:0.99969\teval-aucpr:0.97260\n",
            "[15]\ttrain-aucpr:0.99977\teval-aucpr:0.97317\n",
            "[16]\ttrain-aucpr:0.99982\teval-aucpr:0.97380\n",
            "[17]\ttrain-aucpr:0.99986\teval-aucpr:0.97417\n",
            "[18]\ttrain-aucpr:0.99989\teval-aucpr:0.97432\n",
            "[19]\ttrain-aucpr:0.99990\teval-aucpr:0.97446\n",
            "[20]\ttrain-aucpr:0.99992\teval-aucpr:0.97456\n",
            "[21]\ttrain-aucpr:0.99994\teval-aucpr:0.97464\n",
            "[22]\ttrain-aucpr:0.99995\teval-aucpr:0.97458\n",
            "[23]\ttrain-aucpr:0.99996\teval-aucpr:0.97474\n",
            "[24]\ttrain-aucpr:0.99997\teval-aucpr:0.97516\n",
            "[25]\ttrain-aucpr:0.99998\teval-aucpr:0.97528\n",
            "[26]\ttrain-aucpr:0.99998\teval-aucpr:0.97536\n",
            "[27]\ttrain-aucpr:0.99999\teval-aucpr:0.97557\n",
            "[28]\ttrain-aucpr:0.99999\teval-aucpr:0.97563\n",
            "[29]\ttrain-aucpr:0.99999\teval-aucpr:0.97564\n",
            "[30]\ttrain-aucpr:0.99999\teval-aucpr:0.97559\n",
            "[31]\ttrain-aucpr:0.99999\teval-aucpr:0.97552\n",
            "[32]\ttrain-aucpr:0.99999\teval-aucpr:0.97556\n",
            "[0]\ttrain-aucpr:0.95706\teval-aucpr:0.90727\n",
            "[1]\ttrain-aucpr:0.98162\teval-aucpr:0.93527\n",
            "[2]\ttrain-aucpr:0.98983\teval-aucpr:0.94916\n",
            "[3]\ttrain-aucpr:0.99343\teval-aucpr:0.95620\n",
            "[4]\ttrain-aucpr:0.99551\teval-aucpr:0.95943\n",
            "[5]\ttrain-aucpr:0.99667\teval-aucpr:0.96260\n",
            "[6]\ttrain-aucpr:0.99748\teval-aucpr:0.96522\n",
            "[7]\ttrain-aucpr:0.99806\teval-aucpr:0.96737\n",
            "[8]\ttrain-aucpr:0.99851\teval-aucpr:0.96918\n",
            "[9]\ttrain-aucpr:0.99889\teval-aucpr:0.97064\n",
            "[10]\ttrain-aucpr:0.99913\teval-aucpr:0.97177\n",
            "[11]\ttrain-aucpr:0.99930\teval-aucpr:0.97264\n",
            "[12]\ttrain-aucpr:0.99944\teval-aucpr:0.97303\n",
            "[13]\ttrain-aucpr:0.99955\teval-aucpr:0.97377\n",
            "[14]\ttrain-aucpr:0.99964\teval-aucpr:0.97445\n",
            "[15]\ttrain-aucpr:0.99973\teval-aucpr:0.97481\n",
            "[16]\ttrain-aucpr:0.99976\teval-aucpr:0.97524\n",
            "[17]\ttrain-aucpr:0.99981\teval-aucpr:0.97571\n",
            "[18]\ttrain-aucpr:0.99986\teval-aucpr:0.97586\n",
            "[19]\ttrain-aucpr:0.99989\teval-aucpr:0.97614\n",
            "[20]\ttrain-aucpr:0.99991\teval-aucpr:0.97636\n",
            "[21]\ttrain-aucpr:0.99994\teval-aucpr:0.97657\n",
            "[22]\ttrain-aucpr:0.99995\teval-aucpr:0.97656\n",
            "[23]\ttrain-aucpr:0.99997\teval-aucpr:0.97656\n",
            "[24]\ttrain-aucpr:0.99997\teval-aucpr:0.97678\n",
            "[25]\ttrain-aucpr:0.99998\teval-aucpr:0.97708\n",
            "[26]\ttrain-aucpr:0.99998\teval-aucpr:0.97703\n",
            "[27]\ttrain-aucpr:0.99999\teval-aucpr:0.97718\n",
            "[28]\ttrain-aucpr:0.99999\teval-aucpr:0.97734\n",
            "[29]\ttrain-aucpr:0.99999\teval-aucpr:0.97723\n",
            "[30]\ttrain-aucpr:0.99999\teval-aucpr:0.97714\n",
            "[31]\ttrain-aucpr:0.99999\teval-aucpr:0.97717\n",
            "[0]\ttrain-aucpr:0.95291\teval-aucpr:0.90198\n",
            "[1]\ttrain-aucpr:0.98228\teval-aucpr:0.93551\n",
            "[2]\ttrain-aucpr:0.99034\teval-aucpr:0.95010\n",
            "[3]\ttrain-aucpr:0.99353\teval-aucpr:0.95581\n",
            "[4]\ttrain-aucpr:0.99536\teval-aucpr:0.95967\n",
            "[5]\ttrain-aucpr:0.99675\teval-aucpr:0.96212\n",
            "[6]\ttrain-aucpr:0.99765\teval-aucpr:0.96382\n",
            "[7]\ttrain-aucpr:0.99825\teval-aucpr:0.96571\n",
            "[8]\ttrain-aucpr:0.99868\teval-aucpr:0.96691\n",
            "[9]\ttrain-aucpr:0.99901\teval-aucpr:0.96824\n",
            "[10]\ttrain-aucpr:0.99919\teval-aucpr:0.96922\n",
            "[11]\ttrain-aucpr:0.99938\teval-aucpr:0.97031\n",
            "[12]\ttrain-aucpr:0.99951\teval-aucpr:0.97174\n",
            "[13]\ttrain-aucpr:0.99961\teval-aucpr:0.97269\n",
            "[14]\ttrain-aucpr:0.99969\teval-aucpr:0.97374\n",
            "[15]\ttrain-aucpr:0.99976\teval-aucpr:0.97419\n",
            "[16]\ttrain-aucpr:0.99981\teval-aucpr:0.97465\n",
            "[17]\ttrain-aucpr:0.99984\teval-aucpr:0.97497\n",
            "[18]\ttrain-aucpr:0.99985\teval-aucpr:0.97528\n",
            "[19]\ttrain-aucpr:0.99988\teval-aucpr:0.97558\n",
            "[20]\ttrain-aucpr:0.99991\teval-aucpr:0.97594\n",
            "[21]\ttrain-aucpr:0.99993\teval-aucpr:0.97594\n",
            "[22]\ttrain-aucpr:0.99995\teval-aucpr:0.97599\n",
            "[23]\ttrain-aucpr:0.99996\teval-aucpr:0.97605\n",
            "[24]\ttrain-aucpr:0.99997\teval-aucpr:0.97602\n",
            "[25]\ttrain-aucpr:0.99998\teval-aucpr:0.97617\n",
            "[26]\ttrain-aucpr:0.99998\teval-aucpr:0.97646\n",
            "[27]\ttrain-aucpr:0.99998\teval-aucpr:0.97667\n",
            "[28]\ttrain-aucpr:0.99999\teval-aucpr:0.97672\n",
            "[29]\ttrain-aucpr:0.99999\teval-aucpr:0.97679\n",
            "[30]\ttrain-aucpr:0.99999\teval-aucpr:0.97666\n",
            "[31]\ttrain-aucpr:0.99999\teval-aucpr:0.97679\n",
            "[0]\ttrain-aucpr:0.95219\teval-aucpr:0.90110\n",
            "[1]\ttrain-aucpr:0.98237\teval-aucpr:0.93623\n",
            "[2]\ttrain-aucpr:0.98963\teval-aucpr:0.94565\n",
            "[3]\ttrain-aucpr:0.99332\teval-aucpr:0.95281\n",
            "[4]\ttrain-aucpr:0.99523\teval-aucpr:0.95686\n",
            "[5]\ttrain-aucpr:0.99650\teval-aucpr:0.96003\n",
            "[6]\ttrain-aucpr:0.99758\teval-aucpr:0.96283\n",
            "[7]\ttrain-aucpr:0.99829\teval-aucpr:0.96567\n",
            "[8]\ttrain-aucpr:0.99878\teval-aucpr:0.96651\n",
            "[9]\ttrain-aucpr:0.99908\teval-aucpr:0.96804\n",
            "[10]\ttrain-aucpr:0.99928\teval-aucpr:0.96952\n",
            "[11]\ttrain-aucpr:0.99944\teval-aucpr:0.97103\n",
            "[12]\ttrain-aucpr:0.99955\teval-aucpr:0.97150\n",
            "[13]\ttrain-aucpr:0.99965\teval-aucpr:0.97165\n",
            "[14]\ttrain-aucpr:0.99972\teval-aucpr:0.97256\n",
            "[15]\ttrain-aucpr:0.99975\teval-aucpr:0.97251\n",
            "[16]\ttrain-aucpr:0.99979\teval-aucpr:0.97311\n",
            "[17]\ttrain-aucpr:0.99984\teval-aucpr:0.97352\n",
            "[18]\ttrain-aucpr:0.99988\teval-aucpr:0.97377\n",
            "[19]\ttrain-aucpr:0.99991\teval-aucpr:0.97396\n",
            "[20]\ttrain-aucpr:0.99993\teval-aucpr:0.97392\n",
            "[21]\ttrain-aucpr:0.99995\teval-aucpr:0.97399\n",
            "[22]\ttrain-aucpr:0.99995\teval-aucpr:0.97401\n",
            "[23]\ttrain-aucpr:0.99996\teval-aucpr:0.97446\n",
            "[24]\ttrain-aucpr:0.99997\teval-aucpr:0.97466\n",
            "[25]\ttrain-aucpr:0.99998\teval-aucpr:0.97487\n",
            "[26]\ttrain-aucpr:0.99998\teval-aucpr:0.97509\n",
            "[27]\ttrain-aucpr:0.99999\teval-aucpr:0.97514\n",
            "[28]\ttrain-aucpr:0.99999\teval-aucpr:0.97514\n",
            "[29]\ttrain-aucpr:0.99999\teval-aucpr:0.97538\n",
            "[30]\ttrain-aucpr:0.99999\teval-aucpr:0.97560\n",
            "[31]\ttrain-aucpr:1.00000\teval-aucpr:0.97576\n",
            "[32]\ttrain-aucpr:1.00000\teval-aucpr:0.97570\n",
            "[33]\ttrain-aucpr:1.00000\teval-aucpr:0.97596\n",
            "[34]\ttrain-aucpr:1.00000\teval-aucpr:0.97598\n",
            "[35]\ttrain-aucpr:1.00000\teval-aucpr:0.97593\n",
            "[36]\ttrain-aucpr:1.00000\teval-aucpr:0.97605\n",
            "[37]\ttrain-aucpr:1.00000\teval-aucpr:0.97626\n",
            "[38]\ttrain-aucpr:1.00000\teval-aucpr:0.97625\n",
            "[39]\ttrain-aucpr:1.00000\teval-aucpr:0.97648\n",
            "[40]\ttrain-aucpr:1.00000\teval-aucpr:0.97658\n",
            "[41]\ttrain-aucpr:1.00000\teval-aucpr:0.97647\n",
            "[42]\ttrain-aucpr:1.00000\teval-aucpr:0.97661\n",
            "[43]\ttrain-aucpr:1.00000\teval-aucpr:0.97659\n",
            "[44]\ttrain-aucpr:1.00000\teval-aucpr:0.97662\n",
            "[45]\ttrain-aucpr:1.00000\teval-aucpr:0.97678\n",
            "[46]\ttrain-aucpr:1.00000\teval-aucpr:0.97684\n",
            "[47]\ttrain-aucpr:1.00000\teval-aucpr:0.97676\n",
            "[48]\ttrain-aucpr:1.00000\teval-aucpr:0.97675\n",
            "[49]\ttrain-aucpr:1.00000\teval-aucpr:0.97686\n",
            "[50]\ttrain-aucpr:1.00000\teval-aucpr:0.97689\n",
            "[51]\ttrain-aucpr:1.00000\teval-aucpr:0.97690\n",
            "[52]\ttrain-aucpr:1.00000\teval-aucpr:0.97692\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97711\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97705\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97701\n",
            "[0]\ttrain-aucpr:0.95386\teval-aucpr:0.89461\n",
            "[1]\ttrain-aucpr:0.97975\teval-aucpr:0.92637\n",
            "[2]\ttrain-aucpr:0.98929\teval-aucpr:0.94078\n",
            "[3]\ttrain-aucpr:0.99293\teval-aucpr:0.94927\n",
            "[4]\ttrain-aucpr:0.99504\teval-aucpr:0.95461\n",
            "[5]\ttrain-aucpr:0.99655\teval-aucpr:0.95931\n",
            "[6]\ttrain-aucpr:0.99757\teval-aucpr:0.96193\n",
            "[7]\ttrain-aucpr:0.99815\teval-aucpr:0.96402\n",
            "[8]\ttrain-aucpr:0.99865\teval-aucpr:0.96584\n",
            "[9]\ttrain-aucpr:0.99898\teval-aucpr:0.96770\n",
            "[10]\ttrain-aucpr:0.99923\teval-aucpr:0.96895\n",
            "[11]\ttrain-aucpr:0.99942\teval-aucpr:0.97002\n",
            "[12]\ttrain-aucpr:0.99955\teval-aucpr:0.97097\n",
            "[13]\ttrain-aucpr:0.99965\teval-aucpr:0.97156\n",
            "[14]\ttrain-aucpr:0.99973\teval-aucpr:0.97247\n",
            "[15]\ttrain-aucpr:0.99977\teval-aucpr:0.97290\n",
            "[16]\ttrain-aucpr:0.99983\teval-aucpr:0.97330\n",
            "[17]\ttrain-aucpr:0.99987\teval-aucpr:0.97382\n",
            "[18]\ttrain-aucpr:0.99989\teval-aucpr:0.97428\n",
            "[19]\ttrain-aucpr:0.99992\teval-aucpr:0.97466\n",
            "[20]\ttrain-aucpr:0.99994\teval-aucpr:0.97493\n",
            "[21]\ttrain-aucpr:0.99995\teval-aucpr:0.97499\n",
            "[22]\ttrain-aucpr:0.99996\teval-aucpr:0.97498\n",
            "[23]\ttrain-aucpr:0.99997\teval-aucpr:0.97505\n",
            "[24]\ttrain-aucpr:0.99997\teval-aucpr:0.97503\n",
            "[25]\ttrain-aucpr:0.99998\teval-aucpr:0.97517\n",
            "[26]\ttrain-aucpr:0.99998\teval-aucpr:0.97525\n",
            "[27]\ttrain-aucpr:0.99999\teval-aucpr:0.97542\n",
            "[28]\ttrain-aucpr:0.99999\teval-aucpr:0.97540\n",
            "[29]\ttrain-aucpr:0.99999\teval-aucpr:0.97543\n",
            "[30]\ttrain-aucpr:0.99999\teval-aucpr:0.97556\n",
            "[31]\ttrain-aucpr:1.00000\teval-aucpr:0.97554\n",
            "[32]\ttrain-aucpr:1.00000\teval-aucpr:0.97564\n",
            "[33]\ttrain-aucpr:1.00000\teval-aucpr:0.97585\n",
            "[34]\ttrain-aucpr:1.00000\teval-aucpr:0.97582\n",
            "[35]\ttrain-aucpr:1.00000\teval-aucpr:0.97587\n",
            "[36]\ttrain-aucpr:1.00000\teval-aucpr:0.97596\n",
            "[37]\ttrain-aucpr:1.00000\teval-aucpr:0.97599\n",
            "[38]\ttrain-aucpr:1.00000\teval-aucpr:0.97594\n",
            "[39]\ttrain-aucpr:1.00000\teval-aucpr:0.97589\n",
            "[0]\ttrain-aucpr:0.95114\teval-aucpr:0.89265\n",
            "[1]\ttrain-aucpr:0.98068\teval-aucpr:0.93133\n",
            "[2]\ttrain-aucpr:0.98955\teval-aucpr:0.94399\n",
            "[3]\ttrain-aucpr:0.99320\teval-aucpr:0.95256\n",
            "[4]\ttrain-aucpr:0.99536\teval-aucpr:0.95711\n",
            "[5]\ttrain-aucpr:0.99664\teval-aucpr:0.96026\n",
            "[6]\ttrain-aucpr:0.99769\teval-aucpr:0.96267\n",
            "[7]\ttrain-aucpr:0.99827\teval-aucpr:0.96514\n",
            "[8]\ttrain-aucpr:0.99866\teval-aucpr:0.96733\n",
            "[9]\ttrain-aucpr:0.99892\teval-aucpr:0.96887\n",
            "[10]\ttrain-aucpr:0.99921\teval-aucpr:0.96985\n",
            "[11]\ttrain-aucpr:0.99938\teval-aucpr:0.97097\n",
            "[12]\ttrain-aucpr:0.99951\teval-aucpr:0.97209\n",
            "[13]\ttrain-aucpr:0.99961\teval-aucpr:0.97273\n",
            "[14]\ttrain-aucpr:0.99969\teval-aucpr:0.97327\n",
            "[15]\ttrain-aucpr:0.99973\teval-aucpr:0.97340\n",
            "[16]\ttrain-aucpr:0.99980\teval-aucpr:0.97387\n",
            "[17]\ttrain-aucpr:0.99984\teval-aucpr:0.97413\n",
            "[18]\ttrain-aucpr:0.99988\teval-aucpr:0.97439\n",
            "[19]\ttrain-aucpr:0.99989\teval-aucpr:0.97449\n",
            "[20]\ttrain-aucpr:0.99992\teval-aucpr:0.97435\n",
            "[21]\ttrain-aucpr:0.99994\teval-aucpr:0.97483\n",
            "[22]\ttrain-aucpr:0.99995\teval-aucpr:0.97481\n",
            "[23]\ttrain-aucpr:0.99996\teval-aucpr:0.97501\n",
            "[24]\ttrain-aucpr:0.99997\teval-aucpr:0.97507\n",
            "[25]\ttrain-aucpr:0.99998\teval-aucpr:0.97513\n",
            "[26]\ttrain-aucpr:0.99998\teval-aucpr:0.97546\n",
            "[27]\ttrain-aucpr:0.99999\teval-aucpr:0.97547\n",
            "[28]\ttrain-aucpr:0.99999\teval-aucpr:0.97552\n",
            "[29]\ttrain-aucpr:0.99999\teval-aucpr:0.97551\n",
            "[30]\ttrain-aucpr:0.99999\teval-aucpr:0.97564\n",
            "[31]\ttrain-aucpr:0.99999\teval-aucpr:0.97560\n",
            "[32]\ttrain-aucpr:0.99999\teval-aucpr:0.97559\n",
            "[33]\ttrain-aucpr:1.00000\teval-aucpr:0.97571\n",
            "[34]\ttrain-aucpr:1.00000\teval-aucpr:0.97568\n",
            "[35]\ttrain-aucpr:1.00000\teval-aucpr:0.97585\n",
            "[36]\ttrain-aucpr:1.00000\teval-aucpr:0.97605\n",
            "[37]\ttrain-aucpr:1.00000\teval-aucpr:0.97631\n",
            "[38]\ttrain-aucpr:1.00000\teval-aucpr:0.97638\n",
            "[39]\ttrain-aucpr:1.00000\teval-aucpr:0.97638\n",
            "[40]\ttrain-aucpr:1.00000\teval-aucpr:0.97637\n",
            "[41]\ttrain-aucpr:1.00000\teval-aucpr:0.97636\n",
            "[42]\ttrain-aucpr:1.00000\teval-aucpr:0.97654\n",
            "[43]\ttrain-aucpr:1.00000\teval-aucpr:0.97660\n",
            "[44]\ttrain-aucpr:1.00000\teval-aucpr:0.97659\n",
            "[45]\ttrain-aucpr:1.00000\teval-aucpr:0.97665\n",
            "[46]\ttrain-aucpr:1.00000\teval-aucpr:0.97675\n",
            "[47]\ttrain-aucpr:1.00000\teval-aucpr:0.97676\n",
            "[48]\ttrain-aucpr:1.00000\teval-aucpr:0.97681\n",
            "[49]\ttrain-aucpr:1.00000\teval-aucpr:0.97695\n",
            "[50]\ttrain-aucpr:1.00000\teval-aucpr:0.97695\n",
            "[51]\ttrain-aucpr:1.00000\teval-aucpr:0.97696\n",
            "[52]\ttrain-aucpr:1.00000\teval-aucpr:0.97709\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97708\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97707\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m3 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m3[idx] = np.round(fold_results.get(i).get('predictions')[j], 0)"
      ],
      "metadata": {
        "id": "7hSFBjJSXmnc"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m3_cost = cost_func(preds_m3,y)\n",
        "m3_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSw-zr1_YDa6",
        "outputId": "bf102ba1-74ac-49bc-aa46-40ed798e36c4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1180650"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new3 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    if fold_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new3[idx] = 1\n",
        "    else:\n",
        "      preds_new3[idx] = 0\n",
        "m3_cost_t = cost_func(y,preds_new3)\n",
        "m3_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Adyt-BMxEjNf",
        "outputId": "b29494f1-5220-4e70-f4d5-f2b06f25bde5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1119100"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "qA5qTJxP5amW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sets binary values for predictions\n",
        "def cost(y_true,y_pred):\n",
        "\n",
        "  bin_p = K.switch(K.greater_equal(y_pred,0.5),K.constant(1,shape=y_pred.shape),\n",
        "                   K.constant(0,shape=y_pred.shape))\n",
        "  diff = bin_p-y_true\n",
        "\n",
        "  error = K.switch(\n",
        "      K.equal(diff,1),K.constant(100,shape=y_pred.shape),\n",
        "      K.switch(\n",
        "          K.equal(diff,-1),K.constant(150,shape=y_pred.shape),\n",
        "          K.constant(0,shape=y_pred.shape)\n",
        "      )\n",
        "  )\n",
        "  return(K.sum(error))"
      ],
      "metadata": {
        "id": "z2vUglkTkzxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### define a cost function used in validation with keras and backend\n",
        "### returns the average cost (total cost divided by array tensor size)\n",
        "def cost(y_true,y_pred):\n",
        "  bin_p = tf.where(tf.greater_equal(y_pred,0.5),tf.constant(1,dtype='float32'),tf.constant(0,dtype='float32'))\n",
        "\n",
        "  diff = bin_p - y_true\n",
        "\n",
        "  error = tf.where(\n",
        "      tf.equal(diff,1),100,\n",
        "      tf.where(\n",
        "          tf.equal(diff,-1),150,\n",
        "          0\n",
        "      )\n",
        "  )\n",
        "  return(K.sum(error)/tf.size(bin_p))"
      ],
      "metadata": {
        "id": "EV-gIgK12n02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now"
      ],
      "metadata": {
        "id": "b04x7Mf5dBDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_cost', mode='min',patience=50,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model4 = tf.keras.Sequential()\n",
        "  model4.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model4.add(tf.keras.layers.Dropout(0.4))\n",
        "  model4.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model4.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model4.fit(X[train_index],y[train_index],epochs=1000,batch_size=1024,validation_split=0.1,callbacks=[es])\n",
        "  score = model4.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model4.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEjPIqNtVPF1",
        "outputId": "32627df5-0f67-4087-88f6-3323e954d6d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5461 - auc: 0.7797 - accuracy: 0.7152 - cost: 37.7363 - val_loss: 0.4092 - val_auc: 0.8941 - val_accuracy: 0.8208 - val_cost: 22.7181\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3658 - auc: 0.9148 - accuracy: 0.8432 - cost: 19.9780 - val_loss: 0.3208 - val_auc: 0.9346 - val_accuracy: 0.8622 - val_cost: 17.0117\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3153 - auc: 0.9372 - accuracy: 0.8704 - cost: 16.3913 - val_loss: 0.2950 - val_auc: 0.9455 - val_accuracy: 0.8770 - val_cost: 15.6771\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2870 - auc: 0.9480 - accuracy: 0.8832 - cost: 14.7903 - val_loss: 0.2706 - val_auc: 0.9540 - val_accuracy: 0.8917 - val_cost: 13.1771\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2663 - auc: 0.9553 - accuracy: 0.8932 - cost: 13.4905 - val_loss: 0.2522 - val_auc: 0.9599 - val_accuracy: 0.9006 - val_cost: 12.3340\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2477 - auc: 0.9613 - accuracy: 0.9033 - cost: 12.2641 - val_loss: 0.2382 - val_auc: 0.9648 - val_accuracy: 0.9069 - val_cost: 11.1621\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2323 - auc: 0.9660 - accuracy: 0.9096 - cost: 11.4452 - val_loss: 0.2220 - val_auc: 0.9689 - val_accuracy: 0.9168 - val_cost: 10.0228\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2188 - auc: 0.9697 - accuracy: 0.9161 - cost: 10.6258 - val_loss: 0.2101 - val_auc: 0.9719 - val_accuracy: 0.9228 - val_cost: 9.5898\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2074 - auc: 0.9727 - accuracy: 0.9218 - cost: 9.9067 - val_loss: 0.1998 - val_auc: 0.9746 - val_accuracy: 0.9269 - val_cost: 8.9844\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1971 - auc: 0.9752 - accuracy: 0.9257 - cost: 9.4033 - val_loss: 0.1901 - val_auc: 0.9767 - val_accuracy: 0.9292 - val_cost: 8.8151\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1885 - auc: 0.9772 - accuracy: 0.9300 - cost: 8.8843 - val_loss: 0.1815 - val_auc: 0.9786 - val_accuracy: 0.9352 - val_cost: 8.0404\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1795 - auc: 0.9792 - accuracy: 0.9344 - cost: 8.3312 - val_loss: 0.1749 - val_auc: 0.9800 - val_accuracy: 0.9393 - val_cost: 7.5228\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1729 - auc: 0.9806 - accuracy: 0.9376 - cost: 7.9260 - val_loss: 0.1690 - val_auc: 0.9814 - val_accuracy: 0.9410 - val_cost: 7.2786\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1676 - auc: 0.9817 - accuracy: 0.9401 - cost: 7.6061 - val_loss: 0.1650 - val_auc: 0.9820 - val_accuracy: 0.9422 - val_cost: 7.3014\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1631 - auc: 0.9826 - accuracy: 0.9421 - cost: 7.3632 - val_loss: 0.1604 - val_auc: 0.9830 - val_accuracy: 0.9442 - val_cost: 7.2721\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1571 - auc: 0.9837 - accuracy: 0.9445 - cost: 7.0479 - val_loss: 0.1575 - val_auc: 0.9836 - val_accuracy: 0.9442 - val_cost: 6.8099\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1533 - auc: 0.9843 - accuracy: 0.9465 - cost: 6.7833 - val_loss: 0.1530 - val_auc: 0.9844 - val_accuracy: 0.9478 - val_cost: 6.4811\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1499 - auc: 0.9848 - accuracy: 0.9486 - cost: 6.5357 - val_loss: 0.1503 - val_auc: 0.9847 - val_accuracy: 0.9497 - val_cost: 6.7578\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1465 - auc: 0.9855 - accuracy: 0.9501 - cost: 6.3220 - val_loss: 0.1473 - val_auc: 0.9850 - val_accuracy: 0.9503 - val_cost: 6.2500\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1435 - auc: 0.9861 - accuracy: 0.9505 - cost: 6.2868 - val_loss: 0.1443 - val_auc: 0.9855 - val_accuracy: 0.9519 - val_cost: 6.0449\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1403 - auc: 0.9866 - accuracy: 0.9522 - cost: 6.0633 - val_loss: 0.1438 - val_auc: 0.9856 - val_accuracy: 0.9517 - val_cost: 6.3672\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1373 - auc: 0.9870 - accuracy: 0.9540 - cost: 5.8308 - val_loss: 0.1407 - val_auc: 0.9860 - val_accuracy: 0.9525 - val_cost: 5.9863\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1356 - auc: 0.9872 - accuracy: 0.9545 - cost: 5.7731 - val_loss: 0.1383 - val_auc: 0.9863 - val_accuracy: 0.9544 - val_cost: 5.9538\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1323 - auc: 0.9878 - accuracy: 0.9563 - cost: 5.5696 - val_loss: 0.1361 - val_auc: 0.9866 - val_accuracy: 0.9556 - val_cost: 5.7487\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1304 - auc: 0.9881 - accuracy: 0.9563 - cost: 5.5456 - val_loss: 0.1344 - val_auc: 0.9870 - val_accuracy: 0.9562 - val_cost: 5.5566\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1285 - auc: 0.9883 - accuracy: 0.9578 - cost: 5.3654 - val_loss: 0.1336 - val_auc: 0.9869 - val_accuracy: 0.9565 - val_cost: 5.4850\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1266 - auc: 0.9885 - accuracy: 0.9587 - cost: 5.2537 - val_loss: 0.1335 - val_auc: 0.9869 - val_accuracy: 0.9562 - val_cost: 5.6771\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1250 - auc: 0.9888 - accuracy: 0.9593 - cost: 5.1885 - val_loss: 0.1314 - val_auc: 0.9874 - val_accuracy: 0.9570 - val_cost: 5.5762\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1228 - auc: 0.9891 - accuracy: 0.9597 - cost: 5.1361 - val_loss: 0.1300 - val_auc: 0.9876 - val_accuracy: 0.9591 - val_cost: 5.0846\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1221 - auc: 0.9892 - accuracy: 0.9605 - cost: 5.0269 - val_loss: 0.1278 - val_auc: 0.9876 - val_accuracy: 0.9589 - val_cost: 5.3483\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1197 - auc: 0.9894 - accuracy: 0.9616 - cost: 4.8803 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9608 - val_cost: 4.8991\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1182 - auc: 0.9898 - accuracy: 0.9619 - cost: 4.8355 - val_loss: 0.1263 - val_auc: 0.9877 - val_accuracy: 0.9609 - val_cost: 5.0553\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1175 - auc: 0.9899 - accuracy: 0.9628 - cost: 4.7314 - val_loss: 0.1240 - val_auc: 0.9879 - val_accuracy: 0.9608 - val_cost: 4.8893\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1154 - auc: 0.9901 - accuracy: 0.9632 - cost: 4.6791 - val_loss: 0.1233 - val_auc: 0.9882 - val_accuracy: 0.9618 - val_cost: 4.9544\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1147 - auc: 0.9901 - accuracy: 0.9632 - cost: 4.6888 - val_loss: 0.1228 - val_auc: 0.9884 - val_accuracy: 0.9608 - val_cost: 5.0195\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1126 - auc: 0.9905 - accuracy: 0.9642 - cost: 4.5519 - val_loss: 0.1220 - val_auc: 0.9884 - val_accuracy: 0.9620 - val_cost: 4.7526\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1114 - auc: 0.9907 - accuracy: 0.9650 - cost: 4.4610 - val_loss: 0.1213 - val_auc: 0.9884 - val_accuracy: 0.9627 - val_cost: 4.8014\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1107 - auc: 0.9906 - accuracy: 0.9650 - cost: 4.4477 - val_loss: 0.1208 - val_auc: 0.9883 - val_accuracy: 0.9630 - val_cost: 4.7591\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1093 - auc: 0.9909 - accuracy: 0.9654 - cost: 4.4106 - val_loss: 0.1189 - val_auc: 0.9886 - val_accuracy: 0.9638 - val_cost: 4.7038\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1102 - auc: 0.9907 - accuracy: 0.9654 - cost: 4.4053 - val_loss: 0.1200 - val_auc: 0.9885 - val_accuracy: 0.9630 - val_cost: 4.7201\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1074 - auc: 0.9911 - accuracy: 0.9669 - cost: 4.2130 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9635 - val_cost: 4.6191\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1070 - auc: 0.9911 - accuracy: 0.9667 - cost: 4.2258 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9638 - val_cost: 4.6973\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1068 - auc: 0.9911 - accuracy: 0.9665 - cost: 4.2609 - val_loss: 0.1195 - val_auc: 0.9886 - val_accuracy: 0.9640 - val_cost: 4.5898\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1061 - auc: 0.9912 - accuracy: 0.9673 - cost: 4.1806 - val_loss: 0.1174 - val_auc: 0.9888 - val_accuracy: 0.9651 - val_cost: 4.6289\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1036 - auc: 0.9914 - accuracy: 0.9679 - cost: 4.0859 - val_loss: 0.1153 - val_auc: 0.9892 - val_accuracy: 0.9650 - val_cost: 4.5182\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1034 - auc: 0.9915 - accuracy: 0.9681 - cost: 4.0694 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.3783\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1036 - auc: 0.9915 - accuracy: 0.9680 - cost: 4.0770 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9651 - val_cost: 4.5117\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9685 - cost: 4.0100 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9666 - val_cost: 4.2253\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1015 - auc: 0.9918 - accuracy: 0.9690 - cost: 3.9614 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9659 - val_cost: 4.4987\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1003 - auc: 0.9920 - accuracy: 0.9696 - cost: 3.8707 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.5573\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1009 - auc: 0.9918 - accuracy: 0.9694 - cost: 3.9033 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9661 - val_cost: 4.2155\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1000 - auc: 0.9920 - accuracy: 0.9695 - cost: 3.8851 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9665 - val_cost: 4.3034\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0986 - auc: 0.9921 - accuracy: 0.9697 - cost: 3.8769 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.1569\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0976 - auc: 0.9922 - accuracy: 0.9700 - cost: 3.8188 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0267\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0974 - auc: 0.9922 - accuracy: 0.9704 - cost: 3.7813 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9669 - val_cost: 4.2513\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0977 - auc: 0.9922 - accuracy: 0.9705 - cost: 3.7684 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9670 - val_cost: 4.2090\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0968 - auc: 0.9923 - accuracy: 0.9709 - cost: 3.7214 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 4.1536\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0962 - auc: 0.9923 - accuracy: 0.9714 - cost: 3.6549 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 3.8542\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0960 - auc: 0.9923 - accuracy: 0.9714 - cost: 3.6545 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 4.1309\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0950 - auc: 0.9925 - accuracy: 0.9718 - cost: 3.6053 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9675 - val_cost: 3.9193\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0958 - auc: 0.9923 - accuracy: 0.9719 - cost: 3.5894 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.1439\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0945 - auc: 0.9925 - accuracy: 0.9721 - cost: 3.5517 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.9095\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9925 - accuracy: 0.9721 - cost: 3.5690 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 4.0560\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0937 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5651 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9689 - val_cost: 3.9453\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9723 - cost: 3.5518 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 4.2839\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9928 - accuracy: 0.9726 - cost: 3.5086 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.8249\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0924 - auc: 0.9928 - accuracy: 0.9729 - cost: 3.4615 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 3.9746\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.4822 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0951\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9925 - accuracy: 0.9731 - cost: 3.4426 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 4.0007\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9928 - accuracy: 0.9733 - cost: 3.4271 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 4.0007\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9930 - accuracy: 0.9734 - cost: 3.4001 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0951\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9930 - accuracy: 0.9740 - cost: 3.3415 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 4.0690\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9929 - accuracy: 0.9734 - cost: 3.4026 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9685 - val_cost: 4.0332\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3679 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9193\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0905 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3670 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.8574\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9736 - cost: 3.3812 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.0202\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9930 - accuracy: 0.9740 - cost: 3.3186 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.7923\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9930 - accuracy: 0.9742 - cost: 3.3195 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.8021\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9928 - accuracy: 0.9743 - cost: 3.3110 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.6361\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9932 - accuracy: 0.9744 - cost: 3.2818 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.6458\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9738 - cost: 3.3609 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8021\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0885 - auc: 0.9931 - accuracy: 0.9743 - cost: 3.2893 - val_loss: 0.1075 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9290\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9935 - accuracy: 0.9752 - cost: 3.1803 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9689 - val_cost: 4.1243\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0873 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2286 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6556\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2335 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.5775\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2846 - val_loss: 0.1075 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 4.0658\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9930 - accuracy: 0.9746 - cost: 3.2670 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9695 - val_cost: 3.9876\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.2036 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.6719\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.2092 - val_loss: 0.1119 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.9583\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9933 - accuracy: 0.9752 - cost: 3.1736 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.9062\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9935 - accuracy: 0.9754 - cost: 3.1596 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8216\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.1980 - val_loss: 0.1085 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.9681\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9934 - accuracy: 0.9744 - cost: 3.3000 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.6133\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9936 - accuracy: 0.9751 - cost: 3.2058 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.9941\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1462 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.7630\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9935 - accuracy: 0.9753 - cost: 3.1773 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6589\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9936 - accuracy: 0.9757 - cost: 3.1273 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.9909\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1408 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5254\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9936 - accuracy: 0.9759 - cost: 3.0976 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.5840\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9760 - cost: 3.0794 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 3.8444\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9762 - cost: 3.0723 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.7012\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1629 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0740 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.7728\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9763 - cost: 3.0490 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.9030\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9758 - cost: 3.1262 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7500\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9764 - cost: 3.0370 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.6426\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9766 - cost: 2.9980 - val_loss: 0.1073 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.8607\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0722 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9702 - val_cost: 3.8281\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9938 - accuracy: 0.9764 - cost: 3.0372 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7728\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9886 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.8802\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9935 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6523\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0128 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.6198\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9769 - cost: 2.9743 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.9193\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9985 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.9160\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0547 - val_loss: 0.1096 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.8314\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9772 - cost: 2.9402 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.9062\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9768 - cost: 2.9971 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8607\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0160 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.5677\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9603 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.9714\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9503 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7858\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9301 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6393\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9737 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.9160\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9577 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.4896\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9919 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7533\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9532 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 4.0853\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9261 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.5645\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8890 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.5807\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9251 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.5840\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9264 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7988\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9767 - cost: 3.0146 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7891\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9423 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8477\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8795 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.8542\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9353 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.7402\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0782 - auc: 0.9941 - accuracy: 0.9778 - cost: 2.8640 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.7044\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0791 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9676 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9777 - cost: 2.8734 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.7793\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.9090 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7305\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9777 - cost: 2.8790 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7174\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9058 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.4928\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8851 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.7207\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8410 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7663\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8566 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7337\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8688 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7793\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8439 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6979\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8437 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7435\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9942 - accuracy: 0.9780 - cost: 2.8302 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.7012\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8739 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.6719\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8682 - val_loss: 0.1126 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.6393\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8703 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6230\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8258 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.9128\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8440 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.8021\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8272 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.7240\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8470 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8337 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.3691\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8437 - val_loss: 0.1126 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.6491\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8912 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5710\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8810 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6230\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8501 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.7272\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8427 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5905\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8234 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.7337\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7825 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7663\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7779 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 4.1960\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7896 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.6947\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8071 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6296\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7974 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7272\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7907 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9698 - val_cost: 3.8672\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7846 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.6068\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7938 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 4.0462\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7515 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.6816\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8206 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 4.0104\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9789 - cost: 2.7116 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.8542\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7770 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.5579\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7914 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5775\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7618 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.9648\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7066 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.6458\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7938 - val_loss: 0.1116 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6654\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8479 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.8053\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7642 - val_loss: 0.1110 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.6654\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8095 - val_loss: 0.1124 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7663\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8423 - val_loss: 0.1125 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.6296\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7412 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.7142\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7024 - val_loss: 0.1145 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5156\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7824 - val_loss: 0.1139 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5352\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7504 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6198\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7610 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.7305\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7606 - val_loss: 0.1131 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.6035\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6677 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6133\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7573 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6686\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7629 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.3496\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7894 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6198\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7407 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6784\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7627 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5189\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7490 - val_loss: 0.1173 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.7891\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7947 - val_loss: 0.1145 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5710\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7305 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7534 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6523\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7444 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5938\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7216 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.8053\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7288 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.4928\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7953 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.9030\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7336 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.7760\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7737 - val_loss: 0.1153 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5645\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7932 - val_loss: 0.1127 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6068\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7530 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5352\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7219 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4603\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.7159 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.6589\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6956 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.4993\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7003 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5579\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7149 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5775\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6923 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.5645\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7454 - val_loss: 0.1163 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6947\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7160 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.7038 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5514\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7588 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.7272\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7069 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8542\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7278 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.4245\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6827 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7207\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6910 - val_loss: 0.1157 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.9714\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6832 - val_loss: 0.1154 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.7044\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7127 - val_loss: 0.1148 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5612\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7031 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.6003\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7520 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8021\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6910 - val_loss: 0.1152 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.9714\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6670 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9719 - val_cost: 3.6426\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6750 - val_loss: 0.1140 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5286\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6294 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.6426\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6958 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5677\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6815 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.8770\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6957 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7891\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7072 - val_loss: 0.1145 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.7402\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6016 - val_loss: 0.1133 - val_auc: 0.9900 - val_accuracy: 0.9728 - val_cost: 3.5189\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6583 - val_loss: 0.1132 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.7858\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6667 - val_loss: 0.1142 - val_auc: 0.9902 - val_accuracy: 0.9714 - val_cost: 3.4505\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6729 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6035\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6747 - val_loss: 0.1152 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.9128\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6757 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.9128\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6981 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9716 - val_cost: 3.6914\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6365 - val_loss: 0.1140 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5352\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.6050 - val_loss: 0.1129 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.9583\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1130 - auc: 0.9901 - accuracy: 0.9699 - cost: 3.7344\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:17.147550\n",
            "fold accuracy: 0.9699375033378601 - fold cost: 3.734375\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 7ms/step - loss: 0.5475 - auc: 0.7785 - accuracy: 0.7141 - cost: 37.8737 - val_loss: 0.4109 - val_auc: 0.8938 - val_accuracy: 0.8208 - val_cost: 23.7793\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3679 - auc: 0.9139 - accuracy: 0.8416 - cost: 20.2092 - val_loss: 0.3219 - val_auc: 0.9345 - val_accuracy: 0.8628 - val_cost: 17.0345\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3135 - auc: 0.9379 - accuracy: 0.8704 - cost: 16.3609 - val_loss: 0.2929 - val_auc: 0.9459 - val_accuracy: 0.8790 - val_cost: 15.2279\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2863 - auc: 0.9483 - accuracy: 0.8832 - cost: 14.7550 - val_loss: 0.2692 - val_auc: 0.9544 - val_accuracy: 0.8913 - val_cost: 13.6719\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2637 - auc: 0.9563 - accuracy: 0.8948 - cost: 13.3009 - val_loss: 0.2502 - val_auc: 0.9607 - val_accuracy: 0.9008 - val_cost: 12.3340\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2442 - auc: 0.9624 - accuracy: 0.9035 - cost: 12.1949 - val_loss: 0.2336 - val_auc: 0.9656 - val_accuracy: 0.9110 - val_cost: 11.2760\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2292 - auc: 0.9669 - accuracy: 0.9108 - cost: 11.2420 - val_loss: 0.2203 - val_auc: 0.9693 - val_accuracy: 0.9172 - val_cost: 10.5143\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2168 - auc: 0.9703 - accuracy: 0.9176 - cost: 10.4188 - val_loss: 0.2075 - val_auc: 0.9728 - val_accuracy: 0.9245 - val_cost: 9.8405\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2050 - auc: 0.9732 - accuracy: 0.9226 - cost: 9.8039 - val_loss: 0.1971 - val_auc: 0.9752 - val_accuracy: 0.9278 - val_cost: 9.3848\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1946 - auc: 0.9758 - accuracy: 0.9279 - cost: 9.1503 - val_loss: 0.1888 - val_auc: 0.9771 - val_accuracy: 0.9328 - val_cost: 8.4668\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1865 - auc: 0.9777 - accuracy: 0.9314 - cost: 8.7052 - val_loss: 0.1807 - val_auc: 0.9789 - val_accuracy: 0.9363 - val_cost: 8.2324\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1791 - auc: 0.9792 - accuracy: 0.9342 - cost: 8.3429 - val_loss: 0.1752 - val_auc: 0.9798 - val_accuracy: 0.9388 - val_cost: 8.0371\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1719 - auc: 0.9808 - accuracy: 0.9379 - cost: 7.8777 - val_loss: 0.1689 - val_auc: 0.9813 - val_accuracy: 0.9405 - val_cost: 7.7018\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1669 - auc: 0.9818 - accuracy: 0.9404 - cost: 7.5785 - val_loss: 0.1644 - val_auc: 0.9821 - val_accuracy: 0.9419 - val_cost: 7.6530\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1623 - auc: 0.9827 - accuracy: 0.9429 - cost: 7.2463 - val_loss: 0.1605 - val_auc: 0.9829 - val_accuracy: 0.9449 - val_cost: 7.1908\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1588 - auc: 0.9834 - accuracy: 0.9446 - cost: 7.0406 - val_loss: 0.1581 - val_auc: 0.9833 - val_accuracy: 0.9454 - val_cost: 7.1289\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1535 - auc: 0.9843 - accuracy: 0.9466 - cost: 6.7739 - val_loss: 0.1562 - val_auc: 0.9836 - val_accuracy: 0.9463 - val_cost: 7.1354\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1497 - auc: 0.9849 - accuracy: 0.9487 - cost: 6.5230 - val_loss: 0.1509 - val_auc: 0.9847 - val_accuracy: 0.9475 - val_cost: 6.9206\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1462 - auc: 0.9856 - accuracy: 0.9497 - cost: 6.4178 - val_loss: 0.1509 - val_auc: 0.9846 - val_accuracy: 0.9479 - val_cost: 6.7871\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1437 - auc: 0.9860 - accuracy: 0.9510 - cost: 6.2409 - val_loss: 0.1473 - val_auc: 0.9853 - val_accuracy: 0.9490 - val_cost: 6.5885\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1410 - auc: 0.9864 - accuracy: 0.9519 - cost: 6.1337 - val_loss: 0.1461 - val_auc: 0.9854 - val_accuracy: 0.9500 - val_cost: 6.4974\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1384 - auc: 0.9868 - accuracy: 0.9533 - cost: 5.9436 - val_loss: 0.1430 - val_auc: 0.9860 - val_accuracy: 0.9518 - val_cost: 6.1849\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1352 - auc: 0.9874 - accuracy: 0.9544 - cost: 5.8025 - val_loss: 0.1419 - val_auc: 0.9862 - val_accuracy: 0.9510 - val_cost: 6.6016\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1332 - auc: 0.9876 - accuracy: 0.9550 - cost: 5.7295 - val_loss: 0.1393 - val_auc: 0.9864 - val_accuracy: 0.9534 - val_cost: 6.1100\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1305 - auc: 0.9880 - accuracy: 0.9563 - cost: 5.5699 - val_loss: 0.1370 - val_auc: 0.9867 - val_accuracy: 0.9550 - val_cost: 5.9342\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1277 - auc: 0.9885 - accuracy: 0.9579 - cost: 5.3390 - val_loss: 0.1362 - val_auc: 0.9868 - val_accuracy: 0.9564 - val_cost: 5.6283\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1269 - auc: 0.9886 - accuracy: 0.9585 - cost: 5.3002 - val_loss: 0.1363 - val_auc: 0.9869 - val_accuracy: 0.9550 - val_cost: 5.7487\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9888 - accuracy: 0.9588 - cost: 5.2385 - val_loss: 0.1351 - val_auc: 0.9871 - val_accuracy: 0.9555 - val_cost: 5.8431\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1234 - auc: 0.9891 - accuracy: 0.9594 - cost: 5.1516 - val_loss: 0.1321 - val_auc: 0.9875 - val_accuracy: 0.9574 - val_cost: 5.6185\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1222 - auc: 0.9893 - accuracy: 0.9602 - cost: 5.0716 - val_loss: 0.1306 - val_auc: 0.9876 - val_accuracy: 0.9581 - val_cost: 5.4622\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1209 - auc: 0.9895 - accuracy: 0.9608 - cost: 4.9835 - val_loss: 0.1320 - val_auc: 0.9873 - val_accuracy: 0.9573 - val_cost: 5.6413\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1181 - auc: 0.9898 - accuracy: 0.9617 - cost: 4.8911 - val_loss: 0.1314 - val_auc: 0.9874 - val_accuracy: 0.9586 - val_cost: 5.1855\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1171 - auc: 0.9899 - accuracy: 0.9622 - cost: 4.8129 - val_loss: 0.1289 - val_auc: 0.9879 - val_accuracy: 0.9587 - val_cost: 5.4915\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1156 - auc: 0.9900 - accuracy: 0.9626 - cost: 4.7597 - val_loss: 0.1267 - val_auc: 0.9880 - val_accuracy: 0.9601 - val_cost: 5.2995\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1142 - auc: 0.9902 - accuracy: 0.9636 - cost: 4.6368 - val_loss: 0.1275 - val_auc: 0.9881 - val_accuracy: 0.9596 - val_cost: 5.1204\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1133 - auc: 0.9903 - accuracy: 0.9640 - cost: 4.5770 - val_loss: 0.1249 - val_auc: 0.9883 - val_accuracy: 0.9597 - val_cost: 5.2051\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1122 - auc: 0.9905 - accuracy: 0.9643 - cost: 4.5482 - val_loss: 0.1238 - val_auc: 0.9884 - val_accuracy: 0.9614 - val_cost: 4.8958\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1118 - auc: 0.9906 - accuracy: 0.9648 - cost: 4.4848 - val_loss: 0.1257 - val_auc: 0.9883 - val_accuracy: 0.9615 - val_cost: 4.8796\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1097 - auc: 0.9907 - accuracy: 0.9652 - cost: 4.4384 - val_loss: 0.1240 - val_auc: 0.9883 - val_accuracy: 0.9610 - val_cost: 5.1628\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1089 - auc: 0.9908 - accuracy: 0.9659 - cost: 4.3463 - val_loss: 0.1221 - val_auc: 0.9888 - val_accuracy: 0.9620 - val_cost: 4.9805\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1081 - auc: 0.9910 - accuracy: 0.9662 - cost: 4.3046 - val_loss: 0.1236 - val_auc: 0.9884 - val_accuracy: 0.9633 - val_cost: 4.6289\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1078 - auc: 0.9909 - accuracy: 0.9662 - cost: 4.3023 - val_loss: 0.1230 - val_auc: 0.9886 - val_accuracy: 0.9628 - val_cost: 4.7103\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1064 - auc: 0.9912 - accuracy: 0.9667 - cost: 4.2482 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9639 - val_cost: 4.5833\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1056 - auc: 0.9912 - accuracy: 0.9672 - cost: 4.1774 - val_loss: 0.1254 - val_auc: 0.9885 - val_accuracy: 0.9615 - val_cost: 4.7038\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1048 - auc: 0.9914 - accuracy: 0.9671 - cost: 4.1942 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9629 - val_cost: 4.6419\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1046 - auc: 0.9915 - accuracy: 0.9671 - cost: 4.1993 - val_loss: 0.1211 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 4.6354\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1033 - auc: 0.9916 - accuracy: 0.9675 - cost: 4.1398 - val_loss: 0.1206 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 4.5475\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1030 - auc: 0.9915 - accuracy: 0.9680 - cost: 4.0805 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9643 - val_cost: 4.3294\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9681 - cost: 4.0844 - val_loss: 0.1202 - val_auc: 0.9891 - val_accuracy: 0.9640 - val_cost: 4.5475\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9920 - accuracy: 0.9689 - cost: 3.9658 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9632 - val_cost: 4.7461\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1010 - auc: 0.9917 - accuracy: 0.9689 - cost: 3.9646 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9649 - val_cost: 4.4010\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0998 - auc: 0.9920 - accuracy: 0.9692 - cost: 3.9427 - val_loss: 0.1191 - val_auc: 0.9889 - val_accuracy: 0.9647 - val_cost: 4.4727\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0987 - auc: 0.9922 - accuracy: 0.9695 - cost: 3.8916 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9642 - val_cost: 4.3424\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0983 - auc: 0.9921 - accuracy: 0.9700 - cost: 3.8329 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9651 - val_cost: 4.4531\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8300 - val_loss: 0.1173 - val_auc: 0.9892 - val_accuracy: 0.9648 - val_cost: 4.5280\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9920 - accuracy: 0.9698 - cost: 3.8608 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9658 - val_cost: 4.4238\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9923 - accuracy: 0.9707 - cost: 3.7349 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9664 - val_cost: 4.2383\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9923 - accuracy: 0.9701 - cost: 3.8203 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9658 - val_cost: 4.4499\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9923 - accuracy: 0.9703 - cost: 3.8009 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9661 - val_cost: 4.5150\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0964 - auc: 0.9922 - accuracy: 0.9707 - cost: 3.7554 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9658 - val_cost: 4.1797\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0942 - auc: 0.9925 - accuracy: 0.9716 - cost: 3.6350 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9663 - val_cost: 4.1764\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0941 - auc: 0.9926 - accuracy: 0.9713 - cost: 3.6605 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9657 - val_cost: 4.2643\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0947 - auc: 0.9926 - accuracy: 0.9712 - cost: 3.6799 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9657 - val_cost: 4.2383\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0942 - auc: 0.9927 - accuracy: 0.9717 - cost: 3.6307 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9671 - val_cost: 4.0625\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0934 - auc: 0.9927 - accuracy: 0.9714 - cost: 3.6541 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.1081\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0923 - auc: 0.9927 - accuracy: 0.9720 - cost: 3.5758 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 4.0690\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9720 - cost: 3.5938 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9652 - val_cost: 4.2546\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5549 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.1667\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9927 - accuracy: 0.9727 - cost: 3.5055 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.3457\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5702 - val_loss: 0.1140 - val_auc: 0.9890 - val_accuracy: 0.9674 - val_cost: 4.0332\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0926 - auc: 0.9928 - accuracy: 0.9722 - cost: 3.5642 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0137\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0908 - auc: 0.9929 - accuracy: 0.9732 - cost: 3.4375 - val_loss: 0.1121 - val_auc: 0.9893 - val_accuracy: 0.9684 - val_cost: 3.9746\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0911 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.4976 - val_loss: 0.1110 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 4.0788\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0911 - auc: 0.9929 - accuracy: 0.9728 - cost: 3.4919 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9662 - val_cost: 4.1895\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0910 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.5010 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.9453\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0896 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3613 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 3.9811\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0905 - auc: 0.9929 - accuracy: 0.9728 - cost: 3.4886 - val_loss: 0.1131 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.8965\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0892 - auc: 0.9931 - accuracy: 0.9731 - cost: 3.4485 - val_loss: 0.1133 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.0820\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0899 - auc: 0.9930 - accuracy: 0.9730 - cost: 3.4689 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.0788\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9929 - accuracy: 0.9736 - cost: 3.3905 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 3.9974\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0896 - auc: 0.9930 - accuracy: 0.9731 - cost: 3.4413 - val_loss: 0.1118 - val_auc: 0.9894 - val_accuracy: 0.9676 - val_cost: 4.2090\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3411 - val_loss: 0.1109 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.2057\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0872 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.3122 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 4.1992\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3681 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 4.0918\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0870 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3286 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 3.9583\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0870 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.3033 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.8249\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9935 - accuracy: 0.9747 - cost: 3.2629 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 4.0918\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2395 - val_loss: 0.1145 - val_auc: 0.9888 - val_accuracy: 0.9672 - val_cost: 4.3392\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9744 - cost: 3.2778 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0690\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9931 - accuracy: 0.9746 - cost: 3.2509 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 4.1634\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9934 - accuracy: 0.9746 - cost: 3.2662 - val_loss: 0.1131 - val_auc: 0.9892 - val_accuracy: 0.9666 - val_cost: 4.0267\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2916 - val_loss: 0.1108 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.1211\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0853 - auc: 0.9933 - accuracy: 0.9750 - cost: 3.2019 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9682 - val_cost: 4.1634\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0857 - auc: 0.9934 - accuracy: 0.9748 - cost: 3.2357 - val_loss: 0.1125 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9388\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9934 - accuracy: 0.9745 - cost: 3.2756 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9714\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9935 - accuracy: 0.9749 - cost: 3.2328 - val_loss: 0.1105 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.7891\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9752 - cost: 3.1905 - val_loss: 0.1122 - val_auc: 0.9891 - val_accuracy: 0.9689 - val_cost: 3.9876\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9934 - accuracy: 0.9747 - cost: 3.2626 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.2253\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.1969 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9934 - accuracy: 0.9755 - cost: 3.1493 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 3.9844\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0846 - auc: 0.9936 - accuracy: 0.9752 - cost: 3.1969 - val_loss: 0.1113 - val_auc: 0.9894 - val_accuracy: 0.9672 - val_cost: 4.0169\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1221 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8737\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1128 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7240\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0834 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0814 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0828 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0757 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.8021\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0839 - auc: 0.9935 - accuracy: 0.9757 - cost: 3.1239 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.7240\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0829 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.1062 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.9062\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1529 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.7988\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9939 - accuracy: 0.9756 - cost: 3.1421 - val_loss: 0.1090 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.8509\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9936 - accuracy: 0.9758 - cost: 3.1197 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.6979\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0963 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.7891\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9936 - accuracy: 0.9759 - cost: 3.1021 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.6751\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9763 - cost: 3.0525 - val_loss: 0.1126 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.7565\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9935 - accuracy: 0.9760 - cost: 3.0856 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7760\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0776 - val_loss: 0.1115 - val_auc: 0.9892 - val_accuracy: 0.9695 - val_cost: 3.7663\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0727 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.6589\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0873 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.9323\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9937 - accuracy: 0.9763 - cost: 3.0535 - val_loss: 0.1101 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6816\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0204 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7109\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0818 - auc: 0.9937 - accuracy: 0.9769 - cost: 2.9732 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.6556\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0366 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.6393\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0225 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.6328\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9941 - accuracy: 0.9768 - cost: 2.9869 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5775\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9802 - val_loss: 0.1095 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.6947\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9768 - cost: 3.0054 - val_loss: 0.1115 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7402\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9763 - cost: 3.0500 - val_loss: 0.1101 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.7728\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9767 - cost: 2.9998 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7565\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9688 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8021\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9764 - cost: 3.0235 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6719\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0097 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8411\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9635 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7044\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9539 - val_loss: 0.1115 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7402\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0296 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8184\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9390 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.7793\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9766 - cost: 3.0208 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.5677\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8879 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.6361\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9331 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6458\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9902 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9942 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.8053\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9230 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9695 - val_cost: 3.7272\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.8991 - val_loss: 0.1132 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.6914\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9317 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.9714\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9533 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.6751\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9113 - val_loss: 0.1113 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5352\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9777 - cost: 2.8800 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.5189\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9146 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.5807\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9136 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9693 - val_cost: 3.8249\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.8929 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6751\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8431 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6426\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8507 - val_loss: 0.1112 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6361\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8503 - val_loss: 0.1095 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6035\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8557 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6263\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8535 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6165\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9941 - accuracy: 0.9780 - cost: 2.8357 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.6230\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8616 - val_loss: 0.1111 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4928\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8418 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5514\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8689 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8483 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5514\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8369 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5970\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8488 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5319\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7917 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5156\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7819 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4928\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8282 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8153 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6589\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8653 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9698 - val_cost: 3.7826\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8140 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5677\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8537 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.6296\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8315 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.4733\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7375 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5612\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7732 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5059\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7807 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4863\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8485 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5449\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7615 - val_loss: 0.1163 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.4440\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8579 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.8639\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8284 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.3984\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8099 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9724 - val_cost: 3.3626\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.8083 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6328\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8200 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7706 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9716 - val_cost: 3.5775\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8337 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.5254\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.7875 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.4570\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7492 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6263\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7339 - val_loss: 0.1137 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.5905\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8395 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7371 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4896\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.8032 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5482\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8165 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5059\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7624 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.6100\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7198 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7207\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7911 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.4993\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7487 - val_loss: 0.1146 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.7695\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7676 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4668\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7457 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7207\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7856 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.6882\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7753 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.6882\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7190 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.5645\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6820 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.4505\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7637 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6003\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7352 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.5026\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6821 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.4538\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7536 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6361\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6624 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9724 - val_cost: 3.4147\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7252 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5189\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6597 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4635\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6797 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9721 - val_cost: 3.5710\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9945 - accuracy: 0.9788 - cost: 2.7375 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.5352\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6963 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.4342\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7663 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.7760\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6799 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.6003\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7278 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5710\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7266 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4863\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7169 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.6621\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7469 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6523\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9793 - cost: 2.6704 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9794 - cost: 2.6639 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4733\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7131 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7012\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9795 - cost: 2.6395 - val_loss: 0.1196 - val_auc: 0.9890 - val_accuracy: 0.9711 - val_cost: 3.5286\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6929 - val_loss: 0.1158 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.4993\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6423 - val_loss: 0.1163 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6263\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7452 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.4993\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6439 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.6523\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6708 - val_loss: 0.1156 - val_auc: 0.9892 - val_accuracy: 0.9722 - val_cost: 3.4570\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6899 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.4635\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7047 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.6068\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7287 - val_loss: 0.1154 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.4505\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7072 - val_loss: 0.1184 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.5384\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1072 - auc: 0.9911 - accuracy: 0.9711 - cost: 3.6344\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:11.903353\n",
            "fold accuracy: 0.9710624814033508 - fold cost: 3.6343750953674316\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 7ms/step - loss: 0.5467 - auc: 0.7790 - accuracy: 0.7148 - cost: 37.7937 - val_loss: 0.4074 - val_auc: 0.8945 - val_accuracy: 0.8222 - val_cost: 22.7148\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3648 - auc: 0.9152 - accuracy: 0.8435 - cost: 19.9384 - val_loss: 0.3225 - val_auc: 0.9337 - val_accuracy: 0.8635 - val_cost: 16.8164\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3139 - auc: 0.9376 - accuracy: 0.8695 - cost: 16.4941 - val_loss: 0.2949 - val_auc: 0.9449 - val_accuracy: 0.8788 - val_cost: 14.7428\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2877 - auc: 0.9478 - accuracy: 0.8835 - cost: 14.7044 - val_loss: 0.2721 - val_auc: 0.9534 - val_accuracy: 0.8903 - val_cost: 13.6914\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2665 - auc: 0.9552 - accuracy: 0.8933 - cost: 13.5054 - val_loss: 0.2510 - val_auc: 0.9604 - val_accuracy: 0.9014 - val_cost: 11.9889\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2465 - auc: 0.9617 - accuracy: 0.9025 - cost: 12.3291 - val_loss: 0.2341 - val_auc: 0.9653 - val_accuracy: 0.9128 - val_cost: 10.7812\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2296 - auc: 0.9667 - accuracy: 0.9105 - cost: 11.3346 - val_loss: 0.2214 - val_auc: 0.9689 - val_accuracy: 0.9169 - val_cost: 10.1725\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2169 - auc: 0.9702 - accuracy: 0.9171 - cost: 10.4828 - val_loss: 0.2086 - val_auc: 0.9722 - val_accuracy: 0.9224 - val_cost: 9.6582\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2047 - auc: 0.9734 - accuracy: 0.9225 - cost: 9.8141 - val_loss: 0.1980 - val_auc: 0.9749 - val_accuracy: 0.9267 - val_cost: 9.1862\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1957 - auc: 0.9756 - accuracy: 0.9265 - cost: 9.3076 - val_loss: 0.1912 - val_auc: 0.9765 - val_accuracy: 0.9308 - val_cost: 8.8379\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1865 - auc: 0.9777 - accuracy: 0.9306 - cost: 8.8252 - val_loss: 0.1835 - val_auc: 0.9783 - val_accuracy: 0.9336 - val_cost: 8.4993\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1806 - auc: 0.9789 - accuracy: 0.9341 - cost: 8.3596 - val_loss: 0.1782 - val_auc: 0.9795 - val_accuracy: 0.9337 - val_cost: 8.4180\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1754 - auc: 0.9801 - accuracy: 0.9364 - cost: 8.0795 - val_loss: 0.1728 - val_auc: 0.9805 - val_accuracy: 0.9376 - val_cost: 8.0599\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1688 - auc: 0.9813 - accuracy: 0.9386 - cost: 7.8002 - val_loss: 0.1687 - val_auc: 0.9814 - val_accuracy: 0.9383 - val_cost: 7.7799\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1637 - auc: 0.9824 - accuracy: 0.9412 - cost: 7.4746 - val_loss: 0.1651 - val_auc: 0.9820 - val_accuracy: 0.9415 - val_cost: 7.5749\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1597 - auc: 0.9831 - accuracy: 0.9436 - cost: 7.1390 - val_loss: 0.1615 - val_auc: 0.9829 - val_accuracy: 0.9432 - val_cost: 7.6042\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1559 - auc: 0.9839 - accuracy: 0.9454 - cost: 6.9471 - val_loss: 0.1591 - val_auc: 0.9834 - val_accuracy: 0.9424 - val_cost: 7.2233\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1512 - auc: 0.9846 - accuracy: 0.9469 - cost: 6.7405 - val_loss: 0.1547 - val_auc: 0.9840 - val_accuracy: 0.9457 - val_cost: 7.1680\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1488 - auc: 0.9850 - accuracy: 0.9488 - cost: 6.4934 - val_loss: 0.1540 - val_auc: 0.9842 - val_accuracy: 0.9460 - val_cost: 6.7773\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1467 - auc: 0.9854 - accuracy: 0.9495 - cost: 6.4008 - val_loss: 0.1500 - val_auc: 0.9847 - val_accuracy: 0.9470 - val_cost: 7.0931\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1433 - auc: 0.9861 - accuracy: 0.9506 - cost: 6.2826 - val_loss: 0.1496 - val_auc: 0.9848 - val_accuracy: 0.9477 - val_cost: 6.4388\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1416 - auc: 0.9864 - accuracy: 0.9513 - cost: 6.1756 - val_loss: 0.1469 - val_auc: 0.9853 - val_accuracy: 0.9485 - val_cost: 6.5951\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1391 - auc: 0.9867 - accuracy: 0.9528 - cost: 5.9851 - val_loss: 0.1445 - val_auc: 0.9855 - val_accuracy: 0.9503 - val_cost: 6.3607\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1360 - auc: 0.9872 - accuracy: 0.9544 - cost: 5.7917 - val_loss: 0.1438 - val_auc: 0.9857 - val_accuracy: 0.9505 - val_cost: 6.1914\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1343 - auc: 0.9875 - accuracy: 0.9548 - cost: 5.7513 - val_loss: 0.1417 - val_auc: 0.9858 - val_accuracy: 0.9516 - val_cost: 6.2891\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1314 - auc: 0.9879 - accuracy: 0.9565 - cost: 5.5330 - val_loss: 0.1406 - val_auc: 0.9861 - val_accuracy: 0.9518 - val_cost: 6.1882\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1302 - auc: 0.9881 - accuracy: 0.9566 - cost: 5.5089 - val_loss: 0.1418 - val_auc: 0.9862 - val_accuracy: 0.9520 - val_cost: 6.1458\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1290 - auc: 0.9883 - accuracy: 0.9572 - cost: 5.4229 - val_loss: 0.1373 - val_auc: 0.9866 - val_accuracy: 0.9533 - val_cost: 6.2760\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1263 - auc: 0.9887 - accuracy: 0.9577 - cost: 5.3776 - val_loss: 0.1373 - val_auc: 0.9865 - val_accuracy: 0.9533 - val_cost: 6.2891\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1256 - auc: 0.9886 - accuracy: 0.9590 - cost: 5.2234 - val_loss: 0.1366 - val_auc: 0.9867 - val_accuracy: 0.9556 - val_cost: 5.7650\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1237 - auc: 0.9890 - accuracy: 0.9595 - cost: 5.1450 - val_loss: 0.1333 - val_auc: 0.9871 - val_accuracy: 0.9564 - val_cost: 5.7520\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1222 - auc: 0.9891 - accuracy: 0.9608 - cost: 4.9772 - val_loss: 0.1338 - val_auc: 0.9870 - val_accuracy: 0.9563 - val_cost: 5.7682\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1200 - auc: 0.9895 - accuracy: 0.9611 - cost: 4.9391 - val_loss: 0.1317 - val_auc: 0.9872 - val_accuracy: 0.9577 - val_cost: 5.4427\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1199 - auc: 0.9895 - accuracy: 0.9618 - cost: 4.8478 - val_loss: 0.1324 - val_auc: 0.9873 - val_accuracy: 0.9572 - val_cost: 5.5273\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1174 - auc: 0.9898 - accuracy: 0.9621 - cost: 4.7901 - val_loss: 0.1292 - val_auc: 0.9876 - val_accuracy: 0.9577 - val_cost: 5.6087\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1161 - auc: 0.9900 - accuracy: 0.9632 - cost: 4.6867 - val_loss: 0.1300 - val_auc: 0.9874 - val_accuracy: 0.9592 - val_cost: 5.3971\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1146 - auc: 0.9902 - accuracy: 0.9633 - cost: 4.6597 - val_loss: 0.1291 - val_auc: 0.9874 - val_accuracy: 0.9594 - val_cost: 5.1465\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1147 - auc: 0.9902 - accuracy: 0.9636 - cost: 4.6275 - val_loss: 0.1282 - val_auc: 0.9875 - val_accuracy: 0.9596 - val_cost: 5.0586\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1134 - auc: 0.9903 - accuracy: 0.9637 - cost: 4.6192 - val_loss: 0.1255 - val_auc: 0.9877 - val_accuracy: 0.9593 - val_cost: 5.4329\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1112 - auc: 0.9907 - accuracy: 0.9648 - cost: 4.4812 - val_loss: 0.1264 - val_auc: 0.9879 - val_accuracy: 0.9601 - val_cost: 5.2474\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1115 - auc: 0.9905 - accuracy: 0.9648 - cost: 4.4861 - val_loss: 0.1261 - val_auc: 0.9878 - val_accuracy: 0.9607 - val_cost: 4.9089\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1109 - auc: 0.9906 - accuracy: 0.9652 - cost: 4.4299 - val_loss: 0.1245 - val_auc: 0.9879 - val_accuracy: 0.9614 - val_cost: 4.8568\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1096 - auc: 0.9907 - accuracy: 0.9657 - cost: 4.3761 - val_loss: 0.1230 - val_auc: 0.9883 - val_accuracy: 0.9616 - val_cost: 4.9316\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1085 - auc: 0.9908 - accuracy: 0.9659 - cost: 4.3354 - val_loss: 0.1231 - val_auc: 0.9881 - val_accuracy: 0.9609 - val_cost: 5.1758\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1075 - auc: 0.9910 - accuracy: 0.9666 - cost: 4.2498 - val_loss: 0.1245 - val_auc: 0.9877 - val_accuracy: 0.9623 - val_cost: 4.7103\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1078 - auc: 0.9909 - accuracy: 0.9668 - cost: 4.2262 - val_loss: 0.1246 - val_auc: 0.9879 - val_accuracy: 0.9622 - val_cost: 4.7233\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1057 - auc: 0.9913 - accuracy: 0.9671 - cost: 4.1896 - val_loss: 0.1229 - val_auc: 0.9881 - val_accuracy: 0.9624 - val_cost: 4.8210\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1047 - auc: 0.9914 - accuracy: 0.9674 - cost: 4.1544 - val_loss: 0.1216 - val_auc: 0.9883 - val_accuracy: 0.9622 - val_cost: 5.0456\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9915 - accuracy: 0.9675 - cost: 4.1313 - val_loss: 0.1203 - val_auc: 0.9883 - val_accuracy: 0.9629 - val_cost: 4.8503\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1040 - auc: 0.9914 - accuracy: 0.9682 - cost: 4.0647 - val_loss: 0.1211 - val_auc: 0.9883 - val_accuracy: 0.9638 - val_cost: 4.7721\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1035 - auc: 0.9916 - accuracy: 0.9680 - cost: 4.0852 - val_loss: 0.1192 - val_auc: 0.9884 - val_accuracy: 0.9641 - val_cost: 4.6517\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1028 - auc: 0.9915 - accuracy: 0.9685 - cost: 4.0148 - val_loss: 0.1220 - val_auc: 0.9883 - val_accuracy: 0.9637 - val_cost: 4.6745\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1018 - auc: 0.9917 - accuracy: 0.9688 - cost: 3.9708 - val_loss: 0.1205 - val_auc: 0.9885 - val_accuracy: 0.9629 - val_cost: 5.0163\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1019 - auc: 0.9917 - accuracy: 0.9690 - cost: 3.9374 - val_loss: 0.1217 - val_auc: 0.9883 - val_accuracy: 0.9638 - val_cost: 4.6647\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1007 - auc: 0.9918 - accuracy: 0.9693 - cost: 3.9069 - val_loss: 0.1190 - val_auc: 0.9886 - val_accuracy: 0.9644 - val_cost: 4.7591\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0996 - auc: 0.9920 - accuracy: 0.9696 - cost: 3.8720 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9635 - val_cost: 4.8861\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9920 - accuracy: 0.9696 - cost: 3.8808 - val_loss: 0.1187 - val_auc: 0.9886 - val_accuracy: 0.9649 - val_cost: 4.5345\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0991 - auc: 0.9920 - accuracy: 0.9700 - cost: 3.8380 - val_loss: 0.1202 - val_auc: 0.9885 - val_accuracy: 0.9647 - val_cost: 4.5345\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9920 - accuracy: 0.9700 - cost: 3.8304 - val_loss: 0.1167 - val_auc: 0.9887 - val_accuracy: 0.9652 - val_cost: 4.5638\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9920 - accuracy: 0.9705 - cost: 3.7615 - val_loss: 0.1183 - val_auc: 0.9886 - val_accuracy: 0.9663 - val_cost: 4.4206\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9922 - accuracy: 0.9703 - cost: 3.7901 - val_loss: 0.1179 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.3490\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0980 - auc: 0.9920 - accuracy: 0.9707 - cost: 3.7417 - val_loss: 0.1203 - val_auc: 0.9885 - val_accuracy: 0.9645 - val_cost: 4.6680\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9922 - accuracy: 0.9705 - cost: 3.7705 - val_loss: 0.1176 - val_auc: 0.9887 - val_accuracy: 0.9655 - val_cost: 4.3620\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0975 - auc: 0.9921 - accuracy: 0.9704 - cost: 3.7930 - val_loss: 0.1183 - val_auc: 0.9886 - val_accuracy: 0.9650 - val_cost: 4.5833\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0962 - auc: 0.9924 - accuracy: 0.9709 - cost: 3.7203 - val_loss: 0.1167 - val_auc: 0.9889 - val_accuracy: 0.9664 - val_cost: 4.3913\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0953 - auc: 0.9924 - accuracy: 0.9709 - cost: 3.7178 - val_loss: 0.1147 - val_auc: 0.9891 - val_accuracy: 0.9664 - val_cost: 4.3197\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0946 - auc: 0.9925 - accuracy: 0.9717 - cost: 3.6214 - val_loss: 0.1167 - val_auc: 0.9886 - val_accuracy: 0.9655 - val_cost: 4.4824\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9926 - accuracy: 0.9721 - cost: 3.5721 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9649 - val_cost: 4.3457\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0947 - auc: 0.9925 - accuracy: 0.9714 - cost: 3.6452 - val_loss: 0.1166 - val_auc: 0.9888 - val_accuracy: 0.9656 - val_cost: 4.4434\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9926 - accuracy: 0.9713 - cost: 3.6715 - val_loss: 0.1175 - val_auc: 0.9889 - val_accuracy: 0.9657 - val_cost: 4.3262\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0933 - auc: 0.9926 - accuracy: 0.9720 - cost: 3.5785 - val_loss: 0.1163 - val_auc: 0.9889 - val_accuracy: 0.9662 - val_cost: 4.3034\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5795 - val_loss: 0.1157 - val_auc: 0.9887 - val_accuracy: 0.9660 - val_cost: 4.3620\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0925 - auc: 0.9926 - accuracy: 0.9727 - cost: 3.4885 - val_loss: 0.1174 - val_auc: 0.9886 - val_accuracy: 0.9663 - val_cost: 4.3066\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0933 - auc: 0.9926 - accuracy: 0.9725 - cost: 3.5140 - val_loss: 0.1158 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.2546\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0919 - auc: 0.9929 - accuracy: 0.9724 - cost: 3.5234 - val_loss: 0.1168 - val_auc: 0.9887 - val_accuracy: 0.9674 - val_cost: 4.1374\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9724 - cost: 3.5267 - val_loss: 0.1169 - val_auc: 0.9886 - val_accuracy: 0.9665 - val_cost: 4.2220\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9726 - cost: 3.5140 - val_loss: 0.1188 - val_auc: 0.9886 - val_accuracy: 0.9659 - val_cost: 4.2578\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9928 - accuracy: 0.9726 - cost: 3.5047 - val_loss: 0.1166 - val_auc: 0.9885 - val_accuracy: 0.9665 - val_cost: 4.2936\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9928 - accuracy: 0.9727 - cost: 3.4730 - val_loss: 0.1156 - val_auc: 0.9889 - val_accuracy: 0.9670 - val_cost: 4.2936\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9928 - accuracy: 0.9729 - cost: 3.4648 - val_loss: 0.1161 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 4.1699\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9927 - accuracy: 0.9727 - cost: 3.4980 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.1081\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9929 - accuracy: 0.9731 - cost: 3.4313 - val_loss: 0.1156 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 4.0918\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9732 - cost: 3.4213 - val_loss: 0.1165 - val_auc: 0.9887 - val_accuracy: 0.9664 - val_cost: 4.3783\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9931 - accuracy: 0.9734 - cost: 3.4093 - val_loss: 0.1157 - val_auc: 0.9888 - val_accuracy: 0.9668 - val_cost: 4.0527\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9929 - accuracy: 0.9736 - cost: 3.3728 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9676 - val_cost: 4.1439\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9931 - accuracy: 0.9732 - cost: 3.4290 - val_loss: 0.1141 - val_auc: 0.9891 - val_accuracy: 0.9674 - val_cost: 4.0820\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9930 - accuracy: 0.9733 - cost: 3.4163 - val_loss: 0.1145 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 4.1309\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3302 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9675 - val_cost: 4.1699\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9931 - accuracy: 0.9740 - cost: 3.3216 - val_loss: 0.1170 - val_auc: 0.9889 - val_accuracy: 0.9678 - val_cost: 4.0332\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9736 - cost: 3.3841 - val_loss: 0.1170 - val_auc: 0.9888 - val_accuracy: 0.9658 - val_cost: 4.3490\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0887 - auc: 0.9933 - accuracy: 0.9739 - cost: 3.3457 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.2350\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9933 - accuracy: 0.9740 - cost: 3.3305 - val_loss: 0.1139 - val_auc: 0.9889 - val_accuracy: 0.9687 - val_cost: 3.9909\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0885 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3315 - val_loss: 0.1152 - val_auc: 0.9888 - val_accuracy: 0.9683 - val_cost: 4.0527\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3176 - val_loss: 0.1146 - val_auc: 0.9890 - val_accuracy: 0.9682 - val_cost: 4.1178\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9743 - cost: 3.2949 - val_loss: 0.1136 - val_auc: 0.9891 - val_accuracy: 0.9680 - val_cost: 4.3457\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0882 - auc: 0.9931 - accuracy: 0.9742 - cost: 3.3022 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 4.2025\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.3135 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 4.0592\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9747 - cost: 3.2443 - val_loss: 0.1141 - val_auc: 0.9890 - val_accuracy: 0.9677 - val_cost: 4.0755\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9934 - accuracy: 0.9744 - cost: 3.2913 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 4.1406\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.3001 - val_loss: 0.1125 - val_auc: 0.9891 - val_accuracy: 0.9695 - val_cost: 3.9551\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9933 - accuracy: 0.9749 - cost: 3.2104 - val_loss: 0.1129 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9290\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9743 - cost: 3.2811 - val_loss: 0.1129 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 4.1895\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9934 - accuracy: 0.9746 - cost: 3.2580 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9687 - val_cost: 4.0202\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9934 - accuracy: 0.9750 - cost: 3.2127 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9685 - val_cost: 4.0397\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9934 - accuracy: 0.9747 - cost: 3.2391 - val_loss: 0.1133 - val_auc: 0.9890 - val_accuracy: 0.9683 - val_cost: 4.1569\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0859 - auc: 0.9935 - accuracy: 0.9747 - cost: 3.2379 - val_loss: 0.1162 - val_auc: 0.9889 - val_accuracy: 0.9674 - val_cost: 4.2383\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9935 - accuracy: 0.9745 - cost: 3.2657 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 4.0039\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9934 - accuracy: 0.9751 - cost: 3.1885 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9678 - val_cost: 4.2871\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9934 - accuracy: 0.9750 - cost: 3.2077 - val_loss: 0.1158 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 4.0560\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1728 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 4.0169\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2426 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.1732\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.2013 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9689 - val_cost: 4.2090\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9934 - accuracy: 0.9752 - cost: 3.1645 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 4.0495\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1525 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.9160\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9937 - accuracy: 0.9752 - cost: 3.1970 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 4.0462\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.1944 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.1374\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1434 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9687 - val_cost: 4.0039\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9936 - accuracy: 0.9756 - cost: 3.1296 - val_loss: 0.1128 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 4.1764\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1144 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.8672\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1056 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.8867\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9938 - accuracy: 0.9756 - cost: 3.1387 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.8965\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1180 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.8607\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1401 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9683 - val_cost: 4.0365\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9754 - cost: 3.1531 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.9714\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9938 - accuracy: 0.9757 - cost: 3.1171 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9714\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.1037 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9692 - val_cost: 3.9160\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0657 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0755\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9937 - accuracy: 0.9760 - cost: 3.0765 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 4.1146\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1438 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9693 - val_cost: 3.9518\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9758 - cost: 3.0999 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 4.1699\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0823 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 4.0267\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0947 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.9062\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9763 - cost: 3.0367 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 4.0202\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0564 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 4.0495\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9763 - cost: 3.0457 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9909\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0945 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.9128\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0464 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.9779\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0159 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 4.0625\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0634 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.8509\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9874 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.9323\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9766 - cost: 3.0082 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 4.0104\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0811 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0441 - val_loss: 0.1110 - val_auc: 0.9895 - val_accuracy: 0.9696 - val_cost: 4.0039\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9959 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 4.0202\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0153 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.9193\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9761 - cost: 3.0825 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9687 - val_cost: 4.1406\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9764 - cost: 3.0273 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.9518\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0544 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8770\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9768 - cost: 2.9777 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.8346\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9766 - cost: 3.0248 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9827 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.8509\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9764 - cost: 3.0131 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.8509\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9246 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.8802\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9615 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.9421\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9667 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.9551\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9579 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.8997\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9623 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9695 - val_cost: 3.9876\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9764 - cost: 3.0412 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.9193\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9202 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 4.1569\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9940 - accuracy: 0.9774 - cost: 2.9135 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8477\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9759 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.9258\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.9033 - val_loss: 0.1138 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.9909\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8932 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8444\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.8869 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.1862\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0796 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9482 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9909\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9944 - accuracy: 0.9769 - cost: 2.9728 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.7500\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9401 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8672\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9583 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 4.1178\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0794 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9270 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.8249\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9007 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.8835\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9561 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.6621\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8626 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8216\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9103 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.8151\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8470 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.8704\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9556 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.9486\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9232 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8965\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8681 - val_loss: 0.1139 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5840\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9209 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.6947\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8554 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.6263\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8914 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9686 - val_cost: 3.8574\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8833 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9692 - val_cost: 4.1048\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8102 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7044\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8557 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.8672\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8997 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.7402\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8319 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7891\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8846 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.6556\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8710 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.7207\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8625 - val_loss: 0.1146 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.9453\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8565 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.7858\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8787 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.7272\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8224 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.9160\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8825 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.9323\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8826 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.8346\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8125 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6165\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7854 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.8118\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8119 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.9681\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8510 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.6621\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8154 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.9128\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8173 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.8346\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.9038 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.9714\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8440 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.6328\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8410 - val_loss: 0.1191 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.9746\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8513 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.9258\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8606 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.6068\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8439 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7174\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8088 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.8053\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8818 - val_loss: 0.1145 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 4.0918\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8009 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8737\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8026 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9693 - val_cost: 4.1406\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7714 - val_loss: 0.1148 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7370\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7972 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8281\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8299 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.9811\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8495 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.9095\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8672 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.6263\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8281 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.7598\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7606 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6686\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8249 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9695 - val_cost: 3.8346\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7492 - val_loss: 0.1167 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.6914\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8152 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.6458\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7944 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7435\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8436 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.8542\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8692 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7917 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6458\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7320 - val_loss: 0.1158 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6003\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7288 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7337\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7605 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7109\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.8082 - val_loss: 0.1150 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.7012\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0954 - auc: 0.9921 - accuracy: 0.9741 - cost: 3.2844\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:10.344717\n",
            "fold accuracy: 0.9741250276565552 - fold cost: 3.284374952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5455 - auc: 0.7810 - accuracy: 0.7161 - cost: 37.5245 - val_loss: 0.4033 - val_auc: 0.8968 - val_accuracy: 0.8242 - val_cost: 22.7767\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3640 - auc: 0.9156 - accuracy: 0.8429 - cost: 19.9758 - val_loss: 0.3182 - val_auc: 0.9357 - val_accuracy: 0.8672 - val_cost: 16.3021\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3139 - auc: 0.9377 - accuracy: 0.8694 - cost: 16.5100 - val_loss: 0.2889 - val_auc: 0.9474 - val_accuracy: 0.8813 - val_cost: 14.5964\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2866 - auc: 0.9482 - accuracy: 0.8830 - cost: 14.7634 - val_loss: 0.2666 - val_auc: 0.9550 - val_accuracy: 0.8930 - val_cost: 13.2031\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2640 - auc: 0.9561 - accuracy: 0.8941 - cost: 13.3849 - val_loss: 0.2482 - val_auc: 0.9612 - val_accuracy: 0.9013 - val_cost: 12.0540\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2463 - auc: 0.9619 - accuracy: 0.9032 - cost: 12.2342 - val_loss: 0.2315 - val_auc: 0.9660 - val_accuracy: 0.9112 - val_cost: 10.9212\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2293 - auc: 0.9668 - accuracy: 0.9113 - cost: 11.2080 - val_loss: 0.2186 - val_auc: 0.9699 - val_accuracy: 0.9180 - val_cost: 10.1432\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2161 - auc: 0.9705 - accuracy: 0.9175 - cost: 10.4511 - val_loss: 0.2049 - val_auc: 0.9734 - val_accuracy: 0.9245 - val_cost: 9.3327\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2049 - auc: 0.9734 - accuracy: 0.9220 - cost: 9.8620 - val_loss: 0.1954 - val_auc: 0.9759 - val_accuracy: 0.9297 - val_cost: 8.5547\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1956 - auc: 0.9757 - accuracy: 0.9274 - cost: 9.1895 - val_loss: 0.1869 - val_auc: 0.9775 - val_accuracy: 0.9336 - val_cost: 8.5807\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1871 - auc: 0.9776 - accuracy: 0.9310 - cost: 8.7689 - val_loss: 0.1802 - val_auc: 0.9790 - val_accuracy: 0.9369 - val_cost: 7.7799\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1783 - auc: 0.9796 - accuracy: 0.9349 - cost: 8.2646 - val_loss: 0.1749 - val_auc: 0.9802 - val_accuracy: 0.9387 - val_cost: 8.1738\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1719 - auc: 0.9808 - accuracy: 0.9378 - cost: 7.8931 - val_loss: 0.1682 - val_auc: 0.9814 - val_accuracy: 0.9401 - val_cost: 7.8548\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1670 - auc: 0.9818 - accuracy: 0.9399 - cost: 7.6315 - val_loss: 0.1648 - val_auc: 0.9823 - val_accuracy: 0.9418 - val_cost: 7.4414\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1631 - auc: 0.9826 - accuracy: 0.9424 - cost: 7.3198 - val_loss: 0.1634 - val_auc: 0.9829 - val_accuracy: 0.9431 - val_cost: 7.2038\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1571 - auc: 0.9836 - accuracy: 0.9449 - cost: 7.0114 - val_loss: 0.1573 - val_auc: 0.9837 - val_accuracy: 0.9448 - val_cost: 6.8555\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1531 - auc: 0.9844 - accuracy: 0.9469 - cost: 6.7455 - val_loss: 0.1544 - val_auc: 0.9840 - val_accuracy: 0.9463 - val_cost: 6.7741\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1499 - auc: 0.9850 - accuracy: 0.9479 - cost: 6.6231 - val_loss: 0.1516 - val_auc: 0.9847 - val_accuracy: 0.9464 - val_cost: 7.0540\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1478 - auc: 0.9853 - accuracy: 0.9490 - cost: 6.4843 - val_loss: 0.1502 - val_auc: 0.9846 - val_accuracy: 0.9486 - val_cost: 6.6276\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1436 - auc: 0.9860 - accuracy: 0.9509 - cost: 6.2507 - val_loss: 0.1468 - val_auc: 0.9851 - val_accuracy: 0.9503 - val_cost: 6.2956\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1403 - auc: 0.9866 - accuracy: 0.9525 - cost: 6.0373 - val_loss: 0.1443 - val_auc: 0.9858 - val_accuracy: 0.9519 - val_cost: 6.3737\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1383 - auc: 0.9868 - accuracy: 0.9532 - cost: 5.9374 - val_loss: 0.1425 - val_auc: 0.9860 - val_accuracy: 0.9513 - val_cost: 6.2760\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1354 - auc: 0.9873 - accuracy: 0.9543 - cost: 5.8171 - val_loss: 0.1401 - val_auc: 0.9862 - val_accuracy: 0.9535 - val_cost: 5.9603\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1330 - auc: 0.9877 - accuracy: 0.9554 - cost: 5.6692 - val_loss: 0.1386 - val_auc: 0.9866 - val_accuracy: 0.9544 - val_cost: 5.9049\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1317 - auc: 0.9879 - accuracy: 0.9564 - cost: 5.5584 - val_loss: 0.1371 - val_auc: 0.9866 - val_accuracy: 0.9553 - val_cost: 5.7975\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1284 - auc: 0.9885 - accuracy: 0.9575 - cost: 5.4132 - val_loss: 0.1354 - val_auc: 0.9868 - val_accuracy: 0.9572 - val_cost: 5.6315\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1262 - auc: 0.9887 - accuracy: 0.9581 - cost: 5.3365 - val_loss: 0.1341 - val_auc: 0.9870 - val_accuracy: 0.9565 - val_cost: 5.8691\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1245 - auc: 0.9889 - accuracy: 0.9595 - cost: 5.1548 - val_loss: 0.1339 - val_auc: 0.9871 - val_accuracy: 0.9581 - val_cost: 5.3906\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1231 - auc: 0.9892 - accuracy: 0.9597 - cost: 5.1265 - val_loss: 0.1321 - val_auc: 0.9872 - val_accuracy: 0.9597 - val_cost: 5.2474\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1214 - auc: 0.9894 - accuracy: 0.9602 - cost: 5.0536 - val_loss: 0.1311 - val_auc: 0.9875 - val_accuracy: 0.9599 - val_cost: 5.3320\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1210 - auc: 0.9894 - accuracy: 0.9609 - cost: 4.9750 - val_loss: 0.1302 - val_auc: 0.9875 - val_accuracy: 0.9592 - val_cost: 5.2539\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9896 - accuracy: 0.9617 - cost: 4.8703 - val_loss: 0.1291 - val_auc: 0.9878 - val_accuracy: 0.9606 - val_cost: 5.1009\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1167 - auc: 0.9899 - accuracy: 0.9621 - cost: 4.8243 - val_loss: 0.1274 - val_auc: 0.9879 - val_accuracy: 0.9599 - val_cost: 5.1855\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1166 - auc: 0.9900 - accuracy: 0.9628 - cost: 4.7273 - val_loss: 0.1286 - val_auc: 0.9878 - val_accuracy: 0.9601 - val_cost: 5.1204\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1155 - auc: 0.9901 - accuracy: 0.9628 - cost: 4.7379 - val_loss: 0.1258 - val_auc: 0.9879 - val_accuracy: 0.9613 - val_cost: 4.6745\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1143 - auc: 0.9902 - accuracy: 0.9635 - cost: 4.6484 - val_loss: 0.1256 - val_auc: 0.9881 - val_accuracy: 0.9611 - val_cost: 4.9707\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1128 - auc: 0.9904 - accuracy: 0.9644 - cost: 4.5193 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9619 - val_cost: 4.8763\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1118 - auc: 0.9906 - accuracy: 0.9642 - cost: 4.5694 - val_loss: 0.1249 - val_auc: 0.9883 - val_accuracy: 0.9628 - val_cost: 4.7949\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1119 - auc: 0.9905 - accuracy: 0.9648 - cost: 4.4719 - val_loss: 0.1248 - val_auc: 0.9880 - val_accuracy: 0.9624 - val_cost: 4.8503\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1103 - auc: 0.9907 - accuracy: 0.9656 - cost: 4.3807 - val_loss: 0.1220 - val_auc: 0.9886 - val_accuracy: 0.9633 - val_cost: 4.6452\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1080 - auc: 0.9910 - accuracy: 0.9662 - cost: 4.2952 - val_loss: 0.1236 - val_auc: 0.9884 - val_accuracy: 0.9624 - val_cost: 4.8470\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1085 - auc: 0.9910 - accuracy: 0.9663 - cost: 4.2893 - val_loss: 0.1228 - val_auc: 0.9885 - val_accuracy: 0.9634 - val_cost: 4.6387\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1072 - auc: 0.9910 - accuracy: 0.9663 - cost: 4.2766 - val_loss: 0.1225 - val_auc: 0.9884 - val_accuracy: 0.9638 - val_cost: 4.6387\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1064 - auc: 0.9914 - accuracy: 0.9665 - cost: 4.2677 - val_loss: 0.1218 - val_auc: 0.9886 - val_accuracy: 0.9631 - val_cost: 4.7266\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1049 - auc: 0.9916 - accuracy: 0.9671 - cost: 4.1868 - val_loss: 0.1222 - val_auc: 0.9884 - val_accuracy: 0.9636 - val_cost: 4.5866\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9914 - accuracy: 0.9676 - cost: 4.1268 - val_loss: 0.1219 - val_auc: 0.9885 - val_accuracy: 0.9628 - val_cost: 4.7721\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1040 - auc: 0.9914 - accuracy: 0.9676 - cost: 4.1304 - val_loss: 0.1211 - val_auc: 0.9887 - val_accuracy: 0.9631 - val_cost: 4.9902\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9685 - cost: 4.0195 - val_loss: 0.1216 - val_auc: 0.9886 - val_accuracy: 0.9630 - val_cost: 4.7428\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1027 - auc: 0.9917 - accuracy: 0.9682 - cost: 4.0478 - val_loss: 0.1215 - val_auc: 0.9883 - val_accuracy: 0.9634 - val_cost: 4.7526\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1030 - auc: 0.9916 - accuracy: 0.9681 - cost: 4.0654 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9644 - val_cost: 4.5671\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1016 - auc: 0.9918 - accuracy: 0.9692 - cost: 3.9368 - val_loss: 0.1197 - val_auc: 0.9886 - val_accuracy: 0.9644 - val_cost: 4.5671\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1016 - auc: 0.9917 - accuracy: 0.9689 - cost: 3.9718 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9642 - val_cost: 4.4857\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1006 - auc: 0.9918 - accuracy: 0.9693 - cost: 3.9143 - val_loss: 0.1178 - val_auc: 0.9888 - val_accuracy: 0.9658 - val_cost: 4.4629\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0997 - auc: 0.9920 - accuracy: 0.9694 - cost: 3.8984 - val_loss: 0.1170 - val_auc: 0.9890 - val_accuracy: 0.9650 - val_cost: 4.4759\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9920 - accuracy: 0.9700 - cost: 3.8256 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9649 - val_cost: 4.4466\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9921 - accuracy: 0.9696 - cost: 3.8702 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.5052\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0977 - auc: 0.9922 - accuracy: 0.9697 - cost: 3.8642 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9653 - val_cost: 4.3717\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0975 - auc: 0.9922 - accuracy: 0.9703 - cost: 3.7822 - val_loss: 0.1166 - val_auc: 0.9888 - val_accuracy: 0.9658 - val_cost: 4.3848\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0977 - auc: 0.9922 - accuracy: 0.9706 - cost: 3.7607 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9667 - val_cost: 4.3359\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9923 - accuracy: 0.9704 - cost: 3.7658 - val_loss: 0.1157 - val_auc: 0.9890 - val_accuracy: 0.9645 - val_cost: 4.7559\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0961 - auc: 0.9924 - accuracy: 0.9711 - cost: 3.6952 - val_loss: 0.1163 - val_auc: 0.9891 - val_accuracy: 0.9657 - val_cost: 4.3945\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0964 - auc: 0.9924 - accuracy: 0.9711 - cost: 3.6918 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9658 - val_cost: 4.3424\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0957 - auc: 0.9924 - accuracy: 0.9710 - cost: 3.7090 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9663 - val_cost: 4.4759\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0943 - auc: 0.9925 - accuracy: 0.9713 - cost: 3.6578 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9666 - val_cost: 4.3685\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0940 - auc: 0.9926 - accuracy: 0.9720 - cost: 3.5743 - val_loss: 0.1136 - val_auc: 0.9891 - val_accuracy: 0.9676 - val_cost: 4.1471\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0947 - auc: 0.9925 - accuracy: 0.9717 - cost: 3.6185 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.2383\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0940 - auc: 0.9926 - accuracy: 0.9719 - cost: 3.5874 - val_loss: 0.1130 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.0853\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0933 - auc: 0.9927 - accuracy: 0.9718 - cost: 3.6036 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.3652\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0928 - auc: 0.9926 - accuracy: 0.9723 - cost: 3.5314 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.3164\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9722 - cost: 3.5613 - val_loss: 0.1126 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.2383\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9927 - accuracy: 0.9722 - cost: 3.5475 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0853\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9726 - cost: 3.4939 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9486\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9928 - accuracy: 0.9735 - cost: 3.3916 - val_loss: 0.1120 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 4.1634\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9928 - accuracy: 0.9727 - cost: 3.4973 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9678 - val_cost: 4.2253\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9929 - accuracy: 0.9724 - cost: 3.5355 - val_loss: 0.1127 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.9714\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9727 - cost: 3.4885 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.2025\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0904 - auc: 0.9930 - accuracy: 0.9732 - cost: 3.4467 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.9290\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9929 - accuracy: 0.9734 - cost: 3.4052 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 4.0495\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9931 - accuracy: 0.9737 - cost: 3.3709 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.9030\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9734 - cost: 3.4054 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.9225\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3138 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.8477\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9933 - accuracy: 0.9734 - cost: 3.4132 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 4.0299\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3166 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.6751\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9737 - cost: 3.3716 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.8118\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3135 - val_loss: 0.1094 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 4.0592\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2866 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8542\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9743 - cost: 3.3018 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7760\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3169 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7109\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9740 - cost: 3.3245 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.8997\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0858 - auc: 0.9936 - accuracy: 0.9747 - cost: 3.2506 - val_loss: 0.1106 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.8281\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0860 - auc: 0.9934 - accuracy: 0.9748 - cost: 3.2258 - val_loss: 0.1082 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.9323\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0861 - auc: 0.9934 - accuracy: 0.9749 - cost: 3.2201 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8704\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0856 - auc: 0.9936 - accuracy: 0.9749 - cost: 3.2219 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.7598\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9752 - cost: 3.1931 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.7305\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2302 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.7174\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9748 - cost: 3.2407 - val_loss: 0.1074 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.9518\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9934 - accuracy: 0.9758 - cost: 3.1052 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9355\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1243 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.9193\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.2057 - val_loss: 0.1096 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.7760\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.1980 - val_loss: 0.1085 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.6979\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0730 - val_loss: 0.1085 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.7630\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1009 - val_loss: 0.1082 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7760\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1182 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.7077\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9751 - cost: 3.1961 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7533\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0931 - val_loss: 0.1103 - val_auc: 0.9894 - val_accuracy: 0.9711 - val_cost: 3.7142\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1270 - val_loss: 0.1090 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.7240\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0948 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.9095\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9935 - accuracy: 0.9755 - cost: 3.1323 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.7598\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9937 - accuracy: 0.9764 - cost: 3.0254 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.7793\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0628 - val_loss: 0.1082 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.8346\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0645 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.7435\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0368 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.6328\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0534 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6914\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0799 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.8086\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0081 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.7337\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9759 - cost: 3.0954 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0583 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.6751\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0503 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6068\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9768 - cost: 2.9762 - val_loss: 0.1090 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.5677\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0291 - val_loss: 0.1082 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.7467\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0434 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6654\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9766 - val_loss: 0.1081 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.7728\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.8944 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.7305\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9764 - cost: 3.0214 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.7305\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9036 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.6719\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9879 - val_loss: 0.1090 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.6100\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9767 - cost: 3.0010 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9725 - val_cost: 3.6523\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9770 - cost: 2.9488 - val_loss: 0.1094 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7207\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9569 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9978 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9534 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.7077\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9776 - cost: 2.8717 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6979\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9777 - cost: 2.8700 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6263\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9261 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.7435\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0781 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8473 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.6979\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9940 - accuracy: 0.9774 - cost: 2.8896 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7044\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.8946 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9704 - val_cost: 3.7923\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9204 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6914\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9226 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.6230\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9249 - val_loss: 0.1097 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.6198\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8784 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5710\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8546 - val_loss: 0.1125 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.6393\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9104 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.6491\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9943 - accuracy: 0.9782 - cost: 2.8083 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6556\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8486 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6556\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8508 - val_loss: 0.1098 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.6947\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8293 - val_loss: 0.1090 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.7370\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8687 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6133\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8718 - val_loss: 0.1082 - val_auc: 0.9899 - val_accuracy: 0.9718 - val_cost: 3.5742\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8395 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6947\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8485 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.5775\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7672 - val_loss: 0.1093 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7370\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8596 - val_loss: 0.1108 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6979\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9047 - val_loss: 0.1081 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7109\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8582 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5677\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7898 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6751\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8172 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6719\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8683 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.6393\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7627 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.8379\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7746 - val_loss: 0.1106 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.7305\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8037 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5156\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7609 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.6719\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8390 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.5319\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7433 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9721 - val_cost: 3.5742\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7378 - val_loss: 0.1108 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.7467\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9781 - cost: 2.8193 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.5775\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8134 - val_loss: 0.1104 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6035\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.7817 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.5254\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.7823 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.6296\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7456 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9716 - val_cost: 3.6263\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.7935 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9720 - val_cost: 3.8574\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7700 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5286\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8123 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.5514\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7511 - val_loss: 0.1103 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.7044\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7974 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.5254\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7134 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9720 - val_cost: 3.5352\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7503 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.6686\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7574 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.6068\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7283 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.7402\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7887 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.5254\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7303 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.7077\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7309 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.6068\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7111 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.5482\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7586 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.6523\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7362 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.6068\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7256 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.4961\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9793 - cost: 2.6655 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5710\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7511 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6361\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7092 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.6914\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7246 - val_loss: 0.1150 - val_auc: 0.9898 - val_accuracy: 0.9727 - val_cost: 3.3757\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6503 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.8053\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9946 - accuracy: 0.9792 - cost: 2.6692 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6263\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7021 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.6165\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7290 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5840\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6881 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.5449\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6887 - val_loss: 0.1118 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.6165\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9799 - cost: 2.5892 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9720 - val_cost: 3.5319\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6595 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9724 - val_cost: 3.5352\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7252 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9731 - val_cost: 3.4635\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6984 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.5286\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.6919 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9729 - val_cost: 3.4831\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6346 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.4993\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6355 - val_loss: 0.1147 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.5059\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6339 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6328\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9795 - cost: 2.6608 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.5091\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9795 - cost: 2.6311 - val_loss: 0.1138 - val_auc: 0.9892 - val_accuracy: 0.9722 - val_cost: 3.5221\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9799 - cost: 2.5812 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9721 - val_cost: 3.5840\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6780 - val_loss: 0.1138 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.7793\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6827 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.5710\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6744 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.6198\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7591 - val_loss: 0.1150 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.5091\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9799 - cost: 2.5846 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.5156\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7279 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9719 - val_cost: 3.5807\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9793 - cost: 2.6782 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.6719\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6693 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9725 - val_cost: 3.6458\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6633 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.7044\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6330 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.6296\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6594 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6491\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6398 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.7565\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6679 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.5645\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6387 - val_loss: 0.1156 - val_auc: 0.9889 - val_accuracy: 0.9710 - val_cost: 3.7793\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6942 - val_loss: 0.1148 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.5872\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9797 - cost: 2.6179 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5156\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6592 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9719 - val_cost: 3.5352\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5797 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.6068\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6178 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9722 - val_cost: 3.5645\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6538 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5645\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.6037 - val_loss: 0.1137 - val_auc: 0.9891 - val_accuracy: 0.9735 - val_cost: 3.3594\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6692 - val_loss: 0.1156 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5905\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9804 - cost: 2.5348 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9733 - val_cost: 3.4798\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6591 - val_loss: 0.1138 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.5938\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9946 - accuracy: 0.9797 - cost: 2.6204 - val_loss: 0.1150 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.6263\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5971 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9723 - val_cost: 3.5384\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5774 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9728 - val_cost: 3.4277\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5675 - val_loss: 0.1143 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.6035\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6359 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9716 - val_cost: 3.6003\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6249 - val_loss: 0.1163 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.6556\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6250 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.6979\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9947 - accuracy: 0.9800 - cost: 2.5889 - val_loss: 0.1163 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.5547\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6697 - val_loss: 0.1129 - val_auc: 0.9891 - val_accuracy: 0.9726 - val_cost: 3.4993\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9799 - cost: 2.6106 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9721 - val_cost: 3.5775\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9802 - cost: 2.5385 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.5645\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.5781 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9724 - val_cost: 3.5221\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9802 - cost: 2.5608 - val_loss: 0.1155 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.6068\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5933 - val_loss: 0.1158 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.5384\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9947 - accuracy: 0.9797 - cost: 2.6180 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9724 - val_cost: 3.5254\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6149 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9722 - val_cost: 3.5840\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6030 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5156\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9803 - cost: 2.5453 - val_loss: 0.1185 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.7565\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6130 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.6035\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6152 - val_loss: 0.1149 - val_auc: 0.9889 - val_accuracy: 0.9722 - val_cost: 3.5156\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.6119 - val_loss: 0.1138 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.6263\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6192 - val_loss: 0.1134 - val_auc: 0.9891 - val_accuracy: 0.9719 - val_cost: 3.5352\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6207 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9729 - val_cost: 3.4798\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.6031 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.4831\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.5905 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9724 - val_cost: 3.5059\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9804 - cost: 2.5321 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9720 - val_cost: 3.5547\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.5918 - val_loss: 0.1154 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.7565\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5632 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9718 - val_cost: 3.5645\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.6091 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9723 - val_cost: 3.7174\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.5728 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.7174\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9952 - accuracy: 0.9808 - cost: 2.4867 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9728 - val_cost: 3.5254\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9949 - accuracy: 0.9802 - cost: 2.5559 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.5026\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9949 - accuracy: 0.9802 - cost: 2.5491 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.6003\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6354 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.4408\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9806 - cost: 2.4886 - val_loss: 0.1173 - val_auc: 0.9894 - val_accuracy: 0.9726 - val_cost: 3.4375\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.5952 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.7142\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9949 - accuracy: 0.9807 - cost: 2.4896 - val_loss: 0.1162 - val_auc: 0.9891 - val_accuracy: 0.9733 - val_cost: 3.4538\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5610 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9720 - val_cost: 3.5905\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9803 - cost: 2.5400 - val_loss: 0.1160 - val_auc: 0.9893 - val_accuracy: 0.9729 - val_cost: 3.4277\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9806 - cost: 2.5051 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.5189\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.5909 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9733 - val_cost: 3.4310\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5716 - val_loss: 0.1141 - val_auc: 0.9893 - val_accuracy: 0.9731 - val_cost: 3.4505\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5639 - val_loss: 0.1146 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.5742\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9804 - cost: 2.5293 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.6068\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9807 - cost: 2.4863 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.5352\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5730 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.4766\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9949 - accuracy: 0.9802 - cost: 2.5488 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9727 - val_cost: 3.5938\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1051 - auc: 0.9903 - accuracy: 0.9728 - cost: 3.5000\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:40.180745\n",
            "fold accuracy: 0.9728124737739563 - fold cost: 3.5\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5482 - auc: 0.7776 - accuracy: 0.7138 - cost: 37.9318 - val_loss: 0.4101 - val_auc: 0.8935 - val_accuracy: 0.8213 - val_cost: 23.5059\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3677 - auc: 0.9139 - accuracy: 0.8417 - cost: 20.1542 - val_loss: 0.3223 - val_auc: 0.9340 - val_accuracy: 0.8628 - val_cost: 16.9824\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3151 - auc: 0.9372 - accuracy: 0.8695 - cost: 16.5251 - val_loss: 0.2941 - val_auc: 0.9455 - val_accuracy: 0.8798 - val_cost: 14.4564\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2876 - auc: 0.9478 - accuracy: 0.8828 - cost: 14.8247 - val_loss: 0.2695 - val_auc: 0.9539 - val_accuracy: 0.8908 - val_cost: 13.6719\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2659 - auc: 0.9554 - accuracy: 0.8939 - cost: 13.4195 - val_loss: 0.2506 - val_auc: 0.9606 - val_accuracy: 0.9013 - val_cost: 12.0736\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2468 - auc: 0.9616 - accuracy: 0.9027 - cost: 12.2990 - val_loss: 0.2332 - val_auc: 0.9657 - val_accuracy: 0.9114 - val_cost: 11.0254\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2315 - auc: 0.9662 - accuracy: 0.9096 - cost: 11.4396 - val_loss: 0.2203 - val_auc: 0.9693 - val_accuracy: 0.9177 - val_cost: 10.2083\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2180 - auc: 0.9699 - accuracy: 0.9170 - cost: 10.5095 - val_loss: 0.2072 - val_auc: 0.9728 - val_accuracy: 0.9224 - val_cost: 9.4206\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2072 - auc: 0.9728 - accuracy: 0.9214 - cost: 9.9617 - val_loss: 0.1973 - val_auc: 0.9752 - val_accuracy: 0.9282 - val_cost: 8.8835\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1966 - auc: 0.9754 - accuracy: 0.9258 - cost: 9.4029 - val_loss: 0.1888 - val_auc: 0.9771 - val_accuracy: 0.9300 - val_cost: 8.7305\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1884 - auc: 0.9773 - accuracy: 0.9309 - cost: 8.7840 - val_loss: 0.1812 - val_auc: 0.9790 - val_accuracy: 0.9344 - val_cost: 8.1152\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1798 - auc: 0.9792 - accuracy: 0.9340 - cost: 8.3934 - val_loss: 0.1754 - val_auc: 0.9800 - val_accuracy: 0.9381 - val_cost: 7.6660\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1745 - auc: 0.9803 - accuracy: 0.9365 - cost: 8.0916 - val_loss: 0.1696 - val_auc: 0.9812 - val_accuracy: 0.9403 - val_cost: 7.7767\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1688 - auc: 0.9814 - accuracy: 0.9402 - cost: 7.6007 - val_loss: 0.1650 - val_auc: 0.9822 - val_accuracy: 0.9411 - val_cost: 7.6758\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1621 - auc: 0.9828 - accuracy: 0.9423 - cost: 7.3420 - val_loss: 0.1603 - val_auc: 0.9829 - val_accuracy: 0.9442 - val_cost: 7.3568\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1575 - auc: 0.9836 - accuracy: 0.9441 - cost: 7.1110 - val_loss: 0.1567 - val_auc: 0.9837 - val_accuracy: 0.9449 - val_cost: 6.8587\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1541 - auc: 0.9842 - accuracy: 0.9460 - cost: 6.8655 - val_loss: 0.1523 - val_auc: 0.9845 - val_accuracy: 0.9468 - val_cost: 6.9596\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1496 - auc: 0.9850 - accuracy: 0.9484 - cost: 6.5570 - val_loss: 0.1502 - val_auc: 0.9848 - val_accuracy: 0.9481 - val_cost: 7.0117\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1468 - auc: 0.9855 - accuracy: 0.9495 - cost: 6.4523 - val_loss: 0.1482 - val_auc: 0.9852 - val_accuracy: 0.9485 - val_cost: 6.3216\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1427 - auc: 0.9861 - accuracy: 0.9511 - cost: 6.2219 - val_loss: 0.1453 - val_auc: 0.9856 - val_accuracy: 0.9506 - val_cost: 6.3704\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1411 - auc: 0.9863 - accuracy: 0.9522 - cost: 6.0863 - val_loss: 0.1424 - val_auc: 0.9859 - val_accuracy: 0.9515 - val_cost: 6.3932\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1363 - auc: 0.9871 - accuracy: 0.9543 - cost: 5.8090 - val_loss: 0.1405 - val_auc: 0.9861 - val_accuracy: 0.9535 - val_cost: 6.1784\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1357 - auc: 0.9873 - accuracy: 0.9545 - cost: 5.7991 - val_loss: 0.1372 - val_auc: 0.9865 - val_accuracy: 0.9540 - val_cost: 6.0449\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1315 - auc: 0.9880 - accuracy: 0.9558 - cost: 5.6401 - val_loss: 0.1354 - val_auc: 0.9870 - val_accuracy: 0.9551 - val_cost: 5.8366\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1291 - auc: 0.9883 - accuracy: 0.9566 - cost: 5.5170 - val_loss: 0.1350 - val_auc: 0.9870 - val_accuracy: 0.9561 - val_cost: 5.6738\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1283 - auc: 0.9883 - accuracy: 0.9578 - cost: 5.3726 - val_loss: 0.1324 - val_auc: 0.9874 - val_accuracy: 0.9561 - val_cost: 5.7878\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1257 - auc: 0.9888 - accuracy: 0.9588 - cost: 5.2675 - val_loss: 0.1315 - val_auc: 0.9874 - val_accuracy: 0.9570 - val_cost: 5.5697\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1231 - auc: 0.9891 - accuracy: 0.9597 - cost: 5.1400 - val_loss: 0.1303 - val_auc: 0.9877 - val_accuracy: 0.9576 - val_cost: 5.4036\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1228 - auc: 0.9891 - accuracy: 0.9604 - cost: 5.0554 - val_loss: 0.1306 - val_auc: 0.9877 - val_accuracy: 0.9569 - val_cost: 5.3678\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1213 - auc: 0.9893 - accuracy: 0.9603 - cost: 5.0545 - val_loss: 0.1294 - val_auc: 0.9878 - val_accuracy: 0.9590 - val_cost: 5.6022\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1183 - auc: 0.9897 - accuracy: 0.9616 - cost: 4.8785 - val_loss: 0.1275 - val_auc: 0.9879 - val_accuracy: 0.9602 - val_cost: 5.0651\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1176 - auc: 0.9898 - accuracy: 0.9624 - cost: 4.7998 - val_loss: 0.1243 - val_auc: 0.9883 - val_accuracy: 0.9604 - val_cost: 5.2246\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1157 - auc: 0.9902 - accuracy: 0.9628 - cost: 4.7407 - val_loss: 0.1264 - val_auc: 0.9883 - val_accuracy: 0.9597 - val_cost: 5.4622\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1147 - auc: 0.9903 - accuracy: 0.9635 - cost: 4.6535 - val_loss: 0.1238 - val_auc: 0.9883 - val_accuracy: 0.9610 - val_cost: 5.3190\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1134 - auc: 0.9903 - accuracy: 0.9638 - cost: 4.6182 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9622 - val_cost: 5.0358\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1115 - auc: 0.9906 - accuracy: 0.9650 - cost: 4.4625 - val_loss: 0.1219 - val_auc: 0.9884 - val_accuracy: 0.9622 - val_cost: 5.0033\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1113 - auc: 0.9906 - accuracy: 0.9648 - cost: 4.4969 - val_loss: 0.1208 - val_auc: 0.9886 - val_accuracy: 0.9640 - val_cost: 4.6126\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1106 - auc: 0.9907 - accuracy: 0.9646 - cost: 4.5091 - val_loss: 0.1191 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 5.0130\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1092 - auc: 0.9908 - accuracy: 0.9656 - cost: 4.3993 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9635 - val_cost: 4.6842\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1085 - auc: 0.9910 - accuracy: 0.9663 - cost: 4.2879 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9644 - val_cost: 4.5150\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1071 - auc: 0.9912 - accuracy: 0.9665 - cost: 4.2686 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9642 - val_cost: 4.7135\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1067 - auc: 0.9911 - accuracy: 0.9666 - cost: 4.2636 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9636 - val_cost: 4.7982\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1048 - auc: 0.9914 - accuracy: 0.9671 - cost: 4.2055 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9652 - val_cost: 4.3717\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1047 - auc: 0.9913 - accuracy: 0.9680 - cost: 4.0965 - val_loss: 0.1150 - val_auc: 0.9891 - val_accuracy: 0.9654 - val_cost: 4.4564\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9914 - accuracy: 0.9679 - cost: 4.0892 - val_loss: 0.1150 - val_auc: 0.9894 - val_accuracy: 0.9653 - val_cost: 4.3164\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1027 - auc: 0.9915 - accuracy: 0.9683 - cost: 4.0536 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9647 - val_cost: 4.6094\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1016 - auc: 0.9918 - accuracy: 0.9685 - cost: 4.0207 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9657 - val_cost: 4.5020\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9918 - accuracy: 0.9694 - cost: 3.9088 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9658 - val_cost: 4.3717\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9695 - cost: 3.9052 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9666 - val_cost: 4.2155\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0991 - auc: 0.9920 - accuracy: 0.9695 - cost: 3.8975 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9670 - val_cost: 4.1634\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9921 - accuracy: 0.9701 - cost: 3.8220 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.6061\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8151 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9664 - val_cost: 4.3457\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9922 - accuracy: 0.9700 - cost: 3.8304 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9684 - val_cost: 4.1374\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0967 - auc: 0.9922 - accuracy: 0.9707 - cost: 3.7345 - val_loss: 0.1120 - val_auc: 0.9894 - val_accuracy: 0.9669 - val_cost: 4.2285\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0976 - auc: 0.9921 - accuracy: 0.9709 - cost: 3.7127 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9671 - val_cost: 4.2936\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0966 - auc: 0.9922 - accuracy: 0.9709 - cost: 3.7238 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 4.1895\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0959 - auc: 0.9923 - accuracy: 0.9714 - cost: 3.6515 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 4.0072\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0957 - auc: 0.9924 - accuracy: 0.9714 - cost: 3.6584 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 4.0332\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0958 - auc: 0.9924 - accuracy: 0.9709 - cost: 3.7144 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 4.0788\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9925 - accuracy: 0.9714 - cost: 3.6585 - val_loss: 0.1083 - val_auc: 0.9899 - val_accuracy: 0.9692 - val_cost: 4.0885\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9927 - accuracy: 0.9722 - cost: 3.5578 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 4.0820\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0938 - auc: 0.9925 - accuracy: 0.9723 - cost: 3.5610 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.9714\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9928 - accuracy: 0.9727 - cost: 3.5058 - val_loss: 0.1108 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 4.0299\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9928 - accuracy: 0.9728 - cost: 3.4779 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.0951\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9930 - accuracy: 0.9730 - cost: 3.4551 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 4.0788\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9927 - accuracy: 0.9730 - cost: 3.4677 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 4.0560\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9927 - accuracy: 0.9730 - cost: 3.4609 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9677 - val_cost: 4.0527\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0909 - auc: 0.9929 - accuracy: 0.9732 - cost: 3.4303 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 4.0397\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9930 - accuracy: 0.9735 - cost: 3.3925 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 4.0104\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9927 - accuracy: 0.9736 - cost: 3.3740 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 4.0072\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0896 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3588 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9684 - val_cost: 4.0755\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9929 - accuracy: 0.9737 - cost: 3.3698 - val_loss: 0.1079 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.9095\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9929 - accuracy: 0.9736 - cost: 3.3877 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.9583\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9929 - accuracy: 0.9743 - cost: 3.3017 - val_loss: 0.1110 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9486\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0884 - auc: 0.9930 - accuracy: 0.9742 - cost: 3.3009 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 4.0853\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3368 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 4.1634\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9930 - accuracy: 0.9743 - cost: 3.2934 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8639\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3343 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8900\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0871 - auc: 0.9932 - accuracy: 0.9743 - cost: 3.3051 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9689 - val_cost: 3.7923\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0868 - auc: 0.9932 - accuracy: 0.9746 - cost: 3.2597 - val_loss: 0.1084 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8835\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3456 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9693 - val_cost: 3.9355\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9932 - accuracy: 0.9753 - cost: 3.1837 - val_loss: 0.1092 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.9486\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9933 - accuracy: 0.9752 - cost: 3.1857 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.9616\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2898 - val_loss: 0.1106 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.8737\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9934 - accuracy: 0.9750 - cost: 3.2094 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.8184\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9932 - accuracy: 0.9747 - cost: 3.2494 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 4.0820\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1556 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8379\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9933 - accuracy: 0.9752 - cost: 3.1761 - val_loss: 0.1088 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.6979\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9934 - accuracy: 0.9753 - cost: 3.1614 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8216\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9932 - accuracy: 0.9751 - cost: 3.1967 - val_loss: 0.1077 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6458\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9934 - accuracy: 0.9751 - cost: 3.2088 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9696 - val_cost: 3.8770\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9936 - accuracy: 0.9752 - cost: 3.1898 - val_loss: 0.1081 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6882\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1239 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.5091\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9935 - accuracy: 0.9760 - cost: 3.0927 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 3.5319\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9934 - accuracy: 0.9756 - cost: 3.1271 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.6198\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1470 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.3561\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1297 - val_loss: 0.1078 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.7077\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9935 - accuracy: 0.9762 - cost: 3.0548 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.6198\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9935 - accuracy: 0.9763 - cost: 3.0522 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.3366\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9936 - accuracy: 0.9767 - cost: 3.0052 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.5905\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9936 - accuracy: 0.9761 - cost: 3.0741 - val_loss: 0.1083 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.4928\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0955 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.3691\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0831 - auc: 0.9936 - accuracy: 0.9764 - cost: 3.0522 - val_loss: 0.1093 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5579\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9936 - accuracy: 0.9763 - cost: 3.0478 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.7207\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9937 - accuracy: 0.9766 - cost: 3.0020 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8932\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9764 - cost: 3.0422 - val_loss: 0.1077 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.3952\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0477 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.9421\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0622 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.9258\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0127 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7370\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9938 - accuracy: 0.9771 - cost: 2.9402 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.2715\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0124 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9726 - val_cost: 3.2324\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9938 - accuracy: 0.9769 - cost: 2.9649 - val_loss: 0.1095 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.3789\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9936 - accuracy: 0.9770 - cost: 2.9649 - val_loss: 0.1107 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.3659\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0070 - val_loss: 0.1122 - val_auc: 0.9891 - val_accuracy: 0.9705 - val_cost: 3.7240\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9939 - accuracy: 0.9771 - cost: 2.9570 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6686\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9938 - accuracy: 0.9767 - cost: 2.9768 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.3268\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0136 - val_loss: 0.1110 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 3.5645\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9939 - accuracy: 0.9772 - cost: 2.9444 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.3854\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9939 - accuracy: 0.9770 - cost: 2.9637 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.3952\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9471 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.7728\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9528 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9693 - val_cost: 3.7435\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9938 - accuracy: 0.9771 - cost: 2.9496 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.5872\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9939 - accuracy: 0.9775 - cost: 2.8943 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7305\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9772 - cost: 2.9543 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.7858\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9490 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.4798\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9940 - accuracy: 0.9772 - cost: 2.9324 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.4570\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9777 - cost: 2.8778 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.4928\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9940 - accuracy: 0.9779 - cost: 2.8294 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.3822\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9939 - accuracy: 0.9773 - cost: 2.9223 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8086\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9940 - accuracy: 0.9777 - cost: 2.8789 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.7956\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9940 - accuracy: 0.9778 - cost: 2.8603 - val_loss: 0.1115 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.8867\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9006 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.9811\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9940 - accuracy: 0.9773 - cost: 2.9266 - val_loss: 0.1100 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6458\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9941 - accuracy: 0.9777 - cost: 2.8697 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.4701\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9940 - accuracy: 0.9773 - cost: 2.9396 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.4440\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9776 - cost: 2.8825 - val_loss: 0.1133 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.7858\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9062 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.3561\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9941 - accuracy: 0.9780 - cost: 2.8314 - val_loss: 0.1155 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.3594\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8895 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6882\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9000 - val_loss: 0.1137 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.3691\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9783 - cost: 2.7925 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.7891\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9941 - accuracy: 0.9779 - cost: 2.8404 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5221\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9307 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.5189\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8489 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.4668\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9785 - cost: 2.7704 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.5091\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8827 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.4408\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9942 - accuracy: 0.9783 - cost: 2.7948 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8346\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7836 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.4733\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9779 - cost: 2.8482 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.4863\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8492 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.8053\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9942 - accuracy: 0.9784 - cost: 2.7981 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.4505\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.8948 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.3691\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9943 - accuracy: 0.9782 - cost: 2.8082 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9698 - val_cost: 3.5514\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9941 - accuracy: 0.9786 - cost: 2.7584 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.8021\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8560 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7760\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8412 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.7305\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9943 - accuracy: 0.9784 - cost: 2.7883 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.4766\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9782 - cost: 2.7922 - val_loss: 0.1138 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.7565\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7872 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.4928\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8344 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.7370\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9943 - accuracy: 0.9786 - cost: 2.7504 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.7793\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0978 - auc: 0.9919 - accuracy: 0.9729 - cost: 3.4406\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:33.388056\n",
            "fold accuracy: 0.9729375243186951 - fold cost: 3.440624952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5445 - auc: 0.7817 - accuracy: 0.7161 - cost: 37.5719 - val_loss: 0.4099 - val_auc: 0.8933 - val_accuracy: 0.8222 - val_cost: 22.5749\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3664 - auc: 0.9145 - accuracy: 0.8422 - cost: 20.0714 - val_loss: 0.3243 - val_auc: 0.9334 - val_accuracy: 0.8618 - val_cost: 16.5951\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3140 - auc: 0.9376 - accuracy: 0.8702 - cost: 16.3767 - val_loss: 0.2948 - val_auc: 0.9452 - val_accuracy: 0.8778 - val_cost: 14.6289\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2861 - auc: 0.9485 - accuracy: 0.8831 - cost: 14.7534 - val_loss: 0.2721 - val_auc: 0.9532 - val_accuracy: 0.8905 - val_cost: 13.1608\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2640 - auc: 0.9562 - accuracy: 0.8939 - cost: 13.3815 - val_loss: 0.2521 - val_auc: 0.9600 - val_accuracy: 0.9013 - val_cost: 12.0345\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2467 - auc: 0.9617 - accuracy: 0.9037 - cost: 12.1611 - val_loss: 0.2355 - val_auc: 0.9651 - val_accuracy: 0.9083 - val_cost: 11.2142\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2304 - auc: 0.9666 - accuracy: 0.9106 - cost: 11.3000 - val_loss: 0.2249 - val_auc: 0.9682 - val_accuracy: 0.9151 - val_cost: 10.2344\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2181 - auc: 0.9700 - accuracy: 0.9164 - cost: 10.5916 - val_loss: 0.2122 - val_auc: 0.9715 - val_accuracy: 0.9205 - val_cost: 9.8568\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2062 - auc: 0.9731 - accuracy: 0.9226 - cost: 9.7807 - val_loss: 0.2019 - val_auc: 0.9742 - val_accuracy: 0.9259 - val_cost: 8.9030\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1960 - auc: 0.9755 - accuracy: 0.9267 - cost: 9.2955 - val_loss: 0.1923 - val_auc: 0.9762 - val_accuracy: 0.9305 - val_cost: 8.5970\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1883 - auc: 0.9773 - accuracy: 0.9302 - cost: 8.8368 - val_loss: 0.1842 - val_auc: 0.9780 - val_accuracy: 0.9331 - val_cost: 8.3529\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1815 - auc: 0.9789 - accuracy: 0.9337 - cost: 8.4205 - val_loss: 0.1786 - val_auc: 0.9794 - val_accuracy: 0.9363 - val_cost: 7.8613\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1745 - auc: 0.9803 - accuracy: 0.9369 - cost: 7.9949 - val_loss: 0.1730 - val_auc: 0.9805 - val_accuracy: 0.9399 - val_cost: 7.6139\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1693 - auc: 0.9813 - accuracy: 0.9394 - cost: 7.6940 - val_loss: 0.1688 - val_auc: 0.9813 - val_accuracy: 0.9399 - val_cost: 7.3633\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1629 - auc: 0.9825 - accuracy: 0.9418 - cost: 7.3882 - val_loss: 0.1629 - val_auc: 0.9824 - val_accuracy: 0.9430 - val_cost: 7.1810\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1590 - auc: 0.9834 - accuracy: 0.9442 - cost: 7.0818 - val_loss: 0.1605 - val_auc: 0.9829 - val_accuracy: 0.9444 - val_cost: 7.0866\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1551 - auc: 0.9840 - accuracy: 0.9449 - cost: 6.9803 - val_loss: 0.1565 - val_auc: 0.9838 - val_accuracy: 0.9453 - val_cost: 6.9434\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1523 - auc: 0.9846 - accuracy: 0.9468 - cost: 6.7631 - val_loss: 0.1537 - val_auc: 0.9843 - val_accuracy: 0.9471 - val_cost: 6.9336\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1487 - auc: 0.9851 - accuracy: 0.9485 - cost: 6.5507 - val_loss: 0.1511 - val_auc: 0.9847 - val_accuracy: 0.9469 - val_cost: 6.7806\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1464 - auc: 0.9856 - accuracy: 0.9498 - cost: 6.3831 - val_loss: 0.1512 - val_auc: 0.9847 - val_accuracy: 0.9488 - val_cost: 6.4714\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1435 - auc: 0.9860 - accuracy: 0.9518 - cost: 6.1352 - val_loss: 0.1467 - val_auc: 0.9855 - val_accuracy: 0.9506 - val_cost: 6.4128\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1403 - auc: 0.9867 - accuracy: 0.9520 - cost: 6.0851 - val_loss: 0.1460 - val_auc: 0.9857 - val_accuracy: 0.9513 - val_cost: 6.3542\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1382 - auc: 0.9868 - accuracy: 0.9533 - cost: 5.9293 - val_loss: 0.1416 - val_auc: 0.9863 - val_accuracy: 0.9529 - val_cost: 5.9928\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1353 - auc: 0.9873 - accuracy: 0.9545 - cost: 5.7860 - val_loss: 0.1407 - val_auc: 0.9864 - val_accuracy: 0.9533 - val_cost: 6.0547\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1333 - auc: 0.9876 - accuracy: 0.9557 - cost: 5.6166 - val_loss: 0.1397 - val_auc: 0.9866 - val_accuracy: 0.9528 - val_cost: 6.0742\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1321 - auc: 0.9878 - accuracy: 0.9558 - cost: 5.6268 - val_loss: 0.1375 - val_auc: 0.9868 - val_accuracy: 0.9543 - val_cost: 5.9635\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1296 - auc: 0.9883 - accuracy: 0.9566 - cost: 5.5089 - val_loss: 0.1358 - val_auc: 0.9870 - val_accuracy: 0.9558 - val_cost: 5.6478\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1278 - auc: 0.9885 - accuracy: 0.9579 - cost: 5.3546 - val_loss: 0.1353 - val_auc: 0.9872 - val_accuracy: 0.9563 - val_cost: 5.7292\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1272 - auc: 0.9885 - accuracy: 0.9581 - cost: 5.3163 - val_loss: 0.1336 - val_auc: 0.9873 - val_accuracy: 0.9580 - val_cost: 5.6055\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9890 - accuracy: 0.9592 - cost: 5.1953 - val_loss: 0.1336 - val_auc: 0.9872 - val_accuracy: 0.9574 - val_cost: 5.6901\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1222 - auc: 0.9892 - accuracy: 0.9598 - cost: 5.0976 - val_loss: 0.1304 - val_auc: 0.9877 - val_accuracy: 0.9578 - val_cost: 5.4004\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1216 - auc: 0.9893 - accuracy: 0.9603 - cost: 5.0514 - val_loss: 0.1303 - val_auc: 0.9876 - val_accuracy: 0.9591 - val_cost: 5.0651\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1191 - auc: 0.9895 - accuracy: 0.9615 - cost: 4.8987 - val_loss: 0.1279 - val_auc: 0.9878 - val_accuracy: 0.9601 - val_cost: 5.1465\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1172 - auc: 0.9899 - accuracy: 0.9624 - cost: 4.7962 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9609 - val_cost: 5.0814\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9625 - cost: 4.7796 - val_loss: 0.1254 - val_auc: 0.9880 - val_accuracy: 0.9603 - val_cost: 5.2474\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1155 - auc: 0.9901 - accuracy: 0.9631 - cost: 4.7020 - val_loss: 0.1250 - val_auc: 0.9882 - val_accuracy: 0.9615 - val_cost: 4.8275\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1139 - auc: 0.9904 - accuracy: 0.9635 - cost: 4.6299 - val_loss: 0.1243 - val_auc: 0.9883 - val_accuracy: 0.9622 - val_cost: 4.7884\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1128 - auc: 0.9904 - accuracy: 0.9643 - cost: 4.5415 - val_loss: 0.1226 - val_auc: 0.9884 - val_accuracy: 0.9619 - val_cost: 4.8796\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1119 - auc: 0.9906 - accuracy: 0.9644 - cost: 4.5317 - val_loss: 0.1226 - val_auc: 0.9885 - val_accuracy: 0.9622 - val_cost: 4.7559\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1111 - auc: 0.9907 - accuracy: 0.9649 - cost: 4.4740 - val_loss: 0.1234 - val_auc: 0.9882 - val_accuracy: 0.9625 - val_cost: 4.7168\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1100 - auc: 0.9907 - accuracy: 0.9657 - cost: 4.3742 - val_loss: 0.1206 - val_auc: 0.9888 - val_accuracy: 0.9635 - val_cost: 4.6842\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1108 - auc: 0.9905 - accuracy: 0.9655 - cost: 4.4050 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 4.2611\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1078 - auc: 0.9910 - accuracy: 0.9666 - cost: 4.2453 - val_loss: 0.1209 - val_auc: 0.9885 - val_accuracy: 0.9639 - val_cost: 4.3685\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1080 - auc: 0.9911 - accuracy: 0.9660 - cost: 4.3322 - val_loss: 0.1188 - val_auc: 0.9888 - val_accuracy: 0.9646 - val_cost: 4.3848\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9912 - accuracy: 0.9666 - cost: 4.2515 - val_loss: 0.1198 - val_auc: 0.9889 - val_accuracy: 0.9644 - val_cost: 4.4564\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1057 - auc: 0.9913 - accuracy: 0.9672 - cost: 4.1730 - val_loss: 0.1190 - val_auc: 0.9888 - val_accuracy: 0.9633 - val_cost: 4.5898\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1035 - auc: 0.9915 - accuracy: 0.9676 - cost: 4.1325 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9651 - val_cost: 4.2025\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1043 - auc: 0.9914 - accuracy: 0.9677 - cost: 4.1236 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9651 - val_cost: 4.1927\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1038 - auc: 0.9915 - accuracy: 0.9680 - cost: 4.0737 - val_loss: 0.1186 - val_auc: 0.9887 - val_accuracy: 0.9644 - val_cost: 4.4792\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1038 - auc: 0.9915 - accuracy: 0.9681 - cost: 4.0748 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9654 - val_cost: 4.1569\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1021 - auc: 0.9917 - accuracy: 0.9689 - cost: 3.9664 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9657 - val_cost: 4.1699\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1015 - auc: 0.9917 - accuracy: 0.9690 - cost: 3.9424 - val_loss: 0.1162 - val_auc: 0.9891 - val_accuracy: 0.9656 - val_cost: 4.2025\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1020 - auc: 0.9917 - accuracy: 0.9693 - cost: 3.9301 - val_loss: 0.1153 - val_auc: 0.9890 - val_accuracy: 0.9661 - val_cost: 4.2188\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9919 - accuracy: 0.9694 - cost: 3.9055 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9656 - val_cost: 4.3164\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9920 - accuracy: 0.9698 - cost: 3.8601 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9665 - val_cost: 4.0853\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0993 - auc: 0.9921 - accuracy: 0.9701 - cost: 3.8148 - val_loss: 0.1145 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.0723\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9919 - accuracy: 0.9700 - cost: 3.8394 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.0560\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0990 - auc: 0.9920 - accuracy: 0.9702 - cost: 3.7992 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9672 - val_cost: 4.0658\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9922 - accuracy: 0.9704 - cost: 3.7822 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9671 - val_cost: 4.0104\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0971 - auc: 0.9922 - accuracy: 0.9710 - cost: 3.7063 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9662 - val_cost: 4.2122\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0972 - auc: 0.9921 - accuracy: 0.9706 - cost: 3.7816 - val_loss: 0.1130 - val_auc: 0.9893 - val_accuracy: 0.9665 - val_cost: 4.0853\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0962 - auc: 0.9923 - accuracy: 0.9712 - cost: 3.6745 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9680 - val_cost: 3.9290\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0970 - auc: 0.9922 - accuracy: 0.9711 - cost: 3.7056 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9665 - val_cost: 4.0560\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0956 - auc: 0.9924 - accuracy: 0.9716 - cost: 3.6393 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0885\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9926 - accuracy: 0.9718 - cost: 3.6174 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9671 - val_cost: 3.9583\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0945 - auc: 0.9925 - accuracy: 0.9714 - cost: 3.6594 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 4.0039\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0940 - auc: 0.9925 - accuracy: 0.9721 - cost: 3.5700 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.2513\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9925 - accuracy: 0.9720 - cost: 3.5859 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 3.9844\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0926 - auc: 0.9928 - accuracy: 0.9724 - cost: 3.5483 - val_loss: 0.1145 - val_auc: 0.9891 - val_accuracy: 0.9667 - val_cost: 4.0137\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9723 - cost: 3.5483 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 4.0137\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.4908 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9679 - val_cost: 3.9323\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9725 - cost: 3.5189 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 4.1146\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9927 - accuracy: 0.9732 - cost: 3.4341 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 4.0267\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9728 - cost: 3.4845 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 3.8477\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9929 - accuracy: 0.9729 - cost: 3.4740 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 4.1243\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9929 - accuracy: 0.9730 - cost: 3.4587 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9670 - val_cost: 4.1667\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9930 - accuracy: 0.9736 - cost: 3.3826 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0495\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0895 - auc: 0.9931 - accuracy: 0.9731 - cost: 3.4527 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.7826\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0908 - auc: 0.9930 - accuracy: 0.9731 - cost: 3.4566 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7240\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0903 - auc: 0.9929 - accuracy: 0.9730 - cost: 3.4512 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.7858\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0905 - auc: 0.9929 - accuracy: 0.9734 - cost: 3.4133 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.8053\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9930 - accuracy: 0.9733 - cost: 3.4145 - val_loss: 0.1092 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.7240\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9932 - accuracy: 0.9733 - cost: 3.4274 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.6198\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9930 - accuracy: 0.9741 - cost: 3.3101 - val_loss: 0.1110 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.4668\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3743 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0169\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9737 - cost: 3.3750 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 3.9095\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9932 - accuracy: 0.9745 - cost: 3.2787 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.7402\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9746 - cost: 3.2649 - val_loss: 0.1079 - val_auc: 0.9902 - val_accuracy: 0.9702 - val_cost: 3.8249\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0880 - auc: 0.9931 - accuracy: 0.9743 - cost: 3.3091 - val_loss: 0.1083 - val_auc: 0.9902 - val_accuracy: 0.9698 - val_cost: 3.8770\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0879 - auc: 0.9931 - accuracy: 0.9741 - cost: 3.3217 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.8704\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0870 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3315 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.6882\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0863 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2291 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9689 - val_cost: 3.7793\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0858 - auc: 0.9933 - accuracy: 0.9751 - cost: 3.1921 - val_loss: 0.1081 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 3.6686\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9932 - accuracy: 0.9749 - cost: 3.2281 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.7012\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9932 - accuracy: 0.9746 - cost: 3.2620 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.6426\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9933 - accuracy: 0.9747 - cost: 3.2568 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.7826\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.2048 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.9258\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9935 - accuracy: 0.9754 - cost: 3.1688 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.7435\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9934 - accuracy: 0.9753 - cost: 3.2001 - val_loss: 0.1091 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.8151\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0857 - auc: 0.9934 - accuracy: 0.9749 - cost: 3.2159 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.5254\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9937 - accuracy: 0.9751 - cost: 3.2087 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9692 - val_cost: 3.6361\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.2150 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9691 - val_cost: 3.5645\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9935 - accuracy: 0.9752 - cost: 3.1831 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.8151\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9936 - accuracy: 0.9753 - cost: 3.1797 - val_loss: 0.1092 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.5905\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1379 - val_loss: 0.1086 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.3984\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1135 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.4928\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0847 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.1916 - val_loss: 0.1070 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.5677\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0833 - auc: 0.9936 - accuracy: 0.9758 - cost: 3.1088 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.4342\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9759 - cost: 3.0983 - val_loss: 0.1083 - val_auc: 0.9901 - val_accuracy: 0.9720 - val_cost: 3.2975\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1628 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.4310\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1405 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5156\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0830 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1209 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9713 - val_cost: 3.5449\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9936 - accuracy: 0.9756 - cost: 3.1344 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.5026\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0336 - val_loss: 0.1080 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.5449\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0695 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.4115\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0695 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.6914\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9939 - accuracy: 0.9760 - cost: 3.0965 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.5156\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0856 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6361\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0798 - val_loss: 0.1079 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.4733\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.1180 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.3919\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0839 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.3594\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9903 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.4147\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9767 - cost: 3.0026 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.6589\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0591 - val_loss: 0.1090 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.3952\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0821 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.1167 - val_loss: 0.1076 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.5840\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9937 - accuracy: 0.9766 - cost: 3.0139 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.3952\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9921 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.5319\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0266 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.4147\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9940 - accuracy: 0.9763 - cost: 3.0514 - val_loss: 0.1084 - val_auc: 0.9903 - val_accuracy: 0.9718 - val_cost: 3.4961\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9760 - cost: 3.0922 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.4375\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9695 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.2780\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9902 - val_loss: 0.1081 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.7012\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9767 - cost: 3.0029 - val_loss: 0.1096 - val_auc: 0.9903 - val_accuracy: 0.9704 - val_cost: 3.4831\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0803 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9888 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.4896\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0794 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9815 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.5254\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0794 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9551 - val_loss: 0.1100 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.7370\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0807 - auc: 0.9937 - accuracy: 0.9763 - cost: 3.0461 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.5742\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0806 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9859 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.3691\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9720 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9940 - accuracy: 0.9773 - cost: 2.9405 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.3757\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9642 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.4277\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9114 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5189\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9728 - val_loss: 0.1087 - val_auc: 0.9900 - val_accuracy: 0.9725 - val_cost: 3.2422\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8993 - val_loss: 0.1104 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.4701\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9581 - val_loss: 0.1085 - val_auc: 0.9899 - val_accuracy: 0.9723 - val_cost: 3.2878\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9237 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.3789\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9227 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.4277\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9451 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.4245\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9297 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.3594\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8685 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.4473\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.8936 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5742\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8959 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.4440\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8671 - val_loss: 0.1065 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.3431\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9381 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.4831\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9191 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7012\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0784 - auc: 0.9941 - accuracy: 0.9778 - cost: 2.8597 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.3757\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8989 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.4993\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9941 - accuracy: 0.9778 - cost: 2.8650 - val_loss: 0.1098 - val_auc: 0.9902 - val_accuracy: 0.9713 - val_cost: 3.5612\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.9029 - val_loss: 0.1102 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.6068\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.9079 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.3724\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9010 - val_loss: 0.1093 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5286\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8950 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6556\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.9119 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.3366\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8290 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.3887\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8325 - val_loss: 0.1116 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7109\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8400 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5352\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9591 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.3529\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8419 - val_loss: 0.1156 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.4245\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9258 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9726 - val_cost: 3.2357\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9781 - cost: 2.8168 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.4473\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8885 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.4896\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8552 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.3529\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8189 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.3789\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8727 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6979\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8213 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.3854\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9943 - accuracy: 0.9781 - cost: 2.8400 - val_loss: 0.1116 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.3398\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0775 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9205 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.4701\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8531 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7853 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9728 - val_cost: 3.3724\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0764 - auc: 0.9942 - accuracy: 0.9782 - cost: 2.8178 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.3854\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7848 - val_loss: 0.1109 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.2975\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8665 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.4993\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8313 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.2747\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9787 - cost: 2.7691 - val_loss: 0.1110 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4961\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7977 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.3626\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8088 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.4635\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7844 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.4701\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7774 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.5970\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7377 - val_loss: 0.1141 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6556\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8221 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.5319\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8747 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9720 - val_cost: 3.3659\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8069 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.4538\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7900 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.5645\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8618 - val_loss: 0.1111 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.7533\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7871 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9720 - val_cost: 3.4896\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9786 - cost: 2.7743 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.2487\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7870 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.4961\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7899 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.3268\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9945 - accuracy: 0.9788 - cost: 2.7437 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.5710\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8124 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.3268\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.8040 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9724 - val_cost: 3.5645\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7631 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.3301\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7134 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6491\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7986 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.4245\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.7006 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.4928\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9945 - accuracy: 0.9790 - cost: 2.7118 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9716 - val_cost: 3.4668\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7940 - val_loss: 0.1116 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.3789\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8106 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.7826\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.8100 - val_loss: 0.1130 - val_auc: 0.9901 - val_accuracy: 0.9720 - val_cost: 3.3464\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7321 - val_loss: 0.1124 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.6979\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7440 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.3040\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7307 - val_loss: 0.1095 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.6589\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7668 - val_loss: 0.1129 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.5872\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9944 - accuracy: 0.9789 - cost: 2.7237 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.4408\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7938 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.4049\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7542 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6751\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7728 - val_loss: 0.1151 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.4961\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7435 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.2487\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.8069 - val_loss: 0.1126 - val_auc: 0.9899 - val_accuracy: 0.9726 - val_cost: 3.2096\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7357 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9724 - val_cost: 3.5677\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.8217 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.4505\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.7054 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9728 - val_cost: 3.3919\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7644 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9721 - val_cost: 3.6165\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7629 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9725 - val_cost: 3.4798\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.7042 - val_loss: 0.1154 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.3887\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7094 - val_loss: 0.1147 - val_auc: 0.9897 - val_accuracy: 0.9727 - val_cost: 3.4961\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6489 - val_loss: 0.1145 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.7077\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9792 - cost: 2.6964 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.5547\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7133 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.5482\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6751 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9727 - val_cost: 3.5254\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7103 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.4017\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6362 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.6328\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6827 - val_loss: 0.1124 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.4701\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6638 - val_loss: 0.1131 - val_auc: 0.9899 - val_accuracy: 0.9727 - val_cost: 3.3561\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6964 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.3724\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6697 - val_loss: 0.1160 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.4896\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7229 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.3626\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6951 - val_loss: 0.1147 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.6458\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6992 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.4180\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7241 - val_loss: 0.1158 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6719\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9946 - accuracy: 0.9792 - cost: 2.6905 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.2878\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7106 - val_loss: 0.1161 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.6523\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6600 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5775\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6875 - val_loss: 0.1162 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.4928\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6436 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9728 - val_cost: 3.3561\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6614 - val_loss: 0.1139 - val_auc: 0.9900 - val_accuracy: 0.9735 - val_cost: 3.2812\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6944 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.4863\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6910 - val_loss: 0.1172 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.2520\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9802 - cost: 2.5651 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.5872\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9947 - accuracy: 0.9797 - cost: 2.6408 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.4049\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9947 - accuracy: 0.9795 - cost: 2.6568 - val_loss: 0.1160 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.3952\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6722 - val_loss: 0.1120 - val_auc: 0.9899 - val_accuracy: 0.9723 - val_cost: 3.3464\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7377 - val_loss: 0.1146 - val_auc: 0.9899 - val_accuracy: 0.9724 - val_cost: 3.7240\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6653 - val_loss: 0.1148 - val_auc: 0.9895 - val_accuracy: 0.9733 - val_cost: 3.4733\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6389 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.5872\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9797 - cost: 2.6355 - val_loss: 0.1129 - val_auc: 0.9900 - val_accuracy: 0.9724 - val_cost: 3.4310\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6509 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5319\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6413 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.3561\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.7011 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.4701\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6801 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9724 - val_cost: 3.3984\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6556 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4570\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6998 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.4961\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6308 - val_loss: 0.1174 - val_auc: 0.9891 - val_accuracy: 0.9721 - val_cost: 3.5905\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6754 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.3268\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6427 - val_loss: 0.1141 - val_auc: 0.9896 - val_accuracy: 0.9726 - val_cost: 3.4375\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6336 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9721 - val_cost: 3.5970\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6718 - val_loss: 0.1153 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4570\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6071 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9725 - val_cost: 3.5742\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6046 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9726 - val_cost: 3.5905\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1096 - auc: 0.9907 - accuracy: 0.9708 - cost: 3.6875\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:36.211919\n",
            "fold accuracy: 0.9708124995231628 - fold cost: 3.6875\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5458 - auc: 0.7802 - accuracy: 0.7158 - cost: 37.6375 - val_loss: 0.4082 - val_auc: 0.8940 - val_accuracy: 0.8201 - val_cost: 23.7012\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3657 - auc: 0.9148 - accuracy: 0.8415 - cost: 20.1920 - val_loss: 0.3210 - val_auc: 0.9346 - val_accuracy: 0.8619 - val_cost: 16.8880\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3142 - auc: 0.9377 - accuracy: 0.8707 - cost: 16.3326 - val_loss: 0.2927 - val_auc: 0.9460 - val_accuracy: 0.8781 - val_cost: 14.9316\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2871 - auc: 0.9481 - accuracy: 0.8832 - cost: 14.7582 - val_loss: 0.2708 - val_auc: 0.9539 - val_accuracy: 0.8901 - val_cost: 13.4049\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2654 - auc: 0.9557 - accuracy: 0.8934 - cost: 13.4843 - val_loss: 0.2530 - val_auc: 0.9595 - val_accuracy: 0.9012 - val_cost: 12.0638\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2464 - auc: 0.9617 - accuracy: 0.9027 - cost: 12.2923 - val_loss: 0.2373 - val_auc: 0.9646 - val_accuracy: 0.9088 - val_cost: 11.1686\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2311 - auc: 0.9664 - accuracy: 0.9104 - cost: 11.3029 - val_loss: 0.2233 - val_auc: 0.9686 - val_accuracy: 0.9151 - val_cost: 10.4297\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2170 - auc: 0.9702 - accuracy: 0.9165 - cost: 10.5548 - val_loss: 0.2113 - val_auc: 0.9718 - val_accuracy: 0.9213 - val_cost: 9.8763\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2050 - auc: 0.9733 - accuracy: 0.9224 - cost: 9.8117 - val_loss: 0.2006 - val_auc: 0.9746 - val_accuracy: 0.9276 - val_cost: 8.7630\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1949 - auc: 0.9758 - accuracy: 0.9271 - cost: 9.2664 - val_loss: 0.1925 - val_auc: 0.9763 - val_accuracy: 0.9300 - val_cost: 8.4277\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1873 - auc: 0.9775 - accuracy: 0.9304 - cost: 8.8296 - val_loss: 0.1858 - val_auc: 0.9776 - val_accuracy: 0.9335 - val_cost: 7.9557\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1798 - auc: 0.9792 - accuracy: 0.9334 - cost: 8.4467 - val_loss: 0.1796 - val_auc: 0.9792 - val_accuracy: 0.9351 - val_cost: 8.2585\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1731 - auc: 0.9805 - accuracy: 0.9372 - cost: 7.9694 - val_loss: 0.1757 - val_auc: 0.9798 - val_accuracy: 0.9379 - val_cost: 7.7604\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1672 - auc: 0.9817 - accuracy: 0.9398 - cost: 7.6289 - val_loss: 0.1699 - val_auc: 0.9811 - val_accuracy: 0.9419 - val_cost: 6.9499\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1624 - auc: 0.9827 - accuracy: 0.9415 - cost: 7.4403 - val_loss: 0.1671 - val_auc: 0.9814 - val_accuracy: 0.9422 - val_cost: 6.9661\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1575 - auc: 0.9836 - accuracy: 0.9443 - cost: 7.0919 - val_loss: 0.1634 - val_auc: 0.9822 - val_accuracy: 0.9434 - val_cost: 6.8815\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1543 - auc: 0.9842 - accuracy: 0.9463 - cost: 6.8306 - val_loss: 0.1600 - val_auc: 0.9831 - val_accuracy: 0.9453 - val_cost: 6.5723\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1502 - auc: 0.9849 - accuracy: 0.9479 - cost: 6.6206 - val_loss: 0.1566 - val_auc: 0.9835 - val_accuracy: 0.9473 - val_cost: 6.5299\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1470 - auc: 0.9855 - accuracy: 0.9486 - cost: 6.5353 - val_loss: 0.1540 - val_auc: 0.9840 - val_accuracy: 0.9474 - val_cost: 6.4290\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1437 - auc: 0.9860 - accuracy: 0.9506 - cost: 6.2547 - val_loss: 0.1516 - val_auc: 0.9843 - val_accuracy: 0.9492 - val_cost: 6.3737\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1410 - auc: 0.9865 - accuracy: 0.9522 - cost: 6.0801 - val_loss: 0.1506 - val_auc: 0.9843 - val_accuracy: 0.9493 - val_cost: 6.3477\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1393 - auc: 0.9867 - accuracy: 0.9526 - cost: 6.0282 - val_loss: 0.1471 - val_auc: 0.9851 - val_accuracy: 0.9504 - val_cost: 5.9408\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1355 - auc: 0.9875 - accuracy: 0.9539 - cost: 5.8666 - val_loss: 0.1455 - val_auc: 0.9855 - val_accuracy: 0.9517 - val_cost: 5.7096\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1333 - auc: 0.9878 - accuracy: 0.9553 - cost: 5.6819 - val_loss: 0.1428 - val_auc: 0.9858 - val_accuracy: 0.9522 - val_cost: 5.8659\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1321 - auc: 0.9878 - accuracy: 0.9554 - cost: 5.6668 - val_loss: 0.1409 - val_auc: 0.9861 - val_accuracy: 0.9544 - val_cost: 5.4883\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1288 - auc: 0.9884 - accuracy: 0.9568 - cost: 5.4991 - val_loss: 0.1400 - val_auc: 0.9862 - val_accuracy: 0.9548 - val_cost: 5.5208\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1273 - auc: 0.9886 - accuracy: 0.9583 - cost: 5.3001 - val_loss: 0.1393 - val_auc: 0.9862 - val_accuracy: 0.9551 - val_cost: 5.6641\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1260 - auc: 0.9887 - accuracy: 0.9579 - cost: 5.3379 - val_loss: 0.1357 - val_auc: 0.9868 - val_accuracy: 0.9566 - val_cost: 5.2604\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1238 - auc: 0.9890 - accuracy: 0.9588 - cost: 5.2341 - val_loss: 0.1354 - val_auc: 0.9867 - val_accuracy: 0.9558 - val_cost: 5.3353\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1215 - auc: 0.9894 - accuracy: 0.9604 - cost: 5.0328 - val_loss: 0.1331 - val_auc: 0.9873 - val_accuracy: 0.9574 - val_cost: 5.1888\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1211 - auc: 0.9895 - accuracy: 0.9608 - cost: 4.9855 - val_loss: 0.1321 - val_auc: 0.9872 - val_accuracy: 0.9576 - val_cost: 5.0716\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9898 - accuracy: 0.9617 - cost: 4.8759 - val_loss: 0.1312 - val_auc: 0.9871 - val_accuracy: 0.9588 - val_cost: 5.0879\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1183 - auc: 0.9898 - accuracy: 0.9622 - cost: 4.8239 - val_loss: 0.1294 - val_auc: 0.9876 - val_accuracy: 0.9600 - val_cost: 4.8698\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1161 - auc: 0.9901 - accuracy: 0.9623 - cost: 4.7855 - val_loss: 0.1291 - val_auc: 0.9874 - val_accuracy: 0.9599 - val_cost: 4.8600\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1146 - auc: 0.9904 - accuracy: 0.9628 - cost: 4.7371 - val_loss: 0.1290 - val_auc: 0.9878 - val_accuracy: 0.9596 - val_cost: 4.8079\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1134 - auc: 0.9904 - accuracy: 0.9638 - cost: 4.6149 - val_loss: 0.1269 - val_auc: 0.9880 - val_accuracy: 0.9599 - val_cost: 4.7624\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1120 - auc: 0.9906 - accuracy: 0.9639 - cost: 4.5956 - val_loss: 0.1261 - val_auc: 0.9881 - val_accuracy: 0.9606 - val_cost: 4.7363\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1104 - auc: 0.9908 - accuracy: 0.9653 - cost: 4.4147 - val_loss: 0.1243 - val_auc: 0.9882 - val_accuracy: 0.9611 - val_cost: 4.7038\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1097 - auc: 0.9908 - accuracy: 0.9655 - cost: 4.4009 - val_loss: 0.1236 - val_auc: 0.9882 - val_accuracy: 0.9621 - val_cost: 4.7624\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1087 - auc: 0.9909 - accuracy: 0.9656 - cost: 4.3858 - val_loss: 0.1227 - val_auc: 0.9885 - val_accuracy: 0.9630 - val_cost: 4.5508\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1067 - auc: 0.9911 - accuracy: 0.9672 - cost: 4.1761 - val_loss: 0.1238 - val_auc: 0.9884 - val_accuracy: 0.9624 - val_cost: 4.4694\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1075 - auc: 0.9911 - accuracy: 0.9664 - cost: 4.2721 - val_loss: 0.1211 - val_auc: 0.9886 - val_accuracy: 0.9633 - val_cost: 4.4336\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1059 - auc: 0.9914 - accuracy: 0.9667 - cost: 4.2276 - val_loss: 0.1218 - val_auc: 0.9885 - val_accuracy: 0.9633 - val_cost: 4.4173\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1051 - auc: 0.9913 - accuracy: 0.9674 - cost: 4.1492 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9634 - val_cost: 4.4466\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9916 - accuracy: 0.9672 - cost: 4.1973 - val_loss: 0.1193 - val_auc: 0.9886 - val_accuracy: 0.9653 - val_cost: 4.2741\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9917 - accuracy: 0.9689 - cost: 3.9606 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9631 - val_cost: 4.6484\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9916 - accuracy: 0.9685 - cost: 4.0111 - val_loss: 0.1217 - val_auc: 0.9889 - val_accuracy: 0.9635 - val_cost: 4.2969\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9684 - cost: 4.0418 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9635 - val_cost: 4.5410\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1004 - auc: 0.9919 - accuracy: 0.9691 - cost: 3.9423 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9651 - val_cost: 4.4401\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9920 - accuracy: 0.9693 - cost: 3.9136 - val_loss: 0.1185 - val_auc: 0.9890 - val_accuracy: 0.9647 - val_cost: 4.2611\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1007 - auc: 0.9919 - accuracy: 0.9692 - cost: 3.9139 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9652 - val_cost: 4.3783\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0990 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8135 - val_loss: 0.1181 - val_auc: 0.9888 - val_accuracy: 0.9651 - val_cost: 4.2839\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9921 - accuracy: 0.9699 - cost: 3.8271 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9665 - val_cost: 4.1634\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0984 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8196 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9658 - val_cost: 4.3066\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9922 - accuracy: 0.9705 - cost: 3.7738 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9667 - val_cost: 4.2057\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0966 - auc: 0.9923 - accuracy: 0.9708 - cost: 3.7118 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9668 - val_cost: 4.1602\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0961 - auc: 0.9924 - accuracy: 0.9706 - cost: 3.7454 - val_loss: 0.1168 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.1211\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0963 - auc: 0.9923 - accuracy: 0.9706 - cost: 3.7588 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9674 - val_cost: 4.0462\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0958 - auc: 0.9923 - accuracy: 0.9708 - cost: 3.7390 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9672 - val_cost: 4.3359\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0957 - auc: 0.9923 - accuracy: 0.9716 - cost: 3.6418 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9672 - val_cost: 4.2448\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9717 - cost: 3.6153 - val_loss: 0.1162 - val_auc: 0.9891 - val_accuracy: 0.9669 - val_cost: 4.4434\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0954 - auc: 0.9924 - accuracy: 0.9714 - cost: 3.6487 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9672 - val_cost: 4.2969\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0942 - auc: 0.9926 - accuracy: 0.9716 - cost: 3.6397 - val_loss: 0.1161 - val_auc: 0.9888 - val_accuracy: 0.9678 - val_cost: 3.9258\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0935 - auc: 0.9926 - accuracy: 0.9722 - cost: 3.5508 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9683 - val_cost: 4.1309\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0931 - auc: 0.9926 - accuracy: 0.9723 - cost: 3.5505 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 4.2057\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9718 - cost: 3.6001 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.0332\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5750 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 4.2025\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0923 - auc: 0.9927 - accuracy: 0.9729 - cost: 3.4738 - val_loss: 0.1146 - val_auc: 0.9892 - val_accuracy: 0.9668 - val_cost: 4.2676\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0909 - auc: 0.9928 - accuracy: 0.9726 - cost: 3.5125 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9681 - val_cost: 4.0885\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0911 - auc: 0.9930 - accuracy: 0.9728 - cost: 3.4980 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9674 - val_cost: 4.0690\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9927 - accuracy: 0.9732 - cost: 3.4207 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.9518\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9927 - accuracy: 0.9728 - cost: 3.4760 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9682 - val_cost: 4.0560\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9929 - accuracy: 0.9733 - cost: 3.4221 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 4.2057\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9931 - accuracy: 0.9736 - cost: 3.3902 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9668 - val_cost: 4.3392\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9930 - accuracy: 0.9731 - cost: 3.4487 - val_loss: 0.1138 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 4.0462\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9931 - accuracy: 0.9739 - cost: 3.3328 - val_loss: 0.1185 - val_auc: 0.9892 - val_accuracy: 0.9664 - val_cost: 4.1536\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9730 - cost: 3.4427 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9680 - val_cost: 4.1341\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3676 - val_loss: 0.1130 - val_auc: 0.9891 - val_accuracy: 0.9684 - val_cost: 3.9974\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9742 - cost: 3.2954 - val_loss: 0.1125 - val_auc: 0.9892 - val_accuracy: 0.9673 - val_cost: 4.1276\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2766 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9682 - val_cost: 3.9811\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2823 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9676 - val_cost: 4.0560\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3192 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 4.0592\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0868 - auc: 0.9934 - accuracy: 0.9748 - cost: 3.2406 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9686 - val_cost: 3.9811\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0871 - auc: 0.9932 - accuracy: 0.9745 - cost: 3.2713 - val_loss: 0.1115 - val_auc: 0.9894 - val_accuracy: 0.9693 - val_cost: 3.9355\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0863 - auc: 0.9933 - accuracy: 0.9751 - cost: 3.2018 - val_loss: 0.1155 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.1341\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9749 - cost: 3.2308 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 4.0072\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9934 - accuracy: 0.9743 - cost: 3.2865 - val_loss: 0.1134 - val_auc: 0.9891 - val_accuracy: 0.9692 - val_cost: 3.9030\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9934 - accuracy: 0.9747 - cost: 3.2402 - val_loss: 0.1155 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0788\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9934 - accuracy: 0.9758 - cost: 3.1062 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.8151\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9935 - accuracy: 0.9748 - cost: 3.2234 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.7988\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9936 - accuracy: 0.9749 - cost: 3.2167 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9693 - val_cost: 3.9648\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.1978 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.9388\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9935 - accuracy: 0.9749 - cost: 3.2095 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.9290\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9936 - accuracy: 0.9748 - cost: 3.2388 - val_loss: 0.1138 - val_auc: 0.9890 - val_accuracy: 0.9691 - val_cost: 3.9648\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1457 - val_loss: 0.1151 - val_auc: 0.9888 - val_accuracy: 0.9680 - val_cost: 4.0885\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1361 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9688 - val_cost: 3.9128\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1443 - val_loss: 0.1153 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.7891\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.2021 - val_loss: 0.1150 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.9714\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1267 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.0462\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1182 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9691 - val_cost: 3.7695\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0551 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9518\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1444 - val_loss: 0.1167 - val_auc: 0.9890 - val_accuracy: 0.9687 - val_cost: 4.0039\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0904 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.6263\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1400 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.6882\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0824 - auc: 0.9939 - accuracy: 0.9759 - cost: 3.1048 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.8053\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0833 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0774 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.8477\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0819 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0847 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9938 - accuracy: 0.9757 - cost: 3.1109 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.6393\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9938 - accuracy: 0.9754 - cost: 3.1599 - val_loss: 0.1158 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.6719\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.0910 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.6882\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0218 - val_loss: 0.1126 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.8542\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9871 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.6491\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9938 - accuracy: 0.9765 - cost: 3.0171 - val_loss: 0.1129 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.9062\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0249 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.9648\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0784 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8867\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9911 - val_loss: 0.1135 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9746\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0250 - val_loss: 0.1139 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.9779\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9820 - val_loss: 0.1150 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.7663\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9937 - accuracy: 0.9765 - cost: 3.0189 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7760\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0166 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.6263\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9761 - cost: 3.0582 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9682 - val_cost: 4.0234\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9768 - cost: 2.9754 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8900\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9091 - val_loss: 0.1164 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.9225\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9636 - val_loss: 0.1144 - val_auc: 0.9888 - val_accuracy: 0.9691 - val_cost: 3.9746\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9580 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 3.9355\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9877 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.8672\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0796 - auc: 0.9942 - accuracy: 0.9768 - cost: 2.9945 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6263\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9399 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7207\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9189 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.8281\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9974 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9687 - val_cost: 3.7337\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9829 - val_loss: 0.1139 - val_auc: 0.9891 - val_accuracy: 0.9699 - val_cost: 3.7370\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9348 - val_loss: 0.1157 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6361\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9322 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8672\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8805 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9696 - val_cost: 3.6296\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9585 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.6230\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.8868 - val_loss: 0.1156 - val_auc: 0.9893 - val_accuracy: 0.9689 - val_cost: 3.9876\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9343 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6328\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9435 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 4.0658\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8985 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9746\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9650 - val_loss: 0.1153 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8802\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9200 - val_loss: 0.1171 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.6263\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8613 - val_loss: 0.1160 - val_auc: 0.9891 - val_accuracy: 0.9691 - val_cost: 3.8216\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9115 - val_loss: 0.1156 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6784\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8388 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9696 - val_cost: 3.7858\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8868 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.7337\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9164 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.6719\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8287 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 4.0983\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.7922 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 4.0397\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8824 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9693 - val_cost: 3.7207\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8543 - val_loss: 0.1169 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6068\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0773 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8246 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.7923\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9203 - val_loss: 0.1160 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.9030\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8580 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 4.0332\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8890 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.6882\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8310 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.7272\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8129 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8525 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.7305\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8245 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9699 - val_cost: 3.7305\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.9241 - val_loss: 0.1151 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.9941\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8359 - val_loss: 0.1170 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.8281\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7870 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7565\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8657 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9693 - val_cost: 3.7630\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0782 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8765 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6458\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7920 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.9030\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8346 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.6426\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8520 - val_loss: 0.1157 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.6882\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8020 - val_loss: 0.1170 - val_auc: 0.9889 - val_accuracy: 0.9689 - val_cost: 3.8900\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8214 - val_loss: 0.1164 - val_auc: 0.9890 - val_accuracy: 0.9702 - val_cost: 4.0462\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8178 - val_loss: 0.1176 - val_auc: 0.9890 - val_accuracy: 0.9692 - val_cost: 3.7663\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7543 - val_loss: 0.1152 - val_auc: 0.9889 - val_accuracy: 0.9698 - val_cost: 3.9225\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8395 - val_loss: 0.1161 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.8802\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7866 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.6686\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8490 - val_loss: 0.1179 - val_auc: 0.9886 - val_accuracy: 0.9701 - val_cost: 3.7891\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7493 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.6784\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7673 - val_loss: 0.1173 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6133\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7922 - val_loss: 0.1162 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.6426\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7215 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.5872\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7419 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8574\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7598 - val_loss: 0.1165 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5645\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7367 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9709 - val_cost: 3.7207\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.7914 - val_loss: 0.1157 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.7044\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6592 - val_loss: 0.1176 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6296\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7442 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.6035\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7912 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.7207\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7034 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.7305\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7815 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.5775\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7529 - val_loss: 0.1193 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6230\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7311 - val_loss: 0.1185 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7305\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8120 - val_loss: 0.1192 - val_auc: 0.9888 - val_accuracy: 0.9705 - val_cost: 3.7695\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6918 - val_loss: 0.1201 - val_auc: 0.9888 - val_accuracy: 0.9711 - val_cost: 3.7077\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7616 - val_loss: 0.1173 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.7891\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6882 - val_loss: 0.1184 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.4961\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7981 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9711 - val_cost: 3.7500\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7228 - val_loss: 0.1178 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.8314\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7404 - val_loss: 0.1182 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6133\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7053 - val_loss: 0.1183 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6976 - val_loss: 0.1195 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.5742\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7241 - val_loss: 0.1173 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6556\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7232 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9704 - val_cost: 3.7305\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6684 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7272\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7188 - val_loss: 0.1196 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.5905\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7600 - val_loss: 0.1201 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 3.8086\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7699 - val_loss: 0.1180 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.7826\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7593 - val_loss: 0.1186 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.7826\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6957 - val_loss: 0.1189 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.8932\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7283 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.6328\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6760 - val_loss: 0.1203 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.5970\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7511 - val_loss: 0.1206 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.7793\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0741 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7613 - val_loss: 0.1194 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.8379\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6550 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9693 - val_cost: 3.9355\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6994 - val_loss: 0.1209 - val_auc: 0.9888 - val_accuracy: 0.9705 - val_cost: 3.8639\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7072 - val_loss: 0.1226 - val_auc: 0.9884 - val_accuracy: 0.9709 - val_cost: 3.5026\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6254 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.7305\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7711 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.5807\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6762 - val_loss: 0.1204 - val_auc: 0.9888 - val_accuracy: 0.9712 - val_cost: 3.6458\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7337 - val_loss: 0.1220 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.6491\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7296 - val_loss: 0.1186 - val_auc: 0.9890 - val_accuracy: 0.9711 - val_cost: 3.7370\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7320 - val_loss: 0.1222 - val_auc: 0.9887 - val_accuracy: 0.9707 - val_cost: 3.4896\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6449 - val_loss: 0.1216 - val_auc: 0.9886 - val_accuracy: 0.9716 - val_cost: 3.5645\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7293 - val_loss: 0.1213 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.6523\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0728 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6654 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7207\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.7018 - val_loss: 0.1216 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.6816\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6992 - val_loss: 0.1183 - val_auc: 0.9888 - val_accuracy: 0.9713 - val_cost: 3.7174\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6499 - val_loss: 0.1223 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.8118\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6309 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.8086\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6907 - val_loss: 0.1201 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.8932\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6140 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6705 - val_loss: 0.1205 - val_auc: 0.9889 - val_accuracy: 0.9716 - val_cost: 3.5319\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.5824 - val_loss: 0.1199 - val_auc: 0.9887 - val_accuracy: 0.9715 - val_cost: 3.4798\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6614 - val_loss: 0.1223 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.5221\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6932 - val_loss: 0.1218 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.7891\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5725 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9715 - val_cost: 3.5091\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6758 - val_loss: 0.1204 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.7272\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6220 - val_loss: 0.1198 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.8151\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6276 - val_loss: 0.1203 - val_auc: 0.9886 - val_accuracy: 0.9725 - val_cost: 3.5124\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6724 - val_loss: 0.1214 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.7565\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6655 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5855 - val_loss: 0.1199 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.7565\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0715 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6137 - val_loss: 0.1189 - val_auc: 0.9890 - val_accuracy: 0.9715 - val_cost: 3.6979\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6770 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.7533\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.6046 - val_loss: 0.1206 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.3984\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6255 - val_loss: 0.1187 - val_auc: 0.9888 - val_accuracy: 0.9717 - val_cost: 3.6393\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7140 - val_loss: 0.1214 - val_auc: 0.9884 - val_accuracy: 0.9715 - val_cost: 3.6719\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6230 - val_loss: 0.1197 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.4212\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6238 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.6784\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6695 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9722 - val_cost: 3.5742\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6263 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9711 - val_cost: 3.7402\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6581 - val_loss: 0.1177 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.7240\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5997 - val_loss: 0.1190 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.7695\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6308 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.7695\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9803 - cost: 2.5454 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.7663\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5911 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.8216\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5598 - val_loss: 0.1210 - val_auc: 0.9888 - val_accuracy: 0.9718 - val_cost: 3.6751\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.6044 - val_loss: 0.1191 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.7923\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6419 - val_loss: 0.1212 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5926 - val_loss: 0.1234 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.8542\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6211 - val_loss: 0.1234 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.7272\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6874 - val_loss: 0.1199 - val_auc: 0.9888 - val_accuracy: 0.9713 - val_cost: 3.5710\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6196 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9726 - val_cost: 3.5384\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6060 - val_loss: 0.1188 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.6914\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6350 - val_loss: 0.1175 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.8411\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0708 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5720 - val_loss: 0.1189 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.6032 - val_loss: 0.1211 - val_auc: 0.9887 - val_accuracy: 0.9715 - val_cost: 3.6263\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6054 - val_loss: 0.1217 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.4831\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5794 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9719 - val_cost: 3.6751\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9803 - cost: 2.5382 - val_loss: 0.1193 - val_auc: 0.9889 - val_accuracy: 0.9707 - val_cost: 3.6035\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5998 - val_loss: 0.1221 - val_auc: 0.9885 - val_accuracy: 0.9713 - val_cost: 3.7142\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9803 - cost: 2.5541 - val_loss: 0.1195 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.5677\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9802 - cost: 2.5474 - val_loss: 0.1190 - val_auc: 0.9889 - val_accuracy: 0.9721 - val_cost: 3.6296\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6127 - val_loss: 0.1206 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5514\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5268 - val_loss: 0.1211 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7695\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6074 - val_loss: 0.1209 - val_auc: 0.9884 - val_accuracy: 0.9713 - val_cost: 3.6849\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5828 - val_loss: 0.1202 - val_auc: 0.9888 - val_accuracy: 0.9707 - val_cost: 3.9811\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.6035 - val_loss: 0.1197 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5612\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5799 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.7695\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9803 - cost: 2.5600 - val_loss: 0.1198 - val_auc: 0.9888 - val_accuracy: 0.9718 - val_cost: 3.6719\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5889 - val_loss: 0.1189 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.8021\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6012 - val_loss: 0.1176 - val_auc: 0.9890 - val_accuracy: 0.9713 - val_cost: 3.5482\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9802 - cost: 2.5637 - val_loss: 0.1204 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.7077\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5536 - val_loss: 0.1210 - val_auc: 0.9891 - val_accuracy: 0.9711 - val_cost: 3.6523\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5341 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9722 - val_cost: 3.5742\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5776 - val_loss: 0.1206 - val_auc: 0.9888 - val_accuracy: 0.9720 - val_cost: 3.6068\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5978 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.7695\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5681 - val_loss: 0.1206 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.6100\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5753 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9707 - val_cost: 3.8314\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0704 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5976 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.7272\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5217 - val_loss: 0.1190 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.7435\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9806 - cost: 2.5016 - val_loss: 0.1215 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.7044\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9952 - accuracy: 0.9803 - cost: 2.5381 - val_loss: 0.1218 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.8346\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5729 - val_loss: 0.1186 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.7467\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6168 - val_loss: 0.1238 - val_auc: 0.9884 - val_accuracy: 0.9704 - val_cost: 3.7467\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1037 - auc: 0.9909 - accuracy: 0.9728 - cost: 3.4000\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:50.984269\n",
            "fold accuracy: 0.9727500081062317 - fold cost: 3.4000000953674316\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5455 - auc: 0.7810 - accuracy: 0.7158 - cost: 37.6462 - val_loss: 0.4066 - val_auc: 0.8963 - val_accuracy: 0.8217 - val_cost: 23.4701\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3653 - auc: 0.9151 - accuracy: 0.8432 - cost: 19.9915 - val_loss: 0.3224 - val_auc: 0.9340 - val_accuracy: 0.8621 - val_cost: 17.0638\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3132 - auc: 0.9380 - accuracy: 0.8701 - cost: 16.4269 - val_loss: 0.2957 - val_auc: 0.9446 - val_accuracy: 0.8765 - val_cost: 15.3353\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2860 - auc: 0.9484 - accuracy: 0.8836 - cost: 14.6830 - val_loss: 0.2708 - val_auc: 0.9538 - val_accuracy: 0.8903 - val_cost: 13.4115\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2647 - auc: 0.9558 - accuracy: 0.8941 - cost: 13.3587 - val_loss: 0.2522 - val_auc: 0.9600 - val_accuracy: 0.8994 - val_cost: 12.2363\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2463 - auc: 0.9618 - accuracy: 0.9033 - cost: 12.2278 - val_loss: 0.2370 - val_auc: 0.9645 - val_accuracy: 0.9087 - val_cost: 11.2663\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2312 - auc: 0.9662 - accuracy: 0.9105 - cost: 11.3140 - val_loss: 0.2231 - val_auc: 0.9686 - val_accuracy: 0.9152 - val_cost: 10.3613\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2180 - auc: 0.9699 - accuracy: 0.9164 - cost: 10.5685 - val_loss: 0.2116 - val_auc: 0.9718 - val_accuracy: 0.9210 - val_cost: 9.6875\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2059 - auc: 0.9732 - accuracy: 0.9217 - cost: 9.8939 - val_loss: 0.2007 - val_auc: 0.9745 - val_accuracy: 0.9250 - val_cost: 9.3359\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1963 - auc: 0.9754 - accuracy: 0.9266 - cost: 9.2954 - val_loss: 0.1916 - val_auc: 0.9764 - val_accuracy: 0.9300 - val_cost: 8.9486\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1868 - auc: 0.9776 - accuracy: 0.9308 - cost: 8.7698 - val_loss: 0.1847 - val_auc: 0.9780 - val_accuracy: 0.9345 - val_cost: 8.1022\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1801 - auc: 0.9791 - accuracy: 0.9342 - cost: 8.3383 - val_loss: 0.1780 - val_auc: 0.9794 - val_accuracy: 0.9383 - val_cost: 7.8516\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1736 - auc: 0.9805 - accuracy: 0.9374 - cost: 7.9541 - val_loss: 0.1724 - val_auc: 0.9807 - val_accuracy: 0.9401 - val_cost: 7.5228\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1674 - auc: 0.9817 - accuracy: 0.9400 - cost: 7.5942 - val_loss: 0.1669 - val_auc: 0.9816 - val_accuracy: 0.9436 - val_cost: 7.1387\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1635 - auc: 0.9824 - accuracy: 0.9416 - cost: 7.4254 - val_loss: 0.1628 - val_auc: 0.9826 - val_accuracy: 0.9433 - val_cost: 7.2461\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1601 - auc: 0.9830 - accuracy: 0.9436 - cost: 7.1713 - val_loss: 0.1592 - val_auc: 0.9832 - val_accuracy: 0.9451 - val_cost: 6.7806\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1539 - auc: 0.9842 - accuracy: 0.9455 - cost: 6.9268 - val_loss: 0.1564 - val_auc: 0.9835 - val_accuracy: 0.9465 - val_cost: 6.6895\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1524 - auc: 0.9845 - accuracy: 0.9465 - cost: 6.8136 - val_loss: 0.1556 - val_auc: 0.9837 - val_accuracy: 0.9462 - val_cost: 6.6471\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1483 - auc: 0.9852 - accuracy: 0.9491 - cost: 6.4757 - val_loss: 0.1516 - val_auc: 0.9844 - val_accuracy: 0.9488 - val_cost: 6.3965\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1452 - auc: 0.9857 - accuracy: 0.9503 - cost: 6.3186 - val_loss: 0.1489 - val_auc: 0.9848 - val_accuracy: 0.9487 - val_cost: 6.6439\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1424 - auc: 0.9862 - accuracy: 0.9512 - cost: 6.2118 - val_loss: 0.1467 - val_auc: 0.9851 - val_accuracy: 0.9510 - val_cost: 6.3607\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1402 - auc: 0.9865 - accuracy: 0.9521 - cost: 6.0944 - val_loss: 0.1452 - val_auc: 0.9854 - val_accuracy: 0.9508 - val_cost: 6.4811\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1373 - auc: 0.9870 - accuracy: 0.9536 - cost: 5.8835 - val_loss: 0.1431 - val_auc: 0.9858 - val_accuracy: 0.9528 - val_cost: 6.0840\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1360 - auc: 0.9873 - accuracy: 0.9536 - cost: 5.9118 - val_loss: 0.1432 - val_auc: 0.9858 - val_accuracy: 0.9542 - val_cost: 5.6185\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1328 - auc: 0.9878 - accuracy: 0.9552 - cost: 5.7046 - val_loss: 0.1401 - val_auc: 0.9862 - val_accuracy: 0.9544 - val_cost: 5.8040\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1315 - auc: 0.9879 - accuracy: 0.9554 - cost: 5.6825 - val_loss: 0.1393 - val_auc: 0.9864 - val_accuracy: 0.9544 - val_cost: 5.6608\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1283 - auc: 0.9884 - accuracy: 0.9572 - cost: 5.4332 - val_loss: 0.1380 - val_auc: 0.9865 - val_accuracy: 0.9549 - val_cost: 5.7878\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1278 - auc: 0.9884 - accuracy: 0.9579 - cost: 5.3557 - val_loss: 0.1376 - val_auc: 0.9865 - val_accuracy: 0.9558 - val_cost: 5.7715\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1265 - auc: 0.9886 - accuracy: 0.9582 - cost: 5.3153 - val_loss: 0.1365 - val_auc: 0.9866 - val_accuracy: 0.9569 - val_cost: 5.4818\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1237 - auc: 0.9890 - accuracy: 0.9590 - cost: 5.2108 - val_loss: 0.1346 - val_auc: 0.9869 - val_accuracy: 0.9572 - val_cost: 5.4134\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1230 - auc: 0.9892 - accuracy: 0.9599 - cost: 5.1146 - val_loss: 0.1327 - val_auc: 0.9872 - val_accuracy: 0.9586 - val_cost: 5.1790\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1213 - auc: 0.9893 - accuracy: 0.9605 - cost: 5.0214 - val_loss: 0.1291 - val_auc: 0.9876 - val_accuracy: 0.9593 - val_cost: 5.1921\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1201 - auc: 0.9895 - accuracy: 0.9615 - cost: 4.9090 - val_loss: 0.1296 - val_auc: 0.9874 - val_accuracy: 0.9604 - val_cost: 5.0944\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1182 - auc: 0.9897 - accuracy: 0.9616 - cost: 4.8976 - val_loss: 0.1289 - val_auc: 0.9877 - val_accuracy: 0.9595 - val_cost: 5.2083\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1163 - auc: 0.9900 - accuracy: 0.9627 - cost: 4.7468 - val_loss: 0.1280 - val_auc: 0.9878 - val_accuracy: 0.9607 - val_cost: 4.9316\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1157 - auc: 0.9902 - accuracy: 0.9628 - cost: 4.7349 - val_loss: 0.1286 - val_auc: 0.9880 - val_accuracy: 0.9600 - val_cost: 4.8340\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1147 - auc: 0.9903 - accuracy: 0.9630 - cost: 4.6929 - val_loss: 0.1269 - val_auc: 0.9878 - val_accuracy: 0.9615 - val_cost: 4.8047\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1131 - auc: 0.9904 - accuracy: 0.9636 - cost: 4.6230 - val_loss: 0.1263 - val_auc: 0.9879 - val_accuracy: 0.9608 - val_cost: 4.7917\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1135 - auc: 0.9904 - accuracy: 0.9639 - cost: 4.5962 - val_loss: 0.1254 - val_auc: 0.9880 - val_accuracy: 0.9604 - val_cost: 5.0879\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1119 - auc: 0.9905 - accuracy: 0.9640 - cost: 4.5979 - val_loss: 0.1233 - val_auc: 0.9883 - val_accuracy: 0.9608 - val_cost: 5.0977\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1106 - auc: 0.9906 - accuracy: 0.9650 - cost: 4.4658 - val_loss: 0.1239 - val_auc: 0.9882 - val_accuracy: 0.9616 - val_cost: 4.6549\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1087 - auc: 0.9909 - accuracy: 0.9655 - cost: 4.3920 - val_loss: 0.1219 - val_auc: 0.9881 - val_accuracy: 0.9631 - val_cost: 4.5801\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1094 - auc: 0.9908 - accuracy: 0.9652 - cost: 4.4331 - val_loss: 0.1222 - val_auc: 0.9883 - val_accuracy: 0.9628 - val_cost: 4.6322\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1082 - auc: 0.9911 - accuracy: 0.9657 - cost: 4.3721 - val_loss: 0.1221 - val_auc: 0.9884 - val_accuracy: 0.9627 - val_cost: 4.7201\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1069 - auc: 0.9911 - accuracy: 0.9662 - cost: 4.3197 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9640 - val_cost: 4.6029\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1062 - auc: 0.9911 - accuracy: 0.9664 - cost: 4.2864 - val_loss: 0.1226 - val_auc: 0.9882 - val_accuracy: 0.9628 - val_cost: 4.5215\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1053 - auc: 0.9913 - accuracy: 0.9674 - cost: 4.1489 - val_loss: 0.1217 - val_auc: 0.9883 - val_accuracy: 0.9638 - val_cost: 4.6484\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1054 - auc: 0.9913 - accuracy: 0.9670 - cost: 4.1995 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9638 - val_cost: 4.4694\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1036 - auc: 0.9916 - accuracy: 0.9674 - cost: 4.1649 - val_loss: 0.1179 - val_auc: 0.9888 - val_accuracy: 0.9644 - val_cost: 4.5150\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9915 - accuracy: 0.9675 - cost: 4.1405 - val_loss: 0.1210 - val_auc: 0.9887 - val_accuracy: 0.9629 - val_cost: 4.5020\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1031 - auc: 0.9915 - accuracy: 0.9682 - cost: 4.0462 - val_loss: 0.1172 - val_auc: 0.9888 - val_accuracy: 0.9653 - val_cost: 4.3359\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1028 - auc: 0.9916 - accuracy: 0.9680 - cost: 4.0812 - val_loss: 0.1174 - val_auc: 0.9889 - val_accuracy: 0.9644 - val_cost: 4.5117\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1015 - auc: 0.9917 - accuracy: 0.9692 - cost: 3.9391 - val_loss: 0.1189 - val_auc: 0.9888 - val_accuracy: 0.9649 - val_cost: 4.2643\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1011 - auc: 0.9917 - accuracy: 0.9691 - cost: 3.9430 - val_loss: 0.1191 - val_auc: 0.9885 - val_accuracy: 0.9642 - val_cost: 4.4661\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1012 - auc: 0.9917 - accuracy: 0.9690 - cost: 3.9620 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9653 - val_cost: 4.5866\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9918 - accuracy: 0.9692 - cost: 3.9293 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9653 - val_cost: 4.5215\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0995 - auc: 0.9921 - accuracy: 0.9692 - cost: 3.9540 - val_loss: 0.1177 - val_auc: 0.9887 - val_accuracy: 0.9651 - val_cost: 4.4629\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0987 - auc: 0.9921 - accuracy: 0.9700 - cost: 3.8270 - val_loss: 0.1169 - val_auc: 0.9887 - val_accuracy: 0.9655 - val_cost: 4.3717\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9921 - accuracy: 0.9697 - cost: 3.8635 - val_loss: 0.1189 - val_auc: 0.9885 - val_accuracy: 0.9656 - val_cost: 4.3262\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0984 - auc: 0.9921 - accuracy: 0.9697 - cost: 3.8758 - val_loss: 0.1186 - val_auc: 0.9885 - val_accuracy: 0.9638 - val_cost: 4.8372\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0976 - auc: 0.9922 - accuracy: 0.9704 - cost: 3.7825 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9658 - val_cost: 4.2188\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9702 - cost: 3.8077 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9662 - val_cost: 4.1699\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9922 - accuracy: 0.9706 - cost: 3.7715 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9667 - val_cost: 4.1667\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0963 - auc: 0.9923 - accuracy: 0.9708 - cost: 3.7272 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9664 - val_cost: 4.1178\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9924 - accuracy: 0.9710 - cost: 3.7017 - val_loss: 0.1145 - val_auc: 0.9889 - val_accuracy: 0.9668 - val_cost: 4.1829\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0950 - auc: 0.9925 - accuracy: 0.9711 - cost: 3.6896 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9654 - val_cost: 4.2643\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0950 - auc: 0.9924 - accuracy: 0.9714 - cost: 3.6550 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9672 - val_cost: 4.2318\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0950 - auc: 0.9925 - accuracy: 0.9714 - cost: 3.6628 - val_loss: 0.1156 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.2025\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0943 - auc: 0.9926 - accuracy: 0.9713 - cost: 3.6686 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.0625\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0932 - auc: 0.9927 - accuracy: 0.9720 - cost: 3.5730 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9661 - val_cost: 4.4076\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9926 - accuracy: 0.9721 - cost: 3.5696 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.1309\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9929 - accuracy: 0.9717 - cost: 3.6169 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9673 - val_cost: 4.0365\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9723 - cost: 3.5331 - val_loss: 0.1152 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.0202\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0928 - auc: 0.9927 - accuracy: 0.9723 - cost: 3.5334 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 3.9811\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9732 - cost: 3.4290 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9160\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0910 - auc: 0.9930 - accuracy: 0.9729 - cost: 3.4742 - val_loss: 0.1124 - val_auc: 0.9898 - val_accuracy: 0.9682 - val_cost: 3.9648\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9726 - cost: 3.5099 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9616\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0918 - auc: 0.9929 - accuracy: 0.9726 - cost: 3.5045 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9675 - val_cost: 4.0723\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9931 - accuracy: 0.9728 - cost: 3.4738 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 4.0690\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0903 - auc: 0.9930 - accuracy: 0.9730 - cost: 3.4452 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 4.3099\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9930 - accuracy: 0.9734 - cost: 3.4026 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8574\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9929 - accuracy: 0.9731 - cost: 3.4471 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7923\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9931 - accuracy: 0.9732 - cost: 3.4404 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 3.9388\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9930 - accuracy: 0.9735 - cost: 3.3781 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9685 - val_cost: 3.9290\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9930 - accuracy: 0.9732 - cost: 3.4352 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.7988\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9931 - accuracy: 0.9737 - cost: 3.3683 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 4.0072\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3203 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.9323\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0877 - auc: 0.9932 - accuracy: 0.9743 - cost: 3.2881 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.7956\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3256 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9677 - val_cost: 4.0267\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0877 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2761 - val_loss: 0.1120 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.8216\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0873 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.2956 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.8542\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.2955 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.7435\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2759 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9062\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9747 - cost: 3.2569 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.6784\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0870 - auc: 0.9934 - accuracy: 0.9747 - cost: 3.2369 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8574\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9743 - cost: 3.2938 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 4.0169\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9748 - cost: 3.2373 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.7760\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0857 - auc: 0.9936 - accuracy: 0.9745 - cost: 3.2616 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.7467\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9755 - cost: 3.1332 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.6914\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.1938 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 3.8737\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9934 - accuracy: 0.9751 - cost: 3.1890 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9754 - cost: 3.1687 - val_loss: 0.1106 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.8477\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9753 - cost: 3.1606 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.8346\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9749 - cost: 3.2145 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9698 - val_cost: 3.7435\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1520 - val_loss: 0.1123 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.5970\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9935 - accuracy: 0.9754 - cost: 3.1501 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.7109\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9938 - accuracy: 0.9758 - cost: 3.1030 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9693 - val_cost: 3.8281\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9937 - accuracy: 0.9752 - cost: 3.1750 - val_loss: 0.1108 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7695\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0867 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.7402\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0734 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9700 - val_cost: 3.7109\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1420 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.8542\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1238 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9696 - val_cost: 3.8281\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0783 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.5091\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0846 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.8118\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.0919 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6328\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9937 - accuracy: 0.9762 - cost: 3.0649 - val_loss: 0.1086 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6979\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9757 - cost: 3.1288 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7012\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0836 - val_loss: 0.1098 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.4831\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9761 - cost: 3.0751 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.6882\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9939 - accuracy: 0.9755 - cost: 3.1468 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.6686\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0651 - val_loss: 0.1091 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6784\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9763 - cost: 3.0376 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9695 - val_cost: 3.6719\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0511 - val_loss: 0.1113 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0366 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5938\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9763 - cost: 3.0478 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.6068\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0815 - auc: 0.9940 - accuracy: 0.9766 - cost: 3.0147 - val_loss: 0.1120 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6003\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0481 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.7565\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0158 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.6491\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0228 - val_loss: 0.1087 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9941 - accuracy: 0.9769 - cost: 2.9846 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6100\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9511 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.4668\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9857 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5579\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9764 - cost: 3.0433 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7370\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9262 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.5710\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9952 - val_loss: 0.1081 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.6556\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9611 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.6751\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9892 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.7500\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9769 - cost: 2.9722 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.6784\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9341 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.5677\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9464 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.5905\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9766 - cost: 3.0107 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.6003\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0782 - auc: 0.9944 - accuracy: 0.9767 - cost: 3.0098 - val_loss: 0.1103 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.7565\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9607 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.6914\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9328 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.7663\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9718 - val_loss: 0.1117 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6296\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9769 - cost: 2.9757 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.8411\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9725 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.6947\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9067 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7109\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9402 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7695\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9245 - val_loss: 0.1147 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 3.7467\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8815 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.8672\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9559 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5319\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.9241 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7565\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9543 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.6719\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9777 - cost: 2.8708 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5677\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8971 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7174\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9781 - cost: 2.8227 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8346\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8691 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.8249\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8757 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.8509\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8593 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7370\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8763 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7370\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8887 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7956\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8987 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.4473\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8521 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.6361\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9125 - val_loss: 0.1122 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.6816\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8982 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5807\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8662 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8900\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8346 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.6914\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8988 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9696 - val_cost: 3.9388\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8623 - val_loss: 0.1125 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.6296\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8485 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5026\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8282 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.8346\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8915 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.8118\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8106 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.7370\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8263 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.8704\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8002 - val_loss: 0.1121 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.7044\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8083 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6328\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8272 - val_loss: 0.1126 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8209 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6003\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8214 - val_loss: 0.1117 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.6133\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8146 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.6654\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8608 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5970\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8459 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7272\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7498 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.7760\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7748 - val_loss: 0.1154 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5905\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8055 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.5710\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8104 - val_loss: 0.1133 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.8639\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7773 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9698 - val_cost: 3.8379\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7258 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.7533\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8202 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.6719\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8203 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6296\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8267 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5482\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7772 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5156\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8176 - val_loss: 0.1153 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5091\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7193 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.6979\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7992 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7728\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8307 - val_loss: 0.1137 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.8444\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7530 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.6491\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7513 - val_loss: 0.1150 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.4896\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7784 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.8997\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7516 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.9518\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.8143 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.7793\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6909 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9723 - val_cost: 3.4342\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7281 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.6426\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7343 - val_loss: 0.1150 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.7500\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8120 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6719\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7168 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7533\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.6838 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.6751\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7511 - val_loss: 0.1128 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5449\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7830 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.6068\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7314 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4733\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7591 - val_loss: 0.1123 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5547\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7512 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5612\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7708 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.6068\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.7002 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5482\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7065 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.5482\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7736 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.8542\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.8145 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9695 - val_cost: 3.7826\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7166 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5059\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7975 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.5547\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7212 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7167 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6198\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7457 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.5938\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6803 - val_loss: 0.1144 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.6068\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6479 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5026\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7074 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.4147\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6694 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.8509\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7423 - val_loss: 0.1143 - val_auc: 0.9892 - val_accuracy: 0.9722 - val_cost: 3.7923\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7169 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.5514\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7680 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7012\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7305 - val_loss: 0.1136 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 4.1276\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7867 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.4733\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7726 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6426\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7092 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5807\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6394 - val_loss: 0.1147 - val_auc: 0.9891 - val_accuracy: 0.9721 - val_cost: 3.6686\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0716 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6490 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.5775\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6964 - val_loss: 0.1158 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7695\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6826 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5514\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6630 - val_loss: 0.1141 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5579\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6968 - val_loss: 0.1128 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.7207\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6929 - val_loss: 0.1150 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.5254\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7353 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6035\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6811 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6621\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6704 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.6100\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7137 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.5352\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6579 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6300 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6621\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7143 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 4.0397\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7540 - val_loss: 0.1185 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.6133\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6815 - val_loss: 0.1142 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5645\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6609 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9723 - val_cost: 3.4245\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6718 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.5384\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7674 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6914\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5654 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6621\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6578 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.4798\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6912 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6393\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7054 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.4928\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6849 - val_loss: 0.1130 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6426\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6655 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5221\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6823 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6426\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6299 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.5091\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6629 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6582 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.5254\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7453 - val_loss: 0.1162 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.6523\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.5814 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4310\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9798 - cost: 2.6153 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.4701\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6241 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5775\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5681 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.5482\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6271 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9714 - val_cost: 3.5547\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6712 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5091\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6380 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.4993\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7130 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5807\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6499 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9718 - val_cost: 3.5547\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6519 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.4603\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6229 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.4408\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6224 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9716 - val_cost: 3.5352\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1059 - auc: 0.9908 - accuracy: 0.9719 - cost: 3.5187\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:39.565478\n",
            "fold accuracy: 0.9719374775886536 - fold cost: 3.518749952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5481 - auc: 0.7775 - accuracy: 0.7137 - cost: 37.9522 - val_loss: 0.4113 - val_auc: 0.8930 - val_accuracy: 0.8189 - val_cost: 23.0273\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3656 - auc: 0.9147 - accuracy: 0.8422 - cost: 20.0921 - val_loss: 0.3220 - val_auc: 0.9347 - val_accuracy: 0.8634 - val_cost: 16.3932\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3136 - auc: 0.9379 - accuracy: 0.8701 - cost: 16.4113 - val_loss: 0.2917 - val_auc: 0.9464 - val_accuracy: 0.8792 - val_cost: 14.6712\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2871 - auc: 0.9480 - accuracy: 0.8832 - cost: 14.7536 - val_loss: 0.2689 - val_auc: 0.9547 - val_accuracy: 0.8917 - val_cost: 13.1901\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2643 - auc: 0.9561 - accuracy: 0.8946 - cost: 13.2905 - val_loss: 0.2508 - val_auc: 0.9606 - val_accuracy: 0.9012 - val_cost: 12.3991\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2465 - auc: 0.9618 - accuracy: 0.9031 - cost: 12.2792 - val_loss: 0.2343 - val_auc: 0.9653 - val_accuracy: 0.9107 - val_cost: 11.0449\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2303 - auc: 0.9665 - accuracy: 0.9108 - cost: 11.2697 - val_loss: 0.2211 - val_auc: 0.9694 - val_accuracy: 0.9163 - val_cost: 9.9577\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2176 - auc: 0.9700 - accuracy: 0.9163 - cost: 10.5301 - val_loss: 0.2083 - val_auc: 0.9725 - val_accuracy: 0.9241 - val_cost: 9.4336\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2053 - auc: 0.9732 - accuracy: 0.9222 - cost: 9.8272 - val_loss: 0.1984 - val_auc: 0.9751 - val_accuracy: 0.9272 - val_cost: 8.8184\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1961 - auc: 0.9756 - accuracy: 0.9258 - cost: 9.3657 - val_loss: 0.1893 - val_auc: 0.9771 - val_accuracy: 0.9324 - val_cost: 8.2747\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1867 - auc: 0.9776 - accuracy: 0.9311 - cost: 8.7279 - val_loss: 0.1828 - val_auc: 0.9782 - val_accuracy: 0.9353 - val_cost: 7.9557\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1801 - auc: 0.9791 - accuracy: 0.9344 - cost: 8.3225 - val_loss: 0.1760 - val_auc: 0.9796 - val_accuracy: 0.9378 - val_cost: 7.8158\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1743 - auc: 0.9803 - accuracy: 0.9368 - cost: 7.9964 - val_loss: 0.1732 - val_auc: 0.9804 - val_accuracy: 0.9388 - val_cost: 7.6758\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1694 - auc: 0.9814 - accuracy: 0.9391 - cost: 7.7099 - val_loss: 0.1686 - val_auc: 0.9813 - val_accuracy: 0.9414 - val_cost: 7.2982\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1637 - auc: 0.9823 - accuracy: 0.9414 - cost: 7.4484 - val_loss: 0.1636 - val_auc: 0.9820 - val_accuracy: 0.9428 - val_cost: 7.0801\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1597 - auc: 0.9831 - accuracy: 0.9433 - cost: 7.2003 - val_loss: 0.1598 - val_auc: 0.9828 - val_accuracy: 0.9445 - val_cost: 6.8880\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1564 - auc: 0.9838 - accuracy: 0.9449 - cost: 6.9813 - val_loss: 0.1570 - val_auc: 0.9833 - val_accuracy: 0.9463 - val_cost: 6.6113\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1529 - auc: 0.9844 - accuracy: 0.9463 - cost: 6.8156 - val_loss: 0.1556 - val_auc: 0.9837 - val_accuracy: 0.9471 - val_cost: 6.5592\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1491 - auc: 0.9851 - accuracy: 0.9483 - cost: 6.5633 - val_loss: 0.1530 - val_auc: 0.9841 - val_accuracy: 0.9488 - val_cost: 6.3379\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1466 - auc: 0.9855 - accuracy: 0.9494 - cost: 6.4339 - val_loss: 0.1506 - val_auc: 0.9844 - val_accuracy: 0.9490 - val_cost: 6.3053\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1425 - auc: 0.9862 - accuracy: 0.9508 - cost: 6.2342 - val_loss: 0.1493 - val_auc: 0.9846 - val_accuracy: 0.9510 - val_cost: 6.1947\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1415 - auc: 0.9863 - accuracy: 0.9519 - cost: 6.1240 - val_loss: 0.1469 - val_auc: 0.9852 - val_accuracy: 0.9521 - val_cost: 5.7878\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1391 - auc: 0.9867 - accuracy: 0.9528 - cost: 5.9848 - val_loss: 0.1460 - val_auc: 0.9854 - val_accuracy: 0.9517 - val_cost: 5.9375\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1362 - auc: 0.9871 - accuracy: 0.9545 - cost: 5.7853 - val_loss: 0.1437 - val_auc: 0.9857 - val_accuracy: 0.9531 - val_cost: 5.8724\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1338 - auc: 0.9876 - accuracy: 0.9549 - cost: 5.7244 - val_loss: 0.1439 - val_auc: 0.9857 - val_accuracy: 0.9530 - val_cost: 5.8366\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1328 - auc: 0.9877 - accuracy: 0.9556 - cost: 5.6590 - val_loss: 0.1397 - val_auc: 0.9860 - val_accuracy: 0.9547 - val_cost: 5.6966\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1298 - auc: 0.9882 - accuracy: 0.9564 - cost: 5.5380 - val_loss: 0.1387 - val_auc: 0.9861 - val_accuracy: 0.9557 - val_cost: 5.6152\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1285 - auc: 0.9883 - accuracy: 0.9571 - cost: 5.4734 - val_loss: 0.1381 - val_auc: 0.9864 - val_accuracy: 0.9567 - val_cost: 5.4036\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1272 - auc: 0.9887 - accuracy: 0.9574 - cost: 5.4392 - val_loss: 0.1358 - val_auc: 0.9867 - val_accuracy: 0.9579 - val_cost: 5.3678\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1252 - auc: 0.9889 - accuracy: 0.9586 - cost: 5.2780 - val_loss: 0.1358 - val_auc: 0.9866 - val_accuracy: 0.9583 - val_cost: 5.0130\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9890 - accuracy: 0.9591 - cost: 5.2256 - val_loss: 0.1334 - val_auc: 0.9871 - val_accuracy: 0.9587 - val_cost: 5.3613\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1225 - auc: 0.9893 - accuracy: 0.9602 - cost: 5.0530 - val_loss: 0.1345 - val_auc: 0.9869 - val_accuracy: 0.9576 - val_cost: 5.3190\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9598 - cost: 5.1302 - val_loss: 0.1328 - val_auc: 0.9870 - val_accuracy: 0.9583 - val_cost: 5.2409\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1198 - auc: 0.9895 - accuracy: 0.9613 - cost: 4.9288 - val_loss: 0.1302 - val_auc: 0.9871 - val_accuracy: 0.9599 - val_cost: 4.9349\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1184 - auc: 0.9898 - accuracy: 0.9615 - cost: 4.8934 - val_loss: 0.1313 - val_auc: 0.9870 - val_accuracy: 0.9590 - val_cost: 5.2409\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1179 - auc: 0.9898 - accuracy: 0.9621 - cost: 4.8236 - val_loss: 0.1295 - val_auc: 0.9873 - val_accuracy: 0.9595 - val_cost: 5.0814\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1158 - auc: 0.9901 - accuracy: 0.9630 - cost: 4.7141 - val_loss: 0.1291 - val_auc: 0.9873 - val_accuracy: 0.9600 - val_cost: 5.0293\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1149 - auc: 0.9902 - accuracy: 0.9634 - cost: 4.6569 - val_loss: 0.1281 - val_auc: 0.9874 - val_accuracy: 0.9609 - val_cost: 4.9902\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1131 - auc: 0.9905 - accuracy: 0.9638 - cost: 4.6248 - val_loss: 0.1276 - val_auc: 0.9873 - val_accuracy: 0.9617 - val_cost: 4.7526\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1121 - auc: 0.9906 - accuracy: 0.9644 - cost: 4.5412 - val_loss: 0.1288 - val_auc: 0.9873 - val_accuracy: 0.9614 - val_cost: 4.8047\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1114 - auc: 0.9907 - accuracy: 0.9645 - cost: 4.5446 - val_loss: 0.1261 - val_auc: 0.9876 - val_accuracy: 0.9610 - val_cost: 4.8600\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1095 - auc: 0.9908 - accuracy: 0.9655 - cost: 4.3930 - val_loss: 0.1253 - val_auc: 0.9878 - val_accuracy: 0.9624 - val_cost: 4.6159\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1078 - auc: 0.9911 - accuracy: 0.9658 - cost: 4.3404 - val_loss: 0.1259 - val_auc: 0.9878 - val_accuracy: 0.9622 - val_cost: 4.5768\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1087 - auc: 0.9909 - accuracy: 0.9656 - cost: 4.3892 - val_loss: 0.1240 - val_auc: 0.9879 - val_accuracy: 0.9629 - val_cost: 4.5150\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1072 - auc: 0.9912 - accuracy: 0.9660 - cost: 4.3337 - val_loss: 0.1230 - val_auc: 0.9881 - val_accuracy: 0.9640 - val_cost: 4.3132\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1073 - auc: 0.9911 - accuracy: 0.9667 - cost: 4.2540 - val_loss: 0.1233 - val_auc: 0.9877 - val_accuracy: 0.9636 - val_cost: 4.2806\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1049 - auc: 0.9915 - accuracy: 0.9673 - cost: 4.1700 - val_loss: 0.1238 - val_auc: 0.9880 - val_accuracy: 0.9635 - val_cost: 4.4694\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1051 - auc: 0.9914 - accuracy: 0.9673 - cost: 4.1801 - val_loss: 0.1237 - val_auc: 0.9881 - val_accuracy: 0.9644 - val_cost: 4.1471\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1046 - auc: 0.9915 - accuracy: 0.9675 - cost: 4.1548 - val_loss: 0.1228 - val_auc: 0.9882 - val_accuracy: 0.9636 - val_cost: 4.4336\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1034 - auc: 0.9916 - accuracy: 0.9676 - cost: 4.1368 - val_loss: 0.1225 - val_auc: 0.9881 - val_accuracy: 0.9643 - val_cost: 4.6224\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1018 - auc: 0.9919 - accuracy: 0.9688 - cost: 3.9841 - val_loss: 0.1206 - val_auc: 0.9885 - val_accuracy: 0.9651 - val_cost: 4.4564\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1006 - auc: 0.9919 - accuracy: 0.9690 - cost: 3.9699 - val_loss: 0.1227 - val_auc: 0.9882 - val_accuracy: 0.9670 - val_cost: 4.0202\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9918 - accuracy: 0.9689 - cost: 3.9818 - val_loss: 0.1198 - val_auc: 0.9883 - val_accuracy: 0.9674 - val_cost: 3.9486\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1005 - auc: 0.9920 - accuracy: 0.9699 - cost: 3.8604 - val_loss: 0.1207 - val_auc: 0.9884 - val_accuracy: 0.9649 - val_cost: 4.3164\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0996 - auc: 0.9920 - accuracy: 0.9695 - cost: 3.8963 - val_loss: 0.1198 - val_auc: 0.9886 - val_accuracy: 0.9656 - val_cost: 4.2253\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0991 - auc: 0.9921 - accuracy: 0.9697 - cost: 3.8739 - val_loss: 0.1178 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.2057\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0983 - auc: 0.9922 - accuracy: 0.9700 - cost: 3.8360 - val_loss: 0.1200 - val_auc: 0.9885 - val_accuracy: 0.9656 - val_cost: 4.2220\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9702 - cost: 3.8124 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9673 - val_cost: 3.8444\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0970 - auc: 0.9923 - accuracy: 0.9705 - cost: 3.7617 - val_loss: 0.1197 - val_auc: 0.9885 - val_accuracy: 0.9672 - val_cost: 3.8151\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9923 - accuracy: 0.9708 - cost: 3.7263 - val_loss: 0.1171 - val_auc: 0.9886 - val_accuracy: 0.9668 - val_cost: 4.1471\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0953 - auc: 0.9925 - accuracy: 0.9710 - cost: 3.7103 - val_loss: 0.1168 - val_auc: 0.9886 - val_accuracy: 0.9674 - val_cost: 4.0527\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0953 - auc: 0.9925 - accuracy: 0.9712 - cost: 3.6814 - val_loss: 0.1165 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.1276\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0954 - auc: 0.9925 - accuracy: 0.9709 - cost: 3.7225 - val_loss: 0.1166 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 3.8509\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0942 - auc: 0.9926 - accuracy: 0.9716 - cost: 3.6331 - val_loss: 0.1162 - val_auc: 0.9891 - val_accuracy: 0.9680 - val_cost: 3.9062\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0934 - auc: 0.9927 - accuracy: 0.9719 - cost: 3.6121 - val_loss: 0.1153 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 3.8770\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0949 - auc: 0.9926 - accuracy: 0.9718 - cost: 3.6141 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9681 - val_cost: 3.9746\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0928 - auc: 0.9926 - accuracy: 0.9718 - cost: 3.5933 - val_loss: 0.1164 - val_auc: 0.9888 - val_accuracy: 0.9672 - val_cost: 3.9811\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0937 - auc: 0.9927 - accuracy: 0.9719 - cost: 3.5793 - val_loss: 0.1161 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.8086\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0918 - auc: 0.9928 - accuracy: 0.9728 - cost: 3.4887 - val_loss: 0.1160 - val_auc: 0.9891 - val_accuracy: 0.9693 - val_cost: 3.7109\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9929 - accuracy: 0.9721 - cost: 3.5767 - val_loss: 0.1156 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0072\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.4996 - val_loss: 0.1164 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 3.9160\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9728 - cost: 3.4929 - val_loss: 0.1147 - val_auc: 0.9887 - val_accuracy: 0.9688 - val_cost: 3.8607\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9928 - accuracy: 0.9730 - cost: 3.4638 - val_loss: 0.1141 - val_auc: 0.9887 - val_accuracy: 0.9686 - val_cost: 3.8411\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9931 - accuracy: 0.9733 - cost: 3.4321 - val_loss: 0.1158 - val_auc: 0.9887 - val_accuracy: 0.9700 - val_cost: 3.7109\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9929 - accuracy: 0.9731 - cost: 3.4594 - val_loss: 0.1143 - val_auc: 0.9888 - val_accuracy: 0.9685 - val_cost: 3.6979\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9932 - accuracy: 0.9737 - cost: 3.3710 - val_loss: 0.1156 - val_auc: 0.9889 - val_accuracy: 0.9692 - val_cost: 3.7207\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9931 - accuracy: 0.9735 - cost: 3.3926 - val_loss: 0.1155 - val_auc: 0.9884 - val_accuracy: 0.9675 - val_cost: 4.0202\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9734 - cost: 3.4003 - val_loss: 0.1133 - val_auc: 0.9889 - val_accuracy: 0.9687 - val_cost: 3.9128\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9742 - cost: 3.3170 - val_loss: 0.1126 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.7793\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0884 - auc: 0.9932 - accuracy: 0.9738 - cost: 3.3515 - val_loss: 0.1132 - val_auc: 0.9889 - val_accuracy: 0.9691 - val_cost: 3.8118\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9931 - accuracy: 0.9740 - cost: 3.3532 - val_loss: 0.1120 - val_auc: 0.9889 - val_accuracy: 0.9683 - val_cost: 3.8053\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9736 - cost: 3.3898 - val_loss: 0.1112 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.7695\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9745 - cost: 3.2617 - val_loss: 0.1139 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8672\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9748 - cost: 3.2519 - val_loss: 0.1129 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.6719\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2376 - val_loss: 0.1120 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.6556\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9739 - cost: 3.3589 - val_loss: 0.1125 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.6719\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0857 - auc: 0.9935 - accuracy: 0.9748 - cost: 3.2307 - val_loss: 0.1132 - val_auc: 0.9889 - val_accuracy: 0.9693 - val_cost: 3.7695\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9746 - cost: 3.2639 - val_loss: 0.1147 - val_auc: 0.9884 - val_accuracy: 0.9679 - val_cost: 3.7988\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9936 - accuracy: 0.9751 - cost: 3.1920 - val_loss: 0.1128 - val_auc: 0.9892 - val_accuracy: 0.9693 - val_cost: 3.8151\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9748 - cost: 3.2272 - val_loss: 0.1141 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7305\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9749 - cost: 3.2326 - val_loss: 0.1129 - val_auc: 0.9889 - val_accuracy: 0.9696 - val_cost: 3.8509\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.2045 - val_loss: 0.1132 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7207\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9935 - accuracy: 0.9753 - cost: 3.1710 - val_loss: 0.1131 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.6882\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0857 - auc: 0.9935 - accuracy: 0.9748 - cost: 3.2665 - val_loss: 0.1135 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.6393\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0842 - auc: 0.9936 - accuracy: 0.9754 - cost: 3.1608 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.7533\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9936 - accuracy: 0.9753 - cost: 3.1672 - val_loss: 0.1127 - val_auc: 0.9889 - val_accuracy: 0.9698 - val_cost: 3.7467\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9938 - accuracy: 0.9753 - cost: 3.1667 - val_loss: 0.1138 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.8281\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9753 - cost: 3.1881 - val_loss: 0.1134 - val_auc: 0.9890 - val_accuracy: 0.9696 - val_cost: 3.7370\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.1140 - val_loss: 0.1119 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.6230\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9752 - cost: 3.1731 - val_loss: 0.1137 - val_auc: 0.9889 - val_accuracy: 0.9710 - val_cost: 3.5677\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1156 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9696 - val_cost: 3.7272\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9936 - accuracy: 0.9759 - cost: 3.0920 - val_loss: 0.1159 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.5319\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9936 - accuracy: 0.9757 - cost: 3.1250 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6686\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0128 - val_loss: 0.1108 - val_auc: 0.9889 - val_accuracy: 0.9707 - val_cost: 3.6719\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1545 - val_loss: 0.1127 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6328\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9936 - accuracy: 0.9757 - cost: 3.1264 - val_loss: 0.1141 - val_auc: 0.9889 - val_accuracy: 0.9695 - val_cost: 3.8053\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0647 - val_loss: 0.1144 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.7012\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0549 - val_loss: 0.1130 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.8542\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0823 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0746 - val_loss: 0.1134 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6914\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0867 - val_loss: 0.1132 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.7370\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9768 - cost: 2.9736 - val_loss: 0.1154 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.6589\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9937 - accuracy: 0.9764 - cost: 3.0397 - val_loss: 0.1120 - val_auc: 0.9893 - val_accuracy: 0.9716 - val_cost: 3.4961\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9815 - val_loss: 0.1136 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.6263\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0118 - val_loss: 0.1147 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.7565\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9938 - accuracy: 0.9767 - cost: 3.0041 - val_loss: 0.1136 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.5775\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9937 - accuracy: 0.9762 - cost: 3.0664 - val_loss: 0.1157 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.5645\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9531 - val_loss: 0.1142 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.6296\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9614 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7012\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9879 - val_loss: 0.1132 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.7370\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9770 - cost: 2.9573 - val_loss: 0.1159 - val_auc: 0.9885 - val_accuracy: 0.9704 - val_cost: 3.6068\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9598 - val_loss: 0.1140 - val_auc: 0.9889 - val_accuracy: 0.9709 - val_cost: 3.4310\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9731 - val_loss: 0.1157 - val_auc: 0.9888 - val_accuracy: 0.9711 - val_cost: 3.5319\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9518 - val_loss: 0.1139 - val_auc: 0.9888 - val_accuracy: 0.9700 - val_cost: 4.0430\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0798 - auc: 0.9940 - accuracy: 0.9774 - cost: 2.9052 - val_loss: 0.1138 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.4798\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0198 - val_loss: 0.1146 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7923\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9939 - accuracy: 0.9771 - cost: 2.9472 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.5807\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9439 - val_loss: 0.1131 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.5449\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9902 - val_loss: 0.1165 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.8867\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0781 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8949 - val_loss: 0.1138 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.6686\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.8927 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.6947\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9943 - accuracy: 0.9770 - cost: 2.9516 - val_loss: 0.1122 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.5710\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9138 - val_loss: 0.1143 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.7533\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0787 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9232 - val_loss: 0.1158 - val_auc: 0.9888 - val_accuracy: 0.9716 - val_cost: 3.4733\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9354 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5840\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8677 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9702 - val_cost: 3.6589\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9173 - val_loss: 0.1136 - val_auc: 0.9891 - val_accuracy: 0.9718 - val_cost: 3.4831\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9132 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5905\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8865 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.6947\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9287 - val_loss: 0.1133 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.4180\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9096 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.6947\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8889 - val_loss: 0.1162 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.4961\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9942 - accuracy: 0.9780 - cost: 2.8331 - val_loss: 0.1170 - val_auc: 0.9891 - val_accuracy: 0.9696 - val_cost: 3.6491\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8918 - val_loss: 0.1156 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.6947\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.9128 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.7500\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9782 - cost: 2.8254 - val_loss: 0.1160 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.5905\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8531 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.7240\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9120 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.8021\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8777 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.5221\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.8965 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.5026\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8930 - val_loss: 0.1128 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.4766\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8786 - val_loss: 0.1170 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.5807\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8439 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5254\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8636 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.4342\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0768 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8469 - val_loss: 0.1158 - val_auc: 0.9889 - val_accuracy: 0.9713 - val_cost: 3.5938\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0774 - auc: 0.9943 - accuracy: 0.9783 - cost: 2.7830 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4733\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8447 - val_loss: 0.1146 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.5059\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9786 - cost: 2.7668 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.7207\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8293 - val_loss: 0.1179 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.6491\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9786 - cost: 2.7672 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9710 - val_cost: 3.4896\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7917 - val_loss: 0.1155 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.5807\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9785 - cost: 2.7854 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9704 - val_cost: 3.8184\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7994 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.4863\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8063 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5938\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7732 - val_loss: 0.1147 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.6003\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7593 - val_loss: 0.1152 - val_auc: 0.9891 - val_accuracy: 0.9718 - val_cost: 3.4733\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7380 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.4798\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8110 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.7598\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7810 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.4082\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8066 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.5352\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7960 - val_loss: 0.1155 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.5710\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7704 - val_loss: 0.1161 - val_auc: 0.9890 - val_accuracy: 0.9721 - val_cost: 3.4570\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8261 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.4538\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8034 - val_loss: 0.1153 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.4766\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7926 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4408\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.6936 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5612\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7653 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9718 - val_cost: 3.4473\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7903 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.4993\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8104 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9711 - val_cost: 3.3366\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7644 - val_loss: 0.1176 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.4570\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7385 - val_loss: 0.1156 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5286\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.6911 - val_loss: 0.1174 - val_auc: 0.9891 - val_accuracy: 0.9718 - val_cost: 3.4928\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7354 - val_loss: 0.1181 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.5189\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7298 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9725 - val_cost: 3.3919\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7680 - val_loss: 0.1145 - val_auc: 0.9889 - val_accuracy: 0.9716 - val_cost: 3.5482\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7354 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7137 - val_loss: 0.1197 - val_auc: 0.9889 - val_accuracy: 0.9714 - val_cost: 3.4635\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7057 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.6068\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7080 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9722 - val_cost: 3.6230\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6979 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.5612\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6762 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.6133\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7150 - val_loss: 0.1181 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.5189\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7533 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5840\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6926 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7131 - val_loss: 0.1165 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4180\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7427 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.5449\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6546 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6547 - val_loss: 0.1176 - val_auc: 0.9889 - val_accuracy: 0.9723 - val_cost: 3.3887\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6965 - val_loss: 0.1170 - val_auc: 0.9893 - val_accuracy: 0.9720 - val_cost: 3.6035\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9797 - cost: 2.6164 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9724 - val_cost: 3.3691\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6487 - val_loss: 0.1175 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.8249\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6351 - val_loss: 0.1176 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5775\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6593 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.4277\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7058 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.6100\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7082 - val_loss: 0.1165 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6547 - val_loss: 0.1151 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5612\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6872 - val_loss: 0.1177 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5124\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6397 - val_loss: 0.1173 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5189\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7352 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9726 - val_cost: 3.5352\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7084 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.3822\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6657 - val_loss: 0.1157 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.6133\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6291 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5449\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7133 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.5579\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5955 - val_loss: 0.1191 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.5286\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7188 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.7728\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6635 - val_loss: 0.1176 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.5905\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9797 - cost: 2.6170 - val_loss: 0.1176 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5059\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9946 - accuracy: 0.9793 - cost: 2.6665 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.5221\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6625 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.8151\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6295 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6654\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6638 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.5775\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6715 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.5091\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6682 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.4896\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9797 - cost: 2.6199 - val_loss: 0.1179 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5970\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6538 - val_loss: 0.1166 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.3887\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6873 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.7858\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6416 - val_loss: 0.1192 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5091\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6129 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4896\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6486 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.4115\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1009 - auc: 0.9911 - accuracy: 0.9732 - cost: 3.3281\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:12.507871\n",
            "fold accuracy: 0.9732499718666077 - fold cost: 3.328125\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5426 - auc: 0.7831 - accuracy: 0.7179 - cost: 37.3215 - val_loss: 0.4068 - val_auc: 0.8965 - val_accuracy: 0.8234 - val_cost: 22.4056\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3650 - auc: 0.9151 - accuracy: 0.8438 - cost: 19.8780 - val_loss: 0.3179 - val_auc: 0.9361 - val_accuracy: 0.8653 - val_cost: 16.3835\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3152 - auc: 0.9371 - accuracy: 0.8691 - cost: 16.5779 - val_loss: 0.2903 - val_auc: 0.9467 - val_accuracy: 0.8791 - val_cost: 14.8014\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2877 - auc: 0.9477 - accuracy: 0.8829 - cost: 14.8147 - val_loss: 0.2676 - val_auc: 0.9550 - val_accuracy: 0.8910 - val_cost: 13.8704\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2654 - auc: 0.9556 - accuracy: 0.8943 - cost: 13.3937 - val_loss: 0.2477 - val_auc: 0.9611 - val_accuracy: 0.9025 - val_cost: 12.2428\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2478 - auc: 0.9612 - accuracy: 0.9022 - cost: 12.3806 - val_loss: 0.2320 - val_auc: 0.9660 - val_accuracy: 0.9106 - val_cost: 10.8854\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2326 - auc: 0.9658 - accuracy: 0.9103 - cost: 11.3385 - val_loss: 0.2187 - val_auc: 0.9701 - val_accuracy: 0.9175 - val_cost: 10.1888\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2186 - auc: 0.9698 - accuracy: 0.9163 - cost: 10.5839 - val_loss: 0.2073 - val_auc: 0.9729 - val_accuracy: 0.9229 - val_cost: 9.5280\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2068 - auc: 0.9728 - accuracy: 0.9221 - cost: 9.8734 - val_loss: 0.1947 - val_auc: 0.9758 - val_accuracy: 0.9294 - val_cost: 8.7826\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1962 - auc: 0.9755 - accuracy: 0.9270 - cost: 9.2458 - val_loss: 0.1870 - val_auc: 0.9774 - val_accuracy: 0.9300 - val_cost: 8.8249\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1873 - auc: 0.9775 - accuracy: 0.9308 - cost: 8.7775 - val_loss: 0.1788 - val_auc: 0.9794 - val_accuracy: 0.9358 - val_cost: 8.4408\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1797 - auc: 0.9792 - accuracy: 0.9351 - cost: 8.2605 - val_loss: 0.1721 - val_auc: 0.9807 - val_accuracy: 0.9378 - val_cost: 7.7604\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1749 - auc: 0.9801 - accuracy: 0.9367 - cost: 8.0293 - val_loss: 0.1661 - val_auc: 0.9819 - val_accuracy: 0.9403 - val_cost: 7.9134\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1679 - auc: 0.9816 - accuracy: 0.9396 - cost: 7.6855 - val_loss: 0.1643 - val_auc: 0.9826 - val_accuracy: 0.9422 - val_cost: 7.0475\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1633 - auc: 0.9825 - accuracy: 0.9423 - cost: 7.3348 - val_loss: 0.1593 - val_auc: 0.9829 - val_accuracy: 0.9426 - val_cost: 7.4219\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1578 - auc: 0.9836 - accuracy: 0.9442 - cost: 7.0914 - val_loss: 0.1546 - val_auc: 0.9840 - val_accuracy: 0.9471 - val_cost: 6.8262\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1550 - auc: 0.9840 - accuracy: 0.9461 - cost: 6.8587 - val_loss: 0.1531 - val_auc: 0.9843 - val_accuracy: 0.9474 - val_cost: 6.5820\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1505 - auc: 0.9848 - accuracy: 0.9477 - cost: 6.6549 - val_loss: 0.1479 - val_auc: 0.9850 - val_accuracy: 0.9480 - val_cost: 6.6309\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1468 - auc: 0.9854 - accuracy: 0.9489 - cost: 6.5214 - val_loss: 0.1468 - val_auc: 0.9853 - val_accuracy: 0.9488 - val_cost: 6.3607\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1450 - auc: 0.9857 - accuracy: 0.9497 - cost: 6.4242 - val_loss: 0.1442 - val_auc: 0.9857 - val_accuracy: 0.9511 - val_cost: 5.9245\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1412 - auc: 0.9863 - accuracy: 0.9519 - cost: 6.1388 - val_loss: 0.1418 - val_auc: 0.9860 - val_accuracy: 0.9515 - val_cost: 6.0938\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1396 - auc: 0.9866 - accuracy: 0.9531 - cost: 5.9557 - val_loss: 0.1381 - val_auc: 0.9865 - val_accuracy: 0.9531 - val_cost: 6.1589\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1356 - auc: 0.9873 - accuracy: 0.9538 - cost: 5.8765 - val_loss: 0.1365 - val_auc: 0.9869 - val_accuracy: 0.9538 - val_cost: 6.2891\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1341 - auc: 0.9876 - accuracy: 0.9542 - cost: 5.8348 - val_loss: 0.1360 - val_auc: 0.9869 - val_accuracy: 0.9534 - val_cost: 6.1979\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1312 - auc: 0.9880 - accuracy: 0.9564 - cost: 5.5469 - val_loss: 0.1331 - val_auc: 0.9872 - val_accuracy: 0.9560 - val_cost: 5.8431\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1283 - auc: 0.9885 - accuracy: 0.9570 - cost: 5.4739 - val_loss: 0.1331 - val_auc: 0.9874 - val_accuracy: 0.9560 - val_cost: 5.6250\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1275 - auc: 0.9885 - accuracy: 0.9578 - cost: 5.3799 - val_loss: 0.1309 - val_auc: 0.9876 - val_accuracy: 0.9569 - val_cost: 5.9408\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1248 - auc: 0.9889 - accuracy: 0.9588 - cost: 5.2512 - val_loss: 0.1280 - val_auc: 0.9880 - val_accuracy: 0.9583 - val_cost: 5.5143\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1223 - auc: 0.9892 - accuracy: 0.9605 - cost: 5.0290 - val_loss: 0.1259 - val_auc: 0.9882 - val_accuracy: 0.9599 - val_cost: 5.2279\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1211 - auc: 0.9893 - accuracy: 0.9607 - cost: 5.0061 - val_loss: 0.1256 - val_auc: 0.9881 - val_accuracy: 0.9593 - val_cost: 5.3320\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1195 - auc: 0.9895 - accuracy: 0.9614 - cost: 4.9243 - val_loss: 0.1235 - val_auc: 0.9886 - val_accuracy: 0.9608 - val_cost: 5.2409\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1184 - auc: 0.9898 - accuracy: 0.9615 - cost: 4.9109 - val_loss: 0.1233 - val_auc: 0.9887 - val_accuracy: 0.9612 - val_cost: 5.0456\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1170 - auc: 0.9900 - accuracy: 0.9626 - cost: 4.7595 - val_loss: 0.1231 - val_auc: 0.9885 - val_accuracy: 0.9610 - val_cost: 5.2083\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1149 - auc: 0.9901 - accuracy: 0.9632 - cost: 4.7147 - val_loss: 0.1214 - val_auc: 0.9888 - val_accuracy: 0.9617 - val_cost: 4.9642\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1143 - auc: 0.9903 - accuracy: 0.9636 - cost: 4.6503 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9620 - val_cost: 4.8047\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1122 - auc: 0.9905 - accuracy: 0.9642 - cost: 4.5640 - val_loss: 0.1183 - val_auc: 0.9890 - val_accuracy: 0.9633 - val_cost: 4.8861\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1105 - auc: 0.9907 - accuracy: 0.9651 - cost: 4.4522 - val_loss: 0.1185 - val_auc: 0.9890 - val_accuracy: 0.9626 - val_cost: 4.9609\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1097 - auc: 0.9908 - accuracy: 0.9653 - cost: 4.4271 - val_loss: 0.1176 - val_auc: 0.9892 - val_accuracy: 0.9636 - val_cost: 4.9349\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1091 - auc: 0.9910 - accuracy: 0.9655 - cost: 4.4062 - val_loss: 0.1184 - val_auc: 0.9892 - val_accuracy: 0.9635 - val_cost: 4.7461\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1077 - auc: 0.9911 - accuracy: 0.9665 - cost: 4.2725 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9644 - val_cost: 4.7103\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1067 - auc: 0.9911 - accuracy: 0.9669 - cost: 4.2281 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9649 - val_cost: 4.5573\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1065 - auc: 0.9911 - accuracy: 0.9666 - cost: 4.2665 - val_loss: 0.1159 - val_auc: 0.9895 - val_accuracy: 0.9640 - val_cost: 4.8307\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1044 - auc: 0.9915 - accuracy: 0.9672 - cost: 4.1932 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9644 - val_cost: 4.7135\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1035 - auc: 0.9915 - accuracy: 0.9678 - cost: 4.1166 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9657 - val_cost: 4.3815\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1040 - auc: 0.9915 - accuracy: 0.9680 - cost: 4.0995 - val_loss: 0.1150 - val_auc: 0.9897 - val_accuracy: 0.9638 - val_cost: 4.3978\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1024 - auc: 0.9917 - accuracy: 0.9685 - cost: 4.0240 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9662 - val_cost: 4.3197\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1017 - auc: 0.9918 - accuracy: 0.9686 - cost: 4.0090 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9661 - val_cost: 4.2025\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1015 - auc: 0.9918 - accuracy: 0.9691 - cost: 3.9462 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9669 - val_cost: 4.3522\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1013 - auc: 0.9918 - accuracy: 0.9691 - cost: 3.9572 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9661 - val_cost: 4.5150\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9921 - accuracy: 0.9700 - cost: 3.8218 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9674 - val_cost: 4.3099\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0998 - auc: 0.9919 - accuracy: 0.9697 - cost: 3.8725 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9670 - val_cost: 4.5052\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0982 - auc: 0.9921 - accuracy: 0.9705 - cost: 3.7834 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9669 - val_cost: 4.3132\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0988 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8159 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9678 - val_cost: 4.1602\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0975 - auc: 0.9921 - accuracy: 0.9708 - cost: 3.7236 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9680 - val_cost: 4.2057\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0971 - auc: 0.9922 - accuracy: 0.9707 - cost: 3.7461 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9667 - val_cost: 4.2188\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0958 - auc: 0.9924 - accuracy: 0.9709 - cost: 3.7259 - val_loss: 0.1095 - val_auc: 0.9902 - val_accuracy: 0.9676 - val_cost: 4.2025\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0953 - auc: 0.9923 - accuracy: 0.9715 - cost: 3.6595 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9670 - val_cost: 4.3197\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0952 - auc: 0.9924 - accuracy: 0.9713 - cost: 3.6773 - val_loss: 0.1097 - val_auc: 0.9904 - val_accuracy: 0.9681 - val_cost: 4.1309\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0949 - auc: 0.9924 - accuracy: 0.9714 - cost: 3.6634 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9678 - val_cost: 4.2090\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0932 - auc: 0.9925 - accuracy: 0.9719 - cost: 3.6013 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9675 - val_cost: 4.2676\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0941 - auc: 0.9926 - accuracy: 0.9720 - cost: 3.5970 - val_loss: 0.1080 - val_auc: 0.9903 - val_accuracy: 0.9678 - val_cost: 4.1667\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0935 - auc: 0.9927 - accuracy: 0.9720 - cost: 3.5754 - val_loss: 0.1080 - val_auc: 0.9905 - val_accuracy: 0.9685 - val_cost: 4.0951\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9726 - cost: 3.5110 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9676 - val_cost: 4.2578\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9927 - accuracy: 0.9722 - cost: 3.5572 - val_loss: 0.1076 - val_auc: 0.9907 - val_accuracy: 0.9677 - val_cost: 4.2122\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9927 - accuracy: 0.9729 - cost: 3.4790 - val_loss: 0.1082 - val_auc: 0.9904 - val_accuracy: 0.9683 - val_cost: 4.1016\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9728 - cost: 3.4948 - val_loss: 0.1083 - val_auc: 0.9907 - val_accuracy: 0.9678 - val_cost: 4.2090\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0908 - auc: 0.9929 - accuracy: 0.9731 - cost: 3.4413 - val_loss: 0.1075 - val_auc: 0.9905 - val_accuracy: 0.9681 - val_cost: 4.1634\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9928 - accuracy: 0.9731 - cost: 3.4447 - val_loss: 0.1075 - val_auc: 0.9904 - val_accuracy: 0.9683 - val_cost: 4.1471\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9927 - accuracy: 0.9732 - cost: 3.4273 - val_loss: 0.1078 - val_auc: 0.9907 - val_accuracy: 0.9691 - val_cost: 3.9323\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3714 - val_loss: 0.1073 - val_auc: 0.9904 - val_accuracy: 0.9687 - val_cost: 4.1178\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9733 - cost: 3.4298 - val_loss: 0.1067 - val_auc: 0.9907 - val_accuracy: 0.9690 - val_cost: 3.9616\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9930 - accuracy: 0.9731 - cost: 3.4462 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9691 - val_cost: 4.0039\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9930 - accuracy: 0.9732 - cost: 3.4314 - val_loss: 0.1114 - val_auc: 0.9903 - val_accuracy: 0.9682 - val_cost: 4.0690\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3189 - val_loss: 0.1074 - val_auc: 0.9905 - val_accuracy: 0.9695 - val_cost: 3.8997\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0882 - auc: 0.9932 - accuracy: 0.9744 - cost: 3.2880 - val_loss: 0.1086 - val_auc: 0.9906 - val_accuracy: 0.9691 - val_cost: 4.1016\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0875 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3555 - val_loss: 0.1062 - val_auc: 0.9905 - val_accuracy: 0.9693 - val_cost: 3.9714\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0884 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3453 - val_loss: 0.1057 - val_auc: 0.9908 - val_accuracy: 0.9696 - val_cost: 3.8770\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9737 - cost: 3.3795 - val_loss: 0.1054 - val_auc: 0.9909 - val_accuracy: 0.9698 - val_cost: 3.8574\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9932 - accuracy: 0.9744 - cost: 3.2861 - val_loss: 0.1065 - val_auc: 0.9905 - val_accuracy: 0.9693 - val_cost: 4.0853\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9746 - cost: 3.2702 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.9486\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9743 - cost: 3.3043 - val_loss: 0.1061 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_cost: 3.9486\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0863 - auc: 0.9933 - accuracy: 0.9751 - cost: 3.2035 - val_loss: 0.1063 - val_auc: 0.9904 - val_accuracy: 0.9690 - val_cost: 4.0983\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9935 - accuracy: 0.9752 - cost: 3.1934 - val_loss: 0.1069 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.9909\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0862 - auc: 0.9933 - accuracy: 0.9749 - cost: 3.2181 - val_loss: 0.1062 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.8053\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0862 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2311 - val_loss: 0.1063 - val_auc: 0.9906 - val_accuracy: 0.9699 - val_cost: 3.8835\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0847 - auc: 0.9936 - accuracy: 0.9753 - cost: 3.1637 - val_loss: 0.1065 - val_auc: 0.9909 - val_accuracy: 0.9698 - val_cost: 3.8770\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0841 - auc: 0.9936 - accuracy: 0.9751 - cost: 3.2065 - val_loss: 0.1066 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.8216\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0847 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.2054 - val_loss: 0.1067 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.7760\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0844 - auc: 0.9934 - accuracy: 0.9750 - cost: 3.2063 - val_loss: 0.1062 - val_auc: 0.9905 - val_accuracy: 0.9702 - val_cost: 3.8574\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1464 - val_loss: 0.1062 - val_auc: 0.9907 - val_accuracy: 0.9698 - val_cost: 3.8997\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9934 - accuracy: 0.9756 - cost: 3.1511 - val_loss: 0.1076 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.9583\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1623 - val_loss: 0.1046 - val_auc: 0.9907 - val_accuracy: 0.9701 - val_cost: 3.9453\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1300 - val_loss: 0.1059 - val_auc: 0.9908 - val_accuracy: 0.9701 - val_cost: 3.8932\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1342 - val_loss: 0.1051 - val_auc: 0.9907 - val_accuracy: 0.9719 - val_cost: 3.7337\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9936 - accuracy: 0.9756 - cost: 3.1282 - val_loss: 0.1047 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.8411\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0832 - auc: 0.9936 - accuracy: 0.9756 - cost: 3.1271 - val_loss: 0.1061 - val_auc: 0.9909 - val_accuracy: 0.9712 - val_cost: 3.7467\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0831 - auc: 0.9936 - accuracy: 0.9763 - cost: 3.0459 - val_loss: 0.1060 - val_auc: 0.9908 - val_accuracy: 0.9707 - val_cost: 3.9616\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0985 - val_loss: 0.1056 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.7305\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1212 - val_loss: 0.1057 - val_auc: 0.9907 - val_accuracy: 0.9705 - val_cost: 3.8965\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0827 - auc: 0.9937 - accuracy: 0.9760 - cost: 3.0763 - val_loss: 0.1070 - val_auc: 0.9907 - val_accuracy: 0.9709 - val_cost: 3.6523\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0208 - val_loss: 0.1085 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.9811\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0272 - val_loss: 0.1066 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.8932\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0077 - val_loss: 0.1057 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.9876\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0502 - val_loss: 0.1048 - val_auc: 0.9910 - val_accuracy: 0.9704 - val_cost: 3.8965\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0657 - val_loss: 0.1050 - val_auc: 0.9908 - val_accuracy: 0.9708 - val_cost: 3.8802\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0112 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9698 - val_cost: 3.9811\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0358 - val_loss: 0.1076 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.8607\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0102 - val_loss: 0.1085 - val_auc: 0.9906 - val_accuracy: 0.9701 - val_cost: 3.9453\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9763 - cost: 3.0595 - val_loss: 0.1087 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 4.0723\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0647 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.7826\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9768 - cost: 2.9750 - val_loss: 0.1070 - val_auc: 0.9907 - val_accuracy: 0.9701 - val_cost: 3.8997\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9900 - val_loss: 0.1083 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.9062\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9953 - val_loss: 0.1084 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.8509\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9939 - accuracy: 0.9768 - cost: 3.0049 - val_loss: 0.1083 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.7891\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9940 - accuracy: 0.9773 - cost: 2.9209 - val_loss: 0.1076 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.8411\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9603 - val_loss: 0.1086 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.7728\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9465 - val_loss: 0.1072 - val_auc: 0.9906 - val_accuracy: 0.9709 - val_cost: 4.0430\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0411 - val_loss: 0.1051 - val_auc: 0.9909 - val_accuracy: 0.9712 - val_cost: 3.8542\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9537 - val_loss: 0.1095 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.8249\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9575 - val_loss: 0.1089 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.8997\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9525 - val_loss: 0.1104 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8509\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0802 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9721 - val_loss: 0.1101 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.9681\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9595 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.9421\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9189 - val_loss: 0.1056 - val_auc: 0.9907 - val_accuracy: 0.9718 - val_cost: 3.7207\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9619 - val_loss: 0.1074 - val_auc: 0.9907 - val_accuracy: 0.9707 - val_cost: 3.9681\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9248 - val_loss: 0.1097 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.6198\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9389 - val_loss: 0.1098 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.9518\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9277 - val_loss: 0.1091 - val_auc: 0.9905 - val_accuracy: 0.9714 - val_cost: 3.7923\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8569 - val_loss: 0.1082 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.8607\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9147 - val_loss: 0.1071 - val_auc: 0.9908 - val_accuracy: 0.9712 - val_cost: 3.7728\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9349 - val_loss: 0.1083 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.7598\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9199 - val_loss: 0.1075 - val_auc: 0.9909 - val_accuracy: 0.9712 - val_cost: 3.6816\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8784 - val_loss: 0.1082 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.8737\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.9072 - val_loss: 0.1095 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 4.0527\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9940 - accuracy: 0.9777 - cost: 2.8779 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.8900\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9298 - val_loss: 0.1081 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.8835\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8986 - val_loss: 0.1083 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8054 - val_loss: 0.1079 - val_auc: 0.9905 - val_accuracy: 0.9719 - val_cost: 3.7109\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8908 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.6719\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9781 - cost: 2.8193 - val_loss: 0.1091 - val_auc: 0.9905 - val_accuracy: 0.9711 - val_cost: 3.7793\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8948 - val_loss: 0.1088 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.6654\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9219 - val_loss: 0.1098 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.7598\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8559 - val_loss: 0.1097 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.8737\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8395 - val_loss: 0.1094 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.9355\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8826 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.7923\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.9056 - val_loss: 0.1121 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.5189\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.8979 - val_loss: 0.1111 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.8477\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9167 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6556\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8975 - val_loss: 0.1103 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.7826\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8331 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.7370\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8292 - val_loss: 0.1073 - val_auc: 0.9906 - val_accuracy: 0.9718 - val_cost: 3.7923\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8031 - val_loss: 0.1091 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.7305\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9943 - accuracy: 0.9782 - cost: 2.8143 - val_loss: 0.1109 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.7077\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7885 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.7207\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8159 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.7272\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8501 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6784\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8306 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.8346\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8331 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.5840\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8397 - val_loss: 0.1098 - val_auc: 0.9906 - val_accuracy: 0.9716 - val_cost: 3.7858\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7583 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.7598\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9785 - cost: 2.7878 - val_loss: 0.1132 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.8184\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8315 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.5840\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8438 - val_loss: 0.1094 - val_auc: 0.9903 - val_accuracy: 0.9723 - val_cost: 3.6361\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9788 - cost: 2.7337 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.8151\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8187 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9713 - val_cost: 3.7370\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7946 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.7760\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9786 - cost: 2.7655 - val_loss: 0.1114 - val_auc: 0.9902 - val_accuracy: 0.9716 - val_cost: 3.6589\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7631 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6003\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7504 - val_loss: 0.1138 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.4570\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7435 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.6296\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7529 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9716 - val_cost: 3.7760\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9788 - cost: 2.7392 - val_loss: 0.1103 - val_auc: 0.9907 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7391 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6654\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8021 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.8672\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7970 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6914\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7630 - val_loss: 0.1110 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.7598\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.8026 - val_loss: 0.1103 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.6686\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7676 - val_loss: 0.1103 - val_auc: 0.9905 - val_accuracy: 0.9722 - val_cost: 3.6328\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7892 - val_loss: 0.1117 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.6914\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7476 - val_loss: 0.1115 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.8314\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7688 - val_loss: 0.1107 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.7272\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8070 - val_loss: 0.1116 - val_auc: 0.9900 - val_accuracy: 0.9723 - val_cost: 3.7240\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7625 - val_loss: 0.1116 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.7402\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7151 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9726 - val_cost: 3.4440\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7106 - val_loss: 0.1129 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.6784\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7805 - val_loss: 0.1106 - val_auc: 0.9905 - val_accuracy: 0.9730 - val_cost: 3.5742\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7181 - val_loss: 0.1132 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.7370\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7085 - val_loss: 0.1118 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.7663\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7476 - val_loss: 0.1120 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.8118\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6875 - val_loss: 0.1150 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.8835\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7959 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9718 - val_cost: 3.6426\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7016 - val_loss: 0.1103 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.9128\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7688 - val_loss: 0.1100 - val_auc: 0.9905 - val_accuracy: 0.9721 - val_cost: 3.7142\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7089 - val_loss: 0.1130 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.9583\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7542 - val_loss: 0.1126 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.9681\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7292 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.4798\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7345 - val_loss: 0.1099 - val_auc: 0.9905 - val_accuracy: 0.9721 - val_cost: 3.6296\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8358 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.7207\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7601 - val_loss: 0.1137 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.7305\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6882 - val_loss: 0.1130 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.6100\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7465 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.9160\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7825 - val_loss: 0.1136 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.7988\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7324 - val_loss: 0.1130 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.6751\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6910 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7858\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7339 - val_loss: 0.1141 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.5156\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6933 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.9844\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7494 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.8607\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7261 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.9616\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7216 - val_loss: 0.1134 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.7695\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7052 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 4.0462\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7061 - val_loss: 0.1131 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.8281\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7686 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.6979\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6948 - val_loss: 0.1136 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7500\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7615 - val_loss: 0.1129 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 3.7109\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6549 - val_loss: 0.1122 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.6100\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7246 - val_loss: 0.1134 - val_auc: 0.9901 - val_accuracy: 0.9725 - val_cost: 3.4375\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.7174 - val_loss: 0.1137 - val_auc: 0.9902 - val_accuracy: 0.9723 - val_cost: 3.6198\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6494 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.8835\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7115 - val_loss: 0.1147 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.8151\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7354 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5710\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7094 - val_loss: 0.1141 - val_auc: 0.9902 - val_accuracy: 0.9721 - val_cost: 3.5156\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6898 - val_loss: 0.1139 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.6914\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6223 - val_loss: 0.1138 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.7923\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6985 - val_loss: 0.1141 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.7304 - val_loss: 0.1144 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.7077\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6515 - val_loss: 0.1147 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.6426\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6578 - val_loss: 0.1159 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6556\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5728 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9725 - val_cost: 3.6263\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7441 - val_loss: 0.1160 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.6361\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6621 - val_loss: 0.1133 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.7695\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7021 - val_loss: 0.1157 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.9941\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6881 - val_loss: 0.1140 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.9258\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.7005 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.9258\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6987 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6621\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6572 - val_loss: 0.1152 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8932\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7289 - val_loss: 0.1162 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.9453\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6846 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.8477\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6770 - val_loss: 0.1158 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.8639\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6902 - val_loss: 0.1160 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.9583\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6894 - val_loss: 0.1169 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 4.0072\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6269 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.8379\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6514 - val_loss: 0.1131 - val_auc: 0.9902 - val_accuracy: 0.9718 - val_cost: 3.6849\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7108 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.9323\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6665 - val_loss: 0.1178 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.7077\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6426 - val_loss: 0.1149 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.7012\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.6025 - val_loss: 0.1170 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.7826\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6841 - val_loss: 0.1168 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7207\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6442 - val_loss: 0.1186 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.7044\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6491 - val_loss: 0.1168 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.7012\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7393 - val_loss: 0.1153 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.4701\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6332 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.8053\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6964 - val_loss: 0.1144 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6393\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6046 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5742\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6826 - val_loss: 0.1178 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.7207\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6661 - val_loss: 0.1181 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6230\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6455 - val_loss: 0.1177 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.9648\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.6028 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.8900\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.7105 - val_loss: 0.1195 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6035\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5660 - val_loss: 0.1197 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.9811\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6515 - val_loss: 0.1168 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7826\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6140 - val_loss: 0.1180 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.5677\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6057 - val_loss: 0.1166 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.7305\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6643 - val_loss: 0.1174 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.8477\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6184 - val_loss: 0.1157 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.7500\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6422 - val_loss: 0.1158 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.7695\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6469 - val_loss: 0.1175 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.7630\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1109 - auc: 0.9904 - accuracy: 0.9709 - cost: 3.6656\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:34.631117\n",
            "fold accuracy: 0.9708750247955322 - fold cost: 3.6656250953674316\n",
            "total train/predict time: 0:23:47.793106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m4_results = fold_results"
      ],
      "metadata": {
        "id": "fszFGfDwmD7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m4 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "m4_cost = cost_func(y,preds_m4)\n",
        "m4_cost"
      ],
      "metadata": {
        "id": "WMZkaNGNeKT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11915598-3e5e-4a2b-f39e-9b39c084cfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "554900"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new4 = np.zeros(len(y))\n",
        "for i in m4_results.keys():\n",
        "  for j in range(len(m4_results.get(i).get('predictions'))):\n",
        "    idx = m4_results.get(i).get('index')[j]\n",
        "    if m4_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new4[idx] = 1\n",
        "    else:\n",
        "      preds_new4[idx] = 0\n",
        "m4_cost_t = cost_func(y,preds_new4)\n",
        "m4_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X7K7DWxmHit",
        "outputId": "33c52f02-206b-433d-9480-f3fa642d1615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "570050"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()\n"
      ],
      "metadata": {
        "id": "7jg2oQFvH2QS",
        "outputId": "625633cd-7fe8-467e-f2a7-b25f7aa599da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4480      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,705\n",
            "Trainable params: 8,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save('model4.keras')"
      ],
      "metadata": {
        "id": "ew-ZtZUpzr0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_cost', mode='min',patience=50,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model5 = tf.keras.Sequential()\n",
        "  model5.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model5.add(tf.keras.layers.Dropout(0.2))\n",
        "  model5.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model5.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model5.fit(X[train_index],y[train_index],epochs=1000,batch_size=1024,validation_split=0.1,callbacks=[es])\n",
        "  score = model5.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model5.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "id": "DVNOkJr3oYGb",
        "outputId": "8d70c46e-ecb0-42f5-ecab-d423ec4dbced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5265 - auc: 0.8009 - accuracy: 0.7294 - cost: 35.9773 - val_loss: 0.3919 - val_auc: 0.9022 - val_accuracy: 0.8288 - val_cost: 21.9434\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3471 - auc: 0.9236 - accuracy: 0.8525 - cost: 18.7994 - val_loss: 0.3144 - val_auc: 0.9371 - val_accuracy: 0.8675 - val_cost: 16.4290\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3006 - auc: 0.9428 - accuracy: 0.8754 - cost: 15.7681 - val_loss: 0.2883 - val_auc: 0.9483 - val_accuracy: 0.8801 - val_cost: 15.3385\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2716 - auc: 0.9533 - accuracy: 0.8896 - cost: 14.0008 - val_loss: 0.2614 - val_auc: 0.9572 - val_accuracy: 0.8956 - val_cost: 12.6400\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2488 - auc: 0.9609 - accuracy: 0.9010 - cost: 12.5384 - val_loss: 0.2406 - val_auc: 0.9634 - val_accuracy: 0.9064 - val_cost: 11.6211\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2296 - auc: 0.9666 - accuracy: 0.9102 - cost: 11.3726 - val_loss: 0.2253 - val_auc: 0.9687 - val_accuracy: 0.9117 - val_cost: 10.3613\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2133 - auc: 0.9712 - accuracy: 0.9176 - cost: 10.4416 - val_loss: 0.2072 - val_auc: 0.9727 - val_accuracy: 0.9228 - val_cost: 9.3490\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1996 - auc: 0.9746 - accuracy: 0.9240 - cost: 9.6256 - val_loss: 0.1953 - val_auc: 0.9755 - val_accuracy: 0.9285 - val_cost: 8.7533\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1880 - auc: 0.9773 - accuracy: 0.9296 - cost: 8.9326 - val_loss: 0.1863 - val_auc: 0.9776 - val_accuracy: 0.9322 - val_cost: 8.5612\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1793 - auc: 0.9792 - accuracy: 0.9336 - cost: 8.4066 - val_loss: 0.1797 - val_auc: 0.9790 - val_accuracy: 0.9348 - val_cost: 8.2454\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1708 - auc: 0.9810 - accuracy: 0.9366 - cost: 8.0285 - val_loss: 0.1720 - val_auc: 0.9806 - val_accuracy: 0.9389 - val_cost: 7.7734\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1640 - auc: 0.9824 - accuracy: 0.9406 - cost: 7.5507 - val_loss: 0.1663 - val_auc: 0.9817 - val_accuracy: 0.9424 - val_cost: 7.5326\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1585 - auc: 0.9834 - accuracy: 0.9427 - cost: 7.2557 - val_loss: 0.1619 - val_auc: 0.9826 - val_accuracy: 0.9427 - val_cost: 7.3568\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1528 - auc: 0.9845 - accuracy: 0.9450 - cost: 6.9718 - val_loss: 0.1590 - val_auc: 0.9832 - val_accuracy: 0.9452 - val_cost: 7.1745\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1494 - auc: 0.9851 - accuracy: 0.9465 - cost: 6.7697 - val_loss: 0.1537 - val_auc: 0.9842 - val_accuracy: 0.9473 - val_cost: 6.9336\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1442 - auc: 0.9860 - accuracy: 0.9492 - cost: 6.4565 - val_loss: 0.1517 - val_auc: 0.9844 - val_accuracy: 0.9481 - val_cost: 6.6569\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1413 - auc: 0.9865 - accuracy: 0.9502 - cost: 6.3074 - val_loss: 0.1493 - val_auc: 0.9848 - val_accuracy: 0.9482 - val_cost: 6.6667\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1377 - auc: 0.9870 - accuracy: 0.9525 - cost: 6.0340 - val_loss: 0.1457 - val_auc: 0.9853 - val_accuracy: 0.9507 - val_cost: 6.4128\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1343 - auc: 0.9876 - accuracy: 0.9536 - cost: 5.8673 - val_loss: 0.1439 - val_auc: 0.9857 - val_accuracy: 0.9503 - val_cost: 6.2142\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1314 - auc: 0.9880 - accuracy: 0.9553 - cost: 5.6627 - val_loss: 0.1407 - val_auc: 0.9859 - val_accuracy: 0.9532 - val_cost: 6.0677\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1284 - auc: 0.9884 - accuracy: 0.9556 - cost: 5.6364 - val_loss: 0.1398 - val_auc: 0.9864 - val_accuracy: 0.9543 - val_cost: 6.3086\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1260 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4017 - val_loss: 0.1366 - val_auc: 0.9866 - val_accuracy: 0.9550 - val_cost: 5.7682\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1239 - auc: 0.9890 - accuracy: 0.9581 - cost: 5.3138 - val_loss: 0.1337 - val_auc: 0.9871 - val_accuracy: 0.9560 - val_cost: 5.7357\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9592 - cost: 5.1828 - val_loss: 0.1331 - val_auc: 0.9871 - val_accuracy: 0.9569 - val_cost: 5.5729\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9898 - accuracy: 0.9605 - cost: 5.0111 - val_loss: 0.1312 - val_auc: 0.9875 - val_accuracy: 0.9579 - val_cost: 5.4915\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1163 - auc: 0.9902 - accuracy: 0.9609 - cost: 4.9621 - val_loss: 0.1288 - val_auc: 0.9877 - val_accuracy: 0.9586 - val_cost: 5.4688\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1146 - auc: 0.9903 - accuracy: 0.9621 - cost: 4.8125 - val_loss: 0.1285 - val_auc: 0.9877 - val_accuracy: 0.9592 - val_cost: 5.2995\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1129 - auc: 0.9905 - accuracy: 0.9628 - cost: 4.7334 - val_loss: 0.1264 - val_auc: 0.9881 - val_accuracy: 0.9609 - val_cost: 5.0879\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1108 - auc: 0.9907 - accuracy: 0.9631 - cost: 4.6834 - val_loss: 0.1255 - val_auc: 0.9881 - val_accuracy: 0.9615 - val_cost: 5.0260\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1101 - auc: 0.9908 - accuracy: 0.9642 - cost: 4.5352 - val_loss: 0.1236 - val_auc: 0.9882 - val_accuracy: 0.9619 - val_cost: 5.0098\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1077 - auc: 0.9910 - accuracy: 0.9648 - cost: 4.4798 - val_loss: 0.1224 - val_auc: 0.9883 - val_accuracy: 0.9624 - val_cost: 4.6191\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1058 - auc: 0.9914 - accuracy: 0.9662 - cost: 4.2873 - val_loss: 0.1211 - val_auc: 0.9885 - val_accuracy: 0.9631 - val_cost: 4.9512\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1049 - auc: 0.9915 - accuracy: 0.9659 - cost: 4.3371 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9640 - val_cost: 4.6810\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9917 - accuracy: 0.9670 - cost: 4.1902 - val_loss: 0.1199 - val_auc: 0.9887 - val_accuracy: 0.9638 - val_cost: 4.5410\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.1020 - auc: 0.9918 - accuracy: 0.9669 - cost: 4.2149 - val_loss: 0.1181 - val_auc: 0.9891 - val_accuracy: 0.9634 - val_cost: 4.6842\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9921 - accuracy: 0.9682 - cost: 4.0414 - val_loss: 0.1169 - val_auc: 0.9892 - val_accuracy: 0.9641 - val_cost: 4.5182\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9921 - accuracy: 0.9684 - cost: 4.0076 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9649 - val_cost: 4.4564\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0980 - auc: 0.9922 - accuracy: 0.9689 - cost: 3.9493 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9653 - val_cost: 4.4434\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0972 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9199 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9653 - val_cost: 4.5443\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0961 - auc: 0.9924 - accuracy: 0.9697 - cost: 3.8479 - val_loss: 0.1125 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.1862\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0944 - auc: 0.9925 - accuracy: 0.9702 - cost: 3.7851 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9662 - val_cost: 4.0202\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9926 - accuracy: 0.9709 - cost: 3.6883 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.1569\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9927 - accuracy: 0.9708 - cost: 3.7031 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.1895\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6818 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.1927\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9931 - accuracy: 0.9719 - cost: 3.5782 - val_loss: 0.1093 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.1113\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5397 - val_loss: 0.1086 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 4.0983\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9931 - accuracy: 0.9717 - cost: 3.5989 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 4.1016\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4560 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9583\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4586 - val_loss: 0.1069 - val_auc: 0.9898 - val_accuracy: 0.9678 - val_cost: 4.3294\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9738 - cost: 3.3216 - val_loss: 0.1065 - val_auc: 0.9901 - val_accuracy: 0.9677 - val_cost: 4.3522\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9933 - accuracy: 0.9737 - cost: 3.3450 - val_loss: 0.1082 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.9714\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0861 - auc: 0.9935 - accuracy: 0.9735 - cost: 3.3732 - val_loss: 0.1062 - val_auc: 0.9902 - val_accuracy: 0.9678 - val_cost: 4.1471\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9740 - cost: 3.3171 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9691 - val_cost: 3.9128\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2743 - val_loss: 0.1056 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.9453\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2690 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9694 - val_cost: 3.9062\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2166 - val_loss: 0.1052 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.9030\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2264 - val_loss: 0.1054 - val_auc: 0.9901 - val_accuracy: 0.9688 - val_cost: 3.9551\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9752 - cost: 3.1474 - val_loss: 0.1052 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.7923\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1824 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9699 - val_cost: 3.7923\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9939 - accuracy: 0.9752 - cost: 3.1413 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.6654\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9939 - accuracy: 0.9759 - cost: 3.0602 - val_loss: 0.1047 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7760\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0586 - val_loss: 0.1047 - val_auc: 0.9905 - val_accuracy: 0.9692 - val_cost: 3.9746\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0676 - val_loss: 0.1025 - val_auc: 0.9907 - val_accuracy: 0.9702 - val_cost: 3.8542\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0751 - val_loss: 0.1038 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.6393\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0590 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9709 - val_cost: 3.7891\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9388 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.5677\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9761 - cost: 3.0461 - val_loss: 0.1042 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.6849\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0327 - val_loss: 0.1037 - val_auc: 0.9908 - val_accuracy: 0.9701 - val_cost: 3.8574\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9765 - cost: 2.9852 - val_loss: 0.1040 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.5677\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9765 - cost: 3.0028 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9698 - val_cost: 3.8932\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8646 - val_loss: 0.1032 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.6784\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8302 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.9551\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8584 - val_loss: 0.1035 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.7012\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8513 - val_loss: 0.1030 - val_auc: 0.9905 - val_accuracy: 0.9714 - val_cost: 3.5189\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8685 - val_loss: 0.1035 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.5579\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8819 - val_loss: 0.1028 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6621\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8536 - val_loss: 0.1034 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.6491\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8528 - val_loss: 0.1032 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.4603\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7758 - val_loss: 0.1019 - val_auc: 0.9906 - val_accuracy: 0.9717 - val_cost: 3.4505\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7449 - val_loss: 0.1053 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.5286\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.7784 - val_loss: 0.1024 - val_auc: 0.9907 - val_accuracy: 0.9717 - val_cost: 3.5254\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7465 - val_loss: 0.1029 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7879 - val_loss: 0.1039 - val_auc: 0.9906 - val_accuracy: 0.9715 - val_cost: 3.4896\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7213 - val_loss: 0.1032 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.6654\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7474 - val_loss: 0.1031 - val_auc: 0.9905 - val_accuracy: 0.9719 - val_cost: 3.3040\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7245 - val_loss: 0.1023 - val_auc: 0.9907 - val_accuracy: 0.9717 - val_cost: 3.8607\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7945 - val_loss: 0.1023 - val_auc: 0.9906 - val_accuracy: 0.9722 - val_cost: 3.3626\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.6946 - val_loss: 0.1019 - val_auc: 0.9908 - val_accuracy: 0.9720 - val_cost: 3.4538\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6753 - val_loss: 0.1051 - val_auc: 0.9904 - val_accuracy: 0.9720 - val_cost: 3.5970\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.6884 - val_loss: 0.1030 - val_auc: 0.9904 - val_accuracy: 0.9724 - val_cost: 3.5905\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6982 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.6296\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6430 - val_loss: 0.1029 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.6458\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7242 - val_loss: 0.1026 - val_auc: 0.9905 - val_accuracy: 0.9720 - val_cost: 3.6100\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6858 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.9160\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6769 - val_loss: 0.1051 - val_auc: 0.9905 - val_accuracy: 0.9716 - val_cost: 3.6165\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7307 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9727 - val_cost: 3.4896\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6517 - val_loss: 0.1050 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.6328\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6414 - val_loss: 0.1054 - val_auc: 0.9904 - val_accuracy: 0.9724 - val_cost: 3.5189\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5774 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9726 - val_cost: 3.3073\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6365 - val_loss: 0.1042 - val_auc: 0.9906 - val_accuracy: 0.9722 - val_cost: 3.8346\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6727 - val_loss: 0.1031 - val_auc: 0.9906 - val_accuracy: 0.9724 - val_cost: 3.7012\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.5983 - val_loss: 0.1042 - val_auc: 0.9904 - val_accuracy: 0.9728 - val_cost: 3.4603\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6600 - val_loss: 0.1044 - val_auc: 0.9905 - val_accuracy: 0.9727 - val_cost: 3.5221\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5902 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6553 - val_loss: 0.1042 - val_auc: 0.9905 - val_accuracy: 0.9726 - val_cost: 3.5514\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5626 - val_loss: 0.1046 - val_auc: 0.9907 - val_accuracy: 0.9719 - val_cost: 3.5840\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5181 - val_loss: 0.1031 - val_auc: 0.9904 - val_accuracy: 0.9724 - val_cost: 3.7663\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5690 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9724 - val_cost: 3.5384\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5107 - val_loss: 0.1051 - val_auc: 0.9905 - val_accuracy: 0.9725 - val_cost: 3.5645\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5460 - val_loss: 0.1045 - val_auc: 0.9906 - val_accuracy: 0.9734 - val_cost: 3.4961\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5097 - val_loss: 0.1057 - val_auc: 0.9904 - val_accuracy: 0.9720 - val_cost: 3.6100\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5559 - val_loss: 0.1038 - val_auc: 0.9902 - val_accuracy: 0.9727 - val_cost: 3.5677\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5705 - val_loss: 0.1049 - val_auc: 0.9907 - val_accuracy: 0.9722 - val_cost: 3.5514\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5097 - val_loss: 0.1061 - val_auc: 0.9902 - val_accuracy: 0.9727 - val_cost: 3.3171\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6107 - val_loss: 0.1049 - val_auc: 0.9905 - val_accuracy: 0.9727 - val_cost: 3.4831\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5486 - val_loss: 0.1050 - val_auc: 0.9907 - val_accuracy: 0.9731 - val_cost: 3.4115\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4763 - val_loss: 0.1056 - val_auc: 0.9904 - val_accuracy: 0.9722 - val_cost: 3.2096\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4885 - val_loss: 0.1040 - val_auc: 0.9905 - val_accuracy: 0.9724 - val_cost: 3.5612\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4743 - val_loss: 0.1039 - val_auc: 0.9908 - val_accuracy: 0.9728 - val_cost: 3.6589\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4467 - val_loss: 0.1050 - val_auc: 0.9904 - val_accuracy: 0.9733 - val_cost: 3.4408\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4866 - val_loss: 0.1050 - val_auc: 0.9906 - val_accuracy: 0.9723 - val_cost: 3.5449\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4943 - val_loss: 0.1051 - val_auc: 0.9906 - val_accuracy: 0.9722 - val_cost: 3.5417\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5366 - val_loss: 0.1057 - val_auc: 0.9906 - val_accuracy: 0.9732 - val_cost: 3.3887\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4129 - val_loss: 0.1041 - val_auc: 0.9906 - val_accuracy: 0.9730 - val_cost: 3.5091\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5236 - val_loss: 0.1060 - val_auc: 0.9905 - val_accuracy: 0.9728 - val_cost: 3.4147\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4507 - val_loss: 0.1058 - val_auc: 0.9906 - val_accuracy: 0.9734 - val_cost: 3.4115\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4087 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9731 - val_cost: 3.3887\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4828 - val_loss: 0.1056 - val_auc: 0.9901 - val_accuracy: 0.9736 - val_cost: 3.4831\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4578 - val_loss: 0.1060 - val_auc: 0.9900 - val_accuracy: 0.9741 - val_cost: 3.4180\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4741 - val_loss: 0.1055 - val_auc: 0.9904 - val_accuracy: 0.9735 - val_cost: 3.4375\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4705 - val_loss: 0.1063 - val_auc: 0.9902 - val_accuracy: 0.9733 - val_cost: 3.4408\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4104 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9741 - val_cost: 3.3626\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4238 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9734 - val_cost: 3.4310\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3419 - val_loss: 0.1075 - val_auc: 0.9900 - val_accuracy: 0.9732 - val_cost: 3.4310\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4006 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9738 - val_cost: 3.3757\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4541 - val_loss: 0.1072 - val_auc: 0.9900 - val_accuracy: 0.9733 - val_cost: 3.4180\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4042 - val_loss: 0.1077 - val_auc: 0.9901 - val_accuracy: 0.9737 - val_cost: 3.3854\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4106 - val_loss: 0.1086 - val_auc: 0.9897 - val_accuracy: 0.9731 - val_cost: 3.4310\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4304 - val_loss: 0.1065 - val_auc: 0.9900 - val_accuracy: 0.9746 - val_cost: 3.1152\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3873 - val_loss: 0.1080 - val_auc: 0.9900 - val_accuracy: 0.9724 - val_cost: 3.5710\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3331 - val_loss: 0.1081 - val_auc: 0.9897 - val_accuracy: 0.9740 - val_cost: 3.3431\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4176 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9742 - val_cost: 3.3301\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4282 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.5872\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4005 - val_loss: 0.1086 - val_auc: 0.9900 - val_accuracy: 0.9726 - val_cost: 3.4570\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3511 - val_loss: 0.1092 - val_auc: 0.9901 - val_accuracy: 0.9729 - val_cost: 3.4668\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.3980 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9728 - val_cost: 3.4538\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3778 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.8086\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3892 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9737 - val_cost: 3.4733\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4062 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.4863\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3461 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9734 - val_cost: 3.4245\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3834 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9726 - val_cost: 3.4733\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3653 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9742 - val_cost: 3.2975\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3547 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9732 - val_cost: 3.3984\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3560 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9728 - val_cost: 3.4766\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3001 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9730 - val_cost: 3.4180\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3754 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9735 - val_cost: 3.5645\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3382 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9733 - val_cost: 3.5742\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3325 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9735 - val_cost: 3.5547\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3503 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9729 - val_cost: 3.7337\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3584 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9730 - val_cost: 3.8021\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2846 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9738 - val_cost: 3.5026\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3693 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.8249\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3381 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9735 - val_cost: 3.5417\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2816 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9735 - val_cost: 3.4049\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3184 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9737 - val_cost: 3.3398\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3210 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9733 - val_cost: 3.5612\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3349 - val_loss: 0.1106 - val_auc: 0.9894 - val_accuracy: 0.9737 - val_cost: 3.5840\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3204 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9730 - val_cost: 3.8216\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3592 - val_loss: 0.1112 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.7988\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2876 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9728 - val_cost: 3.4668\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2948 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9730 - val_cost: 3.6230\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3014 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9733 - val_cost: 3.4180\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3126 - val_loss: 0.1101 - val_auc: 0.9900 - val_accuracy: 0.9734 - val_cost: 3.4668\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2544 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9724 - val_cost: 3.7500\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2658 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.5221\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3422 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9725 - val_cost: 3.7240\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3133 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9732 - val_cost: 3.4831\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3389 - val_loss: 0.1106 - val_auc: 0.9898 - val_accuracy: 0.9728 - val_cost: 3.8574\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2871 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9727 - val_cost: 3.6849\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2671 - val_loss: 0.1137 - val_auc: 0.9892 - val_accuracy: 0.9718 - val_cost: 3.5807\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2524 - val_loss: 0.1139 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.7370\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2741 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9727 - val_cost: 3.4766\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2714 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.6361\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9961 - accuracy: 0.9826 - cost: 2.2328 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9726 - val_cost: 3.7174\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3254 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.8021\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2730 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.7370\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2692 - val_loss: 0.1137 - val_auc: 0.9892 - val_accuracy: 0.9729 - val_cost: 3.8639\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2804 - val_loss: 0.1132 - val_auc: 0.9890 - val_accuracy: 0.9718 - val_cost: 3.7793\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2540 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9732 - val_cost: 3.4017\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1061 - auc: 0.9908 - accuracy: 0.9705 - cost: 3.6906\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:45.883969\n",
            "fold accuracy: 0.9704999923706055 - fold cost: 3.690624952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 3s 6ms/step - loss: 0.5261 - auc: 0.8016 - accuracy: 0.7315 - cost: 35.7237 - val_loss: 0.3935 - val_auc: 0.9022 - val_accuracy: 0.8303 - val_cost: 22.6302\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3476 - auc: 0.9233 - accuracy: 0.8516 - cost: 18.9104 - val_loss: 0.3148 - val_auc: 0.9371 - val_accuracy: 0.8664 - val_cost: 16.5788\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2988 - auc: 0.9435 - accuracy: 0.8766 - cost: 15.6157 - val_loss: 0.2861 - val_auc: 0.9486 - val_accuracy: 0.8805 - val_cost: 15.2051\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2707 - auc: 0.9537 - accuracy: 0.8893 - cost: 14.0262 - val_loss: 0.2595 - val_auc: 0.9575 - val_accuracy: 0.8971 - val_cost: 12.7441\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2471 - auc: 0.9615 - accuracy: 0.9010 - cost: 12.5469 - val_loss: 0.2404 - val_auc: 0.9637 - val_accuracy: 0.9060 - val_cost: 11.5560\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2281 - auc: 0.9670 - accuracy: 0.9103 - cost: 11.3700 - val_loss: 0.2232 - val_auc: 0.9685 - val_accuracy: 0.9154 - val_cost: 10.8529\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2123 - auc: 0.9713 - accuracy: 0.9179 - cost: 10.3767 - val_loss: 0.2096 - val_auc: 0.9721 - val_accuracy: 0.9197 - val_cost: 10.2897\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1994 - auc: 0.9746 - accuracy: 0.9235 - cost: 9.6699 - val_loss: 0.1974 - val_auc: 0.9753 - val_accuracy: 0.9285 - val_cost: 9.3327\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1878 - auc: 0.9774 - accuracy: 0.9295 - cost: 8.9213 - val_loss: 0.1873 - val_auc: 0.9775 - val_accuracy: 0.9323 - val_cost: 8.7988\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1776 - auc: 0.9796 - accuracy: 0.9350 - cost: 8.2304 - val_loss: 0.1803 - val_auc: 0.9789 - val_accuracy: 0.9358 - val_cost: 8.3724\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1703 - auc: 0.9811 - accuracy: 0.9381 - cost: 7.8498 - val_loss: 0.1732 - val_auc: 0.9804 - val_accuracy: 0.9384 - val_cost: 8.1413\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1637 - auc: 0.9824 - accuracy: 0.9406 - cost: 7.5259 - val_loss: 0.1686 - val_auc: 0.9812 - val_accuracy: 0.9404 - val_cost: 7.9785\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1573 - auc: 0.9836 - accuracy: 0.9434 - cost: 7.1771 - val_loss: 0.1624 - val_auc: 0.9826 - val_accuracy: 0.9431 - val_cost: 7.2298\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1526 - auc: 0.9845 - accuracy: 0.9457 - cost: 6.8866 - val_loss: 0.1578 - val_auc: 0.9833 - val_accuracy: 0.9456 - val_cost: 7.1810\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1475 - auc: 0.9854 - accuracy: 0.9479 - cost: 6.6080 - val_loss: 0.1540 - val_auc: 0.9841 - val_accuracy: 0.9467 - val_cost: 6.9076\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1445 - auc: 0.9859 - accuracy: 0.9488 - cost: 6.4780 - val_loss: 0.1519 - val_auc: 0.9843 - val_accuracy: 0.9479 - val_cost: 6.8262\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1405 - auc: 0.9865 - accuracy: 0.9514 - cost: 6.1675 - val_loss: 0.1499 - val_auc: 0.9847 - val_accuracy: 0.9477 - val_cost: 6.9271\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1363 - auc: 0.9872 - accuracy: 0.9530 - cost: 5.9652 - val_loss: 0.1466 - val_auc: 0.9854 - val_accuracy: 0.9488 - val_cost: 6.4388\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1339 - auc: 0.9876 - accuracy: 0.9541 - cost: 5.8325 - val_loss: 0.1461 - val_auc: 0.9855 - val_accuracy: 0.9502 - val_cost: 6.6829\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1316 - auc: 0.9880 - accuracy: 0.9552 - cost: 5.6857 - val_loss: 0.1426 - val_auc: 0.9861 - val_accuracy: 0.9518 - val_cost: 6.0905\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1287 - auc: 0.9884 - accuracy: 0.9559 - cost: 5.5883 - val_loss: 0.1414 - val_auc: 0.9861 - val_accuracy: 0.9524 - val_cost: 6.2435\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1263 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4363 - val_loss: 0.1394 - val_auc: 0.9866 - val_accuracy: 0.9530 - val_cost: 6.0059\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1237 - auc: 0.9891 - accuracy: 0.9581 - cost: 5.3077 - val_loss: 0.1375 - val_auc: 0.9867 - val_accuracy: 0.9546 - val_cost: 5.9245\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1214 - auc: 0.9894 - accuracy: 0.9589 - cost: 5.2076 - val_loss: 0.1371 - val_auc: 0.9868 - val_accuracy: 0.9551 - val_cost: 5.4655\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1196 - auc: 0.9896 - accuracy: 0.9598 - cost: 5.1028 - val_loss: 0.1333 - val_auc: 0.9872 - val_accuracy: 0.9574 - val_cost: 5.5827\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1172 - auc: 0.9899 - accuracy: 0.9608 - cost: 4.9772 - val_loss: 0.1329 - val_auc: 0.9873 - val_accuracy: 0.9572 - val_cost: 5.5176\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1153 - auc: 0.9902 - accuracy: 0.9620 - cost: 4.8306 - val_loss: 0.1321 - val_auc: 0.9873 - val_accuracy: 0.9574 - val_cost: 5.1823\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1131 - auc: 0.9905 - accuracy: 0.9626 - cost: 4.7562 - val_loss: 0.1316 - val_auc: 0.9875 - val_accuracy: 0.9577 - val_cost: 5.3353\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1111 - auc: 0.9908 - accuracy: 0.9632 - cost: 4.6730 - val_loss: 0.1290 - val_auc: 0.9878 - val_accuracy: 0.9585 - val_cost: 5.5859\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1104 - auc: 0.9908 - accuracy: 0.9643 - cost: 4.5470 - val_loss: 0.1258 - val_auc: 0.9881 - val_accuracy: 0.9610 - val_cost: 4.9544\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1088 - auc: 0.9911 - accuracy: 0.9646 - cost: 4.5051 - val_loss: 0.1264 - val_auc: 0.9882 - val_accuracy: 0.9597 - val_cost: 5.2018\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9913 - accuracy: 0.9652 - cost: 4.4226 - val_loss: 0.1250 - val_auc: 0.9882 - val_accuracy: 0.9612 - val_cost: 4.8470\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1062 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3607 - val_loss: 0.1242 - val_auc: 0.9885 - val_accuracy: 0.9613 - val_cost: 5.0814\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9915 - accuracy: 0.9665 - cost: 4.2588 - val_loss: 0.1223 - val_auc: 0.9887 - val_accuracy: 0.9616 - val_cost: 4.9577\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1022 - auc: 0.9918 - accuracy: 0.9673 - cost: 4.1600 - val_loss: 0.1238 - val_auc: 0.9886 - val_accuracy: 0.9602 - val_cost: 4.7786\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9675 - cost: 4.1246 - val_loss: 0.1209 - val_auc: 0.9889 - val_accuracy: 0.9618 - val_cost: 5.0879\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1000 - auc: 0.9921 - accuracy: 0.9677 - cost: 4.1231 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9627 - val_cost: 4.8665\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9922 - accuracy: 0.9685 - cost: 4.0122 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9621 - val_cost: 4.6875\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9923 - accuracy: 0.9690 - cost: 3.9345 - val_loss: 0.1190 - val_auc: 0.9890 - val_accuracy: 0.9624 - val_cost: 4.8014\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9924 - accuracy: 0.9693 - cost: 3.9057 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9637 - val_cost: 4.8047\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0953 - auc: 0.9926 - accuracy: 0.9698 - cost: 3.8380 - val_loss: 0.1181 - val_auc: 0.9892 - val_accuracy: 0.9638 - val_cost: 4.4987\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0946 - auc: 0.9925 - accuracy: 0.9706 - cost: 3.7374 - val_loss: 0.1179 - val_auc: 0.9892 - val_accuracy: 0.9634 - val_cost: 4.6257\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0931 - auc: 0.9928 - accuracy: 0.9709 - cost: 3.6886 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9646 - val_cost: 4.5703\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0923 - auc: 0.9929 - accuracy: 0.9710 - cost: 3.6916 - val_loss: 0.1172 - val_auc: 0.9895 - val_accuracy: 0.9635 - val_cost: 4.3229\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6846 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9653 - val_cost: 4.3555\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0911 - auc: 0.9929 - accuracy: 0.9713 - cost: 3.6674 - val_loss: 0.1123 - val_auc: 0.9900 - val_accuracy: 0.9662 - val_cost: 4.3359\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9931 - accuracy: 0.9719 - cost: 3.5928 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9661 - val_cost: 4.1504\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5296 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 4.1960\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9727 - cost: 3.4960 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9644 - val_cost: 4.3066\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9727 - cost: 3.4813 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9667 - val_cost: 4.1178\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9933 - accuracy: 0.9731 - cost: 3.4322 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9662 - val_cost: 4.0755\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9735 - cost: 3.3726 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9667 - val_cost: 4.2546\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3640 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9674 - val_cost: 3.9323\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9936 - accuracy: 0.9745 - cost: 3.2488 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9678 - val_cost: 3.9811\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9739 - cost: 3.3278 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9669 - val_cost: 4.1536\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2883 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9676 - val_cost: 4.0592\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2249 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9680 - val_cost: 4.0625\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2416 - val_loss: 0.1079 - val_auc: 0.9903 - val_accuracy: 0.9678 - val_cost: 3.9876\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1502 - val_loss: 0.1103 - val_auc: 0.9902 - val_accuracy: 0.9672 - val_cost: 4.2741\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9938 - accuracy: 0.9754 - cost: 3.1449 - val_loss: 0.1109 - val_auc: 0.9903 - val_accuracy: 0.9680 - val_cost: 3.8118\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1440 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9675 - val_cost: 3.9616\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0802 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1479 - val_loss: 0.1069 - val_auc: 0.9907 - val_accuracy: 0.9678 - val_cost: 3.9876\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0795 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0588 - val_loss: 0.1082 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.7337\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0791 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1112 - val_loss: 0.1083 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.5970\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9764 - cost: 3.0115 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9686 - val_cost: 3.8867\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0490 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9684 - val_cost: 3.9160\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0091 - val_loss: 0.1089 - val_auc: 0.9903 - val_accuracy: 0.9676 - val_cost: 3.9290\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0265 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9701 - val_cost: 3.6296\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9031 - val_loss: 0.1060 - val_auc: 0.9907 - val_accuracy: 0.9693 - val_cost: 3.7988\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9636 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9690 - val_cost: 3.8314\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9984 - val_loss: 0.1066 - val_auc: 0.9904 - val_accuracy: 0.9690 - val_cost: 3.8314\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9409 - val_loss: 0.1063 - val_auc: 0.9905 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8944 - val_loss: 0.1055 - val_auc: 0.9907 - val_accuracy: 0.9690 - val_cost: 3.8542\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8629 - val_loss: 0.1073 - val_auc: 0.9905 - val_accuracy: 0.9696 - val_cost: 3.8086\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8697 - val_loss: 0.1062 - val_auc: 0.9907 - val_accuracy: 0.9691 - val_cost: 3.8184\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8383 - val_loss: 0.1081 - val_auc: 0.9905 - val_accuracy: 0.9686 - val_cost: 3.7565\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8835 - val_loss: 0.1069 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.9128\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8417 - val_loss: 0.1068 - val_auc: 0.9904 - val_accuracy: 0.9698 - val_cost: 3.6751\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8565 - val_loss: 0.1069 - val_auc: 0.9905 - val_accuracy: 0.9689 - val_cost: 3.7988\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8179 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.6686\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8539 - val_loss: 0.1041 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.7533\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8478 - val_loss: 0.1047 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.8249\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7650 - val_loss: 0.1048 - val_auc: 0.9906 - val_accuracy: 0.9686 - val_cost: 3.9811\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7703 - val_loss: 0.1067 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 3.7370\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7696 - val_loss: 0.1051 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.5514\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7812 - val_loss: 0.1058 - val_auc: 0.9907 - val_accuracy: 0.9696 - val_cost: 3.7728\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7589 - val_loss: 0.1048 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.6882\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7652 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9694 - val_cost: 3.6491\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7799 - val_loss: 0.1043 - val_auc: 0.9907 - val_accuracy: 0.9694 - val_cost: 3.7988\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6904 - val_loss: 0.1066 - val_auc: 0.9906 - val_accuracy: 0.9694 - val_cost: 3.7370\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6938 - val_loss: 0.1059 - val_auc: 0.9906 - val_accuracy: 0.9690 - val_cost: 3.7663\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7399 - val_loss: 0.1041 - val_auc: 0.9908 - val_accuracy: 0.9702 - val_cost: 3.6491\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6673 - val_loss: 0.1038 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.7012\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6888 - val_loss: 0.1069 - val_auc: 0.9904 - val_accuracy: 0.9688 - val_cost: 4.0072\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6224 - val_loss: 0.1055 - val_auc: 0.9907 - val_accuracy: 0.9698 - val_cost: 3.6914\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6271 - val_loss: 0.1055 - val_auc: 0.9905 - val_accuracy: 0.9692 - val_cost: 3.7988\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6610 - val_loss: 0.1058 - val_auc: 0.9908 - val_accuracy: 0.9692 - val_cost: 3.7891\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6390 - val_loss: 0.1055 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.5775\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6966 - val_loss: 0.1082 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.4375\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5479 - val_loss: 0.1058 - val_auc: 0.9907 - val_accuracy: 0.9706 - val_cost: 3.6784\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6139 - val_loss: 0.1062 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5579 - val_loss: 0.1063 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.9095\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5770 - val_loss: 0.1065 - val_auc: 0.9906 - val_accuracy: 0.9697 - val_cost: 3.7174\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5509 - val_loss: 0.1063 - val_auc: 0.9908 - val_accuracy: 0.9706 - val_cost: 3.6100\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5295 - val_loss: 0.1068 - val_auc: 0.9906 - val_accuracy: 0.9691 - val_cost: 3.8249\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5963 - val_loss: 0.1094 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.5677\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5730 - val_loss: 0.1079 - val_auc: 0.9906 - val_accuracy: 0.9704 - val_cost: 3.6947\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6036 - val_loss: 0.1075 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9952 - accuracy: 0.9805 - cost: 2.5057 - val_loss: 0.1051 - val_auc: 0.9909 - val_accuracy: 0.9705 - val_cost: 3.6491\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5287 - val_loss: 0.1069 - val_auc: 0.9906 - val_accuracy: 0.9703 - val_cost: 3.6686\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6030 - val_loss: 0.1075 - val_auc: 0.9904 - val_accuracy: 0.9696 - val_cost: 3.7012\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4852 - val_loss: 0.1074 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5514 - val_loss: 0.1084 - val_auc: 0.9904 - val_accuracy: 0.9701 - val_cost: 3.6361\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4851 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.6393\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4758 - val_loss: 0.1091 - val_auc: 0.9902 - val_accuracy: 0.9700 - val_cost: 3.7207\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4822 - val_loss: 0.1067 - val_auc: 0.9908 - val_accuracy: 0.9700 - val_cost: 3.7305\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4720 - val_loss: 0.1068 - val_auc: 0.9905 - val_accuracy: 0.9697 - val_cost: 3.8021\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5233 - val_loss: 0.1062 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.7435\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4924 - val_loss: 0.1069 - val_auc: 0.9905 - val_accuracy: 0.9716 - val_cost: 3.4993\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9955 - accuracy: 0.9813 - cost: 2.3854 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.6361\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4473 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.5612\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4470 - val_loss: 0.1084 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.4766\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4979 - val_loss: 0.1073 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.5579\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4481 - val_loss: 0.1077 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.6198\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4502 - val_loss: 0.1071 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.6882\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3969 - val_loss: 0.1074 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.6621\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4292 - val_loss: 0.1069 - val_auc: 0.9906 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3906 - val_loss: 0.1076 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.6296\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4302 - val_loss: 0.1080 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.4473\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4582 - val_loss: 0.1068 - val_auc: 0.9905 - val_accuracy: 0.9717 - val_cost: 3.5156\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4131 - val_loss: 0.1078 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.6556\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4064 - val_loss: 0.1096 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.7240\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4512 - val_loss: 0.1089 - val_auc: 0.9905 - val_accuracy: 0.9724 - val_cost: 3.4408\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3790 - val_loss: 0.1086 - val_auc: 0.9904 - val_accuracy: 0.9714 - val_cost: 3.5417\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3949 - val_loss: 0.1099 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.4342\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3708 - val_loss: 0.1109 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.3138\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4216 - val_loss: 0.1081 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.4375\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3719 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.5514\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4096 - val_loss: 0.1062 - val_auc: 0.9907 - val_accuracy: 0.9715 - val_cost: 3.5319\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4212 - val_loss: 0.1094 - val_auc: 0.9905 - val_accuracy: 0.9710 - val_cost: 3.3919\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3298 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6230\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3417 - val_loss: 0.1094 - val_auc: 0.9904 - val_accuracy: 0.9713 - val_cost: 3.6393\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3733 - val_loss: 0.1078 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.3398\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3187 - val_loss: 0.1077 - val_auc: 0.9906 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3787 - val_loss: 0.1080 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.6230\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2960 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.4408\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3533 - val_loss: 0.1093 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.5482\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3593 - val_loss: 0.1092 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3440 - val_loss: 0.1083 - val_auc: 0.9902 - val_accuracy: 0.9726 - val_cost: 3.4180\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3270 - val_loss: 0.1082 - val_auc: 0.9905 - val_accuracy: 0.9721 - val_cost: 3.4798\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3473 - val_loss: 0.1077 - val_auc: 0.9905 - val_accuracy: 0.9719 - val_cost: 3.4831\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3267 - val_loss: 0.1110 - val_auc: 0.9904 - val_accuracy: 0.9709 - val_cost: 3.5970\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3499 - val_loss: 0.1096 - val_auc: 0.9905 - val_accuracy: 0.9719 - val_cost: 3.4928\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0620 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.5905\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3415 - val_loss: 0.1112 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.6751\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.2918 - val_loss: 0.1124 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.2975\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2716 - val_loss: 0.1107 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.5352\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0611 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3068 - val_loss: 0.1107 - val_auc: 0.9905 - val_accuracy: 0.9713 - val_cost: 3.4570\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3423 - val_loss: 0.1077 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.4928\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3264 - val_loss: 0.1089 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.5905\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3625 - val_loss: 0.1102 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.3757\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3025 - val_loss: 0.1092 - val_auc: 0.9904 - val_accuracy: 0.9722 - val_cost: 3.4245\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2849 - val_loss: 0.1113 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2868 - val_loss: 0.1085 - val_auc: 0.9903 - val_accuracy: 0.9721 - val_cost: 3.4961\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3251 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5449\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3203 - val_loss: 0.1097 - val_auc: 0.9904 - val_accuracy: 0.9721 - val_cost: 3.4473\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3161 - val_loss: 0.1107 - val_auc: 0.9903 - val_accuracy: 0.9720 - val_cost: 3.4538\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2687 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2948 - val_loss: 0.1101 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.5579\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2835 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.4017\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9958 - accuracy: 0.9826 - cost: 2.2366 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.5482\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3529 - val_loss: 0.1103 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.4375\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2474 - val_loss: 0.1150 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.4993\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2920 - val_loss: 0.1104 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.5905\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2531 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.3626\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2712 - val_loss: 0.1123 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.5449\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2584 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4049\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3087 - val_loss: 0.1106 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.6035\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2212 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5677\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2530 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.5840\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2477 - val_loss: 0.1117 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.4961\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9960 - accuracy: 0.9827 - cost: 2.2043 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5775\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.1992 - val_loss: 0.1129 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.5286\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2498 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.5449\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2081 - val_loss: 0.1119 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.4798\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2247 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9726 - val_cost: 3.4049\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2503 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9718 - val_cost: 3.4147\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2465 - val_loss: 0.1134 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.7012\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2119 - val_loss: 0.1114 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4863\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2219 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.4342\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2293 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6328\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2322 - val_loss: 0.1134 - val_auc: 0.9900 - val_accuracy: 0.9702 - val_cost: 3.6523\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.2083 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4863\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2118 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.5905\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1999 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9723 - val_cost: 3.4147\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2188 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.5807\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1497 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5026\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2236 - val_loss: 0.1129 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.4245\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2331 - val_loss: 0.1140 - val_auc: 0.9901 - val_accuracy: 0.9732 - val_cost: 3.2812\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1590 - val_loss: 0.1124 - val_auc: 0.9900 - val_accuracy: 0.9733 - val_cost: 3.3529\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2341 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9728 - val_cost: 3.4505\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9835 - cost: 2.1314 - val_loss: 0.1126 - val_auc: 0.9900 - val_accuracy: 0.9730 - val_cost: 3.3366\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.1948 - val_loss: 0.1105 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.2845\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1766 - val_loss: 0.1155 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.4863\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1779 - val_loss: 0.1144 - val_auc: 0.9902 - val_accuracy: 0.9724 - val_cost: 3.3952\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1746 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1632 - val_loss: 0.1122 - val_auc: 0.9903 - val_accuracy: 0.9731 - val_cost: 3.3594\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2197 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.4408\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1555 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9731 - val_cost: 3.3822\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2200 - val_loss: 0.1160 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.2812\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9961 - accuracy: 0.9830 - cost: 2.1839 - val_loss: 0.1158 - val_auc: 0.9895 - val_accuracy: 0.9724 - val_cost: 3.4245\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1943 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.4863\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1530 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9718 - val_cost: 3.5677\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1651 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4570\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9963 - accuracy: 0.9835 - cost: 2.1197 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4570\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1937 - val_loss: 0.1181 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.5059\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1512 - val_loss: 0.1145 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.4115\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1685 - val_loss: 0.1172 - val_auc: 0.9895 - val_accuracy: 0.9718 - val_cost: 3.2617\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2175 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.4668\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1369 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.3008\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1575 - val_loss: 0.1130 - val_auc: 0.9903 - val_accuracy: 0.9721 - val_cost: 3.5254\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2444 - val_loss: 0.1151 - val_auc: 0.9895 - val_accuracy: 0.9733 - val_cost: 3.3366\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1194 - val_loss: 0.1173 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6361\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1529 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.5449\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1839 - val_loss: 0.1162 - val_auc: 0.9897 - val_accuracy: 0.9728 - val_cost: 3.3268\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1906 - val_loss: 0.1164 - val_auc: 0.9895 - val_accuracy: 0.9725 - val_cost: 3.1934\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1262 - val_loss: 0.1137 - val_auc: 0.9900 - val_accuracy: 0.9725 - val_cost: 3.3952\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1185 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9728 - val_cost: 3.3822\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1701 - val_loss: 0.1130 - val_auc: 0.9902 - val_accuracy: 0.9725 - val_cost: 3.4961\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1570 - val_loss: 0.1147 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.4505\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9834 - cost: 2.1398 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9721 - val_cost: 3.4766\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1346 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.4342\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1198 - val_loss: 0.1138 - val_auc: 0.9896 - val_accuracy: 0.9726 - val_cost: 3.4310\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1505 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.4635\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1275 - val_loss: 0.1151 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.6003\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1219 - val_loss: 0.1153 - val_auc: 0.9897 - val_accuracy: 0.9727 - val_cost: 3.3529\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1220 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.4701\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1204 - val_loss: 0.1172 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6003\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1663 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.5091\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1364 - val_loss: 0.1152 - val_auc: 0.9899 - val_accuracy: 0.9727 - val_cost: 3.3854\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.1189 - val_loss: 0.1152 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.4180\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1282 - val_loss: 0.1153 - val_auc: 0.9898 - val_accuracy: 0.9734 - val_cost: 3.2845\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1348 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0973 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9728 - val_cost: 3.4538\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0517 - val_loss: 0.1161 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.4993\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1827 - val_loss: 0.1141 - val_auc: 0.9905 - val_accuracy: 0.9722 - val_cost: 3.4896\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1331 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.5840\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1365 - val_loss: 0.1179 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.4440\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1809 - val_loss: 0.1156 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4766\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1243 - val_loss: 0.1158 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.4635\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0556 - auc: 0.9965 - accuracy: 0.9838 - cost: 2.0835 - val_loss: 0.1153 - val_auc: 0.9900 - val_accuracy: 0.9733 - val_cost: 3.3301\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0556 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1163 - val_loss: 0.1193 - val_auc: 0.9897 - val_accuracy: 0.9723 - val_cost: 3.4049\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0810 - val_loss: 0.1174 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.4798\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9839 - cost: 2.0646 - val_loss: 0.1155 - val_auc: 0.9902 - val_accuracy: 0.9724 - val_cost: 3.4310\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1661 - val_loss: 0.1157 - val_auc: 0.9896 - val_accuracy: 0.9728 - val_cost: 3.4570\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1165 - val_loss: 0.1199 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.4180\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9965 - accuracy: 0.9838 - cost: 2.0861 - val_loss: 0.1167 - val_auc: 0.9899 - val_accuracy: 0.9725 - val_cost: 3.4180\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9840 - cost: 2.0603 - val_loss: 0.1182 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.5124\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1255 - val_loss: 0.1177 - val_auc: 0.9900 - val_accuracy: 0.9724 - val_cost: 3.4310\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.1094 - val_loss: 0.1180 - val_auc: 0.9896 - val_accuracy: 0.9728 - val_cost: 3.4115\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0947 - val_loss: 0.1170 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.6035\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0915 - val_loss: 0.1201 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.3561\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0890 - val_loss: 0.1183 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.3008\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0982 - val_loss: 0.1187 - val_auc: 0.9894 - val_accuracy: 0.9728 - val_cost: 3.3822\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0882 - val_loss: 0.1158 - val_auc: 0.9901 - val_accuracy: 0.9731 - val_cost: 3.3594\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1182 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4049\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1255 - val_loss: 0.1156 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.4993\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1150 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.5026\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0633 - val_loss: 0.1174 - val_auc: 0.9901 - val_accuracy: 0.9733 - val_cost: 3.3138\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9964 - accuracy: 0.9840 - cost: 2.0557 - val_loss: 0.1187 - val_auc: 0.9891 - val_accuracy: 0.9725 - val_cost: 3.4342\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0391 - val_loss: 0.1192 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.5482\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0738 - val_loss: 0.1183 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.5742\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9964 - accuracy: 0.9837 - cost: 2.0941 - val_loss: 0.1172 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.4082\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0542 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0741 - val_loss: 0.1179 - val_auc: 0.9894 - val_accuracy: 0.9726 - val_cost: 3.4603\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0521 - val_loss: 0.1181 - val_auc: 0.9901 - val_accuracy: 0.9727 - val_cost: 3.4342\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9842 - cost: 2.0364 - val_loss: 0.1185 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4766\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1131 - auc: 0.9899 - accuracy: 0.9711 - cost: 3.5812\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:36.601182\n",
            "fold accuracy: 0.9710624814033508 - fold cost: 3.581249952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5258 - auc: 0.8020 - accuracy: 0.7321 - cost: 35.6462 - val_loss: 0.3906 - val_auc: 0.9027 - val_accuracy: 0.8305 - val_cost: 21.4876\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3465 - auc: 0.9237 - accuracy: 0.8528 - cost: 18.7410 - val_loss: 0.3156 - val_auc: 0.9365 - val_accuracy: 0.8672 - val_cost: 16.1882\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2996 - auc: 0.9431 - accuracy: 0.8756 - cost: 15.7371 - val_loss: 0.2858 - val_auc: 0.9482 - val_accuracy: 0.8830 - val_cost: 14.3262\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2713 - auc: 0.9534 - accuracy: 0.8902 - cost: 13.8963 - val_loss: 0.2642 - val_auc: 0.9567 - val_accuracy: 0.8944 - val_cost: 13.6914\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2487 - auc: 0.9609 - accuracy: 0.9010 - cost: 12.5549 - val_loss: 0.2400 - val_auc: 0.9637 - val_accuracy: 0.9085 - val_cost: 11.3184\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2283 - auc: 0.9670 - accuracy: 0.9100 - cost: 11.4013 - val_loss: 0.2229 - val_auc: 0.9685 - val_accuracy: 0.9160 - val_cost: 10.3678\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2116 - auc: 0.9716 - accuracy: 0.9182 - cost: 10.3689 - val_loss: 0.2111 - val_auc: 0.9717 - val_accuracy: 0.9199 - val_cost: 9.7656\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1991 - auc: 0.9746 - accuracy: 0.9241 - cost: 9.5972 - val_loss: 0.1989 - val_auc: 0.9748 - val_accuracy: 0.9267 - val_cost: 9.1439\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1882 - auc: 0.9772 - accuracy: 0.9292 - cost: 8.9770 - val_loss: 0.1901 - val_auc: 0.9767 - val_accuracy: 0.9306 - val_cost: 8.7435\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1802 - auc: 0.9790 - accuracy: 0.9330 - cost: 8.4943 - val_loss: 0.1844 - val_auc: 0.9781 - val_accuracy: 0.9333 - val_cost: 8.6230\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1715 - auc: 0.9809 - accuracy: 0.9371 - cost: 7.9891 - val_loss: 0.1770 - val_auc: 0.9795 - val_accuracy: 0.9360 - val_cost: 8.3431\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1660 - auc: 0.9819 - accuracy: 0.9392 - cost: 7.7193 - val_loss: 0.1733 - val_auc: 0.9807 - val_accuracy: 0.9376 - val_cost: 7.9818\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1609 - auc: 0.9830 - accuracy: 0.9417 - cost: 7.4128 - val_loss: 0.1685 - val_auc: 0.9813 - val_accuracy: 0.9399 - val_cost: 7.7181\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1560 - auc: 0.9839 - accuracy: 0.9438 - cost: 7.1293 - val_loss: 0.1647 - val_auc: 0.9823 - val_accuracy: 0.9408 - val_cost: 7.4447\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1515 - auc: 0.9846 - accuracy: 0.9457 - cost: 6.8799 - val_loss: 0.1610 - val_auc: 0.9829 - val_accuracy: 0.9428 - val_cost: 7.2005\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1475 - auc: 0.9853 - accuracy: 0.9479 - cost: 6.5998 - val_loss: 0.1585 - val_auc: 0.9834 - val_accuracy: 0.9423 - val_cost: 7.7930\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1438 - auc: 0.9859 - accuracy: 0.9494 - cost: 6.4252 - val_loss: 0.1554 - val_auc: 0.9839 - val_accuracy: 0.9441 - val_cost: 7.0508\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1414 - auc: 0.9864 - accuracy: 0.9507 - cost: 6.2508 - val_loss: 0.1522 - val_auc: 0.9844 - val_accuracy: 0.9458 - val_cost: 7.0280\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1382 - auc: 0.9869 - accuracy: 0.9517 - cost: 6.1288 - val_loss: 0.1509 - val_auc: 0.9848 - val_accuracy: 0.9461 - val_cost: 6.8424\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1367 - auc: 0.9870 - accuracy: 0.9528 - cost: 5.9839 - val_loss: 0.1480 - val_auc: 0.9852 - val_accuracy: 0.9476 - val_cost: 6.7122\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1333 - auc: 0.9877 - accuracy: 0.9534 - cost: 5.9194 - val_loss: 0.1476 - val_auc: 0.9853 - val_accuracy: 0.9487 - val_cost: 6.6829\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1317 - auc: 0.9878 - accuracy: 0.9547 - cost: 5.7568 - val_loss: 0.1447 - val_auc: 0.9857 - val_accuracy: 0.9503 - val_cost: 6.2956\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1295 - auc: 0.9882 - accuracy: 0.9562 - cost: 5.5613 - val_loss: 0.1420 - val_auc: 0.9860 - val_accuracy: 0.9523 - val_cost: 5.9831\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1269 - auc: 0.9886 - accuracy: 0.9572 - cost: 5.4282 - val_loss: 0.1419 - val_auc: 0.9860 - val_accuracy: 0.9517 - val_cost: 6.2402\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1251 - auc: 0.9888 - accuracy: 0.9575 - cost: 5.4079 - val_loss: 0.1400 - val_auc: 0.9862 - val_accuracy: 0.9526 - val_cost: 6.2077\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1231 - auc: 0.9891 - accuracy: 0.9586 - cost: 5.2559 - val_loss: 0.1383 - val_auc: 0.9866 - val_accuracy: 0.9538 - val_cost: 5.9668\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1210 - auc: 0.9894 - accuracy: 0.9593 - cost: 5.1770 - val_loss: 0.1389 - val_auc: 0.9866 - val_accuracy: 0.9536 - val_cost: 6.0807\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1203 - auc: 0.9895 - accuracy: 0.9595 - cost: 5.1265 - val_loss: 0.1352 - val_auc: 0.9868 - val_accuracy: 0.9553 - val_cost: 5.8822\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9608 - cost: 4.9932 - val_loss: 0.1352 - val_auc: 0.9869 - val_accuracy: 0.9547 - val_cost: 5.9993\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1163 - auc: 0.9900 - accuracy: 0.9611 - cost: 4.9530 - val_loss: 0.1339 - val_auc: 0.9871 - val_accuracy: 0.9545 - val_cost: 5.9473\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1136 - auc: 0.9903 - accuracy: 0.9627 - cost: 4.7330 - val_loss: 0.1308 - val_auc: 0.9876 - val_accuracy: 0.9572 - val_cost: 5.5729\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1122 - auc: 0.9905 - accuracy: 0.9633 - cost: 4.6578 - val_loss: 0.1304 - val_auc: 0.9875 - val_accuracy: 0.9562 - val_cost: 5.7292\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1114 - auc: 0.9906 - accuracy: 0.9634 - cost: 4.6468 - val_loss: 0.1287 - val_auc: 0.9876 - val_accuracy: 0.9587 - val_cost: 5.5143\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1098 - auc: 0.9908 - accuracy: 0.9642 - cost: 4.5642 - val_loss: 0.1286 - val_auc: 0.9879 - val_accuracy: 0.9569 - val_cost: 5.6250\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1083 - auc: 0.9911 - accuracy: 0.9645 - cost: 4.5344 - val_loss: 0.1262 - val_auc: 0.9877 - val_accuracy: 0.9592 - val_cost: 5.4427\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3616 - val_loss: 0.1254 - val_auc: 0.9882 - val_accuracy: 0.9598 - val_cost: 5.2507\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1051 - auc: 0.9913 - accuracy: 0.9663 - cost: 4.2760 - val_loss: 0.1261 - val_auc: 0.9881 - val_accuracy: 0.9603 - val_cost: 5.0879\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1052 - auc: 0.9913 - accuracy: 0.9663 - cost: 4.2919 - val_loss: 0.1233 - val_auc: 0.9883 - val_accuracy: 0.9603 - val_cost: 5.2148\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1038 - auc: 0.9915 - accuracy: 0.9667 - cost: 4.2448 - val_loss: 0.1223 - val_auc: 0.9883 - val_accuracy: 0.9606 - val_cost: 5.1497\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9919 - accuracy: 0.9674 - cost: 4.1648 - val_loss: 0.1219 - val_auc: 0.9884 - val_accuracy: 0.9614 - val_cost: 5.0553\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9917 - accuracy: 0.9680 - cost: 4.0827 - val_loss: 0.1217 - val_auc: 0.9886 - val_accuracy: 0.9622 - val_cost: 4.9284\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1000 - auc: 0.9920 - accuracy: 0.9686 - cost: 4.0092 - val_loss: 0.1203 - val_auc: 0.9886 - val_accuracy: 0.9624 - val_cost: 4.5573\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9920 - accuracy: 0.9688 - cost: 3.9746 - val_loss: 0.1196 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 4.6484\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9922 - accuracy: 0.9695 - cost: 3.8659 - val_loss: 0.1188 - val_auc: 0.9888 - val_accuracy: 0.9629 - val_cost: 4.8079\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9924 - accuracy: 0.9698 - cost: 3.8452 - val_loss: 0.1182 - val_auc: 0.9887 - val_accuracy: 0.9637 - val_cost: 4.3685\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9924 - accuracy: 0.9700 - cost: 3.8148 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9626 - val_cost: 4.5020\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0946 - auc: 0.9925 - accuracy: 0.9703 - cost: 3.7802 - val_loss: 0.1158 - val_auc: 0.9890 - val_accuracy: 0.9649 - val_cost: 4.5020\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9926 - accuracy: 0.9708 - cost: 3.7052 - val_loss: 0.1158 - val_auc: 0.9889 - val_accuracy: 0.9638 - val_cost: 4.5182\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9712 - cost: 3.6673 - val_loss: 0.1153 - val_auc: 0.9891 - val_accuracy: 0.9643 - val_cost: 4.5996\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9928 - accuracy: 0.9717 - cost: 3.6110 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9657 - val_cost: 4.3359\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9929 - accuracy: 0.9719 - cost: 3.5851 - val_loss: 0.1127 - val_auc: 0.9893 - val_accuracy: 0.9653 - val_cost: 4.4076\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0905 - auc: 0.9931 - accuracy: 0.9724 - cost: 3.5284 - val_loss: 0.1154 - val_auc: 0.9892 - val_accuracy: 0.9648 - val_cost: 4.2969\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9931 - accuracy: 0.9727 - cost: 3.4738 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9650 - val_cost: 4.4792\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9931 - accuracy: 0.9725 - cost: 3.5215 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9658 - val_cost: 4.0951\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9723 - cost: 3.5277 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9660 - val_cost: 4.3197\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0877 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4494 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9657 - val_cost: 4.2122\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4364 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9670 - val_cost: 3.9909\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9734 - cost: 3.3908 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9673 - val_cost: 3.9616\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9736 - cost: 3.3709 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9658 - val_cost: 4.3783\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3866 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9662 - val_cost: 4.1602\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9934 - accuracy: 0.9738 - cost: 3.3389 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9665 - val_cost: 4.0885\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9739 - cost: 3.3441 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9663 - val_cost: 4.0202\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9741 - cost: 3.3030 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9663 - val_cost: 4.1276\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2931 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9659 - val_cost: 4.3034\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2337 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9676 - val_cost: 3.9941\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1778 - val_loss: 0.1088 - val_auc: 0.9901 - val_accuracy: 0.9666 - val_cost: 4.1211\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2413 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9665 - val_cost: 4.1276\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9938 - accuracy: 0.9756 - cost: 3.1213 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9673 - val_cost: 3.9421\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1883 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9673 - val_cost: 4.0039\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1446 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.0137\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.0968 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9669 - val_cost: 3.9290\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.0996 - val_loss: 0.1095 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 4.0820\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1253 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9672 - val_cost: 3.8997\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0272 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9677 - val_cost: 3.9225\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0475 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9663 - val_cost: 4.0560\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0370 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9453\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9764 - cost: 3.0132 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9680 - val_cost: 3.8477\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0475 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9030\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0784 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0361 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.8477\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9425 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9681 - val_cost: 3.9388\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9764 - cost: 3.0027 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9681 - val_cost: 3.9258\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9160 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.9095\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9063 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9682 - val_cost: 3.9160\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9180 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9663 - val_cost: 4.0983\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9679 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.8607\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8784 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.7695\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9446 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.7305\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8767 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9689 - val_cost: 3.7305\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8584 - val_loss: 0.1129 - val_auc: 0.9897 - val_accuracy: 0.9682 - val_cost: 3.8053\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8603 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9676 - val_cost: 3.9844\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8019 - val_loss: 0.1122 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 3.8574\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8676 - val_loss: 0.1088 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.7533\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8689 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9682 - val_cost: 3.9486\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8284 - val_loss: 0.1083 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.8216\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7832 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9876\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8544 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9689 - val_cost: 3.7695\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8393 - val_loss: 0.1082 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8184\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7205 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9680 - val_cost: 3.8672\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7898 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 3.9486\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8367 - val_loss: 0.1068 - val_auc: 0.9902 - val_accuracy: 0.9684 - val_cost: 3.9323\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7473 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9689 - val_cost: 3.7760\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7692 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.7240\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7515 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.7728\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6983 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9687 - val_cost: 3.8346\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7175 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9681 - val_cost: 3.9681\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7088 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.9388\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7058 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8053\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7383 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 3.8607\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6875 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.7598\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6805 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 4.0625\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7325 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9690 - val_cost: 3.7826\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6954 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9680 - val_cost: 3.9746\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6637 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9684 - val_cost: 3.8444\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6069 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.8802\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6607 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9676 - val_cost: 3.8997\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7587 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.8184\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6536 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6383 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7630\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6642 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9682 - val_cost: 3.8542\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6524 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9677 - val_cost: 3.8574\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6236 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.8021\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6231 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7174\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5919 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 3.8997\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5784 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9682 - val_cost: 3.8184\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6509 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.8118\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5688 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7988\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6386 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.7630\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6533 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.7956\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6065 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7988\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6589 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.7891\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6312 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7500\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6039 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9686 - val_cost: 3.8542\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5997 - val_loss: 0.1133 - val_auc: 0.9893 - val_accuracy: 0.9689 - val_cost: 3.8509\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5557 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.7467\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5415 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8802\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5788 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 3.7793\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5717 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9682 - val_cost: 3.8346\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5204 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 3.9811\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5380 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6751\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5410 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9698 - val_cost: 3.7435\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5757 - val_loss: 0.1153 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 4.0430\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6228 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.9746\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5458 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7826\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5299 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8086\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5562 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 3.8802\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4886 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.7337\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5438 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7435\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.5102 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9674 - val_cost: 3.9290\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5567 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.8965\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5451 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.7533\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5054 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8053\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5462 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7337\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5402 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7272\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4309 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9695 - val_cost: 3.7956\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5112 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 3.9128\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5147 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8346\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9957 - accuracy: 0.9800 - cost: 2.5585 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9680 - val_cost: 3.9388\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4124 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.7826\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5163 - val_loss: 0.1166 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8118\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4984 - val_loss: 0.1173 - val_auc: 0.9890 - val_accuracy: 0.9696 - val_cost: 3.7272\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4475 - val_loss: 0.1171 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.9030\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5166 - val_loss: 0.1176 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.7142\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4788 - val_loss: 0.1158 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.8249\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4658 - val_loss: 0.1188 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 3.8932\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4856 - val_loss: 0.1205 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.6816\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4792 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.7728\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9958 - accuracy: 0.9803 - cost: 2.5203 - val_loss: 0.1215 - val_auc: 0.9885 - val_accuracy: 0.9685 - val_cost: 3.8574\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5154 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.6914\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4452 - val_loss: 0.1196 - val_auc: 0.9891 - val_accuracy: 0.9692 - val_cost: 3.8314\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4524 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.6165\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0642 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4533 - val_loss: 0.1197 - val_auc: 0.9889 - val_accuracy: 0.9692 - val_cost: 3.7077\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4586 - val_loss: 0.1184 - val_auc: 0.9888 - val_accuracy: 0.9697 - val_cost: 3.7435\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4216 - val_loss: 0.1183 - val_auc: 0.9887 - val_accuracy: 0.9695 - val_cost: 3.8184\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4344 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9692 - val_cost: 3.8021\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3496 - val_loss: 0.1173 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.5970\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.4904 - val_loss: 0.1192 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.5938\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4383 - val_loss: 0.1177 - val_auc: 0.9889 - val_accuracy: 0.9687 - val_cost: 3.8411\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4927 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.7044\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4227 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9673 - val_cost: 3.9974\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4914 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.7533\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4206 - val_loss: 0.1208 - val_auc: 0.9887 - val_accuracy: 0.9692 - val_cost: 3.7305\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3730 - val_loss: 0.1181 - val_auc: 0.9889 - val_accuracy: 0.9696 - val_cost: 3.8346\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4746 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7533\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4248 - val_loss: 0.1196 - val_auc: 0.9888 - val_accuracy: 0.9697 - val_cost: 3.7467\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4247 - val_loss: 0.1209 - val_auc: 0.9886 - val_accuracy: 0.9698 - val_cost: 3.6556\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4620 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9692 - val_cost: 3.7337\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3995 - val_loss: 0.1199 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7305\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4399 - val_loss: 0.1221 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.6719\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4407 - val_loss: 0.1193 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.6328\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3958 - val_loss: 0.1202 - val_auc: 0.9886 - val_accuracy: 0.9693 - val_cost: 3.8086\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4050 - val_loss: 0.1229 - val_auc: 0.9881 - val_accuracy: 0.9699 - val_cost: 3.7695\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.3952 - val_loss: 0.1216 - val_auc: 0.9889 - val_accuracy: 0.9683 - val_cost: 3.9323\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4287 - val_loss: 0.1215 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.6849\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3361 - val_loss: 0.1212 - val_auc: 0.9885 - val_accuracy: 0.9705 - val_cost: 3.6784\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3713 - val_loss: 0.1226 - val_auc: 0.9886 - val_accuracy: 0.9698 - val_cost: 3.7174\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4241 - val_loss: 0.1216 - val_auc: 0.9890 - val_accuracy: 0.9679 - val_cost: 3.8770\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9960 - accuracy: 0.9808 - cost: 2.4540 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 3.8607\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4093 - val_loss: 0.1218 - val_auc: 0.9887 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3514 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9698 - val_cost: 3.7077\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3482 - val_loss: 0.1232 - val_auc: 0.9887 - val_accuracy: 0.9680 - val_cost: 3.8672\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3452 - val_loss: 0.1235 - val_auc: 0.9887 - val_accuracy: 0.9693 - val_cost: 3.7142\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3625 - val_loss: 0.1225 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.7988\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3338 - val_loss: 0.1220 - val_auc: 0.9887 - val_accuracy: 0.9692 - val_cost: 3.7891\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3867 - val_loss: 0.1236 - val_auc: 0.9885 - val_accuracy: 0.9698 - val_cost: 3.7207\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3664 - val_loss: 0.1225 - val_auc: 0.9888 - val_accuracy: 0.9680 - val_cost: 3.8835\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4401 - val_loss: 0.1214 - val_auc: 0.9885 - val_accuracy: 0.9697 - val_cost: 3.7565\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3459 - val_loss: 0.1238 - val_auc: 0.9885 - val_accuracy: 0.9690 - val_cost: 3.8281\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3414 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8477\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4215 - val_loss: 0.1231 - val_auc: 0.9888 - val_accuracy: 0.9688 - val_cost: 3.7760\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3471 - val_loss: 0.1213 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8932\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3816 - val_loss: 0.1218 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.6426\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3260 - val_loss: 0.1224 - val_auc: 0.9882 - val_accuracy: 0.9703 - val_cost: 3.6654\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3527 - val_loss: 0.1211 - val_auc: 0.9885 - val_accuracy: 0.9709 - val_cost: 3.6133\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3528 - val_loss: 0.1230 - val_auc: 0.9884 - val_accuracy: 0.9681 - val_cost: 3.8607\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3009 - val_loss: 0.1239 - val_auc: 0.9884 - val_accuracy: 0.9694 - val_cost: 3.7240\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3743 - val_loss: 0.1231 - val_auc: 0.9885 - val_accuracy: 0.9692 - val_cost: 3.8737\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3452 - val_loss: 0.1244 - val_auc: 0.9887 - val_accuracy: 0.9694 - val_cost: 3.6914\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3349 - val_loss: 0.1232 - val_auc: 0.9887 - val_accuracy: 0.9689 - val_cost: 3.9030\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3123 - val_loss: 0.1205 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.7533\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3114 - val_loss: 0.1240 - val_auc: 0.9888 - val_accuracy: 0.9689 - val_cost: 3.7402\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3599 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.6849\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9813 - cost: 2.3999 - val_loss: 0.1236 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.7630\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2978 - val_loss: 0.1249 - val_auc: 0.9885 - val_accuracy: 0.9697 - val_cost: 3.8184\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3470 - val_loss: 0.1241 - val_auc: 0.9882 - val_accuracy: 0.9686 - val_cost: 3.8053\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3740 - val_loss: 0.1214 - val_auc: 0.9884 - val_accuracy: 0.9698 - val_cost: 3.7500\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3595 - val_loss: 0.1240 - val_auc: 0.9883 - val_accuracy: 0.9686 - val_cost: 3.7956\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1008 - auc: 0.9915 - accuracy: 0.9722 - cost: 3.5438\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:08.700796\n",
            "fold accuracy: 0.9721875190734863 - fold cost: 3.543750047683716\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5249 - auc: 0.8029 - accuracy: 0.7321 - cost: 35.5695 - val_loss: 0.3867 - val_auc: 0.9046 - val_accuracy: 0.8326 - val_cost: 21.4388\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3461 - auc: 0.9239 - accuracy: 0.8521 - cost: 18.8091 - val_loss: 0.3120 - val_auc: 0.9382 - val_accuracy: 0.8698 - val_cost: 15.9473\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2984 - auc: 0.9437 - accuracy: 0.8751 - cost: 15.8331 - val_loss: 0.2799 - val_auc: 0.9505 - val_accuracy: 0.8858 - val_cost: 14.0007\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2709 - auc: 0.9537 - accuracy: 0.8895 - cost: 13.9755 - val_loss: 0.2557 - val_auc: 0.9587 - val_accuracy: 0.8967 - val_cost: 13.0208\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2465 - auc: 0.9617 - accuracy: 0.9009 - cost: 12.5220 - val_loss: 0.2362 - val_auc: 0.9650 - val_accuracy: 0.9080 - val_cost: 11.1328\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2273 - auc: 0.9675 - accuracy: 0.9114 - cost: 11.2167 - val_loss: 0.2191 - val_auc: 0.9695 - val_accuracy: 0.9156 - val_cost: 10.3158\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2109 - auc: 0.9718 - accuracy: 0.9185 - cost: 10.2994 - val_loss: 0.2057 - val_auc: 0.9733 - val_accuracy: 0.9241 - val_cost: 9.4336\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1978 - auc: 0.9751 - accuracy: 0.9243 - cost: 9.5801 - val_loss: 0.1927 - val_auc: 0.9763 - val_accuracy: 0.9308 - val_cost: 8.4701\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1869 - auc: 0.9777 - accuracy: 0.9295 - cost: 8.9024 - val_loss: 0.1843 - val_auc: 0.9782 - val_accuracy: 0.9342 - val_cost: 7.9590\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1782 - auc: 0.9795 - accuracy: 0.9336 - cost: 8.4084 - val_loss: 0.1772 - val_auc: 0.9796 - val_accuracy: 0.9383 - val_cost: 7.9785\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1704 - auc: 0.9811 - accuracy: 0.9372 - cost: 7.9602 - val_loss: 0.1716 - val_auc: 0.9808 - val_accuracy: 0.9400 - val_cost: 7.3014\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1638 - auc: 0.9825 - accuracy: 0.9395 - cost: 7.6610 - val_loss: 0.1658 - val_auc: 0.9820 - val_accuracy: 0.9421 - val_cost: 7.4577\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1586 - auc: 0.9834 - accuracy: 0.9430 - cost: 7.2252 - val_loss: 0.1618 - val_auc: 0.9826 - val_accuracy: 0.9435 - val_cost: 7.3698\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1537 - auc: 0.9844 - accuracy: 0.9453 - cost: 6.9174 - val_loss: 0.1589 - val_auc: 0.9835 - val_accuracy: 0.9446 - val_cost: 6.9303\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1497 - auc: 0.9850 - accuracy: 0.9472 - cost: 6.6974 - val_loss: 0.1565 - val_auc: 0.9840 - val_accuracy: 0.9446 - val_cost: 6.9954\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1453 - auc: 0.9858 - accuracy: 0.9485 - cost: 6.5347 - val_loss: 0.1512 - val_auc: 0.9848 - val_accuracy: 0.9473 - val_cost: 6.8717\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1423 - auc: 0.9863 - accuracy: 0.9495 - cost: 6.4018 - val_loss: 0.1496 - val_auc: 0.9849 - val_accuracy: 0.9484 - val_cost: 6.8327\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1401 - auc: 0.9866 - accuracy: 0.9510 - cost: 6.2037 - val_loss: 0.1471 - val_auc: 0.9853 - val_accuracy: 0.9496 - val_cost: 6.9206\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1365 - auc: 0.9873 - accuracy: 0.9525 - cost: 6.0092 - val_loss: 0.1467 - val_auc: 0.9853 - val_accuracy: 0.9492 - val_cost: 6.7480\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1342 - auc: 0.9876 - accuracy: 0.9539 - cost: 5.8497 - val_loss: 0.1437 - val_auc: 0.9857 - val_accuracy: 0.9516 - val_cost: 6.2988\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1320 - auc: 0.9879 - accuracy: 0.9542 - cost: 5.8140 - val_loss: 0.1426 - val_auc: 0.9860 - val_accuracy: 0.9518 - val_cost: 6.3477\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1304 - auc: 0.9881 - accuracy: 0.9558 - cost: 5.5970 - val_loss: 0.1415 - val_auc: 0.9862 - val_accuracy: 0.9522 - val_cost: 5.9635\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1279 - auc: 0.9885 - accuracy: 0.9570 - cost: 5.4547 - val_loss: 0.1401 - val_auc: 0.9863 - val_accuracy: 0.9537 - val_cost: 6.0938\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1259 - auc: 0.9888 - accuracy: 0.9570 - cost: 5.4567 - val_loss: 0.1380 - val_auc: 0.9868 - val_accuracy: 0.9535 - val_cost: 6.0677\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9891 - accuracy: 0.9587 - cost: 5.2547 - val_loss: 0.1372 - val_auc: 0.9867 - val_accuracy: 0.9558 - val_cost: 5.9147\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1223 - auc: 0.9893 - accuracy: 0.9591 - cost: 5.2021 - val_loss: 0.1362 - val_auc: 0.9869 - val_accuracy: 0.9565 - val_cost: 5.5794\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1203 - auc: 0.9895 - accuracy: 0.9598 - cost: 5.0958 - val_loss: 0.1345 - val_auc: 0.9871 - val_accuracy: 0.9556 - val_cost: 6.0840\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1182 - auc: 0.9898 - accuracy: 0.9607 - cost: 4.9781 - val_loss: 0.1343 - val_auc: 0.9871 - val_accuracy: 0.9572 - val_cost: 5.4883\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1169 - auc: 0.9901 - accuracy: 0.9609 - cost: 4.9643 - val_loss: 0.1337 - val_auc: 0.9871 - val_accuracy: 0.9568 - val_cost: 5.3418\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1156 - auc: 0.9902 - accuracy: 0.9614 - cost: 4.9017 - val_loss: 0.1311 - val_auc: 0.9875 - val_accuracy: 0.9585 - val_cost: 5.4622\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1142 - auc: 0.9904 - accuracy: 0.9621 - cost: 4.7992 - val_loss: 0.1320 - val_auc: 0.9873 - val_accuracy: 0.9577 - val_cost: 5.2507\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1125 - auc: 0.9906 - accuracy: 0.9628 - cost: 4.7253 - val_loss: 0.1297 - val_auc: 0.9877 - val_accuracy: 0.9590 - val_cost: 5.3353\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1116 - auc: 0.9907 - accuracy: 0.9635 - cost: 4.6345 - val_loss: 0.1287 - val_auc: 0.9879 - val_accuracy: 0.9593 - val_cost: 4.9577\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1104 - auc: 0.9908 - accuracy: 0.9638 - cost: 4.5845 - val_loss: 0.1282 - val_auc: 0.9879 - val_accuracy: 0.9601 - val_cost: 4.9154\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1082 - auc: 0.9912 - accuracy: 0.9653 - cost: 4.3951 - val_loss: 0.1270 - val_auc: 0.9877 - val_accuracy: 0.9602 - val_cost: 4.9349\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1075 - auc: 0.9913 - accuracy: 0.9651 - cost: 4.4206 - val_loss: 0.1274 - val_auc: 0.9878 - val_accuracy: 0.9599 - val_cost: 5.0293\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1065 - auc: 0.9913 - accuracy: 0.9653 - cost: 4.3962 - val_loss: 0.1255 - val_auc: 0.9881 - val_accuracy: 0.9597 - val_cost: 5.4297\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1046 - auc: 0.9916 - accuracy: 0.9660 - cost: 4.3196 - val_loss: 0.1252 - val_auc: 0.9882 - val_accuracy: 0.9613 - val_cost: 4.8568\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1034 - auc: 0.9917 - accuracy: 0.9668 - cost: 4.2100 - val_loss: 0.1240 - val_auc: 0.9881 - val_accuracy: 0.9631 - val_cost: 4.8177\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9918 - accuracy: 0.9671 - cost: 4.1893 - val_loss: 0.1229 - val_auc: 0.9883 - val_accuracy: 0.9632 - val_cost: 4.6940\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9679 - cost: 4.0708 - val_loss: 0.1232 - val_auc: 0.9882 - val_accuracy: 0.9632 - val_cost: 4.7786\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9919 - accuracy: 0.9681 - cost: 4.0553 - val_loss: 0.1222 - val_auc: 0.9883 - val_accuracy: 0.9627 - val_cost: 4.7949\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9686 - cost: 3.9899 - val_loss: 0.1226 - val_auc: 0.9883 - val_accuracy: 0.9627 - val_cost: 4.6810\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9922 - accuracy: 0.9686 - cost: 3.9894 - val_loss: 0.1207 - val_auc: 0.9885 - val_accuracy: 0.9635 - val_cost: 4.8861\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0968 - auc: 0.9924 - accuracy: 0.9695 - cost: 3.8937 - val_loss: 0.1210 - val_auc: 0.9887 - val_accuracy: 0.9638 - val_cost: 4.5182\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0964 - auc: 0.9925 - accuracy: 0.9691 - cost: 3.9156 - val_loss: 0.1191 - val_auc: 0.9889 - val_accuracy: 0.9633 - val_cost: 4.8242\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9701 - cost: 3.7977 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9634 - val_cost: 5.0488\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9703 - cost: 3.7830 - val_loss: 0.1180 - val_auc: 0.9892 - val_accuracy: 0.9642 - val_cost: 4.6354\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9707 - cost: 3.7256 - val_loss: 0.1188 - val_auc: 0.9889 - val_accuracy: 0.9638 - val_cost: 4.8405\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0933 - auc: 0.9927 - accuracy: 0.9711 - cost: 3.6748 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9654 - val_cost: 4.3197\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9713 - cost: 3.6482 - val_loss: 0.1161 - val_auc: 0.9891 - val_accuracy: 0.9650 - val_cost: 4.3490\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9930 - accuracy: 0.9712 - cost: 3.6782 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9644 - val_cost: 4.6257\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9930 - accuracy: 0.9718 - cost: 3.5831 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9664 - val_cost: 4.4564\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5416 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9660 - val_cost: 4.4596\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5384 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9659 - val_cost: 4.3099\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0885 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4542 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9661 - val_cost: 4.2578\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9933 - accuracy: 0.9734 - cost: 3.3979 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 4.2188\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9935 - accuracy: 0.9737 - cost: 3.3441 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.1146\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9737 - cost: 3.3557 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 4.0332\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9736 - cost: 3.3542 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9678 - val_cost: 4.1146\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9935 - accuracy: 0.9743 - cost: 3.2779 - val_loss: 0.1106 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 3.9616\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9936 - accuracy: 0.9746 - cost: 3.2452 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9672 - val_cost: 3.9355\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.2895 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 4.2741\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9746 - cost: 3.2368 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9673 - val_cost: 4.1602\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.2203 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9698 - val_cost: 3.8574\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1810 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7891\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1331 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 4.0658\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1281 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9690 - val_cost: 4.0234\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1138 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.8509\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0498 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.8867\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0732 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9684 - val_cost: 3.9681\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9763 - cost: 3.0294 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9688 - val_cost: 3.9128\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0238 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.6589\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.0799 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 4.0755\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0374 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.9062\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9347 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9682 - val_cost: 4.1471\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9764 - cost: 3.0181 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.8118\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9535 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9696 - val_cost: 3.8835\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8525 - val_loss: 0.1075 - val_auc: 0.9903 - val_accuracy: 0.9695 - val_cost: 3.8346\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8525 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.9160\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9273 - val_loss: 0.1091 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.9258\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8627 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9689 - val_cost: 3.9714\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9314 - val_loss: 0.1079 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.8932\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8796 - val_loss: 0.1097 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.8314\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9205 - val_loss: 0.1082 - val_auc: 0.9904 - val_accuracy: 0.9688 - val_cost: 4.0267\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8918 - val_loss: 0.1079 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.7760\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8311 - val_loss: 0.1069 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.9062\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8357 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.8216\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7673 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8607\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.7778 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.8444\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.7990 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.7793\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7692 - val_loss: 0.1080 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7337\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7218 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7641 - val_loss: 0.1076 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.7826\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7703 - val_loss: 0.1076 - val_auc: 0.9903 - val_accuracy: 0.9708 - val_cost: 3.7305\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7733 - val_loss: 0.1063 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.6751\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6959 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7142\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7426 - val_loss: 0.1079 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.8379\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7123 - val_loss: 0.1077 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.6816\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6803 - val_loss: 0.1088 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7630\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6611 - val_loss: 0.1077 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.7793\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6696 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.9388\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6318 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.8542\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6721 - val_loss: 0.1097 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.5872\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5735 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6035\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6018 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.7402\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6340 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.7370\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6431 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.8184\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6509 - val_loss: 0.1074 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.7858\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5884 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.6361\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6142 - val_loss: 0.1107 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.7728\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6034 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.7174\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6513 - val_loss: 0.1081 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.6849\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5859 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.8509\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5739 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.7174\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5915 - val_loss: 0.1093 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6816\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6232 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9952 - accuracy: 0.9806 - cost: 2.4842 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7044\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5920 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.5286\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5627 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9702 - val_cost: 3.5677\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6373 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5872\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5596 - val_loss: 0.1087 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.7728\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9808 - cost: 2.4541 - val_loss: 0.1098 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8444\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5695 - val_loss: 0.1077 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.6393\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5151 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4635\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5460 - val_loss: 0.1118 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.6361\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5215 - val_loss: 0.1086 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.6914\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4837 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.6426\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9953 - accuracy: 0.9808 - cost: 2.4517 - val_loss: 0.1091 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.6523\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4793 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.5221\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4622 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7826\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4900 - val_loss: 0.1107 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.7858\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4568 - val_loss: 0.1097 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.6361\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4601 - val_loss: 0.1074 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.6849\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9954 - accuracy: 0.9812 - cost: 2.4051 - val_loss: 0.1085 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.6328\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4313 - val_loss: 0.1104 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.7370\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4751 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9714 - val_cost: 3.3952\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9810 - cost: 2.4320 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.7695\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4684 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9714 - val_cost: 3.4766\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4303 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7077\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3712 - val_loss: 0.1098 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.5514\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3877 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.4928\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0652 - auc: 0.9954 - accuracy: 0.9814 - cost: 2.3758 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.7826\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3784 - val_loss: 0.1106 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.6621\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4435 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7565\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9956 - accuracy: 0.9816 - cost: 2.3488 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.7500\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4288 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9720 - val_cost: 3.6230\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4540 - val_loss: 0.1122 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.4440\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3765 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.6328\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3866 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.5417\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.4017 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.5612\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3640 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.6296\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3805 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6133\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4161 - val_loss: 0.1113 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5775\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3867 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.4635\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3250 - val_loss: 0.1119 - val_auc: 0.9905 - val_accuracy: 0.9697 - val_cost: 3.6686\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3472 - val_loss: 0.1121 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5579\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3560 - val_loss: 0.1101 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.4928\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3339 - val_loss: 0.1102 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.4408\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3513 - val_loss: 0.1116 - val_auc: 0.9901 - val_accuracy: 0.9707 - val_cost: 3.7891\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3815 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.5319\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3150 - val_loss: 0.1120 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.6589\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3622 - val_loss: 0.1125 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6556\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3299 - val_loss: 0.1102 - val_auc: 0.9904 - val_accuracy: 0.9722 - val_cost: 3.5547\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3557 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.8477\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3156 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.5938\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3307 - val_loss: 0.1088 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.6882\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3335 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.6426\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3176 - val_loss: 0.1117 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.4733\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.2964 - val_loss: 0.1117 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.7272\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3278 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9720 - val_cost: 3.6361\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3472 - val_loss: 0.1136 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6882\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3222 - val_loss: 0.1131 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.4115\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3164 - val_loss: 0.1107 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.4766\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2733 - val_loss: 0.1109 - val_auc: 0.9902 - val_accuracy: 0.9725 - val_cost: 3.5449\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3113 - val_loss: 0.1124 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.6100\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3212 - val_loss: 0.1122 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5547\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3246 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9716 - val_cost: 3.4863\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2858 - val_loss: 0.1123 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4310\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3198 - val_loss: 0.1139 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.4180\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2431 - val_loss: 0.1122 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.7077\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3101 - val_loss: 0.1130 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.6621\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2464 - val_loss: 0.1140 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6589\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2623 - val_loss: 0.1137 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.7109\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2220 - val_loss: 0.1160 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.4896\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2927 - val_loss: 0.1133 - val_auc: 0.9902 - val_accuracy: 0.9718 - val_cost: 3.3789\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2967 - val_loss: 0.1118 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.5840\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2949 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4408\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2491 - val_loss: 0.1147 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.4473\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2777 - val_loss: 0.1151 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.7044\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2502 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.7956\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2576 - val_loss: 0.1141 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.6686\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2343 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9723 - val_cost: 3.3757\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2420 - val_loss: 0.1134 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.6263\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3151 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5970\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2544 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.6393\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2088 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.4342\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2649 - val_loss: 0.1139 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.6719\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2470 - val_loss: 0.1161 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.4896\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2972 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.5059\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2448 - val_loss: 0.1162 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6003\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2728 - val_loss: 0.1180 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.4538\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2267 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9718 - val_cost: 3.4082\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2949 - val_loss: 0.1161 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.5319\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2365 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.1921 - val_loss: 0.1150 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5254\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2053 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6784\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2296 - val_loss: 0.1134 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6165\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2798 - val_loss: 0.1163 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.4440\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2042 - val_loss: 0.1163 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.4570\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2661 - val_loss: 0.1176 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.5905\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1805 - val_loss: 0.1132 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6556\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2654 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6849\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2150 - val_loss: 0.1141 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1899 - val_loss: 0.1151 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.4668\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2208 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.7630\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2112 - val_loss: 0.1133 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.4896\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1957 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.6523\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1727 - val_loss: 0.1160 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7174\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2332 - val_loss: 0.1161 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.4733\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1721 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.8053\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2350 - val_loss: 0.1187 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.4603\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9961 - accuracy: 0.9833 - cost: 2.1479 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.2617\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1760 - val_loss: 0.1172 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.4896\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2110 - val_loss: 0.1188 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6100\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2331 - val_loss: 0.1177 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4440\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1757 - val_loss: 0.1189 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.4896\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1746 - val_loss: 0.1184 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5254\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1737 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6914\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1582 - val_loss: 0.1165 - val_auc: 0.9899 - val_accuracy: 0.9724 - val_cost: 3.5775\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9833 - cost: 2.1542 - val_loss: 0.1179 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.3984\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1915 - val_loss: 0.1184 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.4342\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1501 - val_loss: 0.1195 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6426\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1819 - val_loss: 0.1170 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.5482\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1911 - val_loss: 0.1164 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.6556\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1614 - val_loss: 0.1177 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.4668\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2193 - val_loss: 0.1193 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2002 - val_loss: 0.1167 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.6491\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1875 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.5026\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2396 - val_loss: 0.1166 - val_auc: 0.9899 - val_accuracy: 0.9720 - val_cost: 3.5938\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1930 - val_loss: 0.1187 - val_auc: 0.9897 - val_accuracy: 0.9727 - val_cost: 3.3398\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1430 - val_loss: 0.1191 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.4375\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1519 - val_loss: 0.1198 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.5449\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2093 - val_loss: 0.1184 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.4408\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2125 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.4766\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2136 - val_loss: 0.1168 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.4701\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1593 - val_loss: 0.1188 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4538\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1783 - val_loss: 0.1181 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.4310\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.1998 - val_loss: 0.1185 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.5970\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1689 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6816\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2468 - val_loss: 0.1175 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.6361\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1236 - val_loss: 0.1177 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4082\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2265 - val_loss: 0.1188 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.4115\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.1954 - val_loss: 0.1193 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4245\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1534 - val_loss: 0.1202 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5384\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2049 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.3431\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1334 - val_loss: 0.1184 - val_auc: 0.9896 - val_accuracy: 0.9724 - val_cost: 3.3691\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2141 - val_loss: 0.1217 - val_auc: 0.9893 - val_accuracy: 0.9725 - val_cost: 3.4017\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9833 - cost: 2.1563 - val_loss: 0.1186 - val_auc: 0.9896 - val_accuracy: 0.9728 - val_cost: 3.3073\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1160 - val_loss: 0.1175 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.4212\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1326 - val_loss: 0.1189 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4310\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1183 - val_loss: 0.1195 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.5026\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1126 - val_loss: 0.1188 - val_auc: 0.9896 - val_accuracy: 0.9716 - val_cost: 3.4473\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1581 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4408\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1855 - val_loss: 0.1217 - val_auc: 0.9894 - val_accuracy: 0.9711 - val_cost: 3.4863\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0947 - val_loss: 0.1237 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.3203\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1642 - val_loss: 0.1198 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1854 - val_loss: 0.1183 - val_auc: 0.9890 - val_accuracy: 0.9724 - val_cost: 3.2194\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1501 - val_loss: 0.1232 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1154 - val_loss: 0.1212 - val_auc: 0.9897 - val_accuracy: 0.9721 - val_cost: 3.3691\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1321 - val_loss: 0.1184 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.4310\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1754 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.4375\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1493 - val_loss: 0.1195 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5221\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1459 - val_loss: 0.1186 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.5482\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0838 - val_loss: 0.1184 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.5840\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1574 - val_loss: 0.1200 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4766\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0885 - val_loss: 0.1206 - val_auc: 0.9900 - val_accuracy: 0.9719 - val_cost: 3.6296\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0563 - auc: 0.9964 - accuracy: 0.9837 - cost: 2.0892 - val_loss: 0.1170 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.5221\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1228 - val_loss: 0.1210 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6263\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1297 - val_loss: 0.1214 - val_auc: 0.9897 - val_accuracy: 0.9725 - val_cost: 3.1934\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1067 - val_loss: 0.1197 - val_auc: 0.9897 - val_accuracy: 0.9720 - val_cost: 3.4212\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1424 - val_loss: 0.1202 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.6296\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1584 - val_loss: 0.1195 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.5840\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1143 - val_loss: 0.1194 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.4375\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1131 - val_loss: 0.1225 - val_auc: 0.9891 - val_accuracy: 0.9709 - val_cost: 3.3952\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1084 - val_loss: 0.1218 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.1058 - val_loss: 0.1197 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.4375\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1489 - val_loss: 0.1210 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6230\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.0991 - val_loss: 0.1245 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.6849\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.2006 - val_loss: 0.1209 - val_auc: 0.9891 - val_accuracy: 0.9714 - val_cost: 3.4961\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9842 - cost: 2.0240 - val_loss: 0.1222 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.4896\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1225 - val_loss: 0.1211 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.5579\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0676 - val_loss: 0.1224 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5059\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0359 - val_loss: 0.1229 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.6426\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1665 - val_loss: 0.1220 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4603\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1349 - val_loss: 0.1215 - val_auc: 0.9892 - val_accuracy: 0.9716 - val_cost: 3.4928\n",
            "Epoch 297/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.0901 - val_loss: 0.1209 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4538\n",
            "Epoch 298/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1262 - val_loss: 0.1207 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.4798\n",
            "Epoch 299/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1311 - val_loss: 0.1224 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.3984\n",
            "Epoch 300/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0656 - val_loss: 0.1236 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.4408\n",
            "Epoch 301/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0768 - val_loss: 0.1236 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5254\n",
            "Epoch 302/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1008 - val_loss: 0.1230 - val_auc: 0.9893 - val_accuracy: 0.9726 - val_cost: 3.1868\n",
            "Epoch 303/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0806 - val_loss: 0.1237 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.5156\n",
            "Epoch 304/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0556 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1178 - val_loss: 0.1247 - val_auc: 0.9893 - val_accuracy: 0.9716 - val_cost: 3.2910\n",
            "Epoch 305/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0551 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0663 - val_loss: 0.1213 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.7174\n",
            "Epoch 306/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0991 - val_loss: 0.1243 - val_auc: 0.9890 - val_accuracy: 0.9718 - val_cost: 3.5026\n",
            "Epoch 307/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1127 - val_loss: 0.1238 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.4928\n",
            "Epoch 308/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0653 - val_loss: 0.1221 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.4310\n",
            "Epoch 309/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0879 - val_loss: 0.1206 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4896\n",
            "Epoch 310/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0861 - val_loss: 0.1269 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.4766\n",
            "Epoch 311/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9967 - accuracy: 0.9842 - cost: 2.0305 - val_loss: 0.1231 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.4668\n",
            "Epoch 312/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0870 - val_loss: 0.1212 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.2715\n",
            "Epoch 313/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1540 - val_loss: 0.1229 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.5970\n",
            "Epoch 314/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0784 - val_loss: 0.1232 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.4603\n",
            "Epoch 315/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0489 - val_loss: 0.1234 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.5319\n",
            "Epoch 316/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0724 - val_loss: 0.1214 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.4928\n",
            "Epoch 317/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0686 - val_loss: 0.1236 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.4603\n",
            "Epoch 318/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0960 - val_loss: 0.1209 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5352\n",
            "Epoch 319/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0889 - val_loss: 0.1206 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5938\n",
            "Epoch 320/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0542 - auc: 0.9967 - accuracy: 0.9842 - cost: 2.0349 - val_loss: 0.1232 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4049\n",
            "Epoch 321/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0314 - val_loss: 0.1212 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.5612\n",
            "Epoch 322/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0689 - val_loss: 0.1238 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5417\n",
            "Epoch 323/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0551 - val_loss: 0.1250 - val_auc: 0.9890 - val_accuracy: 0.9716 - val_cost: 3.3724\n",
            "Epoch 324/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0885 - val_loss: 0.1223 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.5612\n",
            "Epoch 325/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9845 - cost: 1.9917 - val_loss: 0.1220 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.4473\n",
            "Epoch 326/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1162 - val_loss: 0.1233 - val_auc: 0.9893 - val_accuracy: 0.9720 - val_cost: 3.4277\n",
            "Epoch 327/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0861 - val_loss: 0.1234 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5352\n",
            "Epoch 328/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0683 - val_loss: 0.1254 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.4212\n",
            "Epoch 329/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0926 - val_loss: 0.1239 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.3919\n",
            "Epoch 330/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0696 - val_loss: 0.1241 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5612\n",
            "Epoch 331/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0905 - val_loss: 0.1236 - val_auc: 0.9893 - val_accuracy: 0.9718 - val_cost: 3.2617\n",
            "Epoch 332/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0618 - val_loss: 0.1223 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5156\n",
            "Epoch 333/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1071 - val_loss: 0.1244 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.2910\n",
            "Epoch 334/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0723 - val_loss: 0.1264 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.4375\n",
            "Epoch 335/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0475 - val_loss: 0.1218 - val_auc: 0.9891 - val_accuracy: 0.9720 - val_cost: 3.4115\n",
            "Epoch 336/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0503 - val_loss: 0.1197 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.4635\n",
            "Epoch 337/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0551 - val_loss: 0.1230 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.4701\n",
            "Epoch 338/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0316 - val_loss: 0.1226 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.4180\n",
            "Epoch 339/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0367 - val_loss: 0.1233 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.4505\n",
            "Epoch 340/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0535 - val_loss: 0.1227 - val_auc: 0.9892 - val_accuracy: 0.9718 - val_cost: 3.4342\n",
            "Epoch 341/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0339 - val_loss: 0.1257 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 342/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0535 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0463 - val_loss: 0.1239 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4082\n",
            "Epoch 343/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0454 - val_loss: 0.1257 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.4766\n",
            "Epoch 344/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0540 - auc: 0.9967 - accuracy: 0.9844 - cost: 1.9982 - val_loss: 0.1233 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5286\n",
            "Epoch 345/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0533 - auc: 0.9968 - accuracy: 0.9843 - cost: 2.0179 - val_loss: 0.1231 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.4831\n",
            "Epoch 346/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0672 - val_loss: 0.1230 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.3398\n",
            "Epoch 347/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0880 - val_loss: 0.1223 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5742\n",
            "Epoch 348/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0747 - val_loss: 0.1267 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.3691\n",
            "Epoch 349/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0645 - val_loss: 0.1231 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.4733\n",
            "Epoch 350/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0496 - val_loss: 0.1227 - val_auc: 0.9892 - val_accuracy: 0.9722 - val_cost: 3.2357\n",
            "Epoch 351/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0346 - val_loss: 0.1217 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.1966\n",
            "Epoch 352/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0457 - val_loss: 0.1252 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.3073\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1114 - auc: 0.9894 - accuracy: 0.9723 - cost: 3.5031\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:19.503687\n",
            "fold accuracy: 0.9723125100135803 - fold cost: 3.503124952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5280 - auc: 0.7996 - accuracy: 0.7308 - cost: 35.7990 - val_loss: 0.3931 - val_auc: 0.9017 - val_accuracy: 0.8292 - val_cost: 22.3730\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3484 - auc: 0.9228 - accuracy: 0.8502 - cost: 19.0535 - val_loss: 0.3144 - val_auc: 0.9370 - val_accuracy: 0.8659 - val_cost: 16.6243\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2999 - auc: 0.9430 - accuracy: 0.8758 - cost: 15.7348 - val_loss: 0.2836 - val_auc: 0.9490 - val_accuracy: 0.8833 - val_cost: 14.2285\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2718 - auc: 0.9532 - accuracy: 0.8890 - cost: 14.0779 - val_loss: 0.2587 - val_auc: 0.9575 - val_accuracy: 0.8956 - val_cost: 12.8320\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2486 - auc: 0.9610 - accuracy: 0.9005 - cost: 12.5871 - val_loss: 0.2398 - val_auc: 0.9638 - val_accuracy: 0.9062 - val_cost: 11.5104\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2285 - auc: 0.9670 - accuracy: 0.9110 - cost: 11.2494 - val_loss: 0.2207 - val_auc: 0.9692 - val_accuracy: 0.9145 - val_cost: 10.6576\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2118 - auc: 0.9716 - accuracy: 0.9180 - cost: 10.3770 - val_loss: 0.2074 - val_auc: 0.9727 - val_accuracy: 0.9208 - val_cost: 9.7949\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1991 - auc: 0.9747 - accuracy: 0.9235 - cost: 9.6775 - val_loss: 0.1958 - val_auc: 0.9755 - val_accuracy: 0.9268 - val_cost: 8.9746\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1882 - auc: 0.9773 - accuracy: 0.9293 - cost: 8.9484 - val_loss: 0.1868 - val_auc: 0.9777 - val_accuracy: 0.9313 - val_cost: 8.5124\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1794 - auc: 0.9793 - accuracy: 0.9336 - cost: 8.4137 - val_loss: 0.1794 - val_auc: 0.9793 - val_accuracy: 0.9349 - val_cost: 8.3268\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1712 - auc: 0.9810 - accuracy: 0.9374 - cost: 7.9323 - val_loss: 0.1728 - val_auc: 0.9807 - val_accuracy: 0.9387 - val_cost: 7.8451\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1643 - auc: 0.9824 - accuracy: 0.9405 - cost: 7.5567 - val_loss: 0.1690 - val_auc: 0.9812 - val_accuracy: 0.9404 - val_cost: 7.5781\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1592 - auc: 0.9833 - accuracy: 0.9424 - cost: 7.3219 - val_loss: 0.1633 - val_auc: 0.9824 - val_accuracy: 0.9425 - val_cost: 7.4707\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1531 - auc: 0.9844 - accuracy: 0.9453 - cost: 6.9492 - val_loss: 0.1601 - val_auc: 0.9832 - val_accuracy: 0.9428 - val_cost: 7.2559\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1493 - auc: 0.9851 - accuracy: 0.9471 - cost: 6.6991 - val_loss: 0.1567 - val_auc: 0.9837 - val_accuracy: 0.9462 - val_cost: 6.9466\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1448 - auc: 0.9858 - accuracy: 0.9482 - cost: 6.5594 - val_loss: 0.1530 - val_auc: 0.9843 - val_accuracy: 0.9469 - val_cost: 6.7871\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1417 - auc: 0.9863 - accuracy: 0.9502 - cost: 6.3180 - val_loss: 0.1493 - val_auc: 0.9850 - val_accuracy: 0.9481 - val_cost: 6.5951\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1382 - auc: 0.9870 - accuracy: 0.9518 - cost: 6.1200 - val_loss: 0.1470 - val_auc: 0.9853 - val_accuracy: 0.9484 - val_cost: 6.7676\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1360 - auc: 0.9873 - accuracy: 0.9526 - cost: 6.0184 - val_loss: 0.1457 - val_auc: 0.9857 - val_accuracy: 0.9496 - val_cost: 6.2565\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1322 - auc: 0.9879 - accuracy: 0.9546 - cost: 5.7572 - val_loss: 0.1434 - val_auc: 0.9859 - val_accuracy: 0.9508 - val_cost: 6.3542\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1300 - auc: 0.9881 - accuracy: 0.9556 - cost: 5.6365 - val_loss: 0.1410 - val_auc: 0.9863 - val_accuracy: 0.9528 - val_cost: 6.1654\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1268 - auc: 0.9886 - accuracy: 0.9571 - cost: 5.4504 - val_loss: 0.1397 - val_auc: 0.9864 - val_accuracy: 0.9549 - val_cost: 5.8105\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1261 - auc: 0.9887 - accuracy: 0.9577 - cost: 5.3798 - val_loss: 0.1357 - val_auc: 0.9868 - val_accuracy: 0.9552 - val_cost: 5.7650\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1227 - auc: 0.9893 - accuracy: 0.9590 - cost: 5.2123 - val_loss: 0.1346 - val_auc: 0.9871 - val_accuracy: 0.9560 - val_cost: 5.7617\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1198 - auc: 0.9896 - accuracy: 0.9598 - cost: 5.1081 - val_loss: 0.1344 - val_auc: 0.9871 - val_accuracy: 0.9563 - val_cost: 5.5632\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1190 - auc: 0.9896 - accuracy: 0.9603 - cost: 5.0436 - val_loss: 0.1321 - val_auc: 0.9874 - val_accuracy: 0.9578 - val_cost: 5.4069\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1162 - auc: 0.9900 - accuracy: 0.9615 - cost: 4.8784 - val_loss: 0.1288 - val_auc: 0.9878 - val_accuracy: 0.9590 - val_cost: 5.2441\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1140 - auc: 0.9904 - accuracy: 0.9624 - cost: 4.7879 - val_loss: 0.1294 - val_auc: 0.9880 - val_accuracy: 0.9582 - val_cost: 5.3809\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1130 - auc: 0.9905 - accuracy: 0.9627 - cost: 4.7363 - val_loss: 0.1302 - val_auc: 0.9881 - val_accuracy: 0.9587 - val_cost: 4.9609\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1113 - auc: 0.9906 - accuracy: 0.9638 - cost: 4.6048 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9591 - val_cost: 5.1465\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1080 - auc: 0.9911 - accuracy: 0.9647 - cost: 4.4835 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9597 - val_cost: 5.0944\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1072 - auc: 0.9912 - accuracy: 0.9653 - cost: 4.4144 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9619 - val_cost: 4.9512\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1052 - auc: 0.9914 - accuracy: 0.9660 - cost: 4.3160 - val_loss: 0.1236 - val_auc: 0.9887 - val_accuracy: 0.9611 - val_cost: 5.0098\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9915 - accuracy: 0.9665 - cost: 4.2457 - val_loss: 0.1236 - val_auc: 0.9883 - val_accuracy: 0.9608 - val_cost: 5.1660\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9668 - cost: 4.2337 - val_loss: 0.1208 - val_auc: 0.9885 - val_accuracy: 0.9632 - val_cost: 4.6680\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1017 - auc: 0.9919 - accuracy: 0.9675 - cost: 4.1303 - val_loss: 0.1213 - val_auc: 0.9886 - val_accuracy: 0.9622 - val_cost: 4.6257\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1001 - auc: 0.9920 - accuracy: 0.9681 - cost: 4.0609 - val_loss: 0.1204 - val_auc: 0.9888 - val_accuracy: 0.9637 - val_cost: 4.4043\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9922 - accuracy: 0.9686 - cost: 4.0003 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9631 - val_cost: 4.7461\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9691 - cost: 3.9514 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9641 - val_cost: 4.3620\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9924 - accuracy: 0.9698 - cost: 3.8479 - val_loss: 0.1168 - val_auc: 0.9893 - val_accuracy: 0.9645 - val_cost: 4.2415\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0952 - auc: 0.9926 - accuracy: 0.9702 - cost: 3.7913 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9654 - val_cost: 4.2904\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0943 - auc: 0.9927 - accuracy: 0.9700 - cost: 3.8134 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9644 - val_cost: 4.3034\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0932 - auc: 0.9928 - accuracy: 0.9708 - cost: 3.7244 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9660 - val_cost: 4.1471\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9929 - accuracy: 0.9715 - cost: 3.6299 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9653 - val_cost: 4.4368\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9710 - cost: 3.6985 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9658 - val_cost: 4.1569\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9930 - accuracy: 0.9715 - cost: 3.6236 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9647 - val_cost: 4.2513\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5440 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9667 - val_cost: 4.1081\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0884 - auc: 0.9932 - accuracy: 0.9729 - cost: 3.4638 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9649 - val_cost: 4.3522\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4520 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.0918\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9728 - cost: 3.4602 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9667 - val_cost: 4.0788\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4517 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9665 - val_cost: 4.3652\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0873 - auc: 0.9933 - accuracy: 0.9726 - cost: 3.4940 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9667 - val_cost: 4.0332\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9736 - cost: 3.3587 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9671 - val_cost: 4.0267\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9747 - cost: 3.2246 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9679 - val_cost: 4.0007\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3523 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9680 - val_cost: 3.8379\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2558 - val_loss: 0.1074 - val_auc: 0.9902 - val_accuracy: 0.9685 - val_cost: 4.0104\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2329 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9876\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0830 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2324 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 3.9388\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2125 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9674 - val_cost: 4.0951\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1837 - val_loss: 0.1072 - val_auc: 0.9902 - val_accuracy: 0.9689 - val_cost: 3.9616\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0967 - val_loss: 0.1078 - val_auc: 0.9901 - val_accuracy: 0.9686 - val_cost: 4.0202\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1981 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.7598\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9757 - cost: 3.1134 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9682 - val_cost: 4.0397\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0946 - val_loss: 0.1077 - val_auc: 0.9902 - val_accuracy: 0.9682 - val_cost: 4.0690\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0326 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 3.9974\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0888 - val_loss: 0.1059 - val_auc: 0.9904 - val_accuracy: 0.9688 - val_cost: 3.8900\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9757 - cost: 3.0876 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9690 - val_cost: 4.0039\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9766 - cost: 2.9883 - val_loss: 0.1064 - val_auc: 0.9906 - val_accuracy: 0.9682 - val_cost: 4.0072\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9766 - cost: 2.9831 - val_loss: 0.1087 - val_auc: 0.9900 - val_accuracy: 0.9681 - val_cost: 4.0853\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9769 - cost: 2.9542 - val_loss: 0.1069 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.9811\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9766 - cost: 2.9901 - val_loss: 0.1064 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 3.9486\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9485 - val_loss: 0.1071 - val_auc: 0.9903 - val_accuracy: 0.9689 - val_cost: 3.9290\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9821 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9678 - val_cost: 4.1634\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9546 - val_loss: 0.1082 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.9388\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8605 - val_loss: 0.1059 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.9258\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8862 - val_loss: 0.1067 - val_auc: 0.9901 - val_accuracy: 0.9692 - val_cost: 3.9811\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8432 - val_loss: 0.1070 - val_auc: 0.9902 - val_accuracy: 0.9676 - val_cost: 4.1243\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9029 - val_loss: 0.1074 - val_auc: 0.9901 - val_accuracy: 0.9687 - val_cost: 3.9714\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8270 - val_loss: 0.1067 - val_auc: 0.9904 - val_accuracy: 0.9690 - val_cost: 3.8932\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8490 - val_loss: 0.1070 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9160\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8809 - val_loss: 0.1067 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.9583\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8724 - val_loss: 0.1086 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9941\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8107 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.8542\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8549 - val_loss: 0.1070 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.8932\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8167 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9694 - val_cost: 3.8379\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.7964 - val_loss: 0.1059 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.7663\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7652 - val_loss: 0.1082 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.8118\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.6932 - val_loss: 0.1057 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8672\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7397 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.8249\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7568 - val_loss: 0.1061 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.7695\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7486 - val_loss: 0.1070 - val_auc: 0.9902 - val_accuracy: 0.9693 - val_cost: 3.7500\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7224 - val_loss: 0.1074 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7305\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7495 - val_loss: 0.1072 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.6654\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6934 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.6361\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7796 - val_loss: 0.1079 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.8021\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6849 - val_loss: 0.1089 - val_auc: 0.9900 - val_accuracy: 0.9687 - val_cost: 3.7891\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6634 - val_loss: 0.1063 - val_auc: 0.9903 - val_accuracy: 0.9693 - val_cost: 3.8216\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6941 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.6230\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6603 - val_loss: 0.1064 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.6849\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6216 - val_loss: 0.1074 - val_auc: 0.9906 - val_accuracy: 0.9697 - val_cost: 3.6882\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6332 - val_loss: 0.1058 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.5938\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6034 - val_loss: 0.1062 - val_auc: 0.9905 - val_accuracy: 0.9704 - val_cost: 3.6328\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6181 - val_loss: 0.1095 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.6751\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5823 - val_loss: 0.1066 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7500\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5536 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.9388\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6307 - val_loss: 0.1071 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.4635\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6311 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.8346\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.5973 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.6849\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5777 - val_loss: 0.1073 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.9062\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5606 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.6719\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5611 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.5612\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5678 - val_loss: 0.1103 - val_auc: 0.9901 - val_accuracy: 0.9693 - val_cost: 3.7565\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5240 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6145 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.7695\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5804 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9698 - val_cost: 3.7109\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6046 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.7467\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5032 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9698 - val_cost: 3.7077\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5443 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9700 - val_cost: 3.5807\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9952 - accuracy: 0.9806 - cost: 2.4727 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.4505\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4808 - val_loss: 0.1085 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.6198\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5472 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.5742\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5074 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9062\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4944 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8867\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5101 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5124\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9952 - accuracy: 0.9805 - cost: 2.4937 - val_loss: 0.1087 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.5547\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4975 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.5840\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5226 - val_loss: 0.1113 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.6133\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4758 - val_loss: 0.1123 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.6003\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5126 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6003\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4602 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4473\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4910 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6784\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4840 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.6556\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4579 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6100\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3952 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.4701\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5190 - val_loss: 0.1093 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.5807\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4296 - val_loss: 0.1107 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6328\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4116 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9809 - cost: 2.4393 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.4180\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4338 - val_loss: 0.1106 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9816 - cost: 2.3546 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.6263\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9813 - cost: 2.3856 - val_loss: 0.1122 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.6523\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3461 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.5579\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4369 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.6816\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4098 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.6328\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3770 - val_loss: 0.1130 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6035\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3782 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.5710\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.3909 - val_loss: 0.1113 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6198\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9816 - cost: 2.3637 - val_loss: 0.1125 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7272\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3405 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6849\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9955 - accuracy: 0.9813 - cost: 2.3907 - val_loss: 0.1117 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6751\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4127 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.5547\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3843 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5026\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3542 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5482\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3975 - val_loss: 0.1138 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.4473\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9821 - cost: 2.2952 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.7663\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3602 - val_loss: 0.1152 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3634 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.6979\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3220 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7077\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3298 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.7435\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3499 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5775\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3307 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7630\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3724 - val_loss: 0.1168 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6361\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3040 - val_loss: 0.1162 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7826\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3436 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7012\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3206 - val_loss: 0.1150 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5514\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3294 - val_loss: 0.1155 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.7891\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3357 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6230\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3114 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7663\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3202 - val_loss: 0.1154 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7142\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2772 - val_loss: 0.1179 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.6198\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3267 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7207\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2686 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2686 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5807\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3099 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9958 - accuracy: 0.9825 - cost: 2.2358 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.7077\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2518 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.4635\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2997 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.4538\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9958 - accuracy: 0.9825 - cost: 2.2440 - val_loss: 0.1180 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.5124\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3042 - val_loss: 0.1160 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2760 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.4993\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3200 - val_loss: 0.1165 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.4928\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2569 - val_loss: 0.1178 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6165\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2740 - val_loss: 0.1163 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.5384\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2795 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.3268\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2463 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.5547\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2511 - val_loss: 0.1192 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.4082\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2471 - val_loss: 0.1182 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.6589\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2392 - val_loss: 0.1169 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.4245\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2458 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.4701\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2954 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.5352\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2480 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.6393\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2456 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.5775\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2682 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.4928\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0602 - auc: 0.9959 - accuracy: 0.9828 - cost: 2.2094 - val_loss: 0.1157 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5221\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2924 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5970\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0590 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2011 - val_loss: 0.1176 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.5905\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2383 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5319\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9960 - accuracy: 0.9828 - cost: 2.1984 - val_loss: 0.1176 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.5840\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2381 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.3724\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2047 - val_loss: 0.1200 - val_auc: 0.9895 - val_accuracy: 0.9696 - val_cost: 3.6556\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2387 - val_loss: 0.1196 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.3561\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1900 - val_loss: 0.1163 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6198\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2115 - val_loss: 0.1181 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.6979\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9826 - cost: 2.2314 - val_loss: 0.1197 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7272\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9833 - cost: 2.1474 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.5872\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2337 - val_loss: 0.1183 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6296\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1999 - val_loss: 0.1182 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.6165\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1696 - val_loss: 0.1224 - val_auc: 0.9889 - val_accuracy: 0.9698 - val_cost: 3.6426\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.1962 - val_loss: 0.1199 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.4961\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9826 - cost: 2.2406 - val_loss: 0.1185 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.5547\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2432 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.3073\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2085 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.3789\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2053 - val_loss: 0.1209 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.4603\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2211 - val_loss: 0.1169 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.3203\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1698 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.3984\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2383 - val_loss: 0.1187 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5775\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0589 - auc: 0.9961 - accuracy: 0.9831 - cost: 2.1576 - val_loss: 0.1203 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6003\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1495 - val_loss: 0.1201 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.4375\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2198 - val_loss: 0.1191 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5254\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.1973 - val_loss: 0.1212 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.6003\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1971 - val_loss: 0.1214 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.4798\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.2001 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5547\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1222 - val_loss: 0.1217 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.6361\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1735 - val_loss: 0.1206 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 3.8509\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2458 - val_loss: 0.1200 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.2780\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2013 - val_loss: 0.1206 - val_auc: 0.9889 - val_accuracy: 0.9707 - val_cost: 3.3952\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1655 - val_loss: 0.1196 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5059\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1781 - val_loss: 0.1201 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6133\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1670 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9711 - val_cost: 3.3919\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2084 - val_loss: 0.1222 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4082\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1516 - val_loss: 0.1237 - val_auc: 0.9888 - val_accuracy: 0.9703 - val_cost: 3.6198\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2229 - val_loss: 0.1246 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.7044\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2169 - val_loss: 0.1204 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.3984\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1486 - val_loss: 0.1211 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4375\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1817 - val_loss: 0.1219 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.3757\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1486 - val_loss: 0.1251 - val_auc: 0.9889 - val_accuracy: 0.9713 - val_cost: 3.3919\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1684 - val_loss: 0.1193 - val_auc: 0.9890 - val_accuracy: 0.9713 - val_cost: 3.5547\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1164 - val_loss: 0.1235 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.4505\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9963 - accuracy: 0.9836 - cost: 2.1056 - val_loss: 0.1219 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.5775\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1499 - val_loss: 0.1194 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5612\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0570 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1392 - val_loss: 0.1226 - val_auc: 0.9891 - val_accuracy: 0.9705 - val_cost: 3.5905\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1423 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9703 - val_cost: 3.5091\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1478 - val_loss: 0.1226 - val_auc: 0.9888 - val_accuracy: 0.9717 - val_cost: 3.2650\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2147 - val_loss: 0.1206 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.5514\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.1066 - val_loss: 0.1220 - val_auc: 0.9891 - val_accuracy: 0.9711 - val_cost: 3.5840\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1473 - val_loss: 0.1220 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.1868\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1951 - val_loss: 0.1244 - val_auc: 0.9888 - val_accuracy: 0.9716 - val_cost: 3.3464\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1094 - val_loss: 0.1227 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.4277\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2148 - val_loss: 0.1254 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.4115\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1495 - val_loss: 0.1235 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.3431\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1847 - val_loss: 0.1225 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.6458\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1067 - val_loss: 0.1227 - val_auc: 0.9888 - val_accuracy: 0.9702 - val_cost: 3.4733\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1294 - val_loss: 0.1235 - val_auc: 0.9889 - val_accuracy: 0.9714 - val_cost: 3.3626\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1419 - val_loss: 0.1233 - val_auc: 0.9887 - val_accuracy: 0.9709 - val_cost: 3.4375\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1610 - val_loss: 0.1227 - val_auc: 0.9889 - val_accuracy: 0.9715 - val_cost: 3.3724\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1446 - val_loss: 0.1247 - val_auc: 0.9888 - val_accuracy: 0.9719 - val_cost: 3.4798\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.1150 - val_loss: 0.1225 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5514\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1410 - val_loss: 0.1252 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9834 - cost: 2.1332 - val_loss: 0.1231 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.6393\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1143 - val_loss: 0.1233 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.3366\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1271 - val_loss: 0.1253 - val_auc: 0.9886 - val_accuracy: 0.9710 - val_cost: 3.5970\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1241 - val_loss: 0.1231 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.8444\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1550 - val_loss: 0.1248 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.6654\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1818 - val_loss: 0.1222 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.3594\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1040 - val_loss: 0.1208 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.5417\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1741 - val_loss: 0.1239 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.4928\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9839 - cost: 2.0581 - val_loss: 0.1247 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.6003\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0556 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1000 - val_loss: 0.1259 - val_auc: 0.9886 - val_accuracy: 0.9714 - val_cost: 3.3659\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0870 - val_loss: 0.1245 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.6263\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1585 - val_loss: 0.1192 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.5905\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0950 - val_loss: 0.1231 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.0978 - val_loss: 0.1241 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.3366\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1206 - val_loss: 0.1238 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6263\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9964 - accuracy: 0.9837 - cost: 2.0903 - val_loss: 0.1248 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.4375\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0944 - val_loss: 0.1247 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.6165\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9839 - cost: 2.0682 - val_loss: 0.1263 - val_auc: 0.9885 - val_accuracy: 0.9717 - val_cost: 3.3040\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0698 - val_loss: 0.1249 - val_auc: 0.9888 - val_accuracy: 0.9709 - val_cost: 3.4147\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9839 - cost: 2.0770 - val_loss: 0.1255 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.3984\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1303 - val_loss: 0.1220 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.7174\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1228 - val_loss: 0.1230 - val_auc: 0.9888 - val_accuracy: 0.9707 - val_cost: 3.7858\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0947 - val_loss: 0.1245 - val_auc: 0.9888 - val_accuracy: 0.9718 - val_cost: 3.3171\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9965 - accuracy: 0.9840 - cost: 2.0508 - val_loss: 0.1257 - val_auc: 0.9888 - val_accuracy: 0.9700 - val_cost: 3.4928\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1182 - val_loss: 0.1258 - val_auc: 0.9885 - val_accuracy: 0.9709 - val_cost: 3.5514\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1402 - val_loss: 0.1255 - val_auc: 0.9887 - val_accuracy: 0.9711 - val_cost: 3.7728\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0657 - val_loss: 0.1255 - val_auc: 0.9889 - val_accuracy: 0.9710 - val_cost: 3.5645\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1069 - val_loss: 0.1237 - val_auc: 0.9886 - val_accuracy: 0.9708 - val_cost: 3.6296\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0408 - val_loss: 0.1276 - val_auc: 0.9885 - val_accuracy: 0.9716 - val_cost: 3.2910\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0712 - val_loss: 0.1251 - val_auc: 0.9888 - val_accuracy: 0.9709 - val_cost: 3.7598\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0549 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0695 - val_loss: 0.1251 - val_auc: 0.9886 - val_accuracy: 0.9712 - val_cost: 3.7109\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1000 - val_loss: 0.1260 - val_auc: 0.9887 - val_accuracy: 0.9710 - val_cost: 3.4049\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0845 - val_loss: 0.1270 - val_auc: 0.9887 - val_accuracy: 0.9702 - val_cost: 3.8053\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1034 - val_loss: 0.1241 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0592 - val_loss: 0.1275 - val_auc: 0.9887 - val_accuracy: 0.9710 - val_cost: 3.6458\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0944 - val_loss: 0.1256 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.3464\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9967 - accuracy: 0.9843 - cost: 2.0084 - val_loss: 0.1237 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.5938\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0425 - val_loss: 0.1275 - val_auc: 0.9887 - val_accuracy: 0.9713 - val_cost: 3.5807\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1087 - auc: 0.9907 - accuracy: 0.9729 - cost: 3.3125\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:48.238908\n",
            "fold accuracy: 0.9728749990463257 - fold cost: 3.3125\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5248 - auc: 0.8028 - accuracy: 0.7316 - cost: 35.6820 - val_loss: 0.3935 - val_auc: 0.9015 - val_accuracy: 0.8296 - val_cost: 21.7448\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3482 - auc: 0.9230 - accuracy: 0.8514 - cost: 18.8781 - val_loss: 0.3188 - val_auc: 0.9356 - val_accuracy: 0.8639 - val_cost: 16.3346\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3000 - auc: 0.9430 - accuracy: 0.8759 - cost: 15.7019 - val_loss: 0.2867 - val_auc: 0.9481 - val_accuracy: 0.8817 - val_cost: 14.4857\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2710 - auc: 0.9536 - accuracy: 0.8898 - cost: 13.9502 - val_loss: 0.2623 - val_auc: 0.9564 - val_accuracy: 0.8950 - val_cost: 12.6595\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2478 - auc: 0.9613 - accuracy: 0.9013 - cost: 12.4837 - val_loss: 0.2422 - val_auc: 0.9630 - val_accuracy: 0.9055 - val_cost: 11.5365\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2291 - auc: 0.9668 - accuracy: 0.9106 - cost: 11.3212 - val_loss: 0.2255 - val_auc: 0.9679 - val_accuracy: 0.9133 - val_cost: 10.6315\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2134 - auc: 0.9711 - accuracy: 0.9175 - cost: 10.4380 - val_loss: 0.2123 - val_auc: 0.9714 - val_accuracy: 0.9203 - val_cost: 9.8438\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2008 - auc: 0.9743 - accuracy: 0.9236 - cost: 9.6841 - val_loss: 0.2010 - val_auc: 0.9743 - val_accuracy: 0.9265 - val_cost: 9.1471\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1893 - auc: 0.9770 - accuracy: 0.9286 - cost: 9.0206 - val_loss: 0.1917 - val_auc: 0.9766 - val_accuracy: 0.9312 - val_cost: 8.4603\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1808 - auc: 0.9789 - accuracy: 0.9324 - cost: 8.5440 - val_loss: 0.1827 - val_auc: 0.9783 - val_accuracy: 0.9347 - val_cost: 8.1055\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1727 - auc: 0.9806 - accuracy: 0.9364 - cost: 8.0657 - val_loss: 0.1762 - val_auc: 0.9797 - val_accuracy: 0.9365 - val_cost: 8.0306\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1660 - auc: 0.9820 - accuracy: 0.9392 - cost: 7.6971 - val_loss: 0.1726 - val_auc: 0.9809 - val_accuracy: 0.9384 - val_cost: 7.4512\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1592 - auc: 0.9833 - accuracy: 0.9423 - cost: 7.3040 - val_loss: 0.1654 - val_auc: 0.9820 - val_accuracy: 0.9415 - val_cost: 7.5423\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1550 - auc: 0.9840 - accuracy: 0.9450 - cost: 6.9662 - val_loss: 0.1619 - val_auc: 0.9825 - val_accuracy: 0.9424 - val_cost: 7.1810\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1499 - auc: 0.9850 - accuracy: 0.9471 - cost: 6.7105 - val_loss: 0.1574 - val_auc: 0.9834 - val_accuracy: 0.9449 - val_cost: 6.9336\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1457 - auc: 0.9857 - accuracy: 0.9493 - cost: 6.4207 - val_loss: 0.1547 - val_auc: 0.9840 - val_accuracy: 0.9458 - val_cost: 6.8978\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1422 - auc: 0.9863 - accuracy: 0.9503 - cost: 6.2907 - val_loss: 0.1516 - val_auc: 0.9845 - val_accuracy: 0.9467 - val_cost: 6.7904\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1397 - auc: 0.9867 - accuracy: 0.9516 - cost: 6.1308 - val_loss: 0.1499 - val_auc: 0.9850 - val_accuracy: 0.9481 - val_cost: 7.0931\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1369 - auc: 0.9871 - accuracy: 0.9525 - cost: 6.0408 - val_loss: 0.1461 - val_auc: 0.9855 - val_accuracy: 0.9480 - val_cost: 6.8392\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1338 - auc: 0.9876 - accuracy: 0.9543 - cost: 5.7999 - val_loss: 0.1472 - val_auc: 0.9855 - val_accuracy: 0.9488 - val_cost: 6.2891\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1316 - auc: 0.9879 - accuracy: 0.9550 - cost: 5.6977 - val_loss: 0.1423 - val_auc: 0.9860 - val_accuracy: 0.9509 - val_cost: 6.4616\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1287 - auc: 0.9884 - accuracy: 0.9561 - cost: 5.5623 - val_loss: 0.1408 - val_auc: 0.9861 - val_accuracy: 0.9517 - val_cost: 6.3477\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1262 - auc: 0.9887 - accuracy: 0.9571 - cost: 5.4491 - val_loss: 0.1381 - val_auc: 0.9866 - val_accuracy: 0.9533 - val_cost: 5.9440\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9889 - accuracy: 0.9573 - cost: 5.4224 - val_loss: 0.1372 - val_auc: 0.9867 - val_accuracy: 0.9543 - val_cost: 5.8464\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1217 - auc: 0.9894 - accuracy: 0.9592 - cost: 5.1739 - val_loss: 0.1356 - val_auc: 0.9871 - val_accuracy: 0.9545 - val_cost: 5.8464\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1199 - auc: 0.9896 - accuracy: 0.9599 - cost: 5.0925 - val_loss: 0.1335 - val_auc: 0.9872 - val_accuracy: 0.9551 - val_cost: 5.9505\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1177 - auc: 0.9899 - accuracy: 0.9604 - cost: 5.0145 - val_loss: 0.1326 - val_auc: 0.9874 - val_accuracy: 0.9572 - val_cost: 5.4297\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1166 - auc: 0.9900 - accuracy: 0.9615 - cost: 4.8750 - val_loss: 0.1308 - val_auc: 0.9875 - val_accuracy: 0.9576 - val_cost: 5.5436\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1149 - auc: 0.9903 - accuracy: 0.9619 - cost: 4.8242 - val_loss: 0.1296 - val_auc: 0.9878 - val_accuracy: 0.9572 - val_cost: 5.3548\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1119 - auc: 0.9906 - accuracy: 0.9639 - cost: 4.5905 - val_loss: 0.1295 - val_auc: 0.9878 - val_accuracy: 0.9582 - val_cost: 5.3320\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1101 - auc: 0.9908 - accuracy: 0.9642 - cost: 4.5284 - val_loss: 0.1268 - val_auc: 0.9880 - val_accuracy: 0.9592 - val_cost: 5.1823\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1093 - auc: 0.9909 - accuracy: 0.9647 - cost: 4.4854 - val_loss: 0.1270 - val_auc: 0.9879 - val_accuracy: 0.9588 - val_cost: 5.2474\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1069 - auc: 0.9912 - accuracy: 0.9652 - cost: 4.4179 - val_loss: 0.1238 - val_auc: 0.9882 - val_accuracy: 0.9603 - val_cost: 5.0163\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1050 - auc: 0.9915 - accuracy: 0.9665 - cost: 4.2690 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9605 - val_cost: 5.0163\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1045 - auc: 0.9915 - accuracy: 0.9670 - cost: 4.1943 - val_loss: 0.1219 - val_auc: 0.9884 - val_accuracy: 0.9613 - val_cost: 5.0000\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1025 - auc: 0.9917 - accuracy: 0.9670 - cost: 4.1744 - val_loss: 0.1209 - val_auc: 0.9888 - val_accuracy: 0.9622 - val_cost: 4.7070\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9676 - cost: 4.1093 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9628 - val_cost: 4.6810\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0996 - auc: 0.9920 - accuracy: 0.9684 - cost: 4.0186 - val_loss: 0.1189 - val_auc: 0.9888 - val_accuracy: 0.9633 - val_cost: 4.5671\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9921 - accuracy: 0.9687 - cost: 3.9932 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9632 - val_cost: 4.6224\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0980 - auc: 0.9922 - accuracy: 0.9690 - cost: 3.9401 - val_loss: 0.1181 - val_auc: 0.9888 - val_accuracy: 0.9639 - val_cost: 4.5996\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0960 - auc: 0.9924 - accuracy: 0.9695 - cost: 3.8766 - val_loss: 0.1162 - val_auc: 0.9890 - val_accuracy: 0.9644 - val_cost: 4.5833\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0967 - auc: 0.9922 - accuracy: 0.9695 - cost: 3.9001 - val_loss: 0.1156 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.2578\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9927 - accuracy: 0.9705 - cost: 3.7464 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9645 - val_cost: 4.4987\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9709 - cost: 3.6980 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9658 - val_cost: 4.3652\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9928 - accuracy: 0.9716 - cost: 3.6137 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9665 - val_cost: 4.2741\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9712 - cost: 3.6792 - val_loss: 0.1138 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.1341\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9929 - accuracy: 0.9718 - cost: 3.5994 - val_loss: 0.1123 - val_auc: 0.9894 - val_accuracy: 0.9669 - val_cost: 4.1243\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9930 - accuracy: 0.9724 - cost: 3.5219 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.1764\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9930 - accuracy: 0.9722 - cost: 3.5469 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.3327\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9728 - cost: 3.4736 - val_loss: 0.1109 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 4.0658\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0873 - auc: 0.9932 - accuracy: 0.9730 - cost: 3.4343 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 4.0820\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9732 - cost: 3.4213 - val_loss: 0.1095 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 4.0625\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9733 - cost: 3.4040 - val_loss: 0.1096 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 4.0755\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9937 - accuracy: 0.9736 - cost: 3.3722 - val_loss: 0.1093 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 4.1243\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9935 - accuracy: 0.9743 - cost: 3.2814 - val_loss: 0.1083 - val_auc: 0.9900 - val_accuracy: 0.9683 - val_cost: 4.0104\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2657 - val_loss: 0.1079 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 4.0690\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9936 - accuracy: 0.9740 - cost: 3.3088 - val_loss: 0.1081 - val_auc: 0.9900 - val_accuracy: 0.9680 - val_cost: 4.0365\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.2006 - val_loss: 0.1086 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7988\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1806 - val_loss: 0.1074 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.9421\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9937 - accuracy: 0.9749 - cost: 3.1917 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9683 - val_cost: 4.1081\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1521 - val_loss: 0.1076 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.8411\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9937 - accuracy: 0.9753 - cost: 3.1517 - val_loss: 0.1069 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 3.9941\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0710 - val_loss: 0.1073 - val_auc: 0.9898 - val_accuracy: 0.9695 - val_cost: 3.8314\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.0939 - val_loss: 0.1059 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.9909\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9765 - cost: 3.0057 - val_loss: 0.1063 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.7598\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0707 - val_loss: 0.1068 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7435\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.0935 - val_loss: 0.1047 - val_auc: 0.9905 - val_accuracy: 0.9694 - val_cost: 3.9062\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9767 - cost: 2.9792 - val_loss: 0.1054 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.7435\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9220 - val_loss: 0.1066 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.8542\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9767 - cost: 2.9725 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9704 - val_cost: 3.7500\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9821 - val_loss: 0.1041 - val_auc: 0.9903 - val_accuracy: 0.9708 - val_cost: 3.7174\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9314 - val_loss: 0.1049 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.9844\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9175 - val_loss: 0.1048 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 4.0007\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9451 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.8639\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9044 - val_loss: 0.1059 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.7760\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8611 - val_loss: 0.1052 - val_auc: 0.9904 - val_accuracy: 0.9700 - val_cost: 3.8021\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8643 - val_loss: 0.1055 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8411\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8728 - val_loss: 0.1055 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.7077\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8354 - val_loss: 0.1059 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.7500\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8375 - val_loss: 0.1051 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.8346\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8414 - val_loss: 0.1057 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.7337\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7750 - val_loss: 0.1050 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.9258\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8104 - val_loss: 0.1055 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7663\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7386 - val_loss: 0.1064 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.6198\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7667 - val_loss: 0.1067 - val_auc: 0.9903 - val_accuracy: 0.9690 - val_cost: 4.0592\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7917 - val_loss: 0.1061 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.8086\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7463 - val_loss: 0.1043 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.7337\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7359 - val_loss: 0.1057 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.7565\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7028 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.8151\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7219 - val_loss: 0.1051 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 3.8542\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7048 - val_loss: 0.1053 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.6035\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7180 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.7305\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7216 - val_loss: 0.1046 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6784\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6841 - val_loss: 0.1050 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.7044\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.7046 - val_loss: 0.1050 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7142\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6601 - val_loss: 0.1044 - val_auc: 0.9904 - val_accuracy: 0.9718 - val_cost: 3.6230\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6248 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.6979\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6613 - val_loss: 0.1053 - val_auc: 0.9902 - val_accuracy: 0.9713 - val_cost: 3.7500\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6818 - val_loss: 0.1052 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.6849\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6173 - val_loss: 0.1063 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.8704\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0689 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6262 - val_loss: 0.1053 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.7207\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6339 - val_loss: 0.1072 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5547\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6108 - val_loss: 0.1057 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.7630\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5582 - val_loss: 0.1046 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.6523\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5861 - val_loss: 0.1046 - val_auc: 0.9903 - val_accuracy: 0.9723 - val_cost: 3.5059\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5984 - val_loss: 0.1042 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.9551\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5763 - val_loss: 0.1044 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.7305\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5949 - val_loss: 0.1039 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.7044\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5362 - val_loss: 0.1052 - val_auc: 0.9906 - val_accuracy: 0.9710 - val_cost: 3.6328\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5766 - val_loss: 0.1039 - val_auc: 0.9902 - val_accuracy: 0.9716 - val_cost: 3.6556\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5134 - val_loss: 0.1058 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7272\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5344 - val_loss: 0.1040 - val_auc: 0.9903 - val_accuracy: 0.9726 - val_cost: 3.5449\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5541 - val_loss: 0.1053 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.5938\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5743 - val_loss: 0.1063 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.9714\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5896 - val_loss: 0.1068 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.3431\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5137 - val_loss: 0.1073 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.8867\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9951 - accuracy: 0.9803 - cost: 2.5229 - val_loss: 0.1055 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.4993\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5281 - val_loss: 0.1060 - val_auc: 0.9900 - val_accuracy: 0.9728 - val_cost: 3.4863\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5503 - val_loss: 0.1069 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.9421\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5325 - val_loss: 0.1065 - val_auc: 0.9901 - val_accuracy: 0.9721 - val_cost: 3.5612\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.5065 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5254\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4891 - val_loss: 0.1058 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.8314\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4944 - val_loss: 0.1077 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.8281\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4206 - val_loss: 0.1051 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.7891\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5127 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9730 - val_cost: 3.5059\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9810 - cost: 2.4426 - val_loss: 0.1082 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.7272\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4587 - val_loss: 0.1078 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.6816\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4479 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.6491\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4383 - val_loss: 0.1064 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 4.0430\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4725 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6230\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4992 - val_loss: 0.1088 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.6621\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4232 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.9876\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9954 - accuracy: 0.9812 - cost: 2.4152 - val_loss: 0.1072 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.9844\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3882 - val_loss: 0.1076 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.9323\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4224 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.8965\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3853 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.9551\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4505 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.3789\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.4265 - val_loss: 0.1084 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.4538\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4266 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 4.1146\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4503 - val_loss: 0.1088 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.7793\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4446 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.8477\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3910 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 4.0202\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.4009 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.6230\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3685 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.9681\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4114 - val_loss: 0.1082 - val_auc: 0.9900 - val_accuracy: 0.9726 - val_cost: 3.7435\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4004 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.9323\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9816 - cost: 2.3586 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.9355\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3691 - val_loss: 0.1101 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.8053\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4391 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 4.1276\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4159 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5905\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3734 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.7402\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3413 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.7565\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3556 - val_loss: 0.1081 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.8086\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3804 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.9225\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3455 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.6979\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3581 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6198\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3552 - val_loss: 0.1089 - val_auc: 0.9900 - val_accuracy: 0.9723 - val_cost: 3.8574\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3598 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9727 - val_cost: 3.8477\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3290 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.9095\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3398 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 4.0072\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3933 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.8477\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9823 - cost: 2.2735 - val_loss: 0.1103 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.9844\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3444 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.6198\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3523 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.7435\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2847 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.8672\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1052 - auc: 0.9912 - accuracy: 0.9690 - cost: 3.8531\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:35.150792\n",
            "fold accuracy: 0.968999981880188 - fold cost: 3.8531250953674316\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5245 - auc: 0.8034 - accuracy: 0.7324 - cost: 35.5634 - val_loss: 0.3908 - val_auc: 0.9022 - val_accuracy: 0.8295 - val_cost: 21.8424\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3472 - auc: 0.9235 - accuracy: 0.8508 - cost: 18.9853 - val_loss: 0.3141 - val_auc: 0.9372 - val_accuracy: 0.8643 - val_cost: 16.5885\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2996 - auc: 0.9433 - accuracy: 0.8760 - cost: 15.6933 - val_loss: 0.2848 - val_auc: 0.9489 - val_accuracy: 0.8815 - val_cost: 14.2090\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2705 - auc: 0.9538 - accuracy: 0.8899 - cost: 13.9156 - val_loss: 0.2607 - val_auc: 0.9570 - val_accuracy: 0.8947 - val_cost: 12.9688\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2474 - auc: 0.9614 - accuracy: 0.9005 - cost: 12.5905 - val_loss: 0.2423 - val_auc: 0.9629 - val_accuracy: 0.9051 - val_cost: 11.4323\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2282 - auc: 0.9671 - accuracy: 0.9100 - cost: 11.3999 - val_loss: 0.2266 - val_auc: 0.9675 - val_accuracy: 0.9113 - val_cost: 10.7845\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2125 - auc: 0.9714 - accuracy: 0.9180 - cost: 10.3666 - val_loss: 0.2127 - val_auc: 0.9715 - val_accuracy: 0.9203 - val_cost: 9.9382\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1995 - auc: 0.9747 - accuracy: 0.9235 - cost: 9.6798 - val_loss: 0.2014 - val_auc: 0.9742 - val_accuracy: 0.9262 - val_cost: 8.9355\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1883 - auc: 0.9773 - accuracy: 0.9291 - cost: 8.9792 - val_loss: 0.1926 - val_auc: 0.9763 - val_accuracy: 0.9317 - val_cost: 8.1706\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1784 - auc: 0.9794 - accuracy: 0.9343 - cost: 8.3300 - val_loss: 0.1849 - val_auc: 0.9779 - val_accuracy: 0.9343 - val_cost: 8.1771\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1714 - auc: 0.9809 - accuracy: 0.9366 - cost: 8.0238 - val_loss: 0.1780 - val_auc: 0.9791 - val_accuracy: 0.9355 - val_cost: 8.2064\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1651 - auc: 0.9821 - accuracy: 0.9394 - cost: 7.6851 - val_loss: 0.1729 - val_auc: 0.9803 - val_accuracy: 0.9393 - val_cost: 7.7539\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1592 - auc: 0.9833 - accuracy: 0.9424 - cost: 7.3047 - val_loss: 0.1688 - val_auc: 0.9811 - val_accuracy: 0.9416 - val_cost: 7.3307\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1543 - auc: 0.9842 - accuracy: 0.9447 - cost: 7.0006 - val_loss: 0.1646 - val_auc: 0.9820 - val_accuracy: 0.9424 - val_cost: 6.9661\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1501 - auc: 0.9850 - accuracy: 0.9463 - cost: 6.7975 - val_loss: 0.1607 - val_auc: 0.9826 - val_accuracy: 0.9453 - val_cost: 6.6992\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1455 - auc: 0.9857 - accuracy: 0.9487 - cost: 6.5013 - val_loss: 0.1575 - val_auc: 0.9832 - val_accuracy: 0.9460 - val_cost: 6.6634\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1431 - auc: 0.9861 - accuracy: 0.9499 - cost: 6.3632 - val_loss: 0.1566 - val_auc: 0.9838 - val_accuracy: 0.9457 - val_cost: 6.4648\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1396 - auc: 0.9868 - accuracy: 0.9508 - cost: 6.2422 - val_loss: 0.1527 - val_auc: 0.9841 - val_accuracy: 0.9469 - val_cost: 6.4876\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1370 - auc: 0.9871 - accuracy: 0.9521 - cost: 6.0624 - val_loss: 0.1504 - val_auc: 0.9844 - val_accuracy: 0.9491 - val_cost: 6.2272\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1335 - auc: 0.9876 - accuracy: 0.9540 - cost: 5.8269 - val_loss: 0.1489 - val_auc: 0.9848 - val_accuracy: 0.9501 - val_cost: 6.2760\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1312 - auc: 0.9881 - accuracy: 0.9550 - cost: 5.7029 - val_loss: 0.1473 - val_auc: 0.9849 - val_accuracy: 0.9504 - val_cost: 6.2305\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1295 - auc: 0.9883 - accuracy: 0.9556 - cost: 5.6223 - val_loss: 0.1451 - val_auc: 0.9855 - val_accuracy: 0.9517 - val_cost: 5.8822\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1262 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4365 - val_loss: 0.1434 - val_auc: 0.9857 - val_accuracy: 0.9527 - val_cost: 5.6087\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9890 - accuracy: 0.9568 - cost: 5.4855 - val_loss: 0.1418 - val_auc: 0.9859 - val_accuracy: 0.9531 - val_cost: 5.7292\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1229 - auc: 0.9892 - accuracy: 0.9583 - cost: 5.2637 - val_loss: 0.1405 - val_auc: 0.9859 - val_accuracy: 0.9550 - val_cost: 5.6152\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1204 - auc: 0.9896 - accuracy: 0.9594 - cost: 5.1440 - val_loss: 0.1385 - val_auc: 0.9861 - val_accuracy: 0.9557 - val_cost: 5.5176\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1185 - auc: 0.9899 - accuracy: 0.9602 - cost: 5.0428 - val_loss: 0.1384 - val_auc: 0.9861 - val_accuracy: 0.9563 - val_cost: 5.4915\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1168 - auc: 0.9900 - accuracy: 0.9614 - cost: 4.9026 - val_loss: 0.1343 - val_auc: 0.9867 - val_accuracy: 0.9570 - val_cost: 5.3613\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1151 - auc: 0.9903 - accuracy: 0.9617 - cost: 4.8503 - val_loss: 0.1342 - val_auc: 0.9868 - val_accuracy: 0.9580 - val_cost: 5.2409\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1134 - auc: 0.9905 - accuracy: 0.9628 - cost: 4.7107 - val_loss: 0.1323 - val_auc: 0.9872 - val_accuracy: 0.9583 - val_cost: 5.2702\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1125 - auc: 0.9906 - accuracy: 0.9634 - cost: 4.6480 - val_loss: 0.1308 - val_auc: 0.9872 - val_accuracy: 0.9595 - val_cost: 4.8893\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1101 - auc: 0.9909 - accuracy: 0.9641 - cost: 4.5555 - val_loss: 0.1307 - val_auc: 0.9872 - val_accuracy: 0.9595 - val_cost: 5.1823\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1090 - auc: 0.9910 - accuracy: 0.9643 - cost: 4.5155 - val_loss: 0.1270 - val_auc: 0.9878 - val_accuracy: 0.9612 - val_cost: 4.9349\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9913 - accuracy: 0.9652 - cost: 4.4118 - val_loss: 0.1284 - val_auc: 0.9872 - val_accuracy: 0.9609 - val_cost: 4.8861\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1054 - auc: 0.9915 - accuracy: 0.9656 - cost: 4.3746 - val_loss: 0.1264 - val_auc: 0.9879 - val_accuracy: 0.9615 - val_cost: 4.7982\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1041 - auc: 0.9916 - accuracy: 0.9664 - cost: 4.2689 - val_loss: 0.1262 - val_auc: 0.9877 - val_accuracy: 0.9620 - val_cost: 4.5443\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1022 - auc: 0.9919 - accuracy: 0.9668 - cost: 4.2177 - val_loss: 0.1246 - val_auc: 0.9880 - val_accuracy: 0.9610 - val_cost: 4.7070\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1019 - auc: 0.9917 - accuracy: 0.9674 - cost: 4.1435 - val_loss: 0.1245 - val_auc: 0.9879 - val_accuracy: 0.9615 - val_cost: 4.6224\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1004 - auc: 0.9920 - accuracy: 0.9679 - cost: 4.0735 - val_loss: 0.1232 - val_auc: 0.9882 - val_accuracy: 0.9622 - val_cost: 4.5931\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0991 - auc: 0.9922 - accuracy: 0.9685 - cost: 4.0042 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9642 - val_cost: 4.4076\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9690 - cost: 3.9243 - val_loss: 0.1224 - val_auc: 0.9882 - val_accuracy: 0.9635 - val_cost: 4.3392\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0979 - auc: 0.9923 - accuracy: 0.9690 - cost: 3.9187 - val_loss: 0.1204 - val_auc: 0.9885 - val_accuracy: 0.9633 - val_cost: 4.4238\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0966 - auc: 0.9923 - accuracy: 0.9697 - cost: 3.8371 - val_loss: 0.1198 - val_auc: 0.9885 - val_accuracy: 0.9647 - val_cost: 4.2904\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0952 - auc: 0.9925 - accuracy: 0.9699 - cost: 3.8163 - val_loss: 0.1192 - val_auc: 0.9887 - val_accuracy: 0.9639 - val_cost: 4.5215\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9927 - accuracy: 0.9704 - cost: 3.7653 - val_loss: 0.1177 - val_auc: 0.9887 - val_accuracy: 0.9653 - val_cost: 4.1960\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0931 - auc: 0.9927 - accuracy: 0.9709 - cost: 3.6889 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9645 - val_cost: 4.3066\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6692 - val_loss: 0.1175 - val_auc: 0.9888 - val_accuracy: 0.9655 - val_cost: 4.1276\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9711 - cost: 3.6742 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9648 - val_cost: 4.2643\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9930 - accuracy: 0.9718 - cost: 3.5918 - val_loss: 0.1163 - val_auc: 0.9888 - val_accuracy: 0.9651 - val_cost: 4.3164\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9931 - accuracy: 0.9723 - cost: 3.5189 - val_loss: 0.1177 - val_auc: 0.9889 - val_accuracy: 0.9650 - val_cost: 4.1829\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9720 - cost: 3.5597 - val_loss: 0.1175 - val_auc: 0.9890 - val_accuracy: 0.9646 - val_cost: 4.1895\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9725 - cost: 3.5067 - val_loss: 0.1161 - val_auc: 0.9888 - val_accuracy: 0.9658 - val_cost: 4.1797\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9932 - accuracy: 0.9731 - cost: 3.4182 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.1341\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9934 - accuracy: 0.9724 - cost: 3.5128 - val_loss: 0.1149 - val_auc: 0.9890 - val_accuracy: 0.9658 - val_cost: 4.1471\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9933 - accuracy: 0.9733 - cost: 3.3962 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9668 - val_cost: 4.0625\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.4005 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9659 - val_cost: 4.0951\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9740 - cost: 3.2995 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9656 - val_cost: 4.2122\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9935 - accuracy: 0.9740 - cost: 3.2951 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9651 - val_cost: 4.2643\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9935 - accuracy: 0.9739 - cost: 3.3186 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.1602\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.3019 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 3.9258\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.2773 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9663 - val_cost: 4.3066\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2535 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9678 - val_cost: 3.7728\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9939 - accuracy: 0.9744 - cost: 3.2629 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.7044\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9752 - cost: 3.1627 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 3.9258\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9756 - cost: 3.1065 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 3.8965\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1601 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9679 - val_cost: 4.0918\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9756 - cost: 3.1123 - val_loss: 0.1122 - val_auc: 0.9892 - val_accuracy: 0.9683 - val_cost: 3.9062\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.0848 - val_loss: 0.1130 - val_auc: 0.9892 - val_accuracy: 0.9677 - val_cost: 3.8932\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1104 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9062\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0597 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 3.9779\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1079 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9675 - val_cost: 3.8118\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9763 - cost: 3.0266 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9684 - val_cost: 3.8346\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0368 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9673 - val_cost: 4.0234\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9761 - cost: 3.0414 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9669 - val_cost: 3.9941\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9765 - cost: 2.9978 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9676 - val_cost: 3.9225\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9586 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.8477\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9365 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.7891\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9766 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9684 - val_cost: 3.8477\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9000 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9673 - val_cost: 4.1732\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9172 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.7142\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9314 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9689 - val_cost: 3.7500\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8752 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.8900\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8504 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8021\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8852 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 3.8509\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8249 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9672 - val_cost: 3.9355\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9772 - cost: 2.9003 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 4.1536\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8298 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.7402\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8108 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.7858\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8246 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.9974\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7914 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9673 - val_cost: 3.9616\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8138 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7598\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7584 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.7272\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7562 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7207\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8087 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.7826\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7354 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.7109\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7153 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.6979\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7620 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.8770\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7511 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8835\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7302 - val_loss: 0.1125 - val_auc: 0.9892 - val_accuracy: 0.9692 - val_cost: 3.9258\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.6924 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.9030\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7394 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.8737\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6899 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.7207\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6806 - val_loss: 0.1180 - val_auc: 0.9891 - val_accuracy: 0.9680 - val_cost: 3.9160\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7277 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.8867\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6896 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.7272\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6606 - val_loss: 0.1153 - val_auc: 0.9889 - val_accuracy: 0.9688 - val_cost: 3.7077\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6926 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6263\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6606 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.7988\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6307 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.5840\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6335 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.7760\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6447 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.7793\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6070 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7728\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6389 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.5905\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5653 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.7012\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6306 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8314\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.5963 - val_loss: 0.1109 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7988\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.5972 - val_loss: 0.1137 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8802\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6117 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.8249\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6070 - val_loss: 0.1121 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7663\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6395 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.6003\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6013 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6979\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6063 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.9453\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5831 - val_loss: 0.1154 - val_auc: 0.9889 - val_accuracy: 0.9696 - val_cost: 3.8835\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6022 - val_loss: 0.1139 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.8770\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6008 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.8704\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5385 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7272\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5697 - val_loss: 0.1138 - val_auc: 0.9892 - val_accuracy: 0.9693 - val_cost: 3.9062\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5153 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.8086\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5443 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.7305\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9955 - accuracy: 0.9795 - cost: 2.6248 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5692 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.8281\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5022 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.8249\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5128 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7565\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5592 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9687 - val_cost: 3.9258\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5374 - val_loss: 0.1155 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8542\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5674 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.8053\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5190 - val_loss: 0.1170 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.9290\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4541 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.9225\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5169 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9695 - val_cost: 3.7923\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5038 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.6296\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5079 - val_loss: 0.1170 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.7663\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5156 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7891\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4841 - val_loss: 0.1165 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.8151\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.4939 - val_loss: 0.1168 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 3.9030\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4902 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9686 - val_cost: 3.9518\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4553 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.8802\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4979 - val_loss: 0.1181 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.8542\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4897 - val_loss: 0.1169 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.9225\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5201 - val_loss: 0.1196 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8639\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4435 - val_loss: 0.1183 - val_auc: 0.9891 - val_accuracy: 0.9693 - val_cost: 3.7012\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4309 - val_loss: 0.1190 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.8411\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4683 - val_loss: 0.1193 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.8281\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5238 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.8737\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5087 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7630\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4578 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7891\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4259 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9688 - val_cost: 3.8770\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4782 - val_loss: 0.1186 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.8086\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4102 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9693 - val_cost: 3.9030\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4156 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9698 - val_cost: 3.8216\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1058 - auc: 0.9909 - accuracy: 0.9684 - cost: 3.9094\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:32.192342\n",
            "fold accuracy: 0.968375027179718 - fold cost: 3.909374952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5262 - auc: 0.8018 - accuracy: 0.7322 - cost: 35.6144 - val_loss: 0.3912 - val_auc: 0.9032 - val_accuracy: 0.8283 - val_cost: 22.5618\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3475 - auc: 0.9233 - accuracy: 0.8508 - cost: 18.9736 - val_loss: 0.3163 - val_auc: 0.9363 - val_accuracy: 0.8650 - val_cost: 16.9564\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2981 - auc: 0.9437 - accuracy: 0.8762 - cost: 15.6666 - val_loss: 0.2866 - val_auc: 0.9479 - val_accuracy: 0.8798 - val_cost: 15.0618\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2695 - auc: 0.9541 - accuracy: 0.8910 - cost: 13.8050 - val_loss: 0.2597 - val_auc: 0.9574 - val_accuracy: 0.8953 - val_cost: 12.7767\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2464 - auc: 0.9617 - accuracy: 0.9010 - cost: 12.5296 - val_loss: 0.2399 - val_auc: 0.9636 - val_accuracy: 0.9072 - val_cost: 11.2044\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2267 - auc: 0.9675 - accuracy: 0.9113 - cost: 11.2259 - val_loss: 0.2239 - val_auc: 0.9681 - val_accuracy: 0.9135 - val_cost: 10.6510\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2117 - auc: 0.9716 - accuracy: 0.9182 - cost: 10.3138 - val_loss: 0.2095 - val_auc: 0.9720 - val_accuracy: 0.9223 - val_cost: 9.3978\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1981 - auc: 0.9750 - accuracy: 0.9245 - cost: 9.5459 - val_loss: 0.1991 - val_auc: 0.9752 - val_accuracy: 0.9253 - val_cost: 8.9518\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1875 - auc: 0.9775 - accuracy: 0.9292 - cost: 8.9565 - val_loss: 0.1875 - val_auc: 0.9775 - val_accuracy: 0.9315 - val_cost: 8.6458\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1785 - auc: 0.9794 - accuracy: 0.9333 - cost: 8.4431 - val_loss: 0.1788 - val_auc: 0.9792 - val_accuracy: 0.9358 - val_cost: 8.1185\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1698 - auc: 0.9812 - accuracy: 0.9373 - cost: 7.9345 - val_loss: 0.1736 - val_auc: 0.9804 - val_accuracy: 0.9374 - val_cost: 7.7214\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1639 - auc: 0.9823 - accuracy: 0.9408 - cost: 7.4764 - val_loss: 0.1674 - val_auc: 0.9815 - val_accuracy: 0.9413 - val_cost: 7.8418\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1581 - auc: 0.9835 - accuracy: 0.9434 - cost: 7.1871 - val_loss: 0.1638 - val_auc: 0.9822 - val_accuracy: 0.9427 - val_cost: 7.1322\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1520 - auc: 0.9846 - accuracy: 0.9459 - cost: 6.8526 - val_loss: 0.1587 - val_auc: 0.9831 - val_accuracy: 0.9454 - val_cost: 7.1159\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1490 - auc: 0.9851 - accuracy: 0.9473 - cost: 6.6754 - val_loss: 0.1556 - val_auc: 0.9838 - val_accuracy: 0.9465 - val_cost: 6.9661\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1462 - auc: 0.9856 - accuracy: 0.9483 - cost: 6.5529 - val_loss: 0.1517 - val_auc: 0.9846 - val_accuracy: 0.9476 - val_cost: 6.7936\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1412 - auc: 0.9864 - accuracy: 0.9509 - cost: 6.2193 - val_loss: 0.1502 - val_auc: 0.9847 - val_accuracy: 0.9485 - val_cost: 6.8652\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1391 - auc: 0.9868 - accuracy: 0.9514 - cost: 6.1750 - val_loss: 0.1494 - val_auc: 0.9850 - val_accuracy: 0.9494 - val_cost: 6.5462\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1361 - auc: 0.9873 - accuracy: 0.9525 - cost: 6.0056 - val_loss: 0.1465 - val_auc: 0.9853 - val_accuracy: 0.9493 - val_cost: 6.3509\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1330 - auc: 0.9878 - accuracy: 0.9538 - cost: 5.8510 - val_loss: 0.1435 - val_auc: 0.9859 - val_accuracy: 0.9522 - val_cost: 6.5039\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1306 - auc: 0.9882 - accuracy: 0.9551 - cost: 5.6759 - val_loss: 0.1416 - val_auc: 0.9863 - val_accuracy: 0.9519 - val_cost: 6.4714\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1276 - auc: 0.9885 - accuracy: 0.9561 - cost: 5.5844 - val_loss: 0.1401 - val_auc: 0.9864 - val_accuracy: 0.9536 - val_cost: 5.9505\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1256 - auc: 0.9889 - accuracy: 0.9574 - cost: 5.4027 - val_loss: 0.1381 - val_auc: 0.9868 - val_accuracy: 0.9540 - val_cost: 6.1816\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1239 - auc: 0.9891 - accuracy: 0.9580 - cost: 5.3253 - val_loss: 0.1391 - val_auc: 0.9866 - val_accuracy: 0.9557 - val_cost: 5.8171\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1217 - auc: 0.9895 - accuracy: 0.9587 - cost: 5.2629 - val_loss: 0.1360 - val_auc: 0.9869 - val_accuracy: 0.9549 - val_cost: 5.8887\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1204 - auc: 0.9896 - accuracy: 0.9595 - cost: 5.1546 - val_loss: 0.1349 - val_auc: 0.9870 - val_accuracy: 0.9578 - val_cost: 5.3711\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1184 - auc: 0.9898 - accuracy: 0.9605 - cost: 4.9890 - val_loss: 0.1333 - val_auc: 0.9871 - val_accuracy: 0.9567 - val_cost: 5.7910\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1165 - auc: 0.9902 - accuracy: 0.9605 - cost: 5.0109 - val_loss: 0.1326 - val_auc: 0.9872 - val_accuracy: 0.9573 - val_cost: 5.7487\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1151 - auc: 0.9903 - accuracy: 0.9618 - cost: 4.8504 - val_loss: 0.1320 - val_auc: 0.9875 - val_accuracy: 0.9582 - val_cost: 5.2637\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1142 - auc: 0.9904 - accuracy: 0.9621 - cost: 4.8054 - val_loss: 0.1304 - val_auc: 0.9876 - val_accuracy: 0.9583 - val_cost: 5.2148\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1117 - auc: 0.9907 - accuracy: 0.9636 - cost: 4.6220 - val_loss: 0.1289 - val_auc: 0.9879 - val_accuracy: 0.9588 - val_cost: 5.1042\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1111 - auc: 0.9907 - accuracy: 0.9635 - cost: 4.6151 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9608 - val_cost: 5.0358\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1089 - auc: 0.9911 - accuracy: 0.9648 - cost: 4.4821 - val_loss: 0.1270 - val_auc: 0.9879 - val_accuracy: 0.9606 - val_cost: 4.9089\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1075 - auc: 0.9913 - accuracy: 0.9647 - cost: 4.4845 - val_loss: 0.1268 - val_auc: 0.9882 - val_accuracy: 0.9608 - val_cost: 5.0846\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1060 - auc: 0.9914 - accuracy: 0.9655 - cost: 4.3784 - val_loss: 0.1259 - val_auc: 0.9883 - val_accuracy: 0.9614 - val_cost: 4.6191\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9917 - accuracy: 0.9657 - cost: 4.3562 - val_loss: 0.1275 - val_auc: 0.9883 - val_accuracy: 0.9614 - val_cost: 4.5833\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1044 - auc: 0.9916 - accuracy: 0.9660 - cost: 4.3063 - val_loss: 0.1251 - val_auc: 0.9880 - val_accuracy: 0.9618 - val_cost: 4.7819\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1029 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.1617 - val_loss: 0.1244 - val_auc: 0.9883 - val_accuracy: 0.9619 - val_cost: 4.5898\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1018 - auc: 0.9919 - accuracy: 0.9673 - cost: 4.1569 - val_loss: 0.1228 - val_auc: 0.9886 - val_accuracy: 0.9615 - val_cost: 4.8210\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1008 - auc: 0.9920 - accuracy: 0.9679 - cost: 4.0776 - val_loss: 0.1206 - val_auc: 0.9883 - val_accuracy: 0.9647 - val_cost: 4.3685\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0983 - auc: 0.9924 - accuracy: 0.9683 - cost: 4.0169 - val_loss: 0.1224 - val_auc: 0.9885 - val_accuracy: 0.9623 - val_cost: 4.5703\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9131 - val_loss: 0.1207 - val_auc: 0.9882 - val_accuracy: 0.9641 - val_cost: 4.4368\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0972 - auc: 0.9924 - accuracy: 0.9689 - cost: 3.9515 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9647 - val_cost: 4.3099\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0960 - auc: 0.9926 - accuracy: 0.9694 - cost: 3.8859 - val_loss: 0.1188 - val_auc: 0.9890 - val_accuracy: 0.9640 - val_cost: 4.3750\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0946 - auc: 0.9927 - accuracy: 0.9696 - cost: 3.8601 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9649 - val_cost: 4.4564\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9706 - cost: 3.7558 - val_loss: 0.1185 - val_auc: 0.9890 - val_accuracy: 0.9647 - val_cost: 4.2318\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9929 - accuracy: 0.9706 - cost: 3.7355 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9653 - val_cost: 4.2350\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9712 - cost: 3.6641 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9654 - val_cost: 4.2546\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9930 - accuracy: 0.9713 - cost: 3.6546 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9657 - val_cost: 4.2480\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0909 - auc: 0.9931 - accuracy: 0.9712 - cost: 3.6685 - val_loss: 0.1164 - val_auc: 0.9893 - val_accuracy: 0.9656 - val_cost: 4.1732\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9931 - accuracy: 0.9721 - cost: 3.5424 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9655 - val_cost: 4.2155\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9932 - accuracy: 0.9716 - cost: 3.6173 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9652 - val_cost: 4.4434\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5279 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9647 - val_cost: 4.2383\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9933 - accuracy: 0.9724 - cost: 3.5157 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9649 - val_cost: 4.3457\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4399 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9664 - val_cost: 4.3327\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4422 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9664 - val_cost: 4.1276\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9936 - accuracy: 0.9734 - cost: 3.3973 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.8835\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9734 - cost: 3.3867 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.0853\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9937 - accuracy: 0.9739 - cost: 3.3182 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 3.9225\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2122 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9665 - val_cost: 4.1341\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0842 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2931 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 3.9258\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2282 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 3.9616\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.2193 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.1341\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9749 - cost: 3.2040 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 4.0007\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9751 - cost: 3.1670 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9679 - val_cost: 3.9583\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9941 - accuracy: 0.9751 - cost: 3.1838 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 4.0072\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9756 - cost: 3.1061 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9685 - val_cost: 3.7728\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0629 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 3.8607\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0767 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9667 - val_cost: 4.0007\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0766 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9673 - val_cost: 4.1667\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0653 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9669 - val_cost: 3.9746\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0306 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 3.9876\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0307 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.9225\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0175 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9679 - val_cost: 3.9160\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9767 - cost: 2.9728 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9674 - val_cost: 4.0072\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9617 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.7565\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9768 - cost: 2.9609 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.9941\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9031 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 4.1471\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9607 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9693 - val_cost: 3.9518\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9337 - val_loss: 0.1083 - val_auc: 0.9899 - val_accuracy: 0.9692 - val_cost: 3.9779\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8594 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9388\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8463 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.8997\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8697 - val_loss: 0.1090 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 3.9518\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8930 - val_loss: 0.1095 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 4.1113\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8377 - val_loss: 0.1106 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 4.1699\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.9097 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 4.0853\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8321 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.8607\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8594 - val_loss: 0.1088 - val_auc: 0.9901 - val_accuracy: 0.9688 - val_cost: 3.9258\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8043 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.9616\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8239 - val_loss: 0.1081 - val_auc: 0.9901 - val_accuracy: 0.9691 - val_cost: 3.8477\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9777 - cost: 2.8502 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 3.9746\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7809 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.6751\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7809 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 4.1146\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7722 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 4.2188\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7963 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.8835\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7740 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 4.1504\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7589 - val_loss: 0.1083 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 4.1634\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7505 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.9128\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7501 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9648\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7251 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 4.0234\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7819 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 4.0137\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7128 - val_loss: 0.1088 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 4.1634\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6892 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7695\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6598 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 3.9811\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7310 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.7598\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6852 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.7207\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7215 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 4.0885\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7312 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.8867\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6504 - val_loss: 0.1117 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.7467\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6146 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9616\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6504 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.8770\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6358 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7533\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6327 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8900\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6204 - val_loss: 0.1085 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.8704\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5844 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 4.1211\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5969 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.9030\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5908 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.9518\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6070 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.8737\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5576 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.9518\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5996 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9687 - val_cost: 3.9160\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5912 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 4.0951\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5846 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9128\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5773 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8118\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5450 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 4.0365\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5181 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.7956\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6010 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7565\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5402 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.7923\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5155 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7077\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5203 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8509\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4826 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7305\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5077 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.8379\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5173 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5223 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8184\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4593 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.6849\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4802 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.7923\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5233 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9693 - val_cost: 3.9323\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5268 - val_loss: 0.1110 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8900\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4502 - val_loss: 0.1110 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8184\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4796 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.9225\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4362 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.7793\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4908 - val_loss: 0.1129 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.9746\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4565 - val_loss: 0.1095 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.8184\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4709 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.8900\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4042 - val_loss: 0.1108 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.9876\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4507 - val_loss: 0.1113 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.9128\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4328 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.8411\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4089 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.9290\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4604 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 4.0495\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3962 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 4.0755\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4662 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 4.0625\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4303 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9693 - val_cost: 4.0690\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4412 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9693 - val_cost: 4.0690\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4399 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.9225\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4407 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.8672\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5158 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 4.0397\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3754 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 4.0332\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3791 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8477\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3637 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.9616\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3609 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.8477\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4355 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 4.0267\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4453 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.9974\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3819 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.8281\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3401 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.7793\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4562 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.8086\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.4131 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.8314\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3439 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.8281\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3079 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.6947\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3285 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8477\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3971 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.9681\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3112 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 4.0234\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3446 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.9714\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3580 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.9974\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3479 - val_loss: 0.1139 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5026\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3502 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7826\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3317 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.8770\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3200 - val_loss: 0.1143 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.8607\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3754 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.8607\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3240 - val_loss: 0.1161 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.9583\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3257 - val_loss: 0.1130 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.8737\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2811 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.9193\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3528 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.8249\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3164 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.8997\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3071 - val_loss: 0.1164 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.3724\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2660 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.6361\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3415 - val_loss: 0.1155 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7272\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3472 - val_loss: 0.1159 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.6882\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2829 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9696 - val_cost: 3.9876\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2927 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.8444\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2996 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.8932\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2826 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.9388\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2844 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.8477\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2792 - val_loss: 0.1178 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.9421\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3008 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8249\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3191 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5547\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2972 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7630\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3033 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.7272\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3234 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7533\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3102 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.8151\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2523 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9711 - val_cost: 3.4473\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2594 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.9421\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3058 - val_loss: 0.1147 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.8965\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2831 - val_loss: 0.1176 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7402\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3200 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2481 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.7500\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2761 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.9323\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2856 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7174\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2630 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.8184\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2467 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.7402\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9818 - cost: 2.3312 - val_loss: 0.1144 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7630\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2208 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.8346\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2198 - val_loss: 0.1168 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.9974\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2108 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9698 - val_cost: 3.9876\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2959 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.7305\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2502 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.9518\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1638 - val_loss: 0.1172 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.6849\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1924 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.7272\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2502 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.8379\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2246 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.6654\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2622 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.8574\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2569 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.7207\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1688 - val_loss: 0.1170 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.7988\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2195 - val_loss: 0.1164 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.9030\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1633 - val_loss: 0.1197 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.9974\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1883 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.7402\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1985 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6816\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2979 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9704 - val_cost: 3.7142\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2416 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 4.0299\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2238 - val_loss: 0.1166 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.7174\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2368 - val_loss: 0.1166 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 4.0560\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2248 - val_loss: 0.1182 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.5286\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2461 - val_loss: 0.1156 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 4.0658\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2607 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7402\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1659 - val_loss: 0.1170 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.7565\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1070 - auc: 0.9907 - accuracy: 0.9721 - cost: 3.5219\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:13.533926\n",
            "fold accuracy: 0.9721249938011169 - fold cost: 3.5218749046325684\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 7ms/step - loss: 0.5273 - auc: 0.8003 - accuracy: 0.7309 - cost: 35.7981 - val_loss: 0.3946 - val_auc: 0.9016 - val_accuracy: 0.8294 - val_cost: 21.2565\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.3473 - auc: 0.9233 - accuracy: 0.8512 - cost: 18.9520 - val_loss: 0.3152 - val_auc: 0.9375 - val_accuracy: 0.8668 - val_cost: 15.9831\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2982 - auc: 0.9438 - accuracy: 0.8768 - cost: 15.6007 - val_loss: 0.2831 - val_auc: 0.9495 - val_accuracy: 0.8843 - val_cost: 14.0397\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2697 - auc: 0.9541 - accuracy: 0.8899 - cost: 13.9321 - val_loss: 0.2578 - val_auc: 0.9583 - val_accuracy: 0.8972 - val_cost: 12.6074\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2464 - auc: 0.9618 - accuracy: 0.9013 - cost: 12.4921 - val_loss: 0.2394 - val_auc: 0.9639 - val_accuracy: 0.9061 - val_cost: 11.7839\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2274 - auc: 0.9674 - accuracy: 0.9106 - cost: 11.3212 - val_loss: 0.2231 - val_auc: 0.9684 - val_accuracy: 0.9165 - val_cost: 10.3646\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2122 - auc: 0.9714 - accuracy: 0.9178 - cost: 10.3902 - val_loss: 0.2088 - val_auc: 0.9725 - val_accuracy: 0.9224 - val_cost: 9.3001\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1988 - auc: 0.9748 - accuracy: 0.9247 - cost: 9.5071 - val_loss: 0.1968 - val_auc: 0.9752 - val_accuracy: 0.9283 - val_cost: 9.0690\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1872 - auc: 0.9775 - accuracy: 0.9295 - cost: 8.9058 - val_loss: 0.1868 - val_auc: 0.9774 - val_accuracy: 0.9339 - val_cost: 8.1608\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1779 - auc: 0.9796 - accuracy: 0.9341 - cost: 8.3421 - val_loss: 0.1798 - val_auc: 0.9788 - val_accuracy: 0.9364 - val_cost: 7.9264\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1702 - auc: 0.9812 - accuracy: 0.9370 - cost: 7.9742 - val_loss: 0.1734 - val_auc: 0.9801 - val_accuracy: 0.9389 - val_cost: 7.5293\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1636 - auc: 0.9825 - accuracy: 0.9405 - cost: 7.5225 - val_loss: 0.1682 - val_auc: 0.9812 - val_accuracy: 0.9401 - val_cost: 7.3633\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1581 - auc: 0.9835 - accuracy: 0.9430 - cost: 7.2140 - val_loss: 0.1652 - val_auc: 0.9819 - val_accuracy: 0.9426 - val_cost: 7.2396\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1538 - auc: 0.9843 - accuracy: 0.9448 - cost: 6.9764 - val_loss: 0.1631 - val_auc: 0.9824 - val_accuracy: 0.9438 - val_cost: 6.5820\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1494 - auc: 0.9851 - accuracy: 0.9468 - cost: 6.7326 - val_loss: 0.1579 - val_auc: 0.9832 - val_accuracy: 0.9449 - val_cost: 6.8913\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1453 - auc: 0.9857 - accuracy: 0.9482 - cost: 6.5632 - val_loss: 0.1553 - val_auc: 0.9835 - val_accuracy: 0.9456 - val_cost: 6.8099\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1416 - auc: 0.9865 - accuracy: 0.9500 - cost: 6.3113 - val_loss: 0.1527 - val_auc: 0.9841 - val_accuracy: 0.9485 - val_cost: 6.3216\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1395 - auc: 0.9867 - accuracy: 0.9514 - cost: 6.1523 - val_loss: 0.1522 - val_auc: 0.9843 - val_accuracy: 0.9491 - val_cost: 6.2663\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1362 - auc: 0.9873 - accuracy: 0.9521 - cost: 6.0703 - val_loss: 0.1498 - val_auc: 0.9846 - val_accuracy: 0.9488 - val_cost: 6.3932\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1344 - auc: 0.9875 - accuracy: 0.9535 - cost: 5.8896 - val_loss: 0.1480 - val_auc: 0.9849 - val_accuracy: 0.9503 - val_cost: 6.1003\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1316 - auc: 0.9880 - accuracy: 0.9542 - cost: 5.7926 - val_loss: 0.1459 - val_auc: 0.9852 - val_accuracy: 0.9522 - val_cost: 5.8561\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1283 - auc: 0.9885 - accuracy: 0.9558 - cost: 5.6063 - val_loss: 0.1441 - val_auc: 0.9857 - val_accuracy: 0.9531 - val_cost: 5.6901\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1271 - auc: 0.9886 - accuracy: 0.9567 - cost: 5.4930 - val_loss: 0.1438 - val_auc: 0.9858 - val_accuracy: 0.9533 - val_cost: 5.5046\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1244 - auc: 0.9890 - accuracy: 0.9576 - cost: 5.3841 - val_loss: 0.1411 - val_auc: 0.9860 - val_accuracy: 0.9540 - val_cost: 5.5859\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1227 - auc: 0.9892 - accuracy: 0.9589 - cost: 5.2177 - val_loss: 0.1420 - val_auc: 0.9861 - val_accuracy: 0.9540 - val_cost: 5.2441\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1217 - auc: 0.9894 - accuracy: 0.9588 - cost: 5.2126 - val_loss: 0.1379 - val_auc: 0.9863 - val_accuracy: 0.9563 - val_cost: 5.2995\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9898 - accuracy: 0.9598 - cost: 5.1094 - val_loss: 0.1362 - val_auc: 0.9864 - val_accuracy: 0.9565 - val_cost: 5.2311\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1174 - auc: 0.9899 - accuracy: 0.9607 - cost: 4.9853 - val_loss: 0.1351 - val_auc: 0.9867 - val_accuracy: 0.9578 - val_cost: 4.9349\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1159 - auc: 0.9901 - accuracy: 0.9613 - cost: 4.9098 - val_loss: 0.1355 - val_auc: 0.9869 - val_accuracy: 0.9576 - val_cost: 4.8438\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1140 - auc: 0.9905 - accuracy: 0.9620 - cost: 4.8233 - val_loss: 0.1340 - val_auc: 0.9868 - val_accuracy: 0.9592 - val_cost: 4.7624\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1123 - auc: 0.9906 - accuracy: 0.9631 - cost: 4.6876 - val_loss: 0.1318 - val_auc: 0.9870 - val_accuracy: 0.9599 - val_cost: 4.8405\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1112 - auc: 0.9907 - accuracy: 0.9642 - cost: 4.5332 - val_loss: 0.1328 - val_auc: 0.9868 - val_accuracy: 0.9590 - val_cost: 4.8145\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1108 - auc: 0.9908 - accuracy: 0.9637 - cost: 4.6163 - val_loss: 0.1315 - val_auc: 0.9871 - val_accuracy: 0.9603 - val_cost: 4.6973\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1084 - auc: 0.9911 - accuracy: 0.9643 - cost: 4.5463 - val_loss: 0.1292 - val_auc: 0.9875 - val_accuracy: 0.9614 - val_cost: 4.5215\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1064 - auc: 0.9913 - accuracy: 0.9655 - cost: 4.3882 - val_loss: 0.1282 - val_auc: 0.9875 - val_accuracy: 0.9608 - val_cost: 4.6419\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9914 - accuracy: 0.9654 - cost: 4.3892 - val_loss: 0.1278 - val_auc: 0.9877 - val_accuracy: 0.9626 - val_cost: 4.3685\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1051 - auc: 0.9915 - accuracy: 0.9661 - cost: 4.3088 - val_loss: 0.1275 - val_auc: 0.9877 - val_accuracy: 0.9616 - val_cost: 4.5215\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9664 - cost: 4.2430 - val_loss: 0.1264 - val_auc: 0.9878 - val_accuracy: 0.9623 - val_cost: 4.6224\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1022 - auc: 0.9919 - accuracy: 0.9673 - cost: 4.1636 - val_loss: 0.1251 - val_auc: 0.9880 - val_accuracy: 0.9631 - val_cost: 4.4141\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9672 - cost: 4.1723 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9622 - val_cost: 4.2936\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1006 - auc: 0.9920 - accuracy: 0.9679 - cost: 4.0813 - val_loss: 0.1233 - val_auc: 0.9881 - val_accuracy: 0.9631 - val_cost: 4.5443\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9683 - cost: 4.0134 - val_loss: 0.1231 - val_auc: 0.9881 - val_accuracy: 0.9638 - val_cost: 4.2806\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0981 - auc: 0.9923 - accuracy: 0.9689 - cost: 3.9505 - val_loss: 0.1236 - val_auc: 0.9881 - val_accuracy: 0.9638 - val_cost: 4.2025\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9924 - accuracy: 0.9687 - cost: 3.9744 - val_loss: 0.1210 - val_auc: 0.9884 - val_accuracy: 0.9646 - val_cost: 4.2871\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0967 - auc: 0.9924 - accuracy: 0.9692 - cost: 3.9153 - val_loss: 0.1204 - val_auc: 0.9884 - val_accuracy: 0.9642 - val_cost: 4.2578\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9925 - accuracy: 0.9690 - cost: 3.9426 - val_loss: 0.1207 - val_auc: 0.9883 - val_accuracy: 0.9657 - val_cost: 4.0072\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0944 - auc: 0.9927 - accuracy: 0.9703 - cost: 3.7751 - val_loss: 0.1207 - val_auc: 0.9883 - val_accuracy: 0.9644 - val_cost: 4.3034\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0934 - auc: 0.9927 - accuracy: 0.9705 - cost: 3.7476 - val_loss: 0.1200 - val_auc: 0.9885 - val_accuracy: 0.9649 - val_cost: 4.0332\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9927 - accuracy: 0.9706 - cost: 3.7372 - val_loss: 0.1202 - val_auc: 0.9884 - val_accuracy: 0.9647 - val_cost: 4.2415\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9710 - cost: 3.6901 - val_loss: 0.1196 - val_auc: 0.9885 - val_accuracy: 0.9656 - val_cost: 4.2806\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9930 - accuracy: 0.9711 - cost: 3.6781 - val_loss: 0.1184 - val_auc: 0.9887 - val_accuracy: 0.9654 - val_cost: 4.2546\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9931 - accuracy: 0.9720 - cost: 3.5636 - val_loss: 0.1203 - val_auc: 0.9886 - val_accuracy: 0.9649 - val_cost: 4.3359\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0896 - auc: 0.9931 - accuracy: 0.9725 - cost: 3.5040 - val_loss: 0.1170 - val_auc: 0.9888 - val_accuracy: 0.9667 - val_cost: 3.9876\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5084 - val_loss: 0.1171 - val_auc: 0.9887 - val_accuracy: 0.9654 - val_cost: 4.0169\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9730 - cost: 3.4448 - val_loss: 0.1173 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.1081\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9934 - accuracy: 0.9727 - cost: 3.4752 - val_loss: 0.1157 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 3.8997\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4438 - val_loss: 0.1174 - val_auc: 0.9888 - val_accuracy: 0.9659 - val_cost: 4.0885\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9733 - cost: 3.3961 - val_loss: 0.1176 - val_auc: 0.9888 - val_accuracy: 0.9654 - val_cost: 3.9648\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.4027 - val_loss: 0.1173 - val_auc: 0.9889 - val_accuracy: 0.9672 - val_cost: 3.7956\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.3849 - val_loss: 0.1164 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.0527\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9738 - cost: 3.3379 - val_loss: 0.1137 - val_auc: 0.9889 - val_accuracy: 0.9674 - val_cost: 4.0495\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.2882 - val_loss: 0.1154 - val_auc: 0.9889 - val_accuracy: 0.9667 - val_cost: 4.0169\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9938 - accuracy: 0.9740 - cost: 3.3186 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 3.9681\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9744 - cost: 3.2545 - val_loss: 0.1160 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.0462\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9940 - accuracy: 0.9749 - cost: 3.2124 - val_loss: 0.1158 - val_auc: 0.9890 - val_accuracy: 0.9674 - val_cost: 3.7370\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9744 - cost: 3.2549 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 3.9486\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9751 - cost: 3.1734 - val_loss: 0.1167 - val_auc: 0.9886 - val_accuracy: 0.9666 - val_cost: 3.8249\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2249 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9685 - val_cost: 3.8053\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1804 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 3.8118\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0809 - auc: 0.9940 - accuracy: 0.9750 - cost: 3.1866 - val_loss: 0.1155 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 3.8509\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0865 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9672 - val_cost: 3.9714\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1001 - val_loss: 0.1135 - val_auc: 0.9891 - val_accuracy: 0.9683 - val_cost: 3.8477\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9763 - cost: 3.0253 - val_loss: 0.1156 - val_auc: 0.9890 - val_accuracy: 0.9672 - val_cost: 3.7891\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0408 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9682 - val_cost: 3.6458\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0406 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9671 - val_cost: 3.8314\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9751 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9681 - val_cost: 3.7142\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0596 - val_loss: 0.1143 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 3.9160\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9763 - cost: 3.0355 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.8509\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9181 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.6654\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9619 - val_loss: 0.1128 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 3.8900\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9765 - cost: 3.0025 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 4.0202\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9277 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.7207\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9023 - val_loss: 0.1135 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 4.0365\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8481 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.7533\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9558 - val_loss: 0.1120 - val_auc: 0.9893 - val_accuracy: 0.9685 - val_cost: 4.1146\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9773 - cost: 2.8952 - val_loss: 0.1113 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.6296\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8102 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.6523\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8145 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9687 - val_cost: 3.6393\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8667 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 3.8151\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8075 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.7207\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9778 - cost: 2.8373 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.7240\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7963 - val_loss: 0.1113 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6165\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8184 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.7337\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8302 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.7174\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8209 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.7858\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8205 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 3.7207\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7315 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9193\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7763 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.5352\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9951 - accuracy: 0.9786 - cost: 2.7419 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.6458\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7433 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.5352\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7190 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.6621\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7574 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9693 - val_cost: 3.5384\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6720 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.6361\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7169 - val_loss: 0.1108 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.5677\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6820 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.7305\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7076 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.5579\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7130 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.8086\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6990 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6719\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6434 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6458\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6907 - val_loss: 0.1169 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.6719\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6052 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.5775\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6305 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.7272\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6807 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.6165\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6602 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9696 - val_cost: 3.7500\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6530 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9704 - val_cost: 3.4408\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9786 - cost: 2.7448 - val_loss: 0.1164 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.6230\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5844 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5319\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6064 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.4310\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6132 - val_loss: 0.1157 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.4961\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6484 - val_loss: 0.1141 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6146 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.5547\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.5986 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5221\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6251 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.6947\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5628 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.4277\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5571 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.5905\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5593 - val_loss: 0.1123 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.6458\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6216 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.3105\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5312 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.5254\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.5885 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5645\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5465 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.4473\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5434 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.3854\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6310 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.5970\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5726 - val_loss: 0.1167 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.4245\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5307 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6947\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5504 - val_loss: 0.1153 - val_auc: 0.9891 - val_accuracy: 0.9709 - val_cost: 3.5319\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5289 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4212\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5348 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7370\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5135 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5026\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5116 - val_loss: 0.1142 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.4570\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4857 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.4017\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4881 - val_loss: 0.1149 - val_auc: 0.9890 - val_accuracy: 0.9709 - val_cost: 3.3887\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4716 - val_loss: 0.1163 - val_auc: 0.9891 - val_accuracy: 0.9702 - val_cost: 3.4245\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9799 - cost: 2.5696 - val_loss: 0.1143 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.6816\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5072 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9720 - val_cost: 3.2780\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5117 - val_loss: 0.1159 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.5514\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4800 - val_loss: 0.1145 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.5677\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4827 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7923\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4841 - val_loss: 0.1156 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.4766\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5297 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.5221\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.4988 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5221\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4931 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9703 - val_cost: 3.5645\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4352 - val_loss: 0.1156 - val_auc: 0.9890 - val_accuracy: 0.9709 - val_cost: 3.4505\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4428 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.3073\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9954 - accuracy: 0.9809 - cost: 2.4538 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.5514\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4292 - val_loss: 0.1146 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.4049\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4345 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5417\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4629 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.3659\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4365 - val_loss: 0.1173 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.5124\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4179 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9713 - val_cost: 3.3073\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4458 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.5189\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4169 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.4473\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4485 - val_loss: 0.1180 - val_auc: 0.9890 - val_accuracy: 0.9709 - val_cost: 3.5547\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3394 - val_loss: 0.1172 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.2650\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.4002 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.5938\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3851 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6361\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3819 - val_loss: 0.1173 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.3822\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3776 - val_loss: 0.1185 - val_auc: 0.9887 - val_accuracy: 0.9690 - val_cost: 3.7109\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4179 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.4082\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4530 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.3008\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3590 - val_loss: 0.1180 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.4766\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3747 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6068\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4214 - val_loss: 0.1188 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.7012\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4200 - val_loss: 0.1180 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.4766\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4154 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.5026\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3775 - val_loss: 0.1179 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5156\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4442 - val_loss: 0.1186 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.4701\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3451 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.6947\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4080 - val_loss: 0.1199 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.3887\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3995 - val_loss: 0.1193 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.2650\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3214 - val_loss: 0.1196 - val_auc: 0.9886 - val_accuracy: 0.9707 - val_cost: 3.5319\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2712 - val_loss: 0.1187 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.4180\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4059 - val_loss: 0.1181 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.4180\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3473 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5710\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4419 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.7891\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3527 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6914\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3412 - val_loss: 0.1206 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.5807\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3320 - val_loss: 0.1194 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.5970\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3556 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9711 - val_cost: 3.5840\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3598 - val_loss: 0.1190 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.5970\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2693 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.5319\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3408 - val_loss: 0.1207 - val_auc: 0.9887 - val_accuracy: 0.9702 - val_cost: 3.4505\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3706 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.6751\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3439 - val_loss: 0.1197 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.5384\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3698 - val_loss: 0.1216 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.5319\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3697 - val_loss: 0.1180 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.5677\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9962 - accuracy: 0.9818 - cost: 2.3292 - val_loss: 0.1214 - val_auc: 0.9888 - val_accuracy: 0.9702 - val_cost: 3.6100\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3300 - val_loss: 0.1197 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.4082\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9962 - accuracy: 0.9819 - cost: 2.3221 - val_loss: 0.1234 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.6882\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3751 - val_loss: 0.1207 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.6198\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3222 - val_loss: 0.1207 - val_auc: 0.9891 - val_accuracy: 0.9702 - val_cost: 3.6914\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2593 - val_loss: 0.1205 - val_auc: 0.9889 - val_accuracy: 0.9711 - val_cost: 3.5026\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3473 - val_loss: 0.1248 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.5970\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2908 - val_loss: 0.1218 - val_auc: 0.9888 - val_accuracy: 0.9717 - val_cost: 3.4668\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3212 - val_loss: 0.1199 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.6035\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2844 - val_loss: 0.1215 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.4570\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3029 - val_loss: 0.1212 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.4798\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2916 - val_loss: 0.1234 - val_auc: 0.9887 - val_accuracy: 0.9707 - val_cost: 3.5677\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3025 - val_loss: 0.1210 - val_auc: 0.9889 - val_accuracy: 0.9709 - val_cost: 3.5156\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3541 - val_loss: 0.1202 - val_auc: 0.9890 - val_accuracy: 0.9720 - val_cost: 3.3822\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2950 - val_loss: 0.1196 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.5938\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2362 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.6686\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2477 - val_loss: 0.1232 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.4635\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2825 - val_loss: 0.1230 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.3789\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1030 - auc: 0.9912 - accuracy: 0.9717 - cost: 3.5469\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:02.685576\n",
            "fold accuracy: 0.9716874957084656 - fold cost: 3.546875\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5223 - auc: 0.8047 - accuracy: 0.7337 - cost: 35.4095 - val_loss: 0.3889 - val_auc: 0.9049 - val_accuracy: 0.8323 - val_cost: 21.1003\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3468 - auc: 0.9235 - accuracy: 0.8515 - cost: 18.8943 - val_loss: 0.3104 - val_auc: 0.9390 - val_accuracy: 0.8694 - val_cost: 16.0840\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2999 - auc: 0.9430 - accuracy: 0.8753 - cost: 15.8098 - val_loss: 0.2808 - val_auc: 0.9502 - val_accuracy: 0.8831 - val_cost: 14.4238\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2702 - auc: 0.9538 - accuracy: 0.8901 - cost: 13.9252 - val_loss: 0.2550 - val_auc: 0.9591 - val_accuracy: 0.8976 - val_cost: 12.9427\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2467 - auc: 0.9615 - accuracy: 0.9012 - cost: 12.5477 - val_loss: 0.2354 - val_auc: 0.9648 - val_accuracy: 0.9072 - val_cost: 11.7773\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2293 - auc: 0.9667 - accuracy: 0.9093 - cost: 11.4974 - val_loss: 0.2185 - val_auc: 0.9698 - val_accuracy: 0.9157 - val_cost: 10.2344\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2131 - auc: 0.9712 - accuracy: 0.9175 - cost: 10.4424 - val_loss: 0.2055 - val_auc: 0.9735 - val_accuracy: 0.9218 - val_cost: 9.6712\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2008 - auc: 0.9743 - accuracy: 0.9236 - cost: 9.6655 - val_loss: 0.1941 - val_auc: 0.9761 - val_accuracy: 0.9271 - val_cost: 9.0820\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1889 - auc: 0.9771 - accuracy: 0.9290 - cost: 9.0056 - val_loss: 0.1838 - val_auc: 0.9781 - val_accuracy: 0.9336 - val_cost: 8.3984\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1795 - auc: 0.9792 - accuracy: 0.9332 - cost: 8.4660 - val_loss: 0.1782 - val_auc: 0.9792 - val_accuracy: 0.9348 - val_cost: 8.6165\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1716 - auc: 0.9809 - accuracy: 0.9364 - cost: 8.0521 - val_loss: 0.1698 - val_auc: 0.9811 - val_accuracy: 0.9382 - val_cost: 8.0794\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1656 - auc: 0.9821 - accuracy: 0.9396 - cost: 7.6526 - val_loss: 0.1639 - val_auc: 0.9823 - val_accuracy: 0.9416 - val_cost: 7.4902\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1596 - auc: 0.9831 - accuracy: 0.9421 - cost: 7.3463 - val_loss: 0.1590 - val_auc: 0.9832 - val_accuracy: 0.9428 - val_cost: 7.5000\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1548 - auc: 0.9841 - accuracy: 0.9437 - cost: 7.1347 - val_loss: 0.1580 - val_auc: 0.9837 - val_accuracy: 0.9435 - val_cost: 6.9401\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1504 - auc: 0.9848 - accuracy: 0.9464 - cost: 6.8067 - val_loss: 0.1528 - val_auc: 0.9842 - val_accuracy: 0.9459 - val_cost: 7.0150\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1464 - auc: 0.9856 - accuracy: 0.9479 - cost: 6.6059 - val_loss: 0.1493 - val_auc: 0.9848 - val_accuracy: 0.9486 - val_cost: 6.6699\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1426 - auc: 0.9862 - accuracy: 0.9493 - cost: 6.4253 - val_loss: 0.1485 - val_auc: 0.9853 - val_accuracy: 0.9475 - val_cost: 6.6276\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1390 - auc: 0.9868 - accuracy: 0.9517 - cost: 6.1114 - val_loss: 0.1422 - val_auc: 0.9860 - val_accuracy: 0.9513 - val_cost: 6.5853\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1349 - auc: 0.9874 - accuracy: 0.9529 - cost: 5.9860 - val_loss: 0.1409 - val_auc: 0.9863 - val_accuracy: 0.9513 - val_cost: 6.3574\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1330 - auc: 0.9877 - accuracy: 0.9539 - cost: 5.8584 - val_loss: 0.1384 - val_auc: 0.9866 - val_accuracy: 0.9520 - val_cost: 6.1328\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1297 - auc: 0.9883 - accuracy: 0.9556 - cost: 5.6441 - val_loss: 0.1372 - val_auc: 0.9868 - val_accuracy: 0.9534 - val_cost: 6.0938\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1277 - auc: 0.9885 - accuracy: 0.9569 - cost: 5.4682 - val_loss: 0.1331 - val_auc: 0.9874 - val_accuracy: 0.9558 - val_cost: 5.8171\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9891 - accuracy: 0.9578 - cost: 5.3399 - val_loss: 0.1309 - val_auc: 0.9877 - val_accuracy: 0.9557 - val_cost: 6.2402\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1213 - auc: 0.9895 - accuracy: 0.9594 - cost: 5.1654 - val_loss: 0.1299 - val_auc: 0.9878 - val_accuracy: 0.9567 - val_cost: 6.0091\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1199 - auc: 0.9896 - accuracy: 0.9599 - cost: 5.0931 - val_loss: 0.1279 - val_auc: 0.9880 - val_accuracy: 0.9588 - val_cost: 5.3874\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1166 - auc: 0.9901 - accuracy: 0.9610 - cost: 4.9642 - val_loss: 0.1283 - val_auc: 0.9880 - val_accuracy: 0.9581 - val_cost: 5.4460\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1149 - auc: 0.9903 - accuracy: 0.9620 - cost: 4.8256 - val_loss: 0.1241 - val_auc: 0.9884 - val_accuracy: 0.9592 - val_cost: 5.5697\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1129 - auc: 0.9905 - accuracy: 0.9627 - cost: 4.7333 - val_loss: 0.1218 - val_auc: 0.9886 - val_accuracy: 0.9608 - val_cost: 5.2669\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1107 - auc: 0.9908 - accuracy: 0.9640 - cost: 4.5698 - val_loss: 0.1207 - val_auc: 0.9887 - val_accuracy: 0.9622 - val_cost: 5.0358\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1092 - auc: 0.9910 - accuracy: 0.9638 - cost: 4.6016 - val_loss: 0.1195 - val_auc: 0.9886 - val_accuracy: 0.9628 - val_cost: 4.6484\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9912 - accuracy: 0.9650 - cost: 4.4446 - val_loss: 0.1177 - val_auc: 0.9892 - val_accuracy: 0.9631 - val_cost: 5.0456\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1056 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3490 - val_loss: 0.1174 - val_auc: 0.9892 - val_accuracy: 0.9637 - val_cost: 4.5768\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1044 - auc: 0.9915 - accuracy: 0.9665 - cost: 4.2439 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9626 - val_cost: 4.8340\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1027 - auc: 0.9917 - accuracy: 0.9671 - cost: 4.1831 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9645 - val_cost: 4.5703\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1019 - auc: 0.9918 - accuracy: 0.9672 - cost: 4.1681 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9639 - val_cost: 4.5573\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9677 - cost: 4.1008 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9647 - val_cost: 4.3229\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0981 - auc: 0.9923 - accuracy: 0.9686 - cost: 3.9784 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9652 - val_cost: 4.3229\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9923 - accuracy: 0.9693 - cost: 3.9083 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9658 - val_cost: 4.2741\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0967 - auc: 0.9923 - accuracy: 0.9694 - cost: 3.8946 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.0885\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0955 - auc: 0.9925 - accuracy: 0.9695 - cost: 3.8716 - val_loss: 0.1099 - val_auc: 0.9900 - val_accuracy: 0.9664 - val_cost: 4.5475\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0944 - auc: 0.9926 - accuracy: 0.9704 - cost: 3.7721 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9674 - val_cost: 3.9844\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9927 - accuracy: 0.9703 - cost: 3.7673 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9671 - val_cost: 4.1439\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6457 - val_loss: 0.1083 - val_auc: 0.9902 - val_accuracy: 0.9669 - val_cost: 4.0332\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9713 - cost: 3.6615 - val_loss: 0.1083 - val_auc: 0.9901 - val_accuracy: 0.9662 - val_cost: 4.2448\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9928 - accuracy: 0.9716 - cost: 3.6195 - val_loss: 0.1079 - val_auc: 0.9903 - val_accuracy: 0.9669 - val_cost: 3.9811\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9720 - cost: 3.5682 - val_loss: 0.1072 - val_auc: 0.9900 - val_accuracy: 0.9672 - val_cost: 4.2611\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9931 - accuracy: 0.9724 - cost: 3.5138 - val_loss: 0.1076 - val_auc: 0.9901 - val_accuracy: 0.9672 - val_cost: 3.9779\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9725 - cost: 3.4864 - val_loss: 0.1052 - val_auc: 0.9904 - val_accuracy: 0.9681 - val_cost: 4.0039\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0882 - auc: 0.9932 - accuracy: 0.9727 - cost: 3.4849 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9683 - val_cost: 3.8704\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9726 - cost: 3.4715 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9674 - val_cost: 4.1113\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9933 - accuracy: 0.9735 - cost: 3.3631 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9685 - val_cost: 3.9160\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9933 - accuracy: 0.9737 - cost: 3.3583 - val_loss: 0.1049 - val_auc: 0.9904 - val_accuracy: 0.9682 - val_cost: 4.0495\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9936 - accuracy: 0.9733 - cost: 3.3965 - val_loss: 0.1044 - val_auc: 0.9904 - val_accuracy: 0.9682 - val_cost: 3.9388\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0842 - auc: 0.9935 - accuracy: 0.9742 - cost: 3.2843 - val_loss: 0.1039 - val_auc: 0.9903 - val_accuracy: 0.9685 - val_cost: 4.0788\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9935 - accuracy: 0.9744 - cost: 3.2529 - val_loss: 0.1044 - val_auc: 0.9903 - val_accuracy: 0.9689 - val_cost: 3.8965\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9740 - cost: 3.3285 - val_loss: 0.1032 - val_auc: 0.9906 - val_accuracy: 0.9704 - val_cost: 3.6621\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2181 - val_loss: 0.1026 - val_auc: 0.9907 - val_accuracy: 0.9690 - val_cost: 4.2578\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9937 - accuracy: 0.9749 - cost: 3.1882 - val_loss: 0.1036 - val_auc: 0.9908 - val_accuracy: 0.9688 - val_cost: 4.1243\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2346 - val_loss: 0.1033 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_cost: 3.7663\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1276 - val_loss: 0.1033 - val_auc: 0.9907 - val_accuracy: 0.9685 - val_cost: 4.2546\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1295 - val_loss: 0.1044 - val_auc: 0.9909 - val_accuracy: 0.9693 - val_cost: 3.7760\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9755 - cost: 3.1279 - val_loss: 0.1015 - val_auc: 0.9908 - val_accuracy: 0.9692 - val_cost: 3.8411\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0935 - val_loss: 0.1019 - val_auc: 0.9908 - val_accuracy: 0.9684 - val_cost: 4.2318\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0778 - val_loss: 0.1011 - val_auc: 0.9908 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0487 - val_loss: 0.1039 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.6393\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0670 - val_loss: 0.1027 - val_auc: 0.9909 - val_accuracy: 0.9706 - val_cost: 3.6296\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0593 - val_loss: 0.1020 - val_auc: 0.9909 - val_accuracy: 0.9695 - val_cost: 3.7012\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9801 - val_loss: 0.1029 - val_auc: 0.9907 - val_accuracy: 0.9695 - val_cost: 3.8086\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0260 - val_loss: 0.1033 - val_auc: 0.9906 - val_accuracy: 0.9699 - val_cost: 3.6914\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0008 - val_loss: 0.1036 - val_auc: 0.9907 - val_accuracy: 0.9702 - val_cost: 3.8900\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9276 - val_loss: 0.1021 - val_auc: 0.9907 - val_accuracy: 0.9708 - val_cost: 3.7207\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9770 - cost: 2.9336 - val_loss: 0.1040 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.8249\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9353 - val_loss: 0.1065 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.7793\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9399 - val_loss: 0.1032 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.7663\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9314 - val_loss: 0.1048 - val_auc: 0.9906 - val_accuracy: 0.9689 - val_cost: 4.2415\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8903 - val_loss: 0.1039 - val_auc: 0.9907 - val_accuracy: 0.9698 - val_cost: 3.9779\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8245 - val_loss: 0.1026 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.9128\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8735 - val_loss: 0.1028 - val_auc: 0.9908 - val_accuracy: 0.9714 - val_cost: 3.8574\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8043 - val_loss: 0.1041 - val_auc: 0.9907 - val_accuracy: 0.9706 - val_cost: 4.1309\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8299 - val_loss: 0.1051 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.9583\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8351 - val_loss: 0.1035 - val_auc: 0.9907 - val_accuracy: 0.9710 - val_cost: 3.9323\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7582 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.7044\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8038 - val_loss: 0.1042 - val_auc: 0.9905 - val_accuracy: 0.9709 - val_cost: 3.7533\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8020 - val_loss: 0.1040 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.7272\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7885 - val_loss: 0.1035 - val_auc: 0.9907 - val_accuracy: 0.9708 - val_cost: 3.9225\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7732 - val_loss: 0.1067 - val_auc: 0.9905 - val_accuracy: 0.9694 - val_cost: 3.7305\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7306 - val_loss: 0.1057 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 4.0104\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.7982 - val_loss: 0.1031 - val_auc: 0.9904 - val_accuracy: 0.9718 - val_cost: 3.5938\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7223 - val_loss: 0.1039 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.7337\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6637 - val_loss: 0.1065 - val_auc: 0.9904 - val_accuracy: 0.9699 - val_cost: 4.0202\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8126 - val_loss: 0.1060 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.5645\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7526 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9698 - val_cost: 3.8770\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7376 - val_loss: 0.1039 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.8965\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6466 - val_loss: 0.1037 - val_auc: 0.9907 - val_accuracy: 0.9709 - val_cost: 3.7402\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6709 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.8997\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6407 - val_loss: 0.1067 - val_auc: 0.9904 - val_accuracy: 0.9714 - val_cost: 3.5840\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7020 - val_loss: 0.1036 - val_auc: 0.9907 - val_accuracy: 0.9718 - val_cost: 3.5547\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7196 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.5579\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6412 - val_loss: 0.1044 - val_auc: 0.9906 - val_accuracy: 0.9704 - val_cost: 3.8607\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6303 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.8379\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6834 - val_loss: 0.1077 - val_auc: 0.9902 - val_accuracy: 0.9704 - val_cost: 3.9876\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6439 - val_loss: 0.1066 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7826\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6068 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.6426\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6092 - val_loss: 0.1055 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.9128\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6152 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.7370\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6054 - val_loss: 0.1064 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.5905\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6178 - val_loss: 0.1060 - val_auc: 0.9903 - val_accuracy: 0.9708 - val_cost: 3.7695\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5857 - val_loss: 0.1071 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.7500\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.5988 - val_loss: 0.1051 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.8444\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6519 - val_loss: 0.1075 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.9160\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5466 - val_loss: 0.1067 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.9290\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5882 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7826\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6064 - val_loss: 0.1077 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.7598\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5355 - val_loss: 0.1060 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.6654\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6481 - val_loss: 0.1082 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7435\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9952 - accuracy: 0.9807 - cost: 2.4572 - val_loss: 0.1070 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7728\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5218 - val_loss: 0.1069 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.9128\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9803 - cost: 2.5185 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.7500\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5304 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7598\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5705 - val_loss: 0.1068 - val_auc: 0.9902 - val_accuracy: 0.9704 - val_cost: 3.9779\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4616 - val_loss: 0.1077 - val_auc: 0.9907 - val_accuracy: 0.9710 - val_cost: 3.5449\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5284 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6263\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5098 - val_loss: 0.1074 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.5938\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4609 - val_loss: 0.1065 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4681 - val_loss: 0.1077 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 4.0495\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4804 - val_loss: 0.1066 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.6621\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4919 - val_loss: 0.1077 - val_auc: 0.9902 - val_accuracy: 0.9700 - val_cost: 3.9355\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5469 - val_loss: 0.1085 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.7826\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.5052 - val_loss: 0.1074 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.8021\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4953 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.5059\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4701 - val_loss: 0.1082 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.8151\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4783 - val_loss: 0.1060 - val_auc: 0.9904 - val_accuracy: 0.9718 - val_cost: 3.5710\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4648 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.6589\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4233 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.8444\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4558 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9719 - val_cost: 3.5905\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4276 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.7467\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5130 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.6068\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4417 - val_loss: 0.1061 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.8021\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9813 - cost: 2.3900 - val_loss: 0.1079 - val_auc: 0.9900 - val_accuracy: 0.9702 - val_cost: 3.7988\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3663 - val_loss: 0.1080 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.8607\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4502 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.8314\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3966 - val_loss: 0.1090 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.4408\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3938 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.6361\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0641 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.4062 - val_loss: 0.1088 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.7240\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4566 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.9290\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4168 - val_loss: 0.1096 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.6816\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4114 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.5547\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9818 - cost: 2.3434 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7598\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4186 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.8542\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3765 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.7956\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3830 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9721 - val_cost: 3.6165\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3599 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9720 - val_cost: 3.5482\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9955 - accuracy: 0.9819 - cost: 2.3245 - val_loss: 0.1099 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.9811\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3960 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.6263\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3671 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.9160\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3227 - val_loss: 0.1097 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 4.0104\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3420 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 4.1146\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3198 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3406 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 4.1178\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3581 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.9648\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3586 - val_loss: 0.1127 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.8509\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3795 - val_loss: 0.1111 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.5612\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3555 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.7240\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3486 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.8053\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3270 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.7142\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3531 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6719\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3411 - val_loss: 0.1109 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.7467\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0620 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3659 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.8053\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3809 - val_loss: 0.1130 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7858\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9823 - cost: 2.2633 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.9551\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3569 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8477\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2762 - val_loss: 0.1108 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.5449\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2733 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6068\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3271 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 4.1634\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3067 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.9779\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3407 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 4.0658\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3497 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.7012\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9958 - accuracy: 0.9823 - cost: 2.2771 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.9941\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3746 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.9648\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3375 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.7142\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9958 - accuracy: 0.9823 - cost: 2.2703 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9696 - val_cost: 4.0430\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2714 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 4.2578\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3142 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 4.1699\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2777 - val_loss: 0.1126 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6914\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2564 - val_loss: 0.1148 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 4.0755\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3247 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 4.0983\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3071 - val_loss: 0.1132 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.8281\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3308 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.9193\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2751 - val_loss: 0.1138 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.9421\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2905 - val_loss: 0.1144 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.4993\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2528 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8021\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2049 - val_loss: 0.1129 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.8314\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1079 - auc: 0.9905 - accuracy: 0.9695 - cost: 3.7594\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:50.850991\n",
            "fold accuracy: 0.9695000052452087 - fold cost: 3.7593750953674316\n",
            "total train/predict time: 0:21:54.263216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m5_results = fold_results"
      ],
      "metadata": {
        "id": "h8ySkCi9mPHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m5 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m5[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "\n",
        "m5_cost = cost_func(y,preds_m5)\n",
        "m5_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkrG6or3mRV4",
        "outputId": "b977bd6d-06c2-4571-955d-d88ffe938011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "581950"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new5 = np.zeros(len(y))\n",
        "for i in m5_results.keys():\n",
        "  for j in range(len(m5_results.get(i).get('predictions'))):\n",
        "    idx = m5_results.get(i).get('index')[j]\n",
        "    if m5_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new5[idx] = 1\n",
        "    else:\n",
        "      preds_new5[idx] = 0\n",
        "\n",
        "m5_cost_t = cost_func(y,preds_new5)\n",
        "m5_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YGSE-MSmS5Q",
        "outputId": "4365aa00-2d8a-4733-baed-b1e8abd3456b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "571900"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xhEJqvbmWkK",
        "outputId": "36dc6633-ac03-4551-d7db-81db85649aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4480      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,705\n",
            "Trainable params: 8,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.save('model5.keras')"
      ],
      "metadata": {
        "id": "bmq9o4ehJjIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "y_alt = pd.DataFrame()\n",
        "\n",
        "#one hot encoding categorical variables for model\n",
        "cols = df.columns\n",
        "num_cols = df._get_numeric_data().columns\n",
        "cat_cols = list((set(cols) - set(num_cols)))\n",
        "\n",
        "#creating dataframe of categorical columns\n",
        "cat_df = df[cat_cols]\n",
        "cat_df = pd.get_dummies(cat_df, columns=cat_df.columns,sparse=True)\n",
        "cat_df\n",
        "\n",
        "y_alt['Volume_high']= cat_df['Volume_high']\n",
        "y_alt['preds_m1']=preds_m1\n",
        "y_alt['preds_m2']=preds_m2\n",
        "y_alt['preds_m3']=preds_m3\n",
        "y_alt['preds_m4']=preds_m4\n",
        "y_alt['preds_m5']=preds_m5\n",
        "\n",
        "y_alt['preds_new4']=preds_new4\n",
        "y_alt['preds_new5']=preds_new5\n",
        "\n",
        "\n",
        "y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n",
        "files.download('results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "OK8IPut_IfuM",
        "outputId": "c11792f6-6b06-41d7-f4f0-733599438ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-129-e030d734e541>:26: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
            "  y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1973f4bc-2894-419c-b485-b98c81f96dc5\", \"results.csv\", 5168973)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_alt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zPmhthDgm1OQ",
        "outputId": "0d80090e-73e4-41c5-db56-f380f0af98b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Volume_high  preds_m1  preds_m2  preds_m3  preds_m4  preds_m5  \\\n",
              "0                 1         0         0       0.0       0.0       0.0   \n",
              "1                 1         1         0       0.0       0.0       0.0   \n",
              "2                 1         0         0       0.0       0.0       0.0   \n",
              "3                 1         1         1       1.0       0.0       0.0   \n",
              "4                 1         1         1       1.0       1.0       1.0   \n",
              "...             ...       ...       ...       ...       ...       ...   \n",
              "159995            1         1         1       1.0       1.0       1.0   \n",
              "159996            1         0         0       0.0       0.0       0.0   \n",
              "159997            1         1         0       0.0       0.0       0.0   \n",
              "159998            1         0         0       0.0       0.0       0.0   \n",
              "159999            1         0         1       1.0       1.0       1.0   \n",
              "\n",
              "        preds_new4  preds_new5  \n",
              "0              0.0         0.0  \n",
              "1              0.0         0.0  \n",
              "2              0.0         0.0  \n",
              "3              0.0         0.0  \n",
              "4              1.0         1.0  \n",
              "...            ...         ...  \n",
              "159995         1.0         1.0  \n",
              "159996         0.0         0.0  \n",
              "159997         0.0         0.0  \n",
              "159998         0.0         0.0  \n",
              "159999         1.0         1.0  \n",
              "\n",
              "[160000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-46857298-dac1-49e6-b3aa-5b98db247ea2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Volume_high</th>\n",
              "      <th>preds_m1</th>\n",
              "      <th>preds_m2</th>\n",
              "      <th>preds_m3</th>\n",
              "      <th>preds_m4</th>\n",
              "      <th>preds_m5</th>\n",
              "      <th>preds_new4</th>\n",
              "      <th>preds_new5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159995</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159997</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160000 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46857298-dac1-49e6-b3aa-5b98db247ea2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b94e425e-803c-4530-8112-7ae952694255\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b94e425e-803c-4530-8112-7ae952694255')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b94e425e-803c-4530-8112-7ae952694255 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46857298-dac1-49e6-b3aa-5b98db247ea2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46857298-dac1-49e6-b3aa-5b98db247ea2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "OGDgxEMEAh0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix of Results\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cm_preds_m1 = confusion_matrix(y,preds_m1)\n",
        "cm_preds_m2 = confusion_matrix(y,preds_m2)\n",
        "cm_preds_m3 = confusion_matrix(y,preds_m3)\n",
        "cm_preds_m4 = confusion_matrix(y,preds_new4)\n",
        "cm_preds_m5 = confusion_matrix(y,preds_new5)\n",
        "\n",
        "fig, ax = plt.subplots(1,5,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_m1).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Logistic Regression'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m1:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(cm_preds_m2).plot(ax= ax[1],cmap='Blues', colorbar=False)\n",
        "ax[1].set_title('Random Forest'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m2:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "\n",
        "disp3 = ConfusionMatrixDisplay(cm_preds_m3).plot(ax= ax[2],cmap='Blues', colorbar=False)\n",
        "ax[2].set_title('XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m3_cost:,}'), fontsize = 12)\n",
        "ax[2].grid(False)\n",
        "\n",
        "disp4 = ConfusionMatrixDisplay(cm_preds_m4).plot(ax= ax[3],cmap='Blues', colorbar=False)\n",
        "ax[3].set_title('Neural Network 1'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m4_cost_t:,}'), fontsize = 12)\n",
        "ax[3].grid(False)\n",
        "\n",
        "disp5 = ConfusionMatrixDisplay(cm_preds_m5).plot(ax= ax[4],cmap='Blues', colorbar=False)\n",
        "ax[4].set_title('Neural Network 2'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m5_cost_t:,}'), fontsize = 12)\n",
        "ax[4].grid(False)\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hYPzNzlQ36Ct",
        "outputId": "0f8ce5de-cbc6-48ab-bfa9-cbd1eb226eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensembling"
      ],
      "metadata": {
        "id": "lV6Za3-7SvNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "y_alt = pd.DataFrame()\n",
        "\n",
        "#one hot encoding categorical variables for model\n",
        "cols = df.columns\n",
        "num_cols = df._get_numeric_data().columns\n",
        "cat_cols = list((set(cols) - set(num_cols)))\n",
        "\n",
        "#creating dataframe of categorical columns\n",
        "cat_df = df[cat_cols]\n",
        "cat_df = pd.get_dummies(cat_df, columns=cat_df.columns,sparse=True)\n",
        "cat_df\n",
        "\n",
        "y_alt['Volume_high']= cat_df['Volume_high']\n",
        "y_alt['preds_m1']=preds_m1\n",
        "y_alt['preds_m2']=preds_m2\n",
        "y_alt['preds_m3']=preds_m3\n",
        "y_alt['preds_m4']=preds_m4\n",
        "y_alt['preds_m5']=preds_m5\n",
        "\n",
        "y_alt['preds_new4']=preds_new4\n",
        "y_alt['preds_new5']=preds_new5\n",
        "\n",
        "\n",
        "y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n",
        "files.download('results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "b_ZaQ5xy21Pt",
        "outputId": "4ae7b3e9-9e0d-4d8a-c83e-2b01c2efc0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-191-10daa75af518>:26: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
            "  y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fb64e672-eff1-4e39-a112-e15cabe3c112\", \"results.csv\", 5168973)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['y'].values.flatten()\n",
        "skf = StratifiedKFold(n_splits=10,random_state=807,shuffle=True)\n",
        "skf.get_n_splits(y_alt,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch4fk9aA3Uzs",
        "outputId": "e1a31360-ab72-4580-89c7-c6ae6bae1d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensembling\n",
        "logR_ens = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "lr_clf_ens = GridSearchCV(estimator=logR_ens,param_grid=params,n_jobs=-1,cv=skf)\n",
        "lr_clf_ens.fit(y_alt,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "vElSNV8QmkMa",
        "outputId": "084a5601-94fa-4522-fd8f-005daf04d3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight='balanced',\n",
              "                                          penalty='elasticnet',\n",
              "                                          random_state=807, solver='saga'),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
              "                         'l1_ratio': [0, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
              "                                      0.99, 1],\n",
              "                         'max_iter': [25, 50, 75]})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                          penalty=&#x27;elasticnet&#x27;,\n",
              "                                          random_state=807, solver=&#x27;saga&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;C&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
              "                         &#x27;l1_ratio&#x27;: [0, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
              "                                      0.99, 1],\n",
              "                         &#x27;max_iter&#x27;: [25, 50, 75]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                          penalty=&#x27;elasticnet&#x27;,\n",
              "                                          random_state=807, solver=&#x27;saga&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;C&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
              "                         &#x27;l1_ratio&#x27;: [0, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
              "                                      0.99, 1],\n",
              "                         &#x27;max_iter&#x27;: [25, 50, 75]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=&#x27;elasticnet&#x27;,\n",
              "                   random_state=807, solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=&#x27;elasticnet&#x27;,\n",
              "                   random_state=807, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params_ens = lr_clf_ens.best_params_"
      ],
      "metadata": {
        "id": "J6RZiEvlpCh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1ens = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1ens.set_params(**lr_params_ens)\n",
        "model1ens.fit(y_alt,y)\n",
        "skf.get_n_splits(y_alt,y)\n",
        "preds_ens2 = cross_val_predict(model1ens, y_alt,y,cv=skf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAtJAtyrot_t",
        "outputId": "82b655b6-4799-40a2-b9ac-9baf5120bc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensembling\n",
        "cost_ens_log = cost_func(np.round(preds_ens2, 0), y)\n",
        "cm_preds_ens_log = confusion_matrix(y,np.round(preds_ens2, 0))"
      ],
      "metadata": {
        "id": "bca2bRquon1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination of Neural Networks\n",
        "preds_nn = (preds_new4+ preds_new5)/2\n",
        "cost_nn= cost_func(np.round(preds_nn, 0), y)\n",
        "cm_preds_nn = confusion_matrix(y,np.round(preds_nn, 0))\n",
        "\n",
        "#Combination of Neural Networks and XGBoost\n",
        "preds_ens = (preds_new4+ preds_new5+preds_new3 )/3\n",
        "cost_ens = cost_func(np.round(preds_ens, 0), y)\n",
        "cm_preds_ens = confusion_matrix(y,np.round(preds_ens, 0))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2oJ4cy59VAFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,3,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_nn).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Combined Neural Networks'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_nn:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(cm_preds_ens).plot(ax = ax[1],cmap = 'Blues', colorbar=False)\n",
        "ax[1].set_title('Neural Networks and XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "disp3 = ConfusionMatrixDisplay(cm_preds_ens_log).plot(ax = ax[2],cmap = 'Blues', colorbar=False)\n",
        "ax[2].set_title('Ensemble from all Predictions'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens_log:,}'), fontsize = 12)\n",
        "ax[2].grid(False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "J71VGqBYU7hF",
        "outputId": "c5c08171-16c6-4722-d2ac-6b3d90481d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_alt['preds_nn']=preds_nn\n",
        "y_alt['preds_ens']=preds_ens\n",
        "y_alt['preds_ens2']=preds_ens2\n",
        "\n",
        "\n",
        "y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n",
        "files.download('results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "rUY2fsGRwGLf",
        "outputId": "78977f8a-e4c6-4526-e726-77ed79c836b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-174-f5d109dfe8d8>:6: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
            "  y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_358007fe-b3e1-403c-b2d2-c136dd0cfb11\", \"results.csv\", 6776923)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}