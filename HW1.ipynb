{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14d1978-f2ad-44da-a6d8-4877173d11d1",
   "metadata": {},
   "source": [
    "# NLP - Homework 1\n",
    "### Miguel Bonilla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba10752-37c6-4cd6-aa36-6849680aad21",
   "metadata": {},
   "source": [
    "* [Lexical Diversity Score](#Lexical-Diversity-Score)\n",
    "* [Vocabulary Size](#Vocabulary-Size)\n",
    "* [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe79ed2-928f-4aa5-b2da-7a4431871894",
   "metadata": {},
   "source": [
    "1. Install Python (if you don’t have it already) and install NLTK.  \n",
    "2. Follow the instructions in chapter 1 of Bird-Klein for implementing a “lexical diversity” scoring \n",
    "routine.\n",
    "3. Go to http://www.gutenberg.org/ebooks/bookshelf/215  and select texts of different grade levels \n",
    "(e.g., fourth reader, fifth reader et al)\n",
    "Report the lexical diversity score of each. Explain whether the result was surprising.\n",
    "4. Also compare the vocabulary size of the same three texts. Explain whether the result was \n",
    "surprising.  \n",
    "5. Write a paragraph arguing whether vocabulary size and lexical diversity in combination could be \n",
    "a better measure of text difficulty (or reading level) than either measure is by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b688e48e-ea1a-4390-8b32-a8aa2c460585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51634f3f-6bfd-44e5-9f61-613ffa2ea8fe",
   "metadata": {},
   "source": [
    "- First Reader https://www.gutenberg.org/cache/epub/14640/pg14640.txt\n",
    "- Second Reader https://www.gutenberg.org/cache/epub/14668/pg14668.txt\n",
    "- Third Reader https://www.gutenberg.org/cache/epub/14766/pg14766.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873fce82-9fb1-4ac5-b83e-5e54347a7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "url1 = \"https://www.gutenberg.org/cache/epub/14640/pg14640.txt\" #first reader url\n",
    "url2 = \"https://www.gutenberg.org/cache/epub/14668/pg14668.txt\" #second reader url\n",
    "url3 = \"https://www.gutenberg.org/cache/epub/14766/pg14766.txt\" #third reader url\n",
    "\n",
    "#import books\n",
    "text1 = request.urlopen(url1).read().decode('utf8')\n",
    "text2 = request.urlopen(url2).read().decode('utf8')\n",
    "text3 = request.urlopen(url3).read().decode('utf8')\n",
    "\n",
    "# tokenize books by words\n",
    "text1 = word_tokenize(text1)\n",
    "text2 = word_tokenize(text2)\n",
    "text3 = word_tokenize(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b829a806-9910-469d-a2db-0dd9690d7cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning of text 1 is:  1125\n",
      "end of text 1 is:  9335\n",
      "beginning of text 2 is:  1500\n",
      "end of text 2 is:  22004\n",
      "beginning of text 3 is:  2116\n",
      "end of text 3 is:  34675\n"
     ]
    }
   ],
   "source": [
    "## text 1 find beginning and end\n",
    "print('beginning of text 1 is: ',text1.index('LESSON')) #beginning\n",
    "print('end of text 1 is: ',text1.index('PHONIC')-1) #end\n",
    "## text 2 find beginning and end\n",
    "print('beginning of text 2 is: ',text2.index('LESSON')) #beginning\n",
    "print('end of text 2 is: ',text2.index('Tennyson')) #end\n",
    "## text 3 find beginning and end\n",
    "print('beginning of text 3 is: ',text3.index('SHEPHERD')-4) #beginning\n",
    "print('end of text 3 is: ',text3.index('Follen')) #end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051036e0-9ab8-4312-ba06-29e239d4a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "## trim texts removing beginning and end fluff\n",
    "text1 = text1[1125:9335]\n",
    "text2 = text2[1500:22004]\n",
    "text3 = text3[2116:34675]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249bb07-31d4-4dd2-9a43-920e0876ae08",
   "metadata": {},
   "source": [
    "## Lexical Diversity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab17d9d-6650-4137-adde-7c48167821cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define lexical_diversity (from textbook example)\n",
    "def lexical_diversity(text):\n",
    "    return(len(set(text))/len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e2da58d-c540-4ebc-8428-de53ffb7b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the lexical diversity scores for the 3 books\n",
    "ld1 = lexical_diversity(text1)\n",
    "ld2 = lexical_diversity(text2)\n",
    "ld3 = lexical_diversity(text3)\n",
    "# calculate text length\n",
    "length1 = len(text1)\n",
    "length2 = len(text2)\n",
    "length3 = len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bac91b89-6020-4f68-a75b-e9964f3db7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Reader \n",
      " length: 8210 | lexical diversity: 0.14165651644336175\n",
      "--------------------------------\n",
      "Second Reader \n",
      " length: 20504 | lexical diversity: 0.1472395630120952\n",
      "--------------------------------\n",
      "Third Reader \n",
      " length: 32559 | lexical diversity: 0.11701833594397862\n"
     ]
    }
   ],
   "source": [
    "print(f'First Reader \\n length: {length1} | lexical diversity: {ld1}')\n",
    "print('--------------------------------')\n",
    "print(f'Second Reader \\n length: {length2} | lexical diversity: {ld2}')\n",
    "print('--------------------------------')\n",
    "print(f'Third Reader \\n length: {length3} | lexical diversity: {ld3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb5f88-f555-4915-acac-c7eaeee00ce2",
   "metadata": {},
   "source": [
    "We see that Third Reader has the lowest lexical diversity score of the three, this is a little surprising, however, it should be noted that the text has significantly longer length than Second and First Reader. Considering the fact that the books have singificantly different lengths, the lexical diversity scores might not be a great direct comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9beeca6-a721-4816-829c-19e25b5c751f",
   "metadata": {},
   "source": [
    "## Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b3edef8-454e-4acc-b500-d69fdadb8e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate vocabulary size of the 3 texts\n",
    "vs1 = len(set(w.lower() for w in text1))\n",
    "vs2 = len(set(w.lower() for w in text2))\n",
    "vs3 = len(set(w.lower() for w in text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28f563ef-5ef6-4cd3-9289-6d32214e6400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Reader \n",
      " length: 8210 | vocabulary size: 1041\n",
      "--------------------------------\n",
      "First Reader \n",
      " length: 20504 | vocabulary size: 2626\n",
      "--------------------------------\n",
      "First Reader \n",
      " length: 32559 | vocabulary size: 3397\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'First Reader \\n length: {length1} | vocabulary size: {vs1}')\n",
    "print('--------------------------------')\n",
    "print(f'First Reader \\n length: {length2} | vocabulary size: {vs2}')\n",
    "print('--------------------------------')\n",
    "print(f'First Reader \\n length: {length3} | vocabulary size: {vs3}')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e935a43-b39a-4b51-a32d-ef94472a59d1",
   "metadata": {},
   "source": [
    "The results are not suprirising, the vocabulary sizes increase signficantly from one book level to the next. With a more than double jump from First Reader to Second Reader (152% increase in vocabulary size), and a close to one third increase from Second Reader to Third Reader (29% increase in vocabulary size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f47aef-29a7-4dc0-89c3-94b78215c728",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f31664-53ee-410b-b2c8-e4d009d1fac5",
   "metadata": {},
   "source": [
    "Book | Length | Vocabulary Size | Lexical Diversity\n",
    "-----|--------|---------|---------\n",
    "First Reader | 8210 | 1041 | .1417\n",
    "Second Reader | 20504 | 2626 | .1472\n",
    "Third Reader | 32559 | 3397 | .1170"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c66a22-e718-4d98-8acb-bde7e749b293",
   "metadata": {},
   "source": [
    "As previously mentioned, it seems like comparing lexical diversity scores when the texts have significantly different lengths produces misleading results in terms of analyzing text difficulty, since the Lexical Diversity score is a measure of the unique words divided by the total number of words. Though the vocabulary size increased for each subsequent level, the vocabulary size increase from second to third reader was not as large in comparison to the increase in word length of the text, leading to a comparatively lower lexical diversity score.\n",
    "\n",
    "Therefore, lexical diversity alone, is not a good measure of text difficulty. Additionally, vocabulary size alone would not be a great measure of text difficulty, since potentially there could be a text with a higher vocabulary size but lower word count.\n",
    "\n",
    "When analyzing text difficulty, it is probably better to look at both Lexical Diversity Score in conjunction with Vocabulary Size, since a text with both higher vocabulary size and higher word count can produce a lower Lexical Diversity score (given that the incresae in vocabulary size is overshadowed by the increase in word length)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
